{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "285add75",
   "metadata": {},
   "source": [
    "# Recalcule Creance pour toute les entreprises Comparaison Calcule vs Non Calcule (2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbe4a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total d'entreprises: 4,493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\1750787560.py:879: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fichier de comparaison détaillée créé: M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB\\Calcul_Creance_CIR_2021.csv\n",
      "\n",
      "===== COMPARAISON CIR DÉCLARÉ VS RECALCULÉ 2021 =====\n",
      "\n",
      "Nombre total d'entreprises analysées: 4,493\n",
      "Nombre d'entreprises avec CIR déclaré: 1,435\n",
      "Nombre d'entreprises avec dépenses > 100M€: 3\n",
      "\n",
      "CIR TOTAL:\n",
      "CIR déclaré total: 470,488,283.00 €\n",
      "CIR recalculé total: 453,725,388.33 €\n",
      "Différence: -16,762,894.67 €\n",
      "Écart relatif: -3.56%\n",
      "\n",
      "ANALYSE DES ÉCARTS:\n",
      "Entreprises avec CIR conforme (écart ≤ 1€): 3,073 (68.40%)\n",
      "Entreprises avec CIR recalculé > CIR déclaré (écart > 1€): 839\n",
      "Montant total des écarts positifs: 43,788,357.41 €\n",
      "Entreprises avec CIR recalculé < CIR déclaré (écart < -1€): 581\n",
      "Montant total des écarts négatifs: -60,551,253.01 €\n",
      "\n",
      "DÉTAIL PAR COMPOSANTE DU CIR RECALCULÉ:\n",
      "CIR Recherche: 414,591,903.05 €\n",
      "CIR Collection: 1,544,332.70 €\n",
      "CIR Innovation: 37,589,152.58 €\n",
      "\n",
      "Traitement terminé avec succès!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Charger les données\n",
    "df = pd.read_excel(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//output//output_parquet//new_millesime_CIR_2021_corrected_sans_doublon.xlsx\")\n",
    "\n",
    "def convertir_en_nombre(valeur, defaut=0):\n",
    "    \"\"\"Convertit une valeur en nombre de façon sécurisée\"\"\"\n",
    "    if pd.isna(valeur) or valeur == '' or valeur is None:\n",
    "        return defaut\n",
    "    try:\n",
    "        return float(valeur)\n",
    "    except:\n",
    "        return defaut\n",
    "\n",
    "def comparer_cir_declare_recalcule_2021():\n",
    "    \"\"\"Compare le CIR déclaré et le CIR recalculé pour 2021\n",
    "    Note: Toutes les quote-parts sont mises à 0 (pas de prise en compte des sociétés de personnes)\"\"\"\n",
    "    print(f\"Nombre total d'entreprises: {len(df):,}\")\n",
    "\n",
    "    # Colonnes nécessaires pour recalculer le CIR 2021\n",
    "    colonnes = [\n",
    "        'siren_declarant', 'siren_deposant', 'DESIGN', 'COMPLT_DESIGN',\n",
    "        'MT_NET_DEP_RD', 'MT_NET_DEP_RD_DOM', 'MT_TOT_CIR_CI_COLL_CII',\n",
    "        'MT_CIR_RECH_YC_QP', 'MT_CI_COLL_APRS_MINIMI', 'MT_CII_YC_QP',\n",
    "        'DOT_AMORT_IMMO', 'DOT_AMORT_IMMO_SINISTR', 'DEP_CHERCH_TECH', 'REM_SAL_INV',\n",
    "        'DEP_JD', 'OTR_DEP_FONCT', 'FRAIS_BREV_COV', 'DEP_MAINT_BREV_COV',\n",
    "        'DOT_AMORT_BREV', 'DEP_NORMALI', 'PRIM_COTIZ', 'DEP_VEIL_TECHNO',\n",
    "        'MT_DEP_FONCT_TOT', 'MT_TOT_RD_1',\n",
    "        # Sous-traitance organismes publics\n",
    "        'DEP_ST_ORG_PUB_LIE_FR', 'DEP_ST_ORG_PUB_LIE_ETR', \n",
    "        'DEP_ST_ORG_PUB_NON_LIE_FR', 'DEP_ST_ORG_PUB_NON_LIE_ETR',\n",
    "        'MT_TOT_ST_ORG_PUB',\n",
    "        # Sous-traitance organismes privés\n",
    "        'DEP_ST_ORG_PRIV_LIE_FR', 'DEP_ST_ORG_PRIV_LIE_ETR',\n",
    "        'DEP_ST_ORG_PRIV_NON_LIE_FR', 'DEP_ST_ORG_PRIV_NON_LIE_ETR',\n",
    "        'MT_TOT_ST_ORG_PRIV', 'PLAF_ST_ORG_PRIV', 'MT_TOT_ST', \n",
    "        'PLAF_ST_ORG_LIE', 'MT_ST_ORG_NON_LIE_PLAF', 'PLAF_GNRL_ST', 'MT_TOT_ST_PLAF',\n",
    "        'MT_TOT_RD_2',\n",
    "        'MT_AID_SUBV', 'MT_ENC_PRESTA', 'MT_DEP_CONSEILS_CIR', 'REMBST_SUBV',\n",
    "        'FRAIS_COLL', 'FRAIS_DEF_DESSIN', 'MT_TOT_DEP_COLL', 'MT_AID_SUBV_COLL',\n",
    "        'MT_DEP_CONSEILS_CIR_COLL', 'REMBST_SUBV_COLL', 'MT_NET_DEP_COLL', 'MT_NET_DEP_COLL_DOM',\n",
    "        'DOT_AMORT_IMMO_INO', 'DEP_PERSONEL_INO', 'OTR_DEP_FONCT_INO',\n",
    "        'FRAIS_BREV_COV_INO', 'FRAIS_DEF_BREV_INO', 'OP_INOV_EXT', \n",
    "        'MT_TOT_DEP_INO', 'MT_TOT_DEP_INO_PLAF',\n",
    "        'MT_AID_SUBV_INO', 'MT_ENC_PRESTA_INO', 'MT_DEP_CONSEILS_CII', 'REMBST_SUBV_INO',\n",
    "        'MT_NET_DEP_INO', 'MT_NET_DEP_INO_DOM', 'MT_NET_DEP_INO_MPE_CORSE', 'MT_NET_DEP_INO_ME_CORSE',\n",
    "        'MT_QP_CIR_RECU', 'MT_QP_COLL_RECU', 'MT_QP_CII_RECU', 'MT_AIDE_MINIMI'\n",
    "    ]\n",
    "\n",
    "    # Convertir en numérique et créer une copie défragmentée\n",
    "    df_tmp = df.copy()\n",
    "    for col in colonnes:\n",
    "        if col in df_tmp.columns:\n",
    "            if col not in ['siren_declarant', 'siren_deposant', 'DESIGN', 'COMPLT_DESIGN']:\n",
    "                df_tmp[col] = df_tmp[col].apply(convertir_en_nombre)\n",
    "        else:\n",
    "            if col not in ['siren_declarant', 'siren_deposant', 'DESIGN', 'COMPLT_DESIGN']:\n",
    "                df_tmp[col] = 0\n",
    "\n",
    "    # Créer un dictionnaire pour stocker toutes les colonnes calculées\n",
    "    calc_columns = {}\n",
    "\n",
    "    ## I - DÉPENSES DE RECHERCHE OUVRANT DROIT AU CRÉDIT D'IMPÔT \n",
    "    ## ANNÉE CIVILE 2021\n",
    "\n",
    "    # 1. Dépenses internes\n",
    "\n",
    "    # Ligne 6: Autres dépenses de fonctionnement\n",
    "    calc_columns['LIGNE_6_CALC'] = (df_tmp['DOT_AMORT_IMMO'] * 0.75) + \\\n",
    "                               ((df_tmp['DEP_CHERCH_TECH'] + df_tmp['REM_SAL_INV']) * 0.43) + \\\n",
    "                               df_tmp['DEP_JD']\n",
    "\n",
    "    # Ligne 7: Total dépenses de fonctionnement\n",
    "    calc_columns['LIGNE_7_CALC'] = df_tmp['DOT_AMORT_IMMO'] + df_tmp['DOT_AMORT_IMMO_SINISTR'] + \\\n",
    "                               df_tmp['DEP_CHERCH_TECH'] + df_tmp['REM_SAL_INV'] + \\\n",
    "                               df_tmp['DEP_JD'] + calc_columns['LIGNE_6_CALC']\n",
    "\n",
    "    # Appliquer les plafonds pour les lignes concernées\n",
    "    # Ligne 11: Dépenses liées à la normalisation (déjà à 50% dans la déclaration)\n",
    "    calc_columns['DEP_NORMALI_RECALC'] = df_tmp['DEP_NORMALI']\n",
    "\n",
    "    # Ligne 12: Primes et cotisations (plafond 60 000 €)\n",
    "    calc_columns['PRIM_COTIZ_PLAFONNEES'] = np.minimum(df_tmp['PRIM_COTIZ'], 60000)\n",
    "\n",
    "    # Ligne 13: Dépenses de veille technologique (plafond 60 000 €)\n",
    "    calc_columns['DEP_VEIL_TECHNO_PLAFONNEES'] = np.minimum(df_tmp['DEP_VEIL_TECHNO'], 60000)\n",
    "\n",
    "    # Ligne 14: Total dépenses internes avec plafonds appliqués\n",
    "    calc_columns['LIGNE_14_CALC'] = calc_columns['LIGNE_7_CALC'] + df_tmp['FRAIS_BREV_COV'] + \\\n",
    "                                df_tmp['DEP_MAINT_BREV_COV'] + df_tmp['DOT_AMORT_BREV'] + \\\n",
    "                                calc_columns['DEP_NORMALI_RECALC'] + calc_columns['PRIM_COTIZ_PLAFONNEES'] + \\\n",
    "                                calc_columns['DEP_VEIL_TECHNO_PLAFONNEES']\n",
    "\n",
    "    # 2. Dépenses de sous-traitance\n",
    "\n",
    "    # Ligne 17: Total opérations confiées aux organismes publics (avec doublement pour non liés)\n",
    "    calc_columns['LIGNE_17_CALC'] = df_tmp['DEP_ST_ORG_PUB_LIE_FR'] + df_tmp['DEP_ST_ORG_PUB_LIE_ETR'] + \\\n",
    "                                df_tmp['DEP_ST_ORG_PUB_NON_LIE_FR'] + df_tmp['DEP_ST_ORG_PUB_NON_LIE_ETR']\n",
    "\n",
    "    # Ligne 20: Total opérations confiées aux organismes privés\n",
    "    calc_columns['LIGNE_20_CALC'] = df_tmp['DEP_ST_ORG_PRIV_LIE_FR'] + df_tmp['DEP_ST_ORG_PRIV_LIE_ETR'] + \\\n",
    "                                df_tmp['DEP_ST_ORG_PRIV_NON_LIE_FR'] + df_tmp['DEP_ST_ORG_PRIV_NON_LIE_ETR']\n",
    "\n",
    "    # Préparation pour les calculs complexes\n",
    "    df_calc = pd.DataFrame(calc_columns)\n",
    "    df_calc_temp = pd.concat([df_tmp, df_calc], axis=1)\n",
    "\n",
    "    # Ligne 21: Plafonnement des opérations privées (3x dépenses internes + publiques)\n",
    "    calc_columns['LIGNE_21_CALC'] = np.minimum(df_calc_temp['LIGNE_20_CALC'], \n",
    "                                            (df_calc_temp['LIGNE_14_CALC'] + df_calc_temp['LIGNE_17_CALC']) * 3)\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_21_CALC'] = calc_columns['LIGNE_21_CALC']\n",
    "\n",
    "    # Ligne 22: Total des opérations de sous-traitance\n",
    "    calc_columns['LIGNE_22_CALC'] = df_calc_temp['LIGNE_17_CALC'] + df_calc_temp['LIGNE_21_CALC']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_22_CALC'] = calc_columns['LIGNE_22_CALC']\n",
    "\n",
    "    # Ligne 23: Plafonnement organismes liés (2M€)\n",
    "    ligne_23_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        dep_liees_pub = row['DEP_ST_ORG_PUB_LIE_FR'] + row['DEP_ST_ORG_PUB_LIE_ETR']\n",
    "        dep_liees_priv = row['DEP_ST_ORG_PRIV_LIE_FR'] + row['DEP_ST_ORG_PRIV_LIE_ETR']\n",
    "        # Pour les privés, prendre seulement la part dans la limite de ligne 21\n",
    "        dep_priv_plafonnees = min(row['DEP_ST_ORG_PRIV_LIE_FR'] + row['DEP_ST_ORG_PRIV_LIE_ETR'], \n",
    "                                 row['LIGNE_21_CALC'])\n",
    "        total_liees = dep_liees_pub + dep_priv_plafonnees\n",
    "        ligne_23_values.append(min(total_liees, 2000000))\n",
    "    calc_columns['LIGNE_23_CALC'] = np.array(ligne_23_values)\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_23_CALC'] = calc_columns['LIGNE_23_CALC']\n",
    "\n",
    "    # Ligne 24: Montant plafonné organismes non liés\n",
    "    ligne_24_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        dep_non_liees_pub = row['DEP_ST_ORG_PUB_NON_LIE_FR'] + row['DEP_ST_ORG_PUB_NON_LIE_ETR']\n",
    "        dep_non_liees_priv = row['DEP_ST_ORG_PRIV_NON_LIE_FR'] + row['DEP_ST_ORG_PRIV_NON_LIE_ETR']\n",
    "        total_non_liees = dep_non_liees_pub + dep_non_liees_priv\n",
    "        plafond_restant = row['LIGNE_22_CALC'] - row['LIGNE_23_CALC']\n",
    "        ligne_24_values.append(min(total_non_liees, plafond_restant))\n",
    "    calc_columns['LIGNE_24_CALC'] = np.array(ligne_24_values)\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_24_CALC'] = calc_columns['LIGNE_24_CALC']\n",
    "\n",
    "    # Ligne 25: Plafonnement général\n",
    "    ligne_25_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        # Vérifier quelles lignes sont remplies pour déterminer le plafond\n",
    "        has_liees = (row['DEP_ST_ORG_PUB_LIE_FR'] + row['DEP_ST_ORG_PUB_LIE_ETR'] +\n",
    "                    row['DEP_ST_ORG_PRIV_LIE_FR'] + row['DEP_ST_ORG_PRIV_LIE_ETR']) > 0\n",
    "        has_non_liees_priv = (row['DEP_ST_ORG_PRIV_NON_LIE_FR'] + row['DEP_ST_ORG_PRIV_NON_LIE_ETR']) > 0\n",
    "        has_non_liees_pub = (row['DEP_ST_ORG_PUB_NON_LIE_FR'] + row['DEP_ST_ORG_PUB_NON_LIE_ETR']) > 0\n",
    "        \n",
    "        if has_liees and not has_non_liees_priv and not has_non_liees_pub:\n",
    "            # Seules les opérations liées\n",
    "            ligne_25_values.append(2000000)\n",
    "        elif has_liees and has_non_liees_priv and not has_non_liees_pub:\n",
    "            # Liées + non liées privées\n",
    "            ligne_25_values.append(10000000)\n",
    "        elif has_liees and has_non_liees_priv and has_non_liees_pub:\n",
    "            # Toutes les catégories\n",
    "            pub_non_liees = row['DEP_ST_ORG_PUB_NON_LIE_FR'] + row['DEP_ST_ORG_PUB_NON_LIE_ETR']\n",
    "            ligne_25_values.append(10000000 + min(pub_non_liees, 2000000))\n",
    "        else:\n",
    "            ligne_25_values.append(10000000)  # Par défaut\n",
    "    calc_columns['LIGNE_25_CALC'] = np.array(ligne_25_values)\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_25_CALC'] = calc_columns['LIGNE_25_CALC']\n",
    "\n",
    "    # Ligne 26: Total des dépenses de sous-traitance après plafonnements\n",
    "    ligne_26_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        total_avant_plaf = row['LIGNE_23_CALC'] + row['LIGNE_24_CALC']\n",
    "        ligne_26_values.append(min(total_avant_plaf, row['LIGNE_25_CALC']))\n",
    "    calc_columns['LIGNE_26_CALC'] = np.array(ligne_26_values)\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_26_CALC'] = calc_columns['LIGNE_26_CALC']\n",
    "\n",
    "    # 3. Montant total des dépenses de recherche\n",
    "\n",
    "    # Ligne 27: Total dépenses recherche\n",
    "    calc_columns['LIGNE_27_CALC'] = df_calc_temp['LIGNE_14_CALC'] + df_calc_temp['LIGNE_26_CALC']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_27_CALC'] = calc_columns['LIGNE_27_CALC']\n",
    "\n",
    "    # Ligne 31a: Montant net total des dépenses de recherche\n",
    "    calc_columns['LIGNE_31A_CALC'] = df_calc_temp['LIGNE_27_CALC'] - df_tmp['MT_AID_SUBV'] - \\\n",
    "                                  df_tmp['MT_ENC_PRESTA'] - df_tmp['MT_DEP_CONSEILS_CIR'] + \\\n",
    "                                  df_tmp['REMBST_SUBV']\n",
    "\n",
    "    # Ligne 31b: Utiliser la valeur de MT_NET_DEP_RD_DOM directement\n",
    "    calc_columns['LIGNE_31B_CALC'] = df_tmp['MT_NET_DEP_RD_DOM']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_31A_CALC'] = calc_columns['LIGNE_31A_CALC']\n",
    "    df_calc_temp['LIGNE_31B_CALC'] = calc_columns['LIGNE_31B_CALC']\n",
    "\n",
    "    ## II - DÉPENSES DE COLLECTION OUVRANT DROIT AU CRÉDIT D'IMPÔT\n",
    "    ## ANNÉE CIVILE 2021\n",
    "\n",
    "    # Ligne 33: Frais de défense des dessins et modèles (plafond 60 000 €)\n",
    "    calc_columns['FRAIS_DEF_DESSIN_PLAFONNES'] = np.minimum(df_tmp['FRAIS_DEF_DESSIN'], 60000)\n",
    "\n",
    "    # Ligne 34: Total des dépenses de collection\n",
    "    calc_columns['LIGNE_34_CALC'] = df_tmp['FRAIS_COLL'] + calc_columns['FRAIS_DEF_DESSIN_PLAFONNES']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_34_CALC'] = calc_columns['LIGNE_34_CALC']\n",
    "\n",
    "    # Ligne 38a: Montant net des dépenses de collection\n",
    "    calc_columns['LIGNE_38A_CALC'] = df_calc_temp['LIGNE_34_CALC'] - df_tmp['MT_AID_SUBV_COLL'] - \\\n",
    "                                  df_tmp['MT_DEP_CONSEILS_CIR_COLL'] + df_tmp['REMBST_SUBV_COLL']\n",
    "\n",
    "    # Ligne 38b: Utiliser la valeur de MT_NET_DEP_COLL_DOM directement\n",
    "    calc_columns['LIGNE_38B_CALC'] = df_tmp['MT_NET_DEP_COLL_DOM']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_38A_CALC'] = calc_columns['LIGNE_38A_CALC']\n",
    "    df_calc_temp['LIGNE_38B_CALC'] = calc_columns['LIGNE_38B_CALC']\n",
    "\n",
    "    # Ligne 39a: Montant net total des dépenses de recherche et de collection\n",
    "    calc_columns['LIGNE_39A_CALC'] = df_calc_temp['LIGNE_31A_CALC'] + df_calc_temp['LIGNE_38A_CALC']\n",
    "\n",
    "    # Ligne 39b: Montant net total des dépenses de recherche et de collection DOM\n",
    "    calc_columns['LIGNE_39B_CALC'] = df_calc_temp['LIGNE_31B_CALC'] + df_calc_temp['LIGNE_38B_CALC']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_39A_CALC'] = calc_columns['LIGNE_39A_CALC']\n",
    "    df_calc_temp['LIGNE_39B_CALC'] = calc_columns['LIGNE_39B_CALC']\n",
    "\n",
    "    ## III - CALCUL DU CRÉDIT D'IMPÔT AU TITRE DES DÉPENSES DE RECHERCHE ET DE COLLECTION\n",
    "\n",
    "    # Identifier les entreprises <= 100M€\n",
    "    calc_columns['DEPENSES_MOINS_100M'] = df_calc_temp['LIGNE_39A_CALC'] <= 100000000\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['DEPENSES_MOINS_100M'] = calc_columns['DEPENSES_MOINS_100M']\n",
    "\n",
    "    # A. Dépenses <= 100 000 000 €\n",
    "\n",
    "    # CIR Recherche pour entreprises <= 100M€ (ligne 41)\n",
    "    ligne_41_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        if row['DEPENSES_MOINS_100M']:\n",
    "            ligne_41_values.append(max(0, (row['LIGNE_31A_CALC'] - row['LIGNE_31B_CALC']) * 0.3 +\n",
    "                      row['LIGNE_31B_CALC'] * 0.5))\n",
    "        else:\n",
    "            ligne_41_values.append(0)\n",
    "    calc_columns['LIGNE_41_CALC'] = np.array(ligne_41_values)\n",
    "\n",
    "    # Ligne 42: Quote-part de crédit d'impôt recherche (mise à 0)\n",
    "    calc_columns['LIGNE_42'] = np.zeros(len(df_tmp))\n",
    "\n",
    "    # Ligne 43a: Montant du crédit d'impôt pour dépenses de recherche\n",
    "    calc_columns['LIGNE_43A_CALC'] = np.maximum(calc_columns['LIGNE_41_CALC'] + calc_columns['LIGNE_42'], 0)\n",
    "\n",
    "    # Ligne 43b: Montant du CIR pour dépenses de recherche DOM\n",
    "    calc_columns['LIGNE_43B_CALC'] = np.maximum(df_calc_temp['LIGNE_31B_CALC'] * 0.5, 0)\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    for col in ['LIGNE_41_CALC', 'LIGNE_42', 'LIGNE_43A_CALC', 'LIGNE_43B_CALC']:\n",
    "        df_calc_temp[col] = calc_columns[col]\n",
    "\n",
    "    # CIR Collection pour entreprises <= 100M€ (ligne 45)\n",
    "    ligne_45_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        if row['DEPENSES_MOINS_100M']:\n",
    "            ligne_45_values.append(max(0, (row['LIGNE_38A_CALC'] - row['LIGNE_38B_CALC']) * 0.3 +\n",
    "                      row['LIGNE_38B_CALC'] * 0.5))\n",
    "        else:\n",
    "            ligne_45_values.append(0)\n",
    "    calc_columns['LIGNE_45_CALC'] = np.array(ligne_45_values)\n",
    "\n",
    "    # Ligne 46: Quote-part de crédit d'impôt collection (mise à 0)\n",
    "    calc_columns['LIGNE_46'] = np.zeros(len(df_tmp))\n",
    "\n",
    "    # Ligne 47a: Montant total du crédit d'impôt collection avant plafonnement\n",
    "    calc_columns['LIGNE_47A_CALC'] = np.maximum(calc_columns['LIGNE_45_CALC'] + calc_columns['LIGNE_46'], 0)\n",
    "\n",
    "    # Ligne 47b: Montant du crédit collection DOM avant plafonnement\n",
    "    calc_columns['LIGNE_47B_CALC'] = np.maximum(df_calc_temp['LIGNE_38B_CALC'] * 0.5, 0)\n",
    "\n",
    "    # Ligne 48: Montant des aides de minimis\n",
    "    calc_columns['LIGNE_48'] = df_tmp['MT_AIDE_MINIMI']\n",
    "\n",
    "    # Ligne 49: Montant cumulé du crédit d'impôt et des aides de minimis\n",
    "    calc_columns['LIGNE_49'] = calc_columns['LIGNE_47A_CALC'] + calc_columns['LIGNE_48']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    for col in ['LIGNE_45_CALC', 'LIGNE_46', 'LIGNE_47A_CALC', 'LIGNE_47B_CALC', 'LIGNE_48', 'LIGNE_49']:\n",
    "        df_calc_temp[col] = calc_columns[col]\n",
    "\n",
    "    # Ligne 50a: Montant du crédit d'impôt collection après plafonnement\n",
    "    ligne_50a_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        if row['LIGNE_48'] >= 200000:  # Si aides de minimis déjà à 200k€\n",
    "            ligne_50a_values.append(0)\n",
    "        elif row['LIGNE_49'] < 200000:  # Si cumul < 200k€\n",
    "            ligne_50a_values.append(max(0, row['LIGNE_47A_CALC']))\n",
    "        else:  # Si dépassement\n",
    "            ligne_50a_values.append(max(0, 200000 - row['LIGNE_48']))\n",
    "    calc_columns['LIGNE_50A_CALC'] = np.array(ligne_50a_values)\n",
    "\n",
    "    # Ligne 50b: Montant du crédit collection DOM après plafonnement\n",
    "    calc_columns['LIGNE_50B_CALC'] = np.maximum(df_tmp['MT_CI_COLL_APRS_MINIMI_DOM'] if 'MT_CI_COLL_APRS_MINIMI_DOM' in df_tmp.columns else calc_columns['LIGNE_47B_CALC'], 0)\n",
    "\n",
    "    # Ligne 51a: Montant total du crédit d'impôt recherche et collection\n",
    "    calc_columns['LIGNE_51A_CALC'] = np.maximum(calc_columns['LIGNE_43A_CALC'] + calc_columns['LIGNE_50A_CALC'], 0)\n",
    "\n",
    "    # Ligne 51b: Montant du crédit d'impôt recherche et collection DOM\n",
    "    calc_columns['LIGNE_51B_CALC'] = np.maximum(calc_columns['LIGNE_43B_CALC'] + calc_columns['LIGNE_50B_CALC'], 0)\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    for col in ['LIGNE_50A_CALC', 'LIGNE_50B_CALC', 'LIGNE_51A_CALC', 'LIGNE_51B_CALC']:\n",
    "        df_calc_temp[col] = calc_columns[col]\n",
    "\n",
    "    # B. Dépenses > 100 000 000 €\n",
    "\n",
    "    # Identifier les entreprises > 100M€\n",
    "    calc_columns['DEPENSES_PLUS_100M'] = ~df_calc_temp['DEPENSES_MOINS_100M']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['DEPENSES_PLUS_100M'] = calc_columns['DEPENSES_PLUS_100M']\n",
    "\n",
    "    # Ligne 52a: Limiter les dépenses recherche à 100M€\n",
    "    ligne_52a_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        if row['DEPENSES_PLUS_100M']:\n",
    "            ligne_52a_values.append(min(row['LIGNE_31A_CALC'], 100000000))\n",
    "        else:\n",
    "            ligne_52a_values.append(0)\n",
    "    calc_columns['LIGNE_52A_CALC'] = np.array(ligne_52a_values)\n",
    "\n",
    "    # Ligne 52b: Proportion DOM dans la limite des 100M€\n",
    "    ligne_52b_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        if row['DEPENSES_PLUS_100M']:\n",
    "            ligne_52b_values.append(min(row['LIGNE_31B_CALC'], 100000000))\n",
    "        else:\n",
    "            ligne_52b_values.append(0)\n",
    "    calc_columns['LIGNE_52B_CALC'] = np.array(ligne_52b_values)\n",
    "\n",
    "    # Ligne 53: CIR recherche première tranche\n",
    "    ligne_53_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        if row['DEPENSES_PLUS_100M']:\n",
    "            ligne_53_values.append(max(0, (calc_columns['LIGNE_52A_CALC'][_] - calc_columns['LIGNE_52B_CALC'][_]) * 0.3 +\n",
    "                           calc_columns['LIGNE_52B_CALC'][_] * 0.5))\n",
    "        else:\n",
    "            ligne_53_values.append(0)\n",
    "    calc_columns['LIGNE_53_CALC'] = np.array(ligne_53_values)\n",
    "\n",
    "    # Ligne 54: Dépenses > 100M€\n",
    "    ligne_54_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        if row['DEPENSES_PLUS_100M']:\n",
    "            ligne_54_values.append(max(0, row['LIGNE_31A_CALC'] - 100000000))\n",
    "        else:\n",
    "            ligne_54_values.append(0)\n",
    "    calc_columns['LIGNE_54_CALC'] = np.array(ligne_54_values)\n",
    "\n",
    "    # Ligne 55: CIR recherche deuxième tranche\n",
    "    calc_columns['LIGNE_55_CALC'] = np.maximum(calc_columns['LIGNE_54_CALC'] * 0.05, 0)\n",
    "\n",
    "    # Ligne 56: CIR recherche total pour entreprises > 100M€\n",
    "    calc_columns['LIGNE_56_CALC'] = np.maximum(calc_columns['LIGNE_53_CALC'] + calc_columns['LIGNE_55_CALC'], 0)\n",
    "\n",
    "    # Ligne 57: Quote-part recherche > 100M€ (mise à 0)\n",
    "    calc_columns['LIGNE_57'] = np.zeros(len(df_tmp))\n",
    "\n",
    "    # Ligne 58a: Total CIR recherche > 100M€\n",
    "    calc_columns['LIGNE_58A_CALC'] = np.maximum(calc_columns['LIGNE_56_CALC'] + calc_columns['LIGNE_57'], 0)\n",
    "\n",
    "    # Ligne 58b: CIR recherche DOM > 100M€\n",
    "    calc_columns['LIGNE_58B_CALC'] = np.maximum(calc_columns['LIGNE_52B_CALC'] * 0.5, 0)\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    for col in ['LIGNE_52A_CALC', 'LIGNE_52B_CALC', 'LIGNE_53_CALC', 'LIGNE_54_CALC', 'LIGNE_55_CALC', \n",
    "               'LIGNE_56_CALC', 'LIGNE_57', 'LIGNE_58A_CALC', 'LIGNE_58B_CALC']:\n",
    "        df_calc_temp[col] = calc_columns[col]\n",
    "\n",
    "    # Collection pour > 100M€\n",
    "    # Ligne 59a,59b: Dépenses collection\n",
    "    calc_columns['LIGNE_59A_CALC'] = calc_columns['LIGNE_38A_CALC']\n",
    "    calc_columns['LIGNE_59B_CALC'] = calc_columns['LIGNE_38B_CALC']\n",
    "\n",
    "    # Ligne 60: Plafond disponible\n",
    "    ligne_60_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        if row['DEPENSES_PLUS_100M']:\n",
    "            ligne_60_values.append(max(0, 100000000 - row['LIGNE_52A_CALC']))\n",
    "        else:\n",
    "            ligne_60_values.append(0)\n",
    "    calc_columns['LIGNE_60_CALC'] = np.array(ligne_60_values)\n",
    "\n",
    "    # Ligne 61: CIR collection première tranche\n",
    "    ligne_61_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        if row['DEPENSES_PLUS_100M']:\n",
    "            dep_coll_plaf = min(calc_columns['LIGNE_59A_CALC'][_], calc_columns['LIGNE_60_CALC'][_])\n",
    "            dep_coll_dom_plaf = min(calc_columns['LIGNE_59B_CALC'][_], calc_columns['LIGNE_60_CALC'][_])\n",
    "            ligne_61_values.append(max(0, (dep_coll_plaf - dep_coll_dom_plaf) * 0.3 + dep_coll_dom_plaf * 0.5))\n",
    "        else:\n",
    "            ligne_61_values.append(0)\n",
    "    calc_columns['LIGNE_61_CALC'] = np.array(ligne_61_values)\n",
    "\n",
    "    # Ligne 62: CIR collection deuxième tranche\n",
    "    ligne_62_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        if row['DEPENSES_PLUS_100M']:\n",
    "            ligne_62_values.append(max(0, max(0, calc_columns['LIGNE_59A_CALC'][_] - calc_columns['LIGNE_60_CALC'][_]) * 0.05))\n",
    "        else:\n",
    "            ligne_62_values.append(0)\n",
    "    calc_columns['LIGNE_62_CALC'] = np.array(ligne_62_values)\n",
    "\n",
    "    # Ligne 63: CIR collection avant plafonnement\n",
    "    calc_columns['LIGNE_63_CALC'] = np.maximum(calc_columns['LIGNE_61_CALC'] + calc_columns['LIGNE_62_CALC'], 0)\n",
    "\n",
    "    # Ligne 64: Quote-part collection > 100M€ (mise à 0)\n",
    "    calc_columns['LIGNE_64'] = np.zeros(len(df_tmp))\n",
    "\n",
    "    # Ligne 65: Total collection avant plafonnement\n",
    "    calc_columns['LIGNE_65'] = np.maximum(calc_columns['LIGNE_63_CALC'] + calc_columns['LIGNE_64'], 0)\n",
    "\n",
    "    # Ligne 66: Aides de minimis > 100M€\n",
    "    calc_columns['LIGNE_66'] = df_tmp['MT_AIDE_MINIMI']\n",
    "\n",
    "    # Ligne 67: Cumul collection + aides\n",
    "    calc_columns['LIGNE_67'] = calc_columns['LIGNE_65'] + calc_columns['LIGNE_66']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    for col in ['LIGNE_59A_CALC', 'LIGNE_59B_CALC', 'LIGNE_60_CALC', 'LIGNE_61_CALC', 'LIGNE_62_CALC',\n",
    "               'LIGNE_63_CALC', 'LIGNE_64', 'LIGNE_65', 'LIGNE_66', 'LIGNE_67']:\n",
    "        df_calc_temp[col] = calc_columns[col]\n",
    "\n",
    "    # Ligne 68a: Collection après plafonnement > 100M€\n",
    "    ligne_68a_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        if row['LIGNE_66'] >= 200000:\n",
    "            ligne_68a_values.append(0)\n",
    "        elif row['LIGNE_67'] < 200000:\n",
    "            ligne_68a_values.append(max(0, row['LIGNE_65']))\n",
    "        else:\n",
    "            ligne_68a_values.append(max(0, 200000 - row['LIGNE_66']))\n",
    "    calc_columns['LIGNE_68A_CALC'] = np.array(ligne_68a_values)\n",
    "\n",
    "    # Ligne 68b: Collection DOM après plafonnement > 100M€\n",
    "    calc_columns['LIGNE_68B_CALC'] = np.maximum(df_tmp['MT_CI_COLL_APRS_MINIMI_DOM'] if 'MT_CI_COLL_APRS_MINIMI_DOM' in df_tmp.columns else calc_columns['LIGNE_59B_CALC'] * 0.5, 0)\n",
    "\n",
    "    # Ligne 69a: Total CIR recherche + collection > 100M€\n",
    "    calc_columns['LIGNE_69A_CALC'] = np.maximum(calc_columns['LIGNE_58A_CALC'] + calc_columns['LIGNE_68A_CALC'], 0)\n",
    "\n",
    "    # Ligne 69b: Total CIR DOM > 100M€\n",
    "    calc_columns['LIGNE_69B_CALC'] = np.maximum(calc_columns['LIGNE_58B_CALC'] + calc_columns['LIGNE_68B_CALC'], 0)\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    for col in ['LIGNE_68A_CALC', 'LIGNE_68B_CALC', 'LIGNE_69A_CALC', 'LIGNE_69B_CALC']:\n",
    "        df_calc_temp[col] = calc_columns[col]\n",
    "\n",
    "    # Somme du CIR recherche selon le cas\n",
    "    cir_recherche_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        if row['DEPENSES_MOINS_100M']:\n",
    "            cir_recherche_values.append(row['LIGNE_43A_CALC'])\n",
    "        else:\n",
    "            cir_recherche_values.append(row['LIGNE_58A_CALC'])\n",
    "    calc_columns['CIR_RECHERCHE_RECALCULE'] = np.maximum(np.array(cir_recherche_values), 0)\n",
    "\n",
    "    # Somme du CIR collection après plafonnement selon le cas\n",
    "    cir_collection_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        if row['DEPENSES_MOINS_100M']:\n",
    "            cir_collection_values.append(row['LIGNE_50A_CALC'])\n",
    "        else:\n",
    "            cir_collection_values.append(row['LIGNE_68A_CALC'])\n",
    "    calc_columns['CIR_COLLECTION_RECALCULE'] = np.maximum(np.array(cir_collection_values), 0)\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    for col in ['CIR_RECHERCHE_RECALCULE', 'CIR_COLLECTION_RECALCULE']:\n",
    "        df_calc_temp[col] = calc_columns[col]\n",
    "\n",
    "    ## IV - DÉPENSES D'INNOVATION (CIR-INNOVATION)\n",
    "    ## ANNÉE CIVILE 2021\n",
    "    \n",
    "    # Vérifier si les données d'innovation sont disponibles\n",
    "    if all(col in df_tmp.columns for col in ['DOT_AMORT_IMMO_INO', 'DEP_PERSONEL_INO']):\n",
    "        # Ligne 72: Autres dépenses de fonctionnement innovation (calcul spécifique 2021)\n",
    "        calc_columns['LIGNE_72_CALC'] = (df_tmp['DOT_AMORT_IMMO_INO'] * 0.75) + (df_tmp['DEP_PERSONEL_INO'] * 0.43)\n",
    "\n",
    "        # Total dépenses d'innovation (ligne 76)\n",
    "        calc_columns['LIGNE_76_CALC'] = df_tmp['DOT_AMORT_IMMO_INO'] + df_tmp['DEP_PERSONEL_INO'] + \\\n",
    "                                     calc_columns['LIGNE_72_CALC'] + df_tmp['FRAIS_BREV_COV_INO'] + \\\n",
    "                                     df_tmp['FRAIS_DEF_BREV_INO'] + df_tmp['OP_INOV_EXT']\n",
    "\n",
    "        # Plafonnement à 400 000 € (ligne 77)\n",
    "        calc_columns['LIGNE_77_CALC'] = np.minimum(calc_columns['LIGNE_76_CALC'], 400000)\n",
    "\n",
    "        # Montant net des dépenses d'innovation (ligne 82a)\n",
    "        calc_columns['LIGNE_82A_CALC'] = calc_columns['LIGNE_77_CALC'] - df_tmp['MT_AID_SUBV_INO'] - \\\n",
    "                                       df_tmp['MT_ENC_PRESTA_INO'] - df_tmp['MT_DEP_CONSEILS_CII'] + \\\n",
    "                                       df_tmp['REMBST_SUBV_INO']\n",
    "\n",
    "        # Calcul des parts DOM et Corse\n",
    "        calc_columns['LIGNE_82B_CALC'] = df_tmp['MT_NET_DEP_INO_DOM']\n",
    "        calc_columns['LIGNE_82C_CALC'] = df_tmp['MT_NET_DEP_INO_MPE_CORSE']\n",
    "        calc_columns['LIGNE_82D_CALC'] = df_tmp['MT_NET_DEP_INO_ME_CORSE']\n",
    "\n",
    "        # Mise à jour du DataFrame temporaire\n",
    "        for col in ['LIGNE_72_CALC', 'LIGNE_76_CALC', 'LIGNE_77_CALC', 'LIGNE_82A_CALC',\n",
    "                    'LIGNE_82B_CALC', 'LIGNE_82C_CALC', 'LIGNE_82D_CALC']:\n",
    "            df_calc_temp[col] = calc_columns[col]\n",
    "\n",
    "        # CIR Innovation selon les taux 2021 - taux de 20% (ligne 83)\n",
    "        calc_columns['LIGNE_83_CALC'] = np.maximum(((df_calc_temp['LIGNE_82A_CALC'] - df_calc_temp['LIGNE_82B_CALC'] -\n",
    "                                      df_calc_temp['LIGNE_82C_CALC'] - df_calc_temp['LIGNE_82D_CALC']) * 0.2) + \\\n",
    "                                     (df_calc_temp['LIGNE_82B_CALC'] * 0.4) + \\\n",
    "                                     (df_calc_temp['LIGNE_82C_CALC'] * 0.4) + \\\n",
    "                                     (df_calc_temp['LIGNE_82D_CALC'] * 0.35), 0)\n",
    "\n",
    "        # Ligne 84: Quote-part innovation (mise à 0)\n",
    "        calc_columns['LIGNE_84'] = np.zeros(len(df_tmp))\n",
    "\n",
    "        # Ligne 85a: Total CIR innovation\n",
    "        calc_columns['LIGNE_85A_CALC'] = np.maximum(calc_columns['LIGNE_83_CALC'] + calc_columns['LIGNE_84'], 0)\n",
    "\n",
    "        # Ligne 85b: CIR innovation DOM\n",
    "        calc_columns['LIGNE_85B_CALC'] = np.maximum(df_tmp['MT_CII_YC_QP_DOM'] if 'MT_CII_YC_QP_DOM' in df_tmp.columns else df_calc_temp['LIGNE_82B_CALC'] * 0.4, 0)\n",
    "\n",
    "        # Ligne 85c: CIR innovation Corse\n",
    "        calc_columns['LIGNE_85C_CALC'] = np.maximum(df_tmp['MT_CII_CORSE'] if 'MT_CII_CORSE' in df_tmp.columns else (df_calc_temp['LIGNE_82C_CALC'] * 0.4 + df_calc_temp['LIGNE_82D_CALC'] * 0.35), 0)\n",
    "\n",
    "        calc_columns['CIR_INNOVATION_RECALCULE'] = np.maximum(calc_columns['LIGNE_85A_CALC'], 0)\n",
    "    else:\n",
    "        # Si données non disponibles, mettre à 0\n",
    "        calc_columns['CIR_INNOVATION_RECALCULE'] = np.zeros(len(df_tmp))\n",
    "        calc_columns['LIGNE_72_CALC'] = np.zeros(len(df_tmp))\n",
    "        calc_columns['LIGNE_76_CALC'] = np.zeros(len(df_tmp))\n",
    "        calc_columns['LIGNE_77_CALC'] = np.zeros(len(df_tmp))\n",
    "        calc_columns['LIGNE_82A_CALC'] = np.zeros(len(df_tmp))\n",
    "        calc_columns['LIGNE_82B_CALC'] = np.zeros(len(df_tmp))\n",
    "        calc_columns['LIGNE_82C_CALC'] = np.zeros(len(df_tmp))\n",
    "        calc_columns['LIGNE_82D_CALC'] = np.zeros(len(df_tmp))\n",
    "        calc_columns['LIGNE_83_CALC'] = np.zeros(len(df_tmp))\n",
    "        calc_columns['LIGNE_84'] = np.zeros(len(df_tmp))\n",
    "        calc_columns['LIGNE_85A_CALC'] = np.zeros(len(df_tmp))\n",
    "        calc_columns['LIGNE_85B_CALC'] = np.zeros(len(df_tmp))\n",
    "        calc_columns['LIGNE_85C_CALC'] = np.zeros(len(df_tmp))\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    for col in ['CIR_INNOVATION_RECALCULE', 'LIGNE_72_CALC', 'LIGNE_76_CALC', 'LIGNE_77_CALC',\n",
    "               'LIGNE_82A_CALC', 'LIGNE_82B_CALC', 'LIGNE_82C_CALC', 'LIGNE_82D_CALC',\n",
    "               'LIGNE_83_CALC', 'LIGNE_84', 'LIGNE_85A_CALC', 'LIGNE_85B_CALC', 'LIGNE_85C_CALC']:\n",
    "        if col in calc_columns:\n",
    "            df_calc_temp[col] = calc_columns[col]\n",
    "\n",
    "    # Ligne 86a: Total CIR recherche + collection + innovation\n",
    "    ligne_86a_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        if row['DEPENSES_MOINS_100M']:\n",
    "            ligne_86a_values.append(max(0, row['LIGNE_51A_CALC'] + row['LIGNE_85A_CALC']))\n",
    "        else:\n",
    "            ligne_86a_values.append(max(0, row['LIGNE_69A_CALC'] + row['LIGNE_85A_CALC']))\n",
    "    calc_columns['LIGNE_86A_CALC'] = np.array(ligne_86a_values)\n",
    "\n",
    "    # Ligne 86b: Total CIR DOM\n",
    "    ligne_86b_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        if row['DEPENSES_MOINS_100M']:\n",
    "            ligne_86b_values.append(max(0, row['LIGNE_51B_CALC'] + row['LIGNE_85B_CALC']))\n",
    "        else:\n",
    "            ligne_86b_values.append(max(0, row['LIGNE_69B_CALC'] + row['LIGNE_85B_CALC']))\n",
    "    calc_columns['LIGNE_86B_CALC'] = np.array(ligne_86b_values)\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_86A_CALC'] = calc_columns['LIGNE_86A_CALC']\n",
    "    df_calc_temp['LIGNE_86B_CALC'] = calc_columns['LIGNE_86B_CALC']\n",
    "\n",
    "    ## TOTAL DU CRÉDIT D'IMPÔT FINAL (CIR + CII) - Pas de CRC en 2021\n",
    "\n",
    "    # Total CIR recalculé\n",
    "    calc_columns['CIR_TOTAL_RECALCULE'] = np.maximum(calc_columns['CIR_RECHERCHE_RECALCULE'] + \\\n",
    "                                          calc_columns['CIR_COLLECTION_RECALCULE'], 0)\n",
    "\n",
    "    # Ajouter la composante Innovation (CII) si elle a été calculée\n",
    "    if 'CIR_INNOVATION_RECALCULE' in calc_columns:\n",
    "        calc_columns['CIR_TOTAL_RECALCULE'] = np.maximum(calc_columns['CIR_TOTAL_RECALCULE'] + np.nan_to_num(calc_columns['CIR_INNOVATION_RECALCULE']), 0)\n",
    "\n",
    "    # Mettre à jour le DataFrame temporaire\n",
    "    df_calc_temp['CIR_TOTAL_RECALCULE'] = calc_columns['CIR_TOTAL_RECALCULE']\n",
    "\n",
    "    # ANALYSE DES ÉCARTS\n",
    "\n",
    "    # Écarts sur toutes les lignes recalculées\n",
    "    # 1. Dépenses internes\n",
    "    calc_columns['ECART_LIGNE_6'] = calc_columns['LIGNE_6_CALC'] - df_tmp['OTR_DEP_FONCT']\n",
    "    calc_columns['ECART_LIGNE_7'] = calc_columns['LIGNE_7_CALC'] - df_tmp['MT_DEP_FONCT_TOT']\n",
    "    calc_columns['ECART_LIGNE_14'] = calc_columns['LIGNE_14_CALC'] - df_tmp['MT_TOT_RD_1']\n",
    "\n",
    "    # 2. Dépenses de sous-traitance\n",
    "    calc_columns['ECART_LIGNE_17'] = calc_columns['LIGNE_17_CALC'] - df_tmp['MT_TOT_ST_ORG_PUB']\n",
    "    calc_columns['ECART_LIGNE_20'] = calc_columns['LIGNE_20_CALC'] - df_tmp['MT_TOT_ST_ORG_PRIV']\n",
    "    calc_columns['ECART_LIGNE_21'] = calc_columns['LIGNE_21_CALC'] - df_tmp['PLAF_ST_ORG_PRIV']\n",
    "    calc_columns['ECART_LIGNE_22'] = calc_columns['LIGNE_22_CALC'] - df_tmp['MT_TOT_ST']\n",
    "    calc_columns['ECART_LIGNE_23'] = calc_columns['LIGNE_23_CALC'] - df_tmp['PLAF_ST_ORG_LIE']\n",
    "    calc_columns['ECART_LIGNE_24'] = calc_columns['LIGNE_24_CALC'] - df_tmp['MT_ST_ORG_NON_LIE_PLAF']\n",
    "    calc_columns['ECART_LIGNE_25'] = calc_columns['LIGNE_25_CALC'] - df_tmp['PLAF_GNRL_ST']\n",
    "    calc_columns['ECART_LIGNE_26'] = calc_columns['LIGNE_26_CALC'] - df_tmp['MT_TOT_ST_PLAF']\n",
    "\n",
    "    # 3. Montant total et net\n",
    "    calc_columns['ECART_LIGNE_27'] = calc_columns['LIGNE_27_CALC'] - df_tmp['MT_TOT_RD_2']\n",
    "    calc_columns['ECART_LIGNE_31A'] = calc_columns['LIGNE_31A_CALC'] - df_tmp['MT_NET_DEP_RD']\n",
    "    calc_columns['ECART_LIGNE_31B'] = calc_columns['LIGNE_31B_CALC'] - df_tmp['MT_NET_DEP_RD_DOM']\n",
    "\n",
    "    # 4. Dépenses de collection\n",
    "    calc_columns['ECART_LIGNE_34'] = calc_columns['LIGNE_34_CALC'] - df_tmp['MT_TOT_DEP_COLL']\n",
    "    calc_columns['ECART_LIGNE_38A'] = calc_columns['LIGNE_38A_CALC'] - df_tmp['MT_NET_DEP_COLL']\n",
    "    calc_columns['ECART_LIGNE_38B'] = calc_columns['LIGNE_38B_CALC'] - df_tmp['MT_NET_DEP_COLL_DOM']\n",
    "\n",
    "    # 5. Innovation\n",
    "    if all(col in df_tmp.columns for col in ['MT_TOT_DEP_INO', 'MT_TOT_DEP_INO_PLAF', 'MT_NET_DEP_INO']):\n",
    "        calc_columns['ECART_LIGNE_76'] = calc_columns['LIGNE_76_CALC'] - df_tmp['MT_TOT_DEP_INO']\n",
    "        calc_columns['ECART_LIGNE_77'] = calc_columns['LIGNE_77_CALC'] - df_tmp['MT_TOT_DEP_INO_PLAF']\n",
    "        calc_columns['ECART_LIGNE_82A'] = calc_columns['LIGNE_82A_CALC'] - df_tmp['MT_NET_DEP_INO']\n",
    "\n",
    "    # 6. Crédits d'impôt\n",
    "    calc_columns['ECART_CIR_RECHERCHE'] = calc_columns['CIR_RECHERCHE_RECALCULE'] - df_tmp['MT_CIR_RECH_YC_QP']\n",
    "    calc_columns['ECART_CIR_COLLECTION'] = calc_columns['CIR_COLLECTION_RECALCULE'] - df_tmp['MT_CI_COLL_APRS_MINIMI']\n",
    "\n",
    "    if 'CIR_INNOVATION_RECALCULE' in df_calc_temp.columns:\n",
    "        calc_columns['ECART_CIR_INNOVATION'] = df_calc_temp['CIR_INNOVATION_RECALCULE'] - df_tmp['MT_CII_YC_QP']\n",
    "    else:\n",
    "        calc_columns['ECART_CIR_INNOVATION'] = -df_tmp['MT_CII_YC_QP']\n",
    "\n",
    "    # Écart total CIR\n",
    "    calc_columns['ECART_CIR'] = df_calc_temp['CIR_TOTAL_RECALCULE'] - df_tmp['MT_TOT_CIR_CI_COLL_CII']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['ECART_CIR'] = calc_columns['ECART_CIR']\n",
    "\n",
    "    # Indicateur de correspondance (avec seuil de tolérance de 1)\n",
    "    correspondance_values = []\n",
    "    for ecart in calc_columns['ECART_CIR']:\n",
    "        if abs(ecart) <= 1:\n",
    "            correspondance_values.append(\"Oui\")\n",
    "        else:\n",
    "            correspondance_values.append(\"Non\")\n",
    "    calc_columns['CORRESPONDANCE'] = np.array(correspondance_values)\n",
    "\n",
    "    # Écart relatif\n",
    "    ecart_relatif_values = []\n",
    "    for i, row in df_calc_temp.iterrows():\n",
    "        if row['MT_TOT_CIR_CI_COLL_CII'] > 0:\n",
    "            ecart_relatif_values.append((row['ECART_CIR'] / row['MT_TOT_CIR_CI_COLL_CII'] * 100))\n",
    "        else:\n",
    "            ecart_relatif_values.append(100 if row['ECART_CIR'] > 0 else 0)\n",
    "    calc_columns['ECART_RELATIF'] = np.array(ecart_relatif_values)\n",
    "\n",
    "    # Création du DataFrame final avec toutes les colonnes calculées\n",
    "    df_calc_final = pd.DataFrame(calc_columns)\n",
    "\n",
    "    # Création du DataFrame final pour l'analyse\n",
    "    df_num = pd.concat([df_tmp, df_calc_final], axis=1)\n",
    "\n",
    "    ## CRÉATION DU FICHIER DE COMPARAISON DÉTAILLÉ\n",
    "\n",
    "    # Préparation du dictionnaire de mapping pour la sortie\n",
    "    mapping_colonnes = {\n",
    "        # Colonnes d'identification\n",
    "        'siren_declarant': 'SIREN_DECLARANT',\n",
    "        'siren_deposant': 'SIREN_DEPOSANT',\n",
    "        'DESIGN': 'DESIGNATION',\n",
    "        'COMPLT_DESIGN': 'COMPLEMENT_DESIGNATION',\n",
    "\n",
    "        # I. Dépenses internes\n",
    "        'DOT_AMORT_IMMO': 'L1_DOTATION_AMORT_IMMO',\n",
    "        'DOT_AMORT_IMMO_SINISTR': 'L2_DOTATION_AMORT_SINISTR',\n",
    "        'DEP_CHERCH_TECH': 'L3_DEPENSES_PERSONNEL_CHERCHEURS',\n",
    "        'REM_SAL_INV': 'L4_REMUNERATION_INVENTEURS',\n",
    "        'DEP_JD': 'L5_DEPENSES_JEUNES_DOCTEURS',\n",
    "        'OTR_DEP_FONCT': 'L6_AUTRES_DEP_FONCT_DECLARE',\n",
    "        'LIGNE_6_CALC': 'L6_AUTRES_DEP_FONCT_CALCULE',\n",
    "        'ECART_LIGNE_6': 'L6_ECART',\n",
    "        'MT_DEP_FONCT_TOT': 'L7_TOTAL_DEP_FONCT_DECLARE',\n",
    "        'LIGNE_7_CALC': 'L7_TOTAL_DEP_FONCT_CALCULE',\n",
    "        'ECART_LIGNE_7': 'L7_ECART',\n",
    "        'FRAIS_BREV_COV': 'L8_FRAIS_BREVETS_COV',\n",
    "        'DEP_MAINT_BREV_COV': 'L9_DEPENSES_DEFENSE_BREVETS',\n",
    "        'DOT_AMORT_BREV': 'L10_DOTATION_AMORT_BREVETS',\n",
    "        'DEP_NORMALI': 'L11_DEPENSES_NORMALISATION',\n",
    "        'PRIM_COTIZ': 'L12_PRIMES_COTISATIONS_BRUT',\n",
    "        'PRIM_COTIZ_PLAFONNEES': 'L12_PRIMES_COTISATIONS_PLAFONNEES',\n",
    "        'DEP_VEIL_TECHNO': 'L13_VEILLE_TECHNO_BRUT',\n",
    "        'DEP_VEIL_TECHNO_PLAFONNEES': 'L13_VEILLE_TECHNO_PLAFONNEE',\n",
    "        'MT_TOT_RD_1': 'L14_TOTAL_DEPENSES_INTERNES_DECLARE',\n",
    "        'LIGNE_14_CALC': 'L14_TOTAL_DEPENSES_INTERNES_CALCULE',\n",
    "        'ECART_LIGNE_14': 'L14_ECART',\n",
    "\n",
    "        # Sous-traitance organismes publics\n",
    "        'DEP_ST_ORG_PUB_LIE_FR': 'L15A_ST_PUB_LIES_FR',\n",
    "        'DEP_ST_ORG_PUB_LIE_ETR': 'L15B_ST_PUB_LIES_ETR',\n",
    "        'DEP_ST_ORG_PUB_NON_LIE_FR': 'L16A_ST_PUB_NON_LIES_FR',\n",
    "        'DEP_ST_ORG_PUB_NON_LIE_ETR': 'L16B_ST_PUB_NON_LIES_ETR',\n",
    "        'MT_TOT_ST_ORG_PUB': 'L17_TOTAL_ST_PUBLIQUE_DECLARE',\n",
    "        'LIGNE_17_CALC': 'L17_TOTAL_ST_PUBLIQUE_CALCULE',\n",
    "        'ECART_LIGNE_17': 'L17_ECART',\n",
    "\n",
    "        # Sous-traitance organismes privés\n",
    "        'DEP_ST_ORG_PRIV_LIE_FR': 'L18A_ST_PRIV_LIES_FR',\n",
    "        'DEP_ST_ORG_PRIV_LIE_ETR': 'L18B_ST_PRIV_LIES_ETR',\n",
    "        'DEP_ST_ORG_PRIV_NON_LIE_FR': 'L19A_ST_PRIV_NON_LIES_FR',\n",
    "        'DEP_ST_ORG_PRIV_NON_LIE_ETR': 'L19B_ST_PRIV_NON_LIES_ETR',\n",
    "        'MT_TOT_ST_ORG_PRIV': 'L20_TOTAL_ST_PRIVEE_DECLARE',\n",
    "        'LIGNE_20_CALC': 'L20_TOTAL_ST_PRIVEE_CALCULE',\n",
    "        'ECART_LIGNE_20': 'L20_ECART',\n",
    "        'PLAF_ST_ORG_PRIV': 'L21_PLAFOND_ST_PRIVEE_DECLARE',\n",
    "        'LIGNE_21_CALC': 'L21_PLAFOND_ST_PRIVEE_CALCULE',\n",
    "        'ECART_LIGNE_21': 'L21_ECART',\n",
    "        'MT_TOT_ST': 'L22_TOTAL_ST_DECLARE',\n",
    "        'LIGNE_22_CALC': 'L22_TOTAL_ST_CALCULE',\n",
    "        'ECART_LIGNE_22': 'L22_ECART',\n",
    "        'PLAF_ST_ORG_LIE': 'L23_PLAFOND_ORGANISMES_LIES_DECLARE',\n",
    "        'LIGNE_23_CALC': 'L23_PLAFOND_ORGANISMES_LIES_CALCULE',\n",
    "        'ECART_LIGNE_23': 'L23_ECART',\n",
    "        'MT_ST_ORG_NON_LIE_PLAF': 'L24_PLAFOND_ORG_NON_LIES_DECLARE',\n",
    "        'LIGNE_24_CALC': 'L24_PLAFOND_ORG_NON_LIES_CALCULE',\n",
    "        'ECART_LIGNE_24': 'L24_ECART',\n",
    "        'PLAF_GNRL_ST': 'L25_PLAFOND_GENERAL_DECLARE',\n",
    "        'LIGNE_25_CALC': 'L25_PLAFOND_GENERAL_CALCULE',\n",
    "        'ECART_LIGNE_25': 'L25_ECART',\n",
    "        'MT_TOT_ST_PLAF': 'L26_TOTAL_ST_PLAFONNE_DECLARE',\n",
    "        'LIGNE_26_CALC': 'L26_TOTAL_ST_PLAFONNE_CALCULE',\n",
    "        'ECART_LIGNE_26': 'L26_ECART',\n",
    "\n",
    "        # Montant total et net\n",
    "        'MT_TOT_RD_2': 'L27_TOTAL_DEPENSES_RECHERCHE_DECLARE',\n",
    "        'LIGNE_27_CALC': 'L27_TOTAL_DEPENSES_RECHERCHE_CALCULE',\n",
    "        'ECART_LIGNE_27': 'L27_ECART',\n",
    "        'MT_AID_SUBV': 'L28A_SUBVENTIONS',\n",
    "        'MT_ENC_PRESTA': 'L28B_SOMMES_ENCAISSEES_TIERS',\n",
    "        'MT_DEP_CONSEILS_CIR': 'L29_DEPENSES_CONSEIL_CIR',\n",
    "        'REMBST_SUBV': 'L30_REMBOURSEMENTS_SUBVENTIONS',\n",
    "        'MT_NET_DEP_RD': 'L31A_MONTANT_NET_DEPENSES_DECLARE',\n",
    "        'LIGNE_31A_CALC': 'L31A_MONTANT_NET_DEPENSES_CALCULE',\n",
    "        'ECART_LIGNE_31A': 'L31A_ECART',\n",
    "        'MT_NET_DEP_RD_DOM': 'L31B_MONTANT_NET_DEPENSES_DOM_DECLARE',\n",
    "        'LIGNE_31B_CALC': 'L31B_MONTANT_NET_DEPENSES_DOM_CALCULE',\n",
    "        'ECART_LIGNE_31B': 'L31B_ECART',\n",
    "\n",
    "        # II. Dépenses de collection\n",
    "        'FRAIS_COLL': 'L32_FRAIS_COLLECTION',\n",
    "        'FRAIS_DEF_DESSIN': 'L33_FRAIS_DEFENSE_DESSINS_BRUT',\n",
    "        'FRAIS_DEF_DESSIN_PLAFONNES': 'L33_FRAIS_DEFENSE_DESSINS_PLAFONNES',\n",
    "        'MT_TOT_DEP_COLL': 'L34_TOTAL_DEPENSES_COLLECTION_DECLARE',\n",
    "        'LIGNE_34_CALC': 'L34_TOTAL_DEPENSES_COLLECTION_CALCULE',\n",
    "        'ECART_LIGNE_34': 'L34_ECART',\n",
    "        'MT_AID_SUBV_COLL': 'L35_SUBVENTIONS_COLLECTION',\n",
    "        'MT_DEP_CONSEILS_CIR_COLL': 'L36_DEPENSES_CONSEIL_COLLECTION',\n",
    "        'REMBST_SUBV_COLL': 'L37_REMBOURSEMENTS_SUBVENTIONS_COLL',\n",
    "        'MT_NET_DEP_COLL': 'L38A_MONTANT_NET_COLLECTION_DECLARE',\n",
    "        'LIGNE_38A_CALC': 'L38A_MONTANT_NET_COLLECTION_CALCULE',\n",
    "        'ECART_LIGNE_38A': 'L38A_ECART',\n",
    "        'MT_NET_DEP_COLL_DOM': 'L38B_MONTANT_NET_COLLECTION_DOM_DECLARE',\n",
    "        'LIGNE_38B_CALC': 'L38B_MONTANT_NET_COLLECTION_DOM_CALCULE',\n",
    "        'ECART_LIGNE_38B': 'L38B_ECART',\n",
    "        'LIGNE_39A_CALC': 'L39A_MONTANT_NET_TOTAL_RD_COLL',\n",
    "        'LIGNE_39B_CALC': 'L39B_MONTANT_NET_TOTAL_RD_COLL_DOM',\n",
    "\n",
    "        # III. Calcul CIR <= 100M€\n",
    "        'LIGNE_41_CALC': 'L41_CREDIT_IMPOT_RECHERCHE_MOINS_100M',\n",
    "        'LIGNE_42': 'L42_QUOTE_PART_RECHERCHE_SOC_PERSONNES',\n",
    "        'LIGNE_43A_CALC': 'L43A_CREDIT_IMPOT_RECHERCHE_TOTAL',\n",
    "        'LIGNE_43B_CALC': 'L43B_CREDIT_IMPOT_RECHERCHE_DOM',\n",
    "        'LIGNE_45_CALC': 'L45_CREDIT_IMPOT_COLLECTION_MOINS_100M',\n",
    "        'LIGNE_46': 'L46_QUOTE_PART_COLLECTION_SOC_PERSONNES',\n",
    "        'LIGNE_47A_CALC': 'L47A_CREDIT_IMPOT_COLL_AVANT_PLAF',\n",
    "        'LIGNE_47B_CALC': 'L47B_CREDIT_IMPOT_COLL_DOM_AVANT_PLAF',\n",
    "        'LIGNE_48': 'L48_AIDES_MINIMIS',\n",
    "        'LIGNE_49': 'L49_CUMUL_CREDIT_IMPOT_ET_AIDES',\n",
    "        'LIGNE_50A_CALC': 'L50A_CREDIT_IMPOT_COLL_APRES_PLAF',\n",
    "        'LIGNE_50B_CALC': 'L50B_CREDIT_IMPOT_COLL_DOM_APRES_PLAF',\n",
    "        'LIGNE_51A_CALC': 'L51A_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION',\n",
    "        'LIGNE_51B_CALC': 'L51B_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION_DOM',\n",
    "\n",
    "        # III. Calcul CIR > 100M€\n",
    "        'LIGNE_52A_CALC': 'L52A_DEPENSES_RECHERCHE_LIMITE_100M',\n",
    "        'LIGNE_52B_CALC': 'L52B_DEPENSES_RECHERCHE_DOM_LIMITE',\n",
    "        'LIGNE_53_CALC': 'L53_CIR_RECHERCHE_PREMIERE_TRANCHE',\n",
    "        'LIGNE_54_CALC': 'L54_DEPENSES_RECHERCHE_SUP_100M',\n",
    "        'LIGNE_55_CALC': 'L55_CIR_RECHERCHE_DEUXIEME_TRANCHE',\n",
    "        'LIGNE_56_CALC': 'L56_CIR_RECHERCHE_PLUS_100M',\n",
    "        'LIGNE_57': 'L57_QUOTE_PART_RECHERCHE_SOC_PERSONNES_PLUS_100M',\n",
    "        'LIGNE_58A_CALC': 'L58A_CREDIT_IMPOT_RECHERCHE_TOTAL_PLUS_100M',\n",
    "        'LIGNE_58B_CALC': 'L58B_CREDIT_IMPOT_RECHERCHE_DOM_PLUS_100M',\n",
    "        'LIGNE_59A_CALC': 'L59A_MONTANT_NET_COLLECTION_PLUS_100M',\n",
    "        'LIGNE_59B_CALC': 'L59B_MONTANT_NET_COLLECTION_DOM_PLUS_100M',\n",
    "        'LIGNE_60_CALC': 'L60_PLAFOND_DISPO_COLLECTION',\n",
    "        'LIGNE_61_CALC': 'L61_CIR_COLLECTION_PREMIERE_TRANCHE',\n",
    "        'LIGNE_62_CALC': 'L62_CIR_COLLECTION_DEUXIEME_TRANCHE',\n",
    "        'LIGNE_63_CALC': 'L63_CIR_COLLECTION_PLUS_100M',\n",
    "        'LIGNE_64': 'L64_QUOTE_PART_COLLECTION_SOC_PERSONNES_PLUS_100M',\n",
    "        'LIGNE_65': 'L65_CREDIT_IMPOT_COLL_AVANT_PLAF_PLUS_100M',\n",
    "        'LIGNE_66': 'L66_AIDES_MINIMIS_PLUS_100M',\n",
    "        'LIGNE_67': 'L67_CUMUL_CREDIT_IMPOT_ET_AIDES_PLUS_100M',\n",
    "        'LIGNE_68A_CALC': 'L68A_CREDIT_IMPOT_COLL_APRES_PLAF_PLUS_100M',\n",
    "        'LIGNE_68B_CALC': 'L68B_CREDIT_IMPOT_COLL_DOM_APRES_PLAF_PLUS_100M',\n",
    "        'LIGNE_69A_CALC': 'L69A_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION_PLUS_100M',\n",
    "        'LIGNE_69B_CALC': 'L69B_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION_DOM_PLUS_100M',\n",
    "\n",
    "        # IV. Dépenses d'innovation\n",
    "        'DOT_AMORT_IMMO_INO': 'L70_DOTATION_AMORT_IMMO_INNOVATION',\n",
    "        'DEP_PERSONEL_INO': 'L71_DEPENSES_PERSONNEL_INNOVATION',\n",
    "        'LIGNE_72_CALC': 'L72_AUTRES_DEPENSES_FONCT_INNOVATION',\n",
    "        'FRAIS_BREV_COV_INO': 'L73_FRAIS_BREVETS_INNOVATION',\n",
    "        'FRAIS_DEF_BREV_INO': 'L74_FRAIS_DEFENSE_BREVETS_INNOVATION',\n",
    "        'OP_INOV_EXT': 'L75_OPERATIONS_CONFIEES_INNOVATION',\n",
    "        'MT_TOT_DEP_INO': 'L76_TOTAL_DEPENSES_INNOVATION_DECLARE',\n",
    "        'LIGNE_76_CALC': 'L76_TOTAL_DEPENSES_INNOVATION_CALCULE',\n",
    "        'ECART_LIGNE_76': 'L76_ECART',\n",
    "        'MT_TOT_DEP_INO_PLAF': 'L77_DEPENSES_INNOVATION_PLAFONNEES_DECLARE',\n",
    "        'LIGNE_77_CALC': 'L77_DEPENSES_INNOVATION_PLAFONNEES_CALCULE',\n",
    "        'ECART_LIGNE_77': 'L77_ECART',\n",
    "        'MT_AID_SUBV_INO': 'L78_SUBVENTIONS_INNOVATION',\n",
    "        'MT_ENC_PRESTA_INO': 'L79_PRESTATIONS_INNOVATION',\n",
    "        'MT_DEP_CONSEILS_CII': 'L80_DEPENSES_CONSEIL_INNOVATION',\n",
    "        'REMBST_SUBV_INO': 'L81_REMBOURSEMENTS_SUBVENTIONS_INNO',\n",
    "        'MT_NET_DEP_INO': 'L82A_MONTANT_NET_INNOVATION_DECLARE',\n",
    "        'LIGNE_82A_CALC': 'L82A_MONTANT_NET_INNOVATION_CALCULE',\n",
    "        'ECART_LIGNE_82A': 'L82A_ECART',\n",
    "        'MT_NET_DEP_INO_DOM': 'L82B_MONTANT_NET_INNOVATION_DOM',\n",
    "        'MT_NET_DEP_INO_MPE_CORSE': 'L82C_MONTANT_NET_INNOVATION_CORSE_MPE',\n",
    "        'MT_NET_DEP_INO_ME_CORSE': 'L82D_MONTANT_NET_INNOVATION_CORSE_ME',\n",
    "        'LIGNE_83_CALC': 'L83_CREDIT_IMPOT_INNOVATION',\n",
    "        'LIGNE_84': 'L84_QUOTE_PART_INNOVATION_SOC_PERSONNES',\n",
    "        'LIGNE_85A_CALC': 'L85A_TOTAL_CREDIT_IMPOT_INNOVATION',\n",
    "        'LIGNE_85B_CALC': 'L85B_CREDIT_IMPOT_INNOVATION_DOM',\n",
    "        'LIGNE_85C_CALC': 'L85C_CREDIT_IMPOT_INNOVATION_CORSE',\n",
    "        'LIGNE_86A_CALC': 'L86A_TOTAL_CIR_RECH_COLL_INNO',\n",
    "        'LIGNE_86B_CALC': 'L86B_TOTAL_CIR_RECH_COLL_INNO_DOM',\n",
    "\n",
    "        # Crédits d'impôt par composante\n",
    "        'MT_CIR_RECH_YC_QP': 'CIR_RECHERCHE_DECLARE',\n",
    "        'CIR_RECHERCHE_RECALCULE': 'CIR_RECHERCHE_CALCULE',\n",
    "        'ECART_CIR_RECHERCHE': 'CIR_RECHERCHE_ECART',\n",
    "\n",
    "        'MT_CI_COLL_APRS_MINIMI': 'CIR_COLLECTION_DECLARE',\n",
    "        'CIR_COLLECTION_RECALCULE': 'CIR_COLLECTION_CALCULE',\n",
    "        'ECART_CIR_COLLECTION': 'CIR_COLLECTION_ECART',\n",
    "\n",
    "        'MT_CII_YC_QP': 'CIR_INNOVATION_DECLARE',\n",
    "        'CIR_INNOVATION_RECALCULE': 'CIR_INNOVATION_CALCULE',\n",
    "        'ECART_CIR_INNOVATION': 'CIR_INNOVATION_ECART',\n",
    "\n",
    "        # CIR Total\n",
    "        'MT_TOT_CIR_CI_COLL_CII': 'CIR_TOTAL_DECLARE',\n",
    "        'CIR_TOTAL_RECALCULE': 'CIR_TOTAL_CALCULE',\n",
    "        'ECART_CIR': 'CIR_TOTAL_ECART',\n",
    "\n",
    "        # Indicateurs\n",
    "        'CORRESPONDANCE': 'CORRESPONDANCE_CIR',\n",
    "        'ECART_RELATIF': 'ECART_RELATIF_POURCENT'\n",
    "    }\n",
    "\n",
    "    # Création du DataFrame de comparaison\n",
    "    df_comparaison = pd.DataFrame()\n",
    "\n",
    "    # Copier chaque colonne si elle existe\n",
    "    for col_orig, col_dest in mapping_colonnes.items():\n",
    "        if col_orig in df_num.columns:\n",
    "            df_comparaison[col_dest] = df_num[col_orig]\n",
    "\n",
    "    # Concaténation de la désignation et du complément si disponible\n",
    "    if 'COMPLEMENT_DESIGNATION' in df_comparaison.columns:\n",
    "        df_comparaison['DESIGNATION'] = df_comparaison.apply(\n",
    "            lambda x: f\"{x['DESIGNATION']} {x['COMPLEMENT_DESIGNATION']}\" if pd.notna(x['COMPLEMENT_DESIGNATION']) else x['DESIGNATION'],\n",
    "            axis=1\n",
    "        )\n",
    "        df_comparaison.drop('COMPLEMENT_DESIGNATION', axis=1, inplace=True)\n",
    "\n",
    "    # Formatage des montants\n",
    "    montant_cols = [col for col in df_comparaison.columns if col not in ['SIREN_DECLARANT', 'SIREN_DEPOSANT', 'DESIGNATION', 'CORRESPONDANCE_CIR']]\n",
    "    for col in montant_cols:\n",
    "        df_comparaison[col] = df_comparaison[col].round(2)\n",
    "\n",
    "    # Sauvegarde du fichier de sortie\n",
    "    output_filename = f\"Calcul_Creance_CIR_2021.csv\"\n",
    "    output_path = os.path.join(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB\", output_filename)\n",
    "\n",
    "    df_comparaison.to_csv(output_path, index=False, sep=';', encoding='utf-8-sig')\n",
    "\n",
    "    print(f\"\\nFichier de comparaison détaillée créé: {output_path}\")\n",
    "\n",
    "    # RÉSULTATS\n",
    "\n",
    "    # Somme des CIR déclarés\n",
    "    cir_declare_total = df_tmp['MT_TOT_CIR_CI_COLL_CII'].sum()\n",
    "\n",
    "    # Somme des CIR recalculés\n",
    "    cir_recalcule_total = df_calc_final['CIR_TOTAL_RECALCULE'].sum()\n",
    "\n",
    "    # Nombre d'entreprises\n",
    "    nb_entreprises_avec_cir = len(df_tmp[df_tmp['MT_TOT_CIR_CI_COLL_CII'] > 0])\n",
    "    nb_entreprises_plus_100m = df_calc_final['DEPENSES_PLUS_100M'].sum()\n",
    "\n",
    "    # Classement des écarts\n",
    "    ecarts_positifs = df_num[df_num['ECART_CIR'] > 1]\n",
    "    ecarts_negatifs = df_num[df_num['ECART_CIR'] < -1]\n",
    "    ecarts_conformes = df_num[abs(df_num['ECART_CIR']) <= 1]\n",
    "\n",
    "    # AFFICHAGE DES RÉSULTATS\n",
    "    print(\"\\n===== COMPARAISON CIR DÉCLARÉ VS RECALCULÉ 2021 =====\")\n",
    "\n",
    "    print(f\"\\nNombre total d'entreprises analysées: {len(df_num):,}\")\n",
    "    print(f\"Nombre d'entreprises avec CIR déclaré: {nb_entreprises_avec_cir:,}\")\n",
    "    print(f\"Nombre d'entreprises avec dépenses > 100M€: {nb_entreprises_plus_100m:,}\")\n",
    "\n",
    "    print(f\"\\nCIR TOTAL:\")\n",
    "    print(f\"CIR déclaré total: {cir_declare_total:,.2f} €\")\n",
    "    print(f\"CIR recalculé total: {cir_recalcule_total:,.2f} €\")\n",
    "\n",
    "    difference = cir_recalcule_total - cir_declare_total\n",
    "    print(f\"Différence: {difference:,.2f} €\")\n",
    "    if cir_declare_total > 0:\n",
    "        print(f\"Écart relatif: {difference/cir_declare_total*100:.2f}%\")\n",
    "\n",
    "    print(f\"\\nANALYSE DES ÉCARTS:\")\n",
    "    print(f\"Entreprises avec CIR conforme (écart ≤ 1€): {len(ecarts_conformes):,} ({len(ecarts_conformes)/len(df_num)*100:.2f}%)\")\n",
    "\n",
    "    print(f\"Entreprises avec CIR recalculé > CIR déclaré (écart > 1€): {len(ecarts_positifs):,}\")\n",
    "    print(f\"Montant total des écarts positifs: {ecarts_positifs['ECART_CIR'].sum():,.2f} €\")\n",
    "\n",
    "    print(f\"Entreprises avec CIR recalculé < CIR déclaré (écart < -1€): {len(ecarts_negatifs):,}\")\n",
    "    print(f\"Montant total des écarts négatifs: {ecarts_negatifs['ECART_CIR'].sum():,.2f} €\")\n",
    "\n",
    "    # Détail par composante du CIR\n",
    "    print(f\"\\nDÉTAIL PAR COMPOSANTE DU CIR RECALCULÉ:\")\n",
    "    print(f\"CIR Recherche: {df_num['CIR_RECHERCHE_RECALCULE'].sum():,.2f} €\")\n",
    "    print(f\"CIR Collection: {df_num['CIR_COLLECTION_RECALCULE'].sum():,.2f} €\")\n",
    "\n",
    "    if 'CIR_INNOVATION_RECALCULE' in df_num.columns:\n",
    "        print(f\"CIR Innovation: {df_num['CIR_INNOVATION_RECALCULE'].sum():,.2f} €\")\n",
    "    else:\n",
    "        print(f\"CIR Innovation: 0.00 €\")\n",
    "\n",
    "    return df_comparaison\n",
    "\n",
    "# Exécuter le calcul\n",
    "try:\n",
    "    df_resultat = comparer_cir_declare_recalcule_2021()\n",
    "    print(\"\\nTraitement terminé avec succès!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nErreur: {type(e).__name__}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f90fb7",
   "metadata": {},
   "source": [
    "## Erreur depense personnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4d7617c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier CIR 2021 chargé: 4493 lignes\n",
      "Nombre de lignes à corriger: 2\n",
      "\n",
      "Résultats de la correction CIR 2021:\n",
      "Somme CIR_TOTAL_DECLARE: 43,074.00 €\n",
      "Somme CIR_TOTAL_CALCULE avant correction: 117,773.06 €\n",
      "Somme CIR_TOTAL_CALCULE après correction: 131,007.81 €\n",
      "Écart avant correction: 74,699.06 €\n",
      "Écart après correction: 87,933.81 €\n",
      "\n",
      "Nombre de correspondances après correction:\n",
      "  - Non: 2\n",
      "\n",
      "Détail par composante CIR recalculé (lignes corrigées):\n",
      "  - CIR Recherche: 48,305.73 €\n",
      "  - CIR Collection: 0.00 €\n",
      "  - CIR Innovation: 82,702.08 €\n",
      "  - TOTAL: 131,007.81 €\n",
      "\n",
      "Fichier CIR 2021 corrigé sauvegardé: M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//lignes_restantes_a_analyser_corrigees.csv\n",
      "\n",
      "Statistiques finales du fichier complet:\n",
      "  - Oui: 3,073 lignes\n",
      "  - Non: 1,420 lignes\n",
      "\n",
      "Améliorations apportées:\n",
      "  - Réduction de l'écart absolu: -13,234.75 € (-17.7%)\n",
      "\n",
      "Correction terminée pour le millésime 2021.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier original pour 2021\n",
    "df = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2021.csv\", sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier CIR 2021 chargé: {len(df)} lignes\")\n",
    "\n",
    "# Identifier les lignes concernées (ajout du critère correspondance)\n",
    "mask = (\n",
    "    (df['L3_DEPENSES_PERSONNEL_CHERCHEURS'] == 0.0) &\n",
    "    (df['L2_DOTATION_AMORT_SINISTR'] != 0.0) &\n",
    "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
    ")\n",
    "indices_to_update = df[mask].index\n",
    "print(f\"Nombre de lignes à corriger: {len(indices_to_update)}\")\n",
    "\n",
    "# Sauvegarder les valeurs originales pour analyse\n",
    "cir_calcule_avant = df.loc[indices_to_update, 'CIR_TOTAL_CALCULE'].copy()\n",
    "\n",
    "# Pour chaque ligne à corriger\n",
    "for idx in indices_to_update:\n",
    "    # 1. Transférer la valeur de dotation aux amortissements sinistrés vers dépenses de personnel\n",
    "    val_amort_sinistr = df.at[idx, 'L2_DOTATION_AMORT_SINISTR']\n",
    "    df.at[idx, 'L3_DEPENSES_PERSONNEL_CHERCHEURS'] = val_amort_sinistr\n",
    "    df.at[idx, 'L2_DOTATION_AMORT_SINISTR'] = 0.0\n",
    "\n",
    "    # 2. Recalculer la ligne 72 (autres dépenses de fonctionnement innovation - spécifique 2021)\n",
    "    if 'L72_AUTRES_DEPENSES_FONCT_INNOVATION' in df.columns:\n",
    "        dot_amort_immo_ino = df.at[idx, 'L70_DOTATION_AMORT_IMMO_INNOVATION']\n",
    "        dep_personnel_ino = df.at[idx, 'L71_DEPENSES_PERSONNEL_INNOVATION']\n",
    "        autres_dep_fonct_ino = (dot_amort_immo_ino * 0.75) + (dep_personnel_ino * 0.43)\n",
    "        df.at[idx, 'L72_AUTRES_DEPENSES_FONCT_INNOVATION'] = autres_dep_fonct_ino\n",
    "\n",
    "    # 3. Recalculer la ligne 6 (autres dépenses de fonctionnement recherche)\n",
    "    dot_amort_immo = df.at[idx, 'L1_DOTATION_AMORT_IMMO']\n",
    "    dep_cherch_tech = df.at[idx, 'L3_DEPENSES_PERSONNEL_CHERCHEURS']  # Nouvelle valeur\n",
    "    rem_sal_inv = df.at[idx, 'L4_REMUNERATION_INVENTEURS']\n",
    "    dep_jd = df.at[idx, 'L5_DEPENSES_JEUNES_DOCTEURS']\n",
    "\n",
    "    autres_dep_fonct = (dot_amort_immo * 0.75) + ((dep_cherch_tech + rem_sal_inv) * 0.43) + dep_jd\n",
    "    df.at[idx, 'L6_AUTRES_DEP_FONCT_CALCULE'] = autres_dep_fonct\n",
    "\n",
    "    # 4. Recalculer la ligne 7 (total dépenses de fonctionnement)\n",
    "    total_dep_fonct = dot_amort_immo + 0.0 + dep_cherch_tech + rem_sal_inv + dep_jd + autres_dep_fonct\n",
    "    df.at[idx, 'L7_TOTAL_DEP_FONCT_CALCULE'] = total_dep_fonct\n",
    "\n",
    "    # 5. Recalculer la ligne 14 (total dépenses internes)\n",
    "    frais_brev_cov = df.at[idx, 'L8_FRAIS_BREVETS_COV']\n",
    "    dep_maint_brev_cov = df.at[idx, 'L9_DEPENSES_DEFENSE_BREVETS']\n",
    "    dot_amort_brev = df.at[idx, 'L10_DOTATION_AMORT_BREVETS']\n",
    "    dep_normali = df.at[idx, 'L11_DEPENSES_NORMALISATION']\n",
    "    \n",
    "    # Plafonnements spécifiques 2021\n",
    "    prim_cotiz_brut = df.at[idx, 'L12_PRIMES_COTISATIONS_BRUT'] if 'L12_PRIMES_COTISATIONS_BRUT' in df.columns else 0\n",
    "    prim_cotiz = min(prim_cotiz_brut, 60000)\n",
    "    \n",
    "    dep_veil_techno_brut = df.at[idx, 'L13_VEILLE_TECHNO_BRUT'] if 'L13_VEILLE_TECHNO_BRUT' in df.columns else 0\n",
    "    dep_veil_techno = min(dep_veil_techno_brut, 60000)\n",
    "\n",
    "    total_dep_internes = total_dep_fonct + frais_brev_cov + dep_maint_brev_cov + dot_amort_brev + dep_normali + prim_cotiz + dep_veil_techno\n",
    "    df.at[idx, 'L14_TOTAL_DEPENSES_INTERNES_CALCULE'] = total_dep_internes\n",
    "\n",
    "    # 6. Recalculer la ligne 27 (total dépenses de recherche) - 2021 utilise L26 pour ST plafonnée\n",
    "    total_dep_st_plafonnee = df.at[idx, 'L26_TOTAL_ST_PLAFONNE_CALCULE'] if 'L26_TOTAL_ST_PLAFONNE_CALCULE' in df.columns else 0\n",
    "    total_dep_recherche = total_dep_internes + total_dep_st_plafonnee\n",
    "    df.at[idx, 'L27_TOTAL_DEPENSES_RECHERCHE_CALCULE'] = total_dep_recherche\n",
    "\n",
    "    # 7. Recalculer la ligne 31A (montant net des dépenses)\n",
    "    mt_aid_subv = df.at[idx, 'L28A_SUBVENTIONS'] if 'L28A_SUBVENTIONS' in df.columns else 0\n",
    "    mt_enc_presta = df.at[idx, 'L28B_SOMMES_ENCAISSEES_TIERS'] if 'L28B_SOMMES_ENCAISSEES_TIERS' in df.columns else 0\n",
    "    mt_dep_conseils_cir = df.at[idx, 'L29_DEPENSES_CONSEIL_CIR'] if 'L29_DEPENSES_CONSEIL_CIR' in df.columns else 0\n",
    "    rembst_subv = df.at[idx, 'L30_REMBOURSEMENTS_SUBVENTIONS'] if 'L30_REMBOURSEMENTS_SUBVENTIONS' in df.columns else 0\n",
    "\n",
    "    montant_net = total_dep_recherche - mt_aid_subv - mt_enc_presta - mt_dep_conseils_cir + rembst_subv\n",
    "    df.at[idx, 'L31A_MONTANT_NET_DEPENSES_CALCULE'] = montant_net\n",
    "\n",
    "    # 8. Recalculer le CIR recherche (avec gestion DOM/non-DOM pour 2021)\n",
    "    montant_net_dom = df.at[idx, 'L31B_MONTANT_NET_DEPENSES_DOM_CALCULE'] if 'L31B_MONTANT_NET_DEPENSES_DOM_CALCULE' in df.columns else 0\n",
    "    \n",
    "    # Taux 2021 : 30% métropole, 50% DOM\n",
    "    taux_dom = 0.50\n",
    "    taux_non_dom = 0.30\n",
    "    \n",
    "    if montant_net_dom > 0:\n",
    "        montant_net_non_dom = max(0, montant_net - montant_net_dom)\n",
    "        cir_recherche = (montant_net_non_dom * taux_non_dom) + (montant_net_dom * taux_dom)\n",
    "    else:\n",
    "        cir_recherche = montant_net * taux_non_dom\n",
    "    \n",
    "    # S'assurer que le CIR recherche n'est pas négatif\n",
    "    cir_recherche = max(0, cir_recherche)\n",
    "    df.at[idx, 'CIR_RECHERCHE_CALCULE'] = cir_recherche\n",
    "\n",
    "    # 9. Recalculer le CIR total (sans CRC pour 2021)\n",
    "    cir_collection = df.at[idx, 'CIR_COLLECTION_CALCULE'] if 'CIR_COLLECTION_CALCULE' in df.columns else 0\n",
    "    cir_innovation = df.at[idx, 'CIR_INNOVATION_CALCULE'] if 'CIR_INNOVATION_CALCULE' in df.columns else 0\n",
    "    \n",
    "    # Pas de CRC en 2021\n",
    "    cir_total = cir_recherche + cir_collection + cir_innovation\n",
    "    \n",
    "    # S'assurer que le CIR total n'est pas négatif\n",
    "    cir_total = max(0, cir_total)\n",
    "    df.at[idx, 'CIR_TOTAL_CALCULE'] = cir_total\n",
    "\n",
    "    # 10. Recalculer l'écart et mettre à jour la correspondance\n",
    "    cir_declare = df.at[idx, 'CIR_TOTAL_DECLARE']\n",
    "    ecart_cir = cir_total - cir_declare\n",
    "    df.at[idx, 'CIR_TOTAL_ECART'] = ecart_cir\n",
    "    \n",
    "    # Écart relatif\n",
    "    if abs(cir_declare) > 0.01:\n",
    "        ecart_relatif = (ecart_cir / cir_declare) * 100\n",
    "    else:\n",
    "        ecart_relatif = 100 if ecart_cir > 0 else 0\n",
    "    df.at[idx, 'ECART_RELATIF_POURCENT'] = ecart_relatif\n",
    "    \n",
    "    # Correspondance (seuil de tolérance de 1€)\n",
    "    df.at[idx, 'CORRESPONDANCE_CIR'] = \"Oui\" if abs(ecart_cir) <= 1 else \"Non\"\n",
    "\n",
    "# Afficher les résultats\n",
    "somme_declare = df.loc[indices_to_update, 'CIR_TOTAL_DECLARE'].sum()\n",
    "somme_calcule_avant = cir_calcule_avant.sum()\n",
    "somme_calcule_apres = df.loc[indices_to_update, 'CIR_TOTAL_CALCULE'].sum()\n",
    "\n",
    "print(f\"\\nRésultats de la correction CIR 2021:\")\n",
    "print(f\"Somme CIR_TOTAL_DECLARE: {somme_declare:,.2f} €\")\n",
    "print(f\"Somme CIR_TOTAL_CALCULE avant correction: {somme_calcule_avant:,.2f} €\")\n",
    "print(f\"Somme CIR_TOTAL_CALCULE après correction: {somme_calcule_apres:,.2f} €\")\n",
    "print(f\"Écart avant correction: {somme_calcule_avant - somme_declare:,.2f} €\")\n",
    "print(f\"Écart après correction: {somme_calcule_apres - somme_declare:,.2f} €\")\n",
    "\n",
    "# Vérifier le nombre de correspondances après correction\n",
    "nouvelles_correspondances = df.loc[indices_to_update, 'CORRESPONDANCE_CIR'].value_counts()\n",
    "print(f\"\\nNombre de correspondances après correction:\")\n",
    "for correspondance, count in nouvelles_correspondances.items():\n",
    "    print(f\"  - {correspondance}: {count}\")\n",
    "\n",
    "# Détail par composante CIR après correction\n",
    "if len(indices_to_update) > 0:\n",
    "    print(f\"\\nDétail par composante CIR recalculé (lignes corrigées):\")\n",
    "    total_recherche = df.loc[indices_to_update, 'CIR_RECHERCHE_CALCULE'].sum()\n",
    "    total_collection = df.loc[indices_to_update, 'CIR_COLLECTION_CALCULE'].sum() if 'CIR_COLLECTION_CALCULE' in df.columns else 0\n",
    "    total_innovation = df.loc[indices_to_update, 'CIR_INNOVATION_CALCULE'].sum() if 'CIR_INNOVATION_CALCULE' in df.columns else 0\n",
    "    \n",
    "    print(f\"  - CIR Recherche: {total_recherche:,.2f} €\")\n",
    "    print(f\"  - CIR Collection: {total_collection:,.2f} €\")\n",
    "    print(f\"  - CIR Innovation: {total_innovation:,.2f} €\")\n",
    "    print(f\"  - TOTAL: {total_recherche + total_collection + total_innovation:,.2f} €\")\n",
    "\n",
    "# Sauvegarder le fichier corrigé pour 2021\n",
    "output_filename = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//lignes_restantes_a_analyser_corrigees.csv\"\n",
    "df.to_csv(output_filename, sep=';', encoding='utf-8-sig', index=False)\n",
    "print(f\"\\nFichier CIR 2021 corrigé sauvegardé: {output_filename}\")\n",
    "\n",
    "# Statistiques finales\n",
    "total_correspondances_finales = df['CORRESPONDANCE_CIR'].value_counts()\n",
    "print(f\"\\nStatistiques finales du fichier complet:\")\n",
    "for correspondance, count in total_correspondances_finales.items():\n",
    "    print(f\"  - {correspondance}: {count:,} lignes\")\n",
    "\n",
    "print(f\"\\nAméliorations apportées:\")\n",
    "ecart_avant = abs(somme_calcule_avant - somme_declare)\n",
    "ecart_apres = abs(somme_calcule_apres - somme_declare)\n",
    "if ecart_avant > 0:\n",
    "    reduction_ecart = ((ecart_avant - ecart_apres) / ecart_avant) * 100\n",
    "    print(f\"  - Réduction de l'écart absolu: {ecart_avant - ecart_apres:,.2f} € ({reduction_ecart:.1f}%)\")\n",
    "else:\n",
    "    print(f\"  - Écart initial déjà nul\")\n",
    "\n",
    "print(f\"\\nCorrection terminée pour le millésime 2021.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6fa61a",
   "metadata": {},
   "source": [
    "### mise à jour ligne restante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffdd2333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier chargé: 4493 lignes\n",
      "Nombre de lignes après filtrage: 2\n",
      "Somme CIR_TOTAL_DECLARE : 43,074.00 €\n",
      "Somme CIR_TOTAL_CALCULE : 117,773.06 €\n",
      "Résultats exportés dans: lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\n",
      "\n",
      "Aperçu des données trouvées:\n",
      "Nombre d'entreprises: 2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier\n",
    "df = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2021.csv\", sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier chargé: {len(df)} lignes\")\n",
    "\n",
    "# Appliquer les filtres :\n",
    "# - L5_DEPENSES_JEUNES_DOCTEURS = 0.0\n",
    "# - L2_DOTATION_AMORT_SINISTR différent de 0.0\n",
    "df_filtered = df[\n",
    "    (df['L3_DEPENSES_PERSONNEL_CHERCHEURS'] == 0.0) &\n",
    "    (df['L2_DOTATION_AMORT_SINISTR'] != 0.0) &\n",
    "    (df['CORRESPONDANCE_CIR'] == \"Non\") \n",
    "]\n",
    "\n",
    "print(f\"Nombre de lignes après filtrage: {len(df_filtered)}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\"\n",
    "df_filtered.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "# Calculer les sommes\n",
    "somme_declare = df_filtered['CIR_TOTAL_DECLARE'].sum()\n",
    "somme_calcule = df_filtered['CIR_TOTAL_CALCULE'].sum()\n",
    "\n",
    "print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
    "print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
    "print(f\"Résultats exportés dans: {output_file}\")\n",
    "\n",
    "# Afficher quelques statistiques sur les lignes trouvées\n",
    "if len(df_filtered) > 0:\n",
    "    print(\"\\nAperçu des données trouvées:\")\n",
    "    print(f\"Nombre d'entreprises: {len(df_filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24aa1020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier principal chargé: 4493 lignes\n",
      "\n",
      "Nombre de lignes restantes à analyser: 1418\n",
      "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier principal\n",
    "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2021.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
    "\n",
    "# Charger les fichiers d'analyse précédents\n",
    "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')  # Nouveau fichier\n",
    "\n",
    "# Identifier les SIREN à exclure\n",
    "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT'])  # Nouveau set\n",
    "\n",
    "# Combiner tous les SIREN à exclure\n",
    "siren_a_exclure =  siren_jeunes_docteurs  # Ajout du nouveau set\n",
    "\n",
    "# Filtrer le DataFrame principal\n",
    "# - Exclure les SIREN déjà analysés\n",
    "# - Garder uniquement les lignes où CORRESPONDANCE_CIR est \"Non\"\n",
    "df_restant = df[\n",
    "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) & \n",
    "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
    "]\n",
    "\n",
    "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_restantes_a_analyser.csv\"\n",
    "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf31ede8",
   "metadata": {},
   "source": [
    "## Erreur DEP Fonctionnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6c325fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier chargé: 1418 lignes\n",
      "Nombre de lignes à corriger: 0\n",
      "\n",
      "Résumé des corrections :\n",
      "Somme L7_TOTAL_DEP_FONCT_DECLARE avant correction: 0.00 €\n",
      "Somme L7_TOTAL_DEP_FONCT_CALCULE après correction: 0.00 €\n",
      "Différence sur L7: 0.00 €\n",
      "\n",
      "Impact sur le CIR :\n",
      "Somme CIR_TOTAL_DECLARE: 0.00 €\n",
      "Somme CIR_TOTAL_CALCULE avant correction: 0.00 €\n",
      "Somme CIR_TOTAL_CALCULE après correction: 0.00 €\n",
      "Écart avant correction: 0.00 €\n",
      "Écart après correction: 0.00 €\n",
      "Amélioration de l'écart: 0.00 €\n",
      "\n",
      "Nombre de lignes où la correspondance est passée de 'Non' à 'Oui': 0\n",
      "\n",
      "Fichier corrigé sauvegardé: lignes_restantes_a_analyser_corrigees_L7L8.csv\n",
      "\n",
      "Exemples de modifications significatives:\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier original\n",
    "file_path = \"lignes_restantes_a_analyser.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier chargé: {len(df)} lignes\")\n",
    "\n",
    "# Identifier les lignes à corriger\n",
    "mask = (df['L7_TOTAL_DEP_FONCT_DECLARE'] == df['L8_FRAIS_BREVETS_COV']) & (df['L7_TOTAL_DEP_FONCT_DECLARE'] != 0.0)\n",
    "indices_to_update = df[mask].index\n",
    "print(f\"Nombre de lignes à corriger: {len(indices_to_update)}\")\n",
    "\n",
    "# Sauvegarder les valeurs originales pour analyse\n",
    "cir_calcule_avant = df.loc[indices_to_update, 'CIR_TOTAL_CALCULE'].copy()\n",
    "l7_original = df.loc[indices_to_update, 'L7_TOTAL_DEP_FONCT_DECLARE'].copy()\n",
    "\n",
    "# Pour chaque ligne à corriger\n",
    "for idx in indices_to_update:\n",
    "    # 1. Calculer correctement le montant de la ligne 7 (total dépenses de fonctionnement)\n",
    "    dot_amort_immo = df.at[idx, 'L1_DOTATION_AMORT_IMMO']\n",
    "    dot_amort_sinistr = df.at[idx, 'L2_DOTATION_AMORT_SINISTR']\n",
    "    dep_cherch_tech = df.at[idx, 'L3_DEPENSES_PERSONNEL_CHERCHEURS']\n",
    "    rem_sal_inv = df.at[idx, 'L4_REMUNERATION_INVENTEURS']\n",
    "    dep_jd = df.at[idx, 'L5_DEPENSES_JEUNES_DOCTEURS']\n",
    "\n",
    "    # Calculer L6 si nécessaire\n",
    "    autres_dep_fonct = (dot_amort_immo * 0.75) + ((dep_cherch_tech + rem_sal_inv) * 0.43) + dep_jd\n",
    "\n",
    "    # Mettre à jour L6 calculé\n",
    "    df.at[idx, 'L6_AUTRES_DEP_FONCT_CALCULE'] = autres_dep_fonct\n",
    "\n",
    "    # Calculer le vrai montant de L7\n",
    "    total_dep_fonct = dot_amort_immo + dot_amort_sinistr + dep_cherch_tech + rem_sal_inv + dep_jd + autres_dep_fonct\n",
    "\n",
    "    # 2. Mettre à jour L7\n",
    "    df.at[idx, 'L7_TOTAL_DEP_FONCT_CALCULE'] = total_dep_fonct # laisser L7 tel quel (inchangé)\n",
    "\n",
    "    # Garder L8_FRAIS_BREVETS_COV tel quel (inchangé)\n",
    "    frais_brev_cov = df.at[idx, 'L8_FRAIS_BREVETS_COV'] # mettre à 0\n",
    "\n",
    "    # 3. Recalculer la ligne 14 (total dépenses internes)\n",
    "    dep_maint_brev_cov = df.at[idx, 'L9_DEPENSES_DEFENSE_BREVETS']\n",
    "    dot_amort_brev = df.at[idx, 'L10_DOTATION_AMORT_BREVETS']\n",
    "    dep_normali = df.at[idx, 'L11_DEPENSES_NORMALISATION_DECLARE']\n",
    "    prim_cotiz = df.at[idx, 'L12_PRIMES_COTISATIONS_PLAFONNEES']\n",
    "    dep_veil_techno = df.at[idx, 'L13_VEILLE_TECHNO_PLAFONNEE']\n",
    "\n",
    "    total_dep_internes = total_dep_fonct + frais_brev_cov + dep_maint_brev_cov + dot_amort_brev + dep_normali + prim_cotiz + dep_veil_techno\n",
    "    df.at[idx, 'L14_TOTAL_DEPENSES_INTERNES_CALCULE'] = total_dep_internes\n",
    "\n",
    "    # 4. Recalculer la ligne 22 (total dépenses de recherche)\n",
    "    total_dep_ext = df.at[idx, 'L21_TOTAL_DEP_EXT_PLAFONNEES_CALCULE']\n",
    "    total_dep_recherche = total_dep_internes + total_dep_ext\n",
    "    df.at[idx, 'L22_TOTAL_DEPENSES_RECHERCHE_CALCULE'] = total_dep_recherche\n",
    "\n",
    "    # 5. Recalculer la ligne 26A (montant net des dépenses)\n",
    "    mt_aid_subv = df.at[idx, 'L23A_SUBVENTIONS']\n",
    "    mt_enc_presta = df.at[idx, 'L23B_SOMMES_ENCAISSEES_TIERS']\n",
    "    mt_dep_conseils_cir = df.at[idx, 'L24_DEPENSES_CONSEIL_CIR']\n",
    "    rembst_subv = df.at[idx, 'L25_REMBOURSEMENTS_SUBVENTIONS']\n",
    "\n",
    "    montant_net = total_dep_recherche - mt_aid_subv - mt_enc_presta - mt_dep_conseils_cir + rembst_subv\n",
    "    df.at[idx, 'L26A_MONTANT_NET_DEPENSES_CALCULE'] = montant_net\n",
    "\n",
    "    # 6. Récupérer le montant DOM pour le calcul du CIR\n",
    "    montant_net_dom = df.at[idx, 'L26B_MONTANT_NET_DEPENSES_DOM_CALCULE']\n",
    "\n",
    "    # 7. Recalculer le CIR recherche (30% ou 50% selon localisation)\n",
    "    cir_recherche = ((montant_net - montant_net_dom) * 0.30) + (montant_net_dom * 0.50)\n",
    "    df.at[idx, 'CIR_RECHERCHE_CALCULE'] = cir_recherche\n",
    "\n",
    "    # 8. Recalculer le CIR total\n",
    "    cir_collection = df.at[idx, 'CIR_COLLECTION_CALCULE']\n",
    "    cir_innovation = df.at[idx, 'CIR_INNOVATION_CALCULE']\n",
    "    cir_collaboratif = df.at[idx, 'CIR_COLLABORATIF_CALCULE']\n",
    "\n",
    "    cir_total = cir_recherche + cir_collection + cir_innovation + cir_collaboratif\n",
    "    df.at[idx, 'CIR_TOTAL_CALCULE'] = cir_total\n",
    "\n",
    "    # 9. Recalculer l'écart et mettre à jour la correspondance\n",
    "    ecart_cir = cir_total - df.at[idx, 'CIR_TOTAL_DECLARE']\n",
    "    df.at[idx, 'CIR_TOTAL_ECART'] = ecart_cir\n",
    "    df.at[idx, 'CORRESPONDANCE_CIR'] = \"Oui\" if abs(ecart_cir) <= 1 else \"Non\"\n",
    "\n",
    "# Afficher le résumé des modifications\n",
    "l7_corrige = df.loc[indices_to_update, 'L7_TOTAL_DEP_FONCT_CALCULE']\n",
    "somme_declare = df.loc[indices_to_update, 'CIR_TOTAL_DECLARE'].sum()\n",
    "somme_calcule_avant = cir_calcule_avant.sum()\n",
    "somme_calcule_apres = df.loc[indices_to_update, 'CIR_TOTAL_CALCULE'].sum()\n",
    "\n",
    "print(f\"\\nRésumé des corrections :\")\n",
    "print(f\"Somme L7_TOTAL_DEP_FONCT_DECLARE avant correction: {l7_original.sum():,.2f} €\")\n",
    "print(f\"Somme L7_TOTAL_DEP_FONCT_CALCULE après correction: {l7_corrige.sum():,.2f} €\")\n",
    "print(f\"Différence sur L7: {l7_corrige.sum() - l7_original.sum():,.2f} €\")\n",
    "\n",
    "print(f\"\\nImpact sur le CIR :\")\n",
    "print(f\"Somme CIR_TOTAL_DECLARE: {somme_declare:,.2f} €\")\n",
    "print(f\"Somme CIR_TOTAL_CALCULE avant correction: {somme_calcule_avant:,.2f} €\")\n",
    "print(f\"Somme CIR_TOTAL_CALCULE après correction: {somme_calcule_apres:,.2f} €\")\n",
    "print(f\"Écart avant correction: {somme_calcule_avant - somme_declare:,.2f} €\")\n",
    "print(f\"Écart après correction: {somme_calcule_apres - somme_declare:,.2f} €\")\n",
    "print(f\"Amélioration de l'écart: {abs(somme_calcule_avant - somme_declare) - abs(somme_calcule_apres - somme_declare):,.2f} €\")\n",
    "\n",
    "# Compter les lignes où la correspondance s'est améliorée\n",
    "count_improved = 0\n",
    "for idx in indices_to_update:\n",
    "    if df.at[idx, 'CORRESPONDANCE_CIR'] == \"Oui\" and abs(cir_calcule_avant[idx] - df.at[idx, 'CIR_TOTAL_DECLARE']) > 1:\n",
    "        count_improved += 1\n",
    "\n",
    "print(f\"\\nNombre de lignes où la correspondance est passée de 'Non' à 'Oui': {count_improved}\")\n",
    "\n",
    "# Sauvegarder le fichier corrigé\n",
    "df.to_csv(\"lignes_restantes_a_analyser_corrigees_L7L8.csv\", sep=';', encoding='utf-8-sig', index=False)\n",
    "print(f\"\\nFichier corrigé sauvegardé: lignes_restantes_a_analyser_corrigees_L7L8.csv\")\n",
    "\n",
    "# Afficher des exemples de modifications\n",
    "print(\"\\nExemples de modifications significatives:\")\n",
    "# Calculer l'impact en pourcentage sur le CIR\n",
    "df_impact = pd.DataFrame({\n",
    "    'SIREN': df.loc[indices_to_update, 'SIREN_DECLARANT'],\n",
    "    'Désignation': df.loc[indices_to_update, 'DESIGNATION'],\n",
    "    'L7 avant': l7_original,\n",
    "    'L7 après': l7_corrige,\n",
    "    'CIR avant': cir_calcule_avant,\n",
    "    'CIR après': df.loc[indices_to_update, 'CIR_TOTAL_CALCULE'],\n",
    "    'Impact': abs(df.loc[indices_to_update, 'CIR_TOTAL_CALCULE'] - cir_calcule_avant)\n",
    "})\n",
    "\n",
    "# Afficher les 5 cas avec le plus grand impact en valeur absolue\n",
    "for _, row in df_impact.sort_values('Impact', ascending=False).head(5).iterrows():\n",
    "    print(f\"SIREN: {row['SIREN']}\")\n",
    "    print(f\"  Désignation: {row['Désignation']}\")\n",
    "    print(f\"  L7 avant: {row['L7 avant']:,.2f} €\")\n",
    "    print(f\"  L7 après: {row['L7 après']:,.2f} €\")\n",
    "    print(f\"  CIR avant: {row['CIR avant']:,.2f} €\")\n",
    "    print(f\"  CIR après: {row['CIR après']:,.2f} €\")\n",
    "    print(f\"  Impact: {row['Impact']:,.2f} € ({row['Impact']/row['CIR avant']*100 if row['CIR avant'] != 0 else 0:.2f}%)\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28e2280",
   "metadata": {},
   "source": [
    "### ligne liée au erreur dep fonctionnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "899a3c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier chargé: 1418 lignes\n",
      "Nombre de lignes où L7_TOTAL_DEP_FONCT_DECLARE = L8_FRAIS_BREVETS_COV: 0\n",
      "Somme CIR_TOTAL_DECLARE : 0.00 €\n",
      "Somme CIR_TOTAL_CALCULE : 0.00 €\n",
      "Résultats exportés dans: lignes_L7_egal_L8.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier des lignes restantes\n",
    "file_path = \"lignes_restantes_a_analyser.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier chargé: {len(df)} lignes\")\n",
    "\n",
    "# Filtrer les lignes où L7_TOTAL_DEP_FONCT_DECLARE = L8_FRAIS_BREVETS_COV\n",
    "df_filtered = df[(df['L7_TOTAL_DEP_FONCT_DECLARE'] == df['L8_FRAIS_BREVETS_COV']) & (df['L7_TOTAL_DEP_FONCT_DECLARE'] != 0.0)]\n",
    "\n",
    "print(f\"Nombre de lignes où L7_TOTAL_DEP_FONCT_DECLARE = L8_FRAIS_BREVETS_COV: {len(df_filtered)}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_L7_egal_L8.csv\"\n",
    "df_filtered.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "# Calculer les sommes\n",
    "somme_declare = df_filtered['CIR_TOTAL_DECLARE'].sum()\n",
    "somme_calcule = df_filtered['CIR_TOTAL_CALCULE'].sum()\n",
    "\n",
    "print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
    "print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6cf7779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier principal chargé: 4493 lignes\n",
      "\n",
      "Nombre de lignes restantes à analyser: 1418\n",
      "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier principal\n",
    "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2021.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
    "\n",
    "# Charger les fichiers d'analyse précédents\n",
    "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')  # Nouveau fichier\n",
    "l7_egal_l8 = pd.read_csv(\"lignes_L7_egal_L8.csv\", sep=';', encoding='utf-8-sig')\n",
    "\n",
    "# Identifier les SIREN à exclure\n",
    "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT']) \n",
    "siren_l7_l8 = set(l7_egal_l8['SIREN_DECLARANT'])\n",
    "\n",
    "# Combiner tous les SIREN à exclure\n",
    "siren_a_exclure =  siren_jeunes_docteurs | siren_l7_l8 \n",
    "\n",
    "# Filtrer le DataFrame principal\n",
    "# - Exclure les SIREN déjà analysés\n",
    "# - Garder uniquement les lignes où CORRESPONDANCE_CIR est \"Non\"\n",
    "df_restant = df[\n",
    "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) & \n",
    "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
    "]\n",
    "\n",
    "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_restantes_a_analyser.csv\"\n",
    "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9368e9",
   "metadata": {},
   "source": [
    "## Erreur Cir Recherche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ee8e342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier chargé: 1418 lignes\n",
      "Nombre de lignes après filtrage: 934\n",
      "Somme CIR_TOTAL_DECLARE : 434,828,912.00 €\n",
      "Somme CIR_TOTAL_CALCULE : 429,530,660.55 €\n",
      "Résultats exportés dans: lignes_depenses_non0_cir_recherche_0_2021.csv\n",
      "\n",
      "Aperçu des données trouvées:\n",
      "Nombre d'entreprises: 934\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier\n",
    "df = pd.read_csv(\"lignes_restantes_a_analyser.csv\", sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier chargé: {len(df)} lignes\")\n",
    "\n",
    "# Appliquer les filtres :\n",
    "# - L27_TOTAL_DEPENSES_RECHERCHE_DECLARE différent de 0.0\n",
    "# - CIR_RECHERCHE_DECLARE = 0.0\n",
    "df_filtered = df[\n",
    "    (df['L27_TOTAL_DEPENSES_RECHERCHE_DECLARE'] != 0.0) &\n",
    "    (df['CIR_RECHERCHE_DECLARE'] == 0.0)\n",
    "]\n",
    "\n",
    "print(f\"Nombre de lignes après filtrage: {len(df_filtered)}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_depenses_non0_cir_recherche_0_2021.csv\"\n",
    "df_filtered.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "# Calculer les sommes\n",
    "somme_declare = df_filtered['CIR_TOTAL_DECLARE'].sum()\n",
    "somme_calcule = df_filtered['CIR_TOTAL_CALCULE'].sum()\n",
    "\n",
    "print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
    "print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
    "print(f\"Résultats exportés dans: {output_file}\")\n",
    "\n",
    "# Afficher quelques statistiques sur les lignes trouvées\n",
    "if len(df_filtered) > 0:\n",
    "    print(\"\\nAperçu des données trouvées:\")\n",
    "    print(f\"Nombre d'entreprises: {len(df_filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78508163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier principal chargé: 4493 lignes\n",
      "\n",
      "Nombre de lignes restantes à analyser: 1418\n",
      "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier principal\n",
    "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2021.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
    "\n",
    "# Charger les fichiers d'analyse précédents\n",
    "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')\n",
    "l7_egal_l8 = pd.read_csv(\"lignes_L7_egal_L8.csv\", sep=';', encoding='utf-8-sig')\n",
    "depenses_non0_cir0 = pd.read_csv(\"lignes_depenses_non0_cir_recherche_0.csv\", sep=';', encoding='utf-8-sig')\n",
    "\n",
    "# Identifier les SIREN à exclure\n",
    "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT'])\n",
    "siren_l7_l8 = set(l7_egal_l8['SIREN_DECLARANT'])\n",
    "siren_depenses_non0_cir0 = set(depenses_non0_cir0['SIREN_DECLARANT'])\n",
    "\n",
    "# Combiner tous les SIREN à exclure (ajout du nouveau cas)\n",
    "siren_a_exclure = siren_jeunes_docteurs | siren_l7_l8  | siren_depenses_non0_cir0\n",
    "\n",
    "# Filtrer le DataFrame principal\n",
    "df_restant = df[\n",
    "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) &\n",
    "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
    "]\n",
    "\n",
    "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_restantes_a_analyser.csv\"\n",
    "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6663c48a",
   "metadata": {},
   "source": [
    "## Erreur depense Externalisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "242f8c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier chargé: 1418 lignes\n",
      "Nombre de lignes extraites: 0\n",
      "Lignes exportées dans: lignes_ecart_cir_recherche_externalise.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Chemin du fichier\n",
    "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//lignes_restantes_a_analyser.csv\"\n",
    "\n",
    "# Charger le fichier\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier chargé: {len(df)} lignes\")\n",
    "\n",
    "# Colonnes d'écart pour les dépenses de sous-traitance (2021)\n",
    "colonnes_ext = ['L17_ECART', 'L20_ECART', 'L21_ECART', 'L22_ECART', 'L26_ECART']\n",
    "\n",
    "# Extraire les lignes qui répondent à tous les critères\n",
    "mask_correspondance = df['CORRESPONDANCE_CIR'] == \"Non\"\n",
    "mask_cir = df['CIR_RECHERCHE_ECART'] != 0\n",
    "mask_ext = df[colonnes_ext].abs().sum(axis=1) > 0\n",
    "\n",
    "# Combiner tous les filtres\n",
    "df_resultat = df[mask_correspondance & mask_cir & mask_ext]\n",
    "\n",
    "print(f\"Nombre de lignes extraites: {len(df_resultat)}\")\n",
    "\n",
    "# Exporter vers un fichier CSV\n",
    "output_file = \"lignes_ecart_cir_recherche_externalise.csv\"\n",
    "df_resultat.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "print(f\"Lignes exportées dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "907b8286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier chargé: 0 lignes\n",
      "\n",
      "Résultats de l'analyse:\n",
      "- Nombre de lignes où L31A_ECART = CIR_TOTAL_ECART / 3: 0 sur 0\n",
      "- Pourcentage: nan%\n",
      "\n",
      "Exemples où L31A_ECART = CIR_TOTAL_ECART / 3:\n",
      "\n",
      "Exemples où L31A_ECART ≠ CIR_TOTAL_ECART / 3:\n",
      "\n",
      "Résultats détaillés exportés dans: analyse_L31A_vs_CIR_TOTAL.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_928\\700265953.py:20: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  pourcentage = (nb_egal / len(df)) * 100\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier CSV généré précédemment\n",
    "fichier = \"lignes_ecart_cir_recherche_externalise.csv\"\n",
    "df = pd.read_csv(fichier, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier chargé: {len(df)} lignes\")\n",
    "\n",
    "# Convertir les colonnes en numérique pour s'assurer que les calculs seront corrects\n",
    "df['L31A_ECART'] = pd.to_numeric(df['L31A_ECART'], errors='coerce')\n",
    "df['CIR_TOTAL_ECART'] = pd.to_numeric(df['CIR_TOTAL_ECART'], errors='coerce')\n",
    "\n",
    "# Créer une colonne pour vérifier si L31A_ECART = CIR_TOTAL_ECART / 0.3\n",
    "# Permettre une petite marge d'erreur pour les arrondis (0.1%)\n",
    "df['RATIO'] = df['L31A_ECART'] / (df['CIR_TOTAL_ECART'] / 0.3)\n",
    "df['EST_EGAL'] = np.isclose(df['RATIO'], 1, rtol=1)  # Tolérance relative de 0.1%\n",
    "\n",
    "# Compter combien de lignes respectent cette relation\n",
    "nb_egal = df['EST_EGAL'].sum()\n",
    "pourcentage = (nb_egal / len(df)) * 100\n",
    "\n",
    "print(f\"\\nRésultats de l'analyse:\")\n",
    "print(f\"- Nombre de lignes où L31A_ECART = CIR_TOTAL_ECART / 3: {nb_egal} sur {len(df)}\")\n",
    "print(f\"- Pourcentage: {pourcentage:.2f}%\")\n",
    "\n",
    "# Afficher quelques exemples où la relation est respectée\n",
    "print(\"\\nExemples où L31A_ECART = CIR_TOTAL_ECART / 3:\")\n",
    "exemples_egal = df[df['EST_EGAL']].head(5)\n",
    "for _, row in exemples_egal.iterrows():\n",
    "    print(f\"SIREN: {row['SIREN_DECLARANT']}, L31A_ECART: {row['L31A_ECART']}, CIR_TOTAL_ECART/3: {row['CIR_TOTAL_ECART']/3}\")\n",
    "    # Filtrer uniquement les lignes où L31A_ECART = CIR_TOTAL_ECART / 3 est vrai\n",
    "    df_resultat = df[df['EST_EGAL']]\n",
    "\n",
    "    # Afficher le nombre de lignes correspondantes\n",
    "    print(f\"Nombre de lignes où L31A_ECART = CIR_TOTAL_ECART / 3: {len(df_resultat)}\")\n",
    "\n",
    "    # Exporter les résultats filtrés dans un fichier CSV\n",
    "    df_resultat.to_csv(\"lignes_L31A_egal_CIR_TOTAL_div_3.csv\", sep=';', encoding='utf-8-sig', index=False)\n",
    "    # Calculer les sommes\n",
    "    somme_declare = df_resultat['CIR_TOTAL_DECLARE'].sum()\n",
    "    somme_calcule = df_resultat['CIR_TOTAL_CALCULE'].sum()\n",
    "\n",
    "    print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
    "    print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
    "    print(f\"Résultats exportés dans: lignes_L31A_egal_CIR_TOTAL_div_3_2021.csv\")\n",
    "# Afficher quelques exemples où la relation n'est pas respectée\n",
    "print(\"\\nExemples où L31A_ECART ≠ CIR_TOTAL_ECART / 3:\")\n",
    "exemples_different = df[~df['EST_EGAL']].head(5)\n",
    "for _, row in exemples_different.iterrows():\n",
    "    print(f\"SIREN: {row['SIREN_DECLARANT']}, L31A_ECART: {row['L31A_ECART']}, CIR_TOTAL_ECART/3: {row['CIR_TOTAL_ECART']/3}, Ratio: {row['RATIO']:.4f}\")\n",
    "\n",
    "# Exporter les résultats avec la colonne d'analyse supplémentaire\n",
    "df.to_csv(\"analyse_L31A_vs_CIR_TOTAL.csv\", sep=';', encoding='utf-8-sig', index=False)\n",
    "print(f\"\\nRésultats détaillés exportés dans: analyse_L31A_vs_CIR_TOTAL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "741596a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier principal chargé: 4493 lignes\n",
      "\n",
      "Nombre de lignes restantes à analyser: 1417\n",
      "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier principal\n",
    "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2021.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
    "\n",
    "# Charger les fichiers d'analyse précédents\n",
    "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')\n",
    "l7_egal_l8 = pd.read_csv(\"lignes_L7_egal_L8.csv\", sep=';', encoding='utf-8-sig')\n",
    "depenses_non0_cir0 = pd.read_csv(\"lignes_depenses_non0_cir_recherche_0.csv\", sep=';', encoding='utf-8-sig')\n",
    "analyse_l26a = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//analyse_L26A_vs_CIR_TOTAL.csv\", sep=';', encoding='utf-8-sig')\n",
    "\n",
    "# Identifier les SIREN à exclure\n",
    "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT'])\n",
    "siren_l7_l8 = set(l7_egal_l8['SIREN_DECLARANT'])\n",
    "siren_depenses_non0_cir0 = set(depenses_non0_cir0['SIREN_DECLARANT'])\n",
    "siren_analyse_l26a = set(analyse_l26a['SIREN_DECLARANT'])\n",
    "\n",
    "# Combiner tous les SIREN à exclure (ajout du cas analyse_L26A_vs_CIR_TOTAL.csv)\n",
    "siren_a_exclure = siren_jeunes_docteurs | siren_l7_l8 | siren_depenses_non0_cir0 | siren_analyse_l26a\n",
    "\n",
    "# Filtrer le DataFrame principal\n",
    "df_restant = df[\n",
    "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) &\n",
    "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
    "]\n",
    "\n",
    "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_restantes_a_analyser.csv\"\n",
    "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b61ecc",
   "metadata": {},
   "source": [
    "## Erreur doublement sans motif de la créance total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6e1a7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier chargé: 1417 lignes\n",
      "Lignes extraites: 0\n",
      "Somme CIR_TOTAL_DECLARE : 0.00 €\n",
      "Somme CIR_TOTAL_CALCULE : 0.00 €\n",
      "Résultats exportés dans: lignes_ecart_relatif_50_innovation0_recherche1.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier des lignes restantes\n",
    "file_path = \"lignes_restantes_a_analyser.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier chargé: {len(df)} lignes\")\n",
    "\n",
    "# Filtrer selon les critères :\n",
    "# - ECART_RELATIF_POURCENT == -50 ou 50\n",
    "# - CIR_INNOVATION_ECART == 0\n",
    "# - CIR_RECHERCHE_ECART entre -1 et 1 inclus\n",
    "mask = (\n",
    "    df['ECART_RELATIF_POURCENT'].isin([-50.0, 50.0]) &\n",
    "    (df['CIR_INNOVATION_ECART'] == 0.0) &\n",
    "    (df['CIR_RECHERCHE_ECART'].between(-1, 1))\n",
    ")\n",
    "\n",
    "df_filtered = df[mask]\n",
    "print(f\"Lignes extraites: {len(df_filtered)}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_ecart_relatif_50_innovation0_recherche1.csv\"\n",
    "df_filtered.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "# Calculer les sommes\n",
    "somme_declare = df_filtered['CIR_TOTAL_DECLARE'].sum()\n",
    "somme_calcule = df_filtered['CIR_TOTAL_CALCULE'].sum()\n",
    "\n",
    "print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
    "print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb6a302d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier principal chargé: 4493 lignes\n",
      "\n",
      "Nombre de lignes restantes à analyser: 1417\n",
      "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier principal\n",
    "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2021.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
    "\n",
    "# Charger les fichiers d'analyse précédents\n",
    "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')\n",
    "l7_egal_l8 = pd.read_csv(\"lignes_L7_egal_L8.csv\", sep=';', encoding='utf-8-sig')\n",
    "depenses_non0_cir0 = pd.read_csv(\"lignes_depenses_non0_cir_recherche_0.csv\", sep=';', encoding='utf-8-sig')\n",
    "analyse_l26a = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//analyse_L26A_vs_CIR_TOTAL.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_relatif_50_innov0_rech1 = pd.read_csv(\"lignes_ecart_relatif_50_innovation0_recherche1.csv\", sep=';', encoding='utf-8-sig')\n",
    "\n",
    "# Identifier les SIREN à exclure\n",
    "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT'])\n",
    "siren_l7_l8 = set(l7_egal_l8['SIREN_DECLARANT'])\n",
    "siren_depenses_non0_cir0 = set(depenses_non0_cir0['SIREN_DECLARANT'])\n",
    "siren_analyse_l26a = set(analyse_l26a['SIREN_DECLARANT'])\n",
    "siren_ecart_relatif_50_innov0_rech1 = set(ecart_relatif_50_innov0_rech1['SIREN_DECLARANT'])\n",
    "\n",
    "# Combiner tous les SIREN à exclure (ajout du cas analyse_L26A_vs_CIR_TOTAL.csv)\n",
    "siren_a_exclure = siren_jeunes_docteurs | siren_l7_l8 | siren_depenses_non0_cir0 | siren_analyse_l26a | siren_ecart_relatif_50_innov0_rech1\n",
    "\n",
    "# Filtrer le DataFrame principal\n",
    "df_restant = df[\n",
    "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) &\n",
    "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
    "]\n",
    "\n",
    "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_restantes_a_analyser.csv\"\n",
    "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd2f582",
   "metadata": {},
   "source": [
    "## erreur diff Cir total compris entre -500 et 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b8313698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier chargé: 1417 lignes\n",
      "Nombre de lignes extraites: 3\n",
      "Somme CIR_TOTAL_DECLARE : 196,752.00 €\n",
      "Somme CIR_TOTAL_CALCULE : 196,690.58 €\n",
      "Résultats exportés dans: lignes_ecart_total_entre_-500_et_500.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier des lignes restantes à analyser\n",
    "file_path = \"lignes_restantes_a_analyser.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier chargé: {len(df)} lignes\")\n",
    "\n",
    "# Filtrer les lignes où CIR_TOTAL_ECART est entre -500 et 500 et CORRESPONDANCE_CIR == \"Non\"\n",
    "mask_ecart = df['CIR_TOTAL_ECART'].between(-500, 500) & df['CORRESPONDANCE_CIR'].eq(\"Non\")\n",
    "df_resultat = df[mask_ecart]\n",
    "\n",
    "print(f\"Nombre de lignes extraites: {len(df_resultat)}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_ecart_total_entre_-500_et_500.csv\"\n",
    "df_resultat.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "# Calculer les sommes\n",
    "somme_declare = df_resultat['CIR_TOTAL_DECLARE'].sum()\n",
    "somme_calcule = df_resultat['CIR_TOTAL_CALCULE'].sum()\n",
    "\n",
    "print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
    "print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "18915a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier principal chargé: 4493 lignes\n",
      "\n",
      "Nombre de lignes restantes à analyser: 1414\n",
      "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier principal\n",
    "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2021.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
    "\n",
    "# Charger les fichiers d'analyse précédents\n",
    "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')\n",
    "l7_egal_l8 = pd.read_csv(\"lignes_L7_egal_L8.csv\", sep=';', encoding='utf-8-sig')\n",
    "depenses_non0_cir0 = pd.read_csv(\"lignes_depenses_non0_cir_recherche_0.csv\", sep=';', encoding='utf-8-sig')\n",
    "analyse_l26a = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//analyse_L26A_vs_CIR_TOTAL.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_relatif_50_innov0_rech1 = pd.read_csv(\"lignes_ecart_relatif_50_innovation0_recherche1.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_total500 = pd.read_csv(\"lignes_ecart_total_entre_-500_et_500.csv\", sep=';', encoding='utf-8-sig')\n",
    "\n",
    "# Identifier les SIREN à exclure\n",
    "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT'])\n",
    "siren_l7_l8 = set(l7_egal_l8['SIREN_DECLARANT'])\n",
    "siren_depenses_non0_cir0 = set(depenses_non0_cir0['SIREN_DECLARANT'])\n",
    "siren_analyse_l26a = set(analyse_l26a['SIREN_DECLARANT'])\n",
    "siren_ecart_relatif_50_innov0_rech1 = set(ecart_relatif_50_innov0_rech1['SIREN_DECLARANT'])\n",
    "siren_ecart_total500 = set(ecart_total500['SIREN_DECLARANT'])\n",
    "\n",
    "# Combiner tous les SIREN à exclure (ajout du cas lignes_ecart_total_entre_-500_et_500.csv)\n",
    "siren_a_exclure = siren_jeunes_docteurs | siren_l7_l8 | siren_depenses_non0_cir0 | siren_analyse_l26a | siren_ecart_relatif_50_innov0_rech1 | siren_ecart_total500\n",
    "\n",
    "# Filtrer le DataFrame principal\n",
    "df_restant = df[\n",
    "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) &\n",
    "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
    "]\n",
    "\n",
    "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_restantes_a_analyser.csv\"\n",
    "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4413c334",
   "metadata": {},
   "source": [
    "## Plafond Partout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0387140c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier chargé: 1414 lignes\n",
      "Nombre de lignes avec ECART_RELATIF_POURCENT = -100: 446\n",
      "Somme CIR_TOTAL_DECLARE : 12,611,200.00 €\n",
      "Somme CIR_TOTAL_CALCULE : 0.43 €\n",
      "Résultats exportés dans: lignes_ecart_relatif_moins_100.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier avec les 703 lignes restantes\n",
    "file_path = \"lignes_restantes_a_analyser.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier chargé: {len(df)} lignes\")\n",
    "\n",
    "# Filtrer les lignes où ECART_RELATIF_POURCENT est égal à -100\n",
    "df_ecart_negatif = df[df['ECART_RELATIF_POURCENT'] == -100]\n",
    "print(f\"Nombre de lignes avec ECART_RELATIF_POURCENT = -100: {len(df_ecart_negatif)}\")\n",
    "\n",
    "# Exporter les résultats dans un fichier CSV\n",
    "output_file = \"lignes_ecart_relatif_moins_100.csv\"\n",
    "df_ecart_negatif.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "# Calculer les sommes\n",
    "somme_declare = df_ecart_negatif['CIR_TOTAL_DECLARE'].sum()\n",
    "somme_calcule = df_ecart_negatif['CIR_TOTAL_CALCULE'].sum()\n",
    "\n",
    "print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
    "print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "37a52c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier principal chargé: 4493 lignes\n",
      "\n",
      "Nombre de lignes restantes à analyser: 968\n",
      "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier principal\n",
    "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2021.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
    "\n",
    "# Charger les fichiers d'analyse précédents\n",
    "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')\n",
    "l7_egal_l8 = pd.read_csv(\"lignes_L7_egal_L8.csv\", sep=';', encoding='utf-8-sig')\n",
    "depenses_non0_cir0 = pd.read_csv(\"lignes_depenses_non0_cir_recherche_0.csv\", sep=';', encoding='utf-8-sig')\n",
    "analyse_l26a = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//analyse_L26A_vs_CIR_TOTAL.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_relatif_50_innov0_rech1 = pd.read_csv(\"lignes_ecart_relatif_50_innovation0_recherche1.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_total500 = pd.read_csv(\"lignes_ecart_total_entre_-500_et_500.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_moins_100 = pd.read_csv(\"lignes_ecart_relatif_moins_100.csv\", sep=';', encoding='utf-8-sig')\n",
    "\n",
    "# Identifier les SIREN à exclure\n",
    "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT'])\n",
    "siren_l7_l8 = set(l7_egal_l8['SIREN_DECLARANT'])\n",
    "siren_depenses_non0_cir0 = set(depenses_non0_cir0['SIREN_DECLARANT'])\n",
    "siren_analyse_l26a = set(analyse_l26a['SIREN_DECLARANT'])\n",
    "siren_ecart_relatif_50_innov0_rech1 = set(ecart_relatif_50_innov0_rech1['SIREN_DECLARANT'])\n",
    "siren_ecart_total500 = set(ecart_total500['SIREN_DECLARANT'])\n",
    "siren_ecart_moins_100 = set(ecart_moins_100['SIREN_DECLARANT'])\n",
    "\n",
    "# Combiner tous les SIREN à exclure (ajout du cas lignes_ecart_relatif_moins_100.csv)\n",
    "siren_a_exclure = siren_jeunes_docteurs | siren_l7_l8 | siren_depenses_non0_cir0 | \\\n",
    "                  siren_analyse_l26a | siren_ecart_relatif_50_innov0_rech1 | \\\n",
    "                  siren_ecart_total500 | siren_ecart_moins_100\n",
    "\n",
    "# Filtrer le DataFrame principal\n",
    "df_restant = df[\n",
    "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) &\n",
    "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
    "]\n",
    "\n",
    "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_restantes_a_analyser.csv\"\n",
    "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc891b6",
   "metadata": {},
   "source": [
    "## Erreur Cir innovation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3a06c32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier chargé: 968 lignes\n",
      "\n",
      "Nombre de lignes où CIR_TOTAL_ECART = CIR_INNOVATION_ECART (±1): 643\n",
      "\n",
      "Exemples :\n",
      "SIREN: 421100645\n",
      "CIR_TOTAL_ECART: 54071.43\n",
      "CIR_INNOVATION_ECART: 54071.20\n",
      "SIREN: 314704057\n",
      "CIR_TOTAL_ECART: 3944.88\n",
      "CIR_INNOVATION_ECART: 3944.80\n",
      "SIREN: 531583888\n",
      "CIR_TOTAL_ECART: 67314.91\n",
      "CIR_INNOVATION_ECART: 67314.40\n",
      "SIREN: 435405923\n",
      "CIR_TOTAL_ECART: 70034.23\n",
      "CIR_INNOVATION_ECART: 70034.60\n",
      "SIREN: 537523615\n",
      "CIR_TOTAL_ECART: 33959.99\n",
      "CIR_INNOVATION_ECART: 33960.32\n",
      "Somme CIR_TOTAL_DECLARE : 34,392,892.00 €\n",
      "Somme CIR_TOTAL_CALCULE : 60,719,903.55 €\n",
      "\n",
      "Résultats exportés dans: lignes_ecart_total_egal_innovation.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier des lignes restantes\n",
    "file_path = \"lignes_restantes_a_analyser.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier chargé: {len(df)} lignes\")\n",
    "\n",
    "# Filtrer les lignes où CIR_TOTAL_ECART = CIR_INNOVATION_ECART (±1)\n",
    "mask = np.isclose(df['CIR_TOTAL_ECART'], df['CIR_INNOVATION_ECART'], atol=1.0)\n",
    "df_filtered = df[mask]\n",
    "\n",
    "print(f\"\\nNombre de lignes où CIR_TOTAL_ECART = CIR_INNOVATION_ECART (±1): {len(df_filtered)}\")\n",
    "\n",
    "# Afficher quelques exemples\n",
    "if len(df_filtered) > 0:\n",
    "    print(\"\\nExemples :\")\n",
    "    for _, row in df_filtered.head().iterrows():\n",
    "        print(f\"SIREN: {row['SIREN_DECLARANT']}\")\n",
    "        print(f\"CIR_TOTAL_ECART: {row['CIR_TOTAL_ECART']:.2f}\")\n",
    "        print(f\"CIR_INNOVATION_ECART: {row['CIR_INNOVATION_ECART']:.2f}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_ecart_total_egal_innovation.csv\"\n",
    "df_filtered.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "# Calculer les sommes\n",
    "somme_declare = df_filtered['CIR_TOTAL_DECLARE'].sum()\n",
    "somme_calcule = df_filtered['CIR_TOTAL_CALCULE'].sum()\n",
    "\n",
    "print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
    "print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
    "print(f\"\\nRésultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0cdf73c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier chargé: 968 lignes\n",
      "\n",
      "Nombre de lignes où CIR_TOTAL_ECART = CIR_INNOVATION_ECART (±1): 643\n",
      "\n",
      "Exemples :\n",
      "SIREN: 421100645\n",
      "CIR_TOTAL_ECART: 54071.43\n",
      "CIR_INNOVATION_ECART: 54071.20\n",
      "SIREN: 314704057\n",
      "CIR_TOTAL_ECART: 3944.88\n",
      "CIR_INNOVATION_ECART: 3944.80\n",
      "SIREN: 531583888\n",
      "CIR_TOTAL_ECART: 67314.91\n",
      "CIR_INNOVATION_ECART: 67314.40\n",
      "SIREN: 435405923\n",
      "CIR_TOTAL_ECART: 70034.23\n",
      "CIR_INNOVATION_ECART: 70034.60\n",
      "SIREN: 537523615\n",
      "CIR_TOTAL_ECART: 33959.99\n",
      "CIR_INNOVATION_ECART: 33960.32\n",
      "Somme CIR_TOTAL_DECLARE : 34,392,892.00 €\n",
      "Somme CIR_TOTAL_CALCULE : 60,719,903.55 €\n",
      "\n",
      "Résultats exportés dans: lignes_ecart_total_egal_innovation.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier des lignes restantes\n",
    "file_path = \"lignes_restantes_a_analyser.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier chargé: {len(df)} lignes\")\n",
    "\n",
    "# Filtrer les lignes où CIR_TOTAL_ECART = CIR_INNOVATION_ECART (±1)\n",
    "mask = np.isclose(df['CIR_TOTAL_ECART'], df['CIR_INNOVATION_ECART'], atol=1.0)\n",
    "df_filtered = df[mask]\n",
    "\n",
    "print(f\"\\nNombre de lignes où CIR_TOTAL_ECART = CIR_INNOVATION_ECART (±1): {len(df_filtered)}\")\n",
    "\n",
    "# Afficher quelques exemples\n",
    "if len(df_filtered) > 0:\n",
    "    print(\"\\nExemples :\")\n",
    "    for _, row in df_filtered.head().iterrows():\n",
    "        print(f\"SIREN: {row['SIREN_DECLARANT']}\")\n",
    "        print(f\"CIR_TOTAL_ECART: {row['CIR_TOTAL_ECART']:.2f}\")\n",
    "        print(f\"CIR_INNOVATION_ECART: {row['CIR_INNOVATION_ECART']:.2f}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_ecart_total_egal_innovation.csv\"\n",
    "df_filtered.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "# Calculer les sommes\n",
    "somme_declare = df_filtered['CIR_TOTAL_DECLARE'].sum()\n",
    "somme_calcule = df_filtered['CIR_TOTAL_CALCULE'].sum()\n",
    "\n",
    "print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
    "print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
    "print(f\"\\nRésultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76646720",
   "metadata": {},
   "source": [
    "## Erreur Cir Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5b46a34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier chargé: 968 lignes\n",
      "\n",
      "Nombre de lignes où CIR_TOTAL_ECART = CIR_COLLECTION_ECART (±1): 0\n",
      "Somme CIR_TOTAL_DECLARE : 0.00 €\n",
      "Somme CIR_TOTAL_CALCULE : 0.00 €\n",
      "\n",
      "Résultats exportés dans: lignes_ecart_total_egal_collection.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier\n",
    "file_path = \"lignes_restantes_a_analyser.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier chargé: {len(df)} lignes\")\n",
    "\n",
    "# Créer le masque pour identifier où CIR_TOTAL_ECART = CIR_COLLECTION_ECART (±1)\n",
    "mask = np.isclose(df['CIR_TOTAL_ECART'], df['CIR_COLLECTION_ECART'], atol=1.0)\n",
    "\n",
    "# Filtrer les lignes\n",
    "df_filtered = df[mask]\n",
    "\n",
    "print(f\"\\nNombre de lignes où CIR_TOTAL_ECART = CIR_COLLECTION_ECART (±1): {len(df_filtered)}\")\n",
    "\n",
    "# Afficher quelques statistiques sur ces lignes\n",
    "if len(df_filtered) > 0:\n",
    "    print(\"\\nQuelques exemples :\")\n",
    "    for _, row in df_filtered.head().iterrows():\n",
    "        print(f\"\\nSIREN: {row['SIREN_DECLARANT']}\")\n",
    "        print(f\"CIR_TOTAL_ECART: {row['CIR_TOTAL_ECART']:.2f}\")\n",
    "        print(f\"CIR_COLLECTION_ECART: {row['CIR_COLLECTION_ECART']:.2f}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_ecart_total_egal_collection.csv\"\n",
    "df_filtered.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "# Calculer les sommes\n",
    "somme_declare = df_filtered['CIR_TOTAL_DECLARE'].sum()\n",
    "somme_calcule = df_filtered['CIR_TOTAL_CALCULE'].sum()\n",
    "\n",
    "print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
    "print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
    "print(f\"\\nRésultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e2c3f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier principal chargé: 4493 lignes\n",
      "\n",
      "Nombre de lignes restantes à analyser: 324\n",
      "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier principal\n",
    "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2021.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
    "\n",
    "# Charger les fichiers d'analyse précédents\n",
    "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')\n",
    "l7_egal_l8 = pd.read_csv(\"lignes_L7_egal_L8.csv\", sep=';', encoding='utf-8-sig')\n",
    "depenses_non0_cir0 = pd.read_csv(\"lignes_depenses_non0_cir_recherche_0.csv\", sep=';', encoding='utf-8-sig')\n",
    "#analyse_l26a = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//analyse_L26A_vs_CIR_TOTAL.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_relatif_50_innov0_rech1 = pd.read_csv(\"lignes_ecart_relatif_50_innovation0_recherche1.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_total500 = pd.read_csv(\"lignes_ecart_total_entre_-500_et_500.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_moins_100 = pd.read_csv(\"lignes_ecart_relatif_moins_100.csv\", sep=';', encoding='utf-8-sig')\n",
    "innovation_egal_total = pd.read_csv(\"lignes_ecart_total_egal_innovation.csv\", sep=';', encoding='utf-8-sig')\n",
    "collection_egal_total = pd.read_csv(\"lignes_ecart_total_egal_collection.csv\", sep=';', encoding='utf-8-sig')\n",
    "\n",
    "# Identifier les SIREN à exclure\n",
    "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT'])\n",
    "siren_l7_l8 = set(l7_egal_l8['SIREN_DECLARANT'])\n",
    "siren_depenses_non0_cir0 = set(depenses_non0_cir0['SIREN_DECLARANT'])\n",
    "siren_analyse_l26a = set(analyse_l26a['SIREN_DECLARANT'])\n",
    "siren_ecart_relatif_50_innov0_rech1 = set(ecart_relatif_50_innov0_rech1['SIREN_DECLARANT'])\n",
    "siren_ecart_total500 = set(ecart_total500['SIREN_DECLARANT'])\n",
    "siren_ecart_moins_100 = set(ecart_moins_100['SIREN_DECLARANT'])\n",
    "siren_innovation_egal_total = set(innovation_egal_total['SIREN_DECLARANT'])\n",
    "siren_collection_egal_total = set(collection_egal_total['SIREN_DECLARANT'])\n",
    "\n",
    "# Combiner tous les SIREN à exclure (ajout du cas collection_egal_total)\n",
    "siren_a_exclure = siren_jeunes_docteurs | siren_l7_l8 | siren_depenses_non0_cir0 | \\\n",
    "                  siren_analyse_l26a | siren_ecart_relatif_50_innov0_rech1 | \\\n",
    "                  siren_ecart_total500 | siren_ecart_moins_100 | \\\n",
    "                  siren_innovation_egal_total | siren_collection_egal_total\n",
    "\n",
    "# Filtrer le DataFrame principal\n",
    "df_restant = df[\n",
    "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) &\n",
    "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
    "]\n",
    "\n",
    "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_restantes_a_analyser.csv\"\n",
    "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1e414b",
   "metadata": {},
   "source": [
    "## Erreur Cir Déclarer vaut 0 alors que sa ne l'est pas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6f4e1a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier chargé: 324 lignes\n",
      "Nombre de lignes où ECART_RELATIF_POURCENT = 100 et CIR_TOTAL_DECLARE = 0: 3\n",
      "Somme CIR_TOTAL_DECLARE : 0.00 €\n",
      "Somme CIR_TOTAL_CALCULE : 234,295.90 €\n",
      "Résultats exportés dans: lignes_ecart_100_cir_declare_0.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier des lignes restantes\n",
    "file_path = \"lignes_restantes_a_analyser.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier chargé: {len(df)} lignes\")\n",
    "\n",
    "# Filtrer les lignes où ECART_RELATIF_POURCENT = 100 et CIR_TOTAL_DECLARE = 0\n",
    "df_filtered = df[(df['ECART_RELATIF_POURCENT'] == 100) & (df['CIR_TOTAL_DECLARE'] == 0)]\n",
    "\n",
    "print(f\"Nombre de lignes où ECART_RELATIF_POURCENT = 100 et CIR_TOTAL_DECLARE = 0: {len(df_filtered)}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_ecart_100_cir_declare_0.csv\"\n",
    "df_filtered.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "# Calculer les sommes\n",
    "somme_declare = df_filtered['CIR_TOTAL_DECLARE'].sum()\n",
    "somme_calcule = df_filtered['CIR_TOTAL_CALCULE'].sum()\n",
    "\n",
    "print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
    "print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "543cdb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier principal chargé: 4493 lignes\n",
      "\n",
      "Nombre de lignes restantes à analyser: 321\n",
      "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier principal\n",
    "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2021.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
    "\n",
    "# Charger tous les fichiers d'analyse précédents\n",
    "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')\n",
    "l7_egal_l8 = pd.read_csv(\"lignes_L7_egal_L8.csv\", sep=';', encoding='utf-8-sig')\n",
    "depenses_non0_cir0 = pd.read_csv(\"lignes_depenses_non0_cir_recherche_0.csv\", sep=';', encoding='utf-8-sig')\n",
    "analyse_l26a = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//analyse_L26A_vs_CIR_TOTAL.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_relatif_50_innov0_rech1 = pd.read_csv(\"lignes_ecart_relatif_50_innovation0_recherche1.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_total500 = pd.read_csv(\"lignes_ecart_total_entre_-500_et_500.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_moins_100 = pd.read_csv(\"lignes_ecart_relatif_moins_100.csv\", sep=';', encoding='utf-8-sig')\n",
    "innovation_egal_total = pd.read_csv(\"lignes_ecart_total_egal_innovation.csv\", sep=';', encoding='utf-8-sig')\n",
    "collection_egal_total = pd.read_csv(\"lignes_ecart_total_egal_collection.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_100_cir_declare_0 = pd.read_csv(\"lignes_ecart_100_cir_declare_0.csv\", sep=';', encoding='utf-8-sig')\n",
    "\n",
    "# Identifier les SIREN à exclure\n",
    "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT'])\n",
    "siren_l7_l8 = set(l7_egal_l8['SIREN_DECLARANT'])\n",
    "siren_depenses_non0_cir0 = set(depenses_non0_cir0['SIREN_DECLARANT'])\n",
    "siren_analyse_l26a = set(analyse_l26a['SIREN_DECLARANT'])\n",
    "siren_ecart_relatif_50_innov0_rech1 = set(ecart_relatif_50_innov0_rech1['SIREN_DECLARANT'])\n",
    "siren_ecart_total500 = set(ecart_total500['SIREN_DECLARANT'])\n",
    "siren_ecart_moins_100 = set(ecart_moins_100['SIREN_DECLARANT'])\n",
    "siren_innovation_egal_total = set(innovation_egal_total['SIREN_DECLARANT'])\n",
    "siren_collection_egal_total = set(collection_egal_total['SIREN_DECLARANT'])\n",
    "siren_ecart_100_cir_declare_0 = set(ecart_100_cir_declare_0['SIREN_DECLARANT'])\n",
    "\n",
    "# Combiner tous les SIREN à exclure (ajout du cas ecart_100_cir_declare_0)\n",
    "siren_a_exclure = siren_jeunes_docteurs | siren_l7_l8 | siren_depenses_non0_cir0 | \\\n",
    "                  siren_analyse_l26a | siren_ecart_relatif_50_innov0_rech1 | \\\n",
    "                  siren_ecart_total500 | siren_ecart_moins_100 | \\\n",
    "                  siren_innovation_egal_total | siren_collection_egal_total | \\\n",
    "                  siren_ecart_100_cir_declare_0\n",
    "\n",
    "# Filtrer le DataFrame principal\n",
    "df_restant = df[\n",
    "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) &\n",
    "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
    "]\n",
    "\n",
    "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_restantes_a_analyser.csv\"\n",
    "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48277e3b",
   "metadata": {},
   "source": [
    "## Erreur liée à L6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "79dc0781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier chargé: 321 lignes\n",
      "\n",
      "Nombre de lignes où CIR_TOTAL_ECART = CIR_RECHERCHE_ECART (±1) et L6_ECART hors [-1, 1]: 0\n",
      "Somme CIR_TOTAL_DECLARE : 0.00 €\n",
      "Somme CIR_TOTAL_CALCULE : 0.00 €\n",
      "\n",
      "Résultats exportés dans: lignes_ecart_total_egal_recherche_l6_ecart_hors_1.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier des lignes restantes\n",
    "file_path = \"lignes_restantes_a_analyser.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier chargé: {len(df)} lignes\")\n",
    "\n",
    "# Filtrer les lignes où CIR_TOTAL_ECART = CIR_RECHERCHE_ECART (±1)\n",
    "mask_ecart = np.isclose(df['CIR_TOTAL_ECART'], df['CIR_RECHERCHE_ECART'], atol=1.0)\n",
    "\n",
    "# Filtrer les lignes où L6_ECART est strictement en dehors de [-1, 1]\n",
    "mask_l6 = (df['L6_ECART'] < -1) | (df['L6_ECART'] > 1)\n",
    "\n",
    "# Appliquer les deux filtres\n",
    "df_filtered = df[mask_ecart & mask_l6]\n",
    "\n",
    "print(f\"\\nNombre de lignes où CIR_TOTAL_ECART = CIR_RECHERCHE_ECART (±1) et L6_ECART hors [-1, 1]: {len(df_filtered)}\")\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_ecart_total_egal_recherche_l6_ecart_hors_1.csv\"\n",
    "df_filtered.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "# Calculer les sommes\n",
    "somme_declare = df_filtered['CIR_TOTAL_DECLARE'].sum()\n",
    "somme_calcule = df_filtered['CIR_TOTAL_CALCULE'].sum()\n",
    "\n",
    "print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
    "print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
    "print(f\"\\nRésultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "13f1fd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier principal chargé: 4493 lignes\n",
      "\n",
      "Nombre de lignes restantes à analyser: 321\n",
      "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier principal\n",
    "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2021.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
    "\n",
    "# Charger tous les fichiers d'analyse précédents\n",
    "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')\n",
    "l7_egal_l8 = pd.read_csv(\"lignes_L7_egal_L8.csv\", sep=';', encoding='utf-8-sig')\n",
    "depenses_non0_cir0 = pd.read_csv(\"lignes_depenses_non0_cir_recherche_0.csv\", sep=';', encoding='utf-8-sig')\n",
    "analyse_l26a = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//analyse_L26A_vs_CIR_TOTAL.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_relatif_50_innov0_rech1 = pd.read_csv(\"lignes_ecart_relatif_50_innovation0_recherche1.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_total500 = pd.read_csv(\"lignes_ecart_total_entre_-500_et_500.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_moins_100 = pd.read_csv(\"lignes_ecart_relatif_moins_100.csv\", sep=';', encoding='utf-8-sig')\n",
    "innovation_egal_total = pd.read_csv(\"lignes_ecart_total_egal_innovation.csv\", sep=';', encoding='utf-8-sig')\n",
    "collection_egal_total = pd.read_csv(\"lignes_ecart_total_egal_collection.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_100_cir_declare_0 = pd.read_csv(\"lignes_ecart_100_cir_declare_0.csv\", sep=';', encoding='utf-8-sig')\n",
    "l6_ecart_hors_1 = pd.read_csv(\"lignes_ecart_total_egal_recherche_l6_ecart_hors_1.csv\", sep=';', encoding='utf-8-sig')\n",
    "\n",
    "# Identifier les SIREN à exclure\n",
    "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT'])\n",
    "siren_l7_l8 = set(l7_egal_l8['SIREN_DECLARANT'])\n",
    "siren_depenses_non0_cir0 = set(depenses_non0_cir0['SIREN_DECLARANT'])\n",
    "siren_analyse_l26a = set(analyse_l26a['SIREN_DECLARANT'])\n",
    "siren_ecart_relatif_50_innov0_rech1 = set(ecart_relatif_50_innov0_rech1['SIREN_DECLARANT'])\n",
    "siren_ecart_total500 = set(ecart_total500['SIREN_DECLARANT'])\n",
    "siren_ecart_moins_100 = set(ecart_moins_100['SIREN_DECLARANT'])\n",
    "siren_innovation_egal_total = set(innovation_egal_total['SIREN_DECLARANT'])\n",
    "siren_collection_egal_total = set(collection_egal_total['SIREN_DECLARANT'])\n",
    "siren_ecart_100_cir_declare_0 = set(ecart_100_cir_declare_0['SIREN_DECLARANT'])\n",
    "siren_l6_ecart_hors_1 = set(l6_ecart_hors_1['SIREN_DECLARANT'])\n",
    "\n",
    "# Combiner tous les SIREN à exclure (ajout du cas l6_ecart_hors_1)\n",
    "siren_a_exclure = siren_jeunes_docteurs | siren_l7_l8 | siren_depenses_non0_cir0 | \\\n",
    "                  siren_analyse_l26a | siren_ecart_relatif_50_innov0_rech1 | \\\n",
    "                  siren_ecart_total500 | siren_ecart_moins_100 | \\\n",
    "                  siren_innovation_egal_total | siren_collection_egal_total | \\\n",
    "                  siren_ecart_100_cir_declare_0 | siren_l6_ecart_hors_1\n",
    "\n",
    "# Filtrer le DataFrame principal\n",
    "df_restant = df[\n",
    "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) &\n",
    "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
    "]\n",
    "\n",
    "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_restantes_a_analyser.csv\"\n",
    "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847b4803",
   "metadata": {},
   "source": [
    "## Erreur liée à L26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1cb3f691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier chargé: 321 lignes\n",
      "Nombre de lignes correspondant au cas demandé : 0\n",
      "Somme CIR_TOTAL_DECLARE : 0.00 €\n",
      "Somme CIR_TOTAL_CALCULE : 0.00 €\n",
      "Résultats exportés dans: lignes_cas_L31A_ecart_hors_1_L14_L22_L26_dans_1_2021.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier des lignes restantes\n",
    "file_path = \"lignes_restantes_a_analyser.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier chargé: {len(df)} lignes\")\n",
    "\n",
    "# Appliquer les filtres demandés (adaptés pour 2021)\n",
    "mask = (\n",
    "    ((df['L31A_ECART'] > 1) | (df['L31A_ECART'] < -1))\n",
    "    & ((df['L14_ECART'] > -1) & (df['L14_ECART'] < 1))\n",
    "    & ((df['L22_ECART'] > -1) & (df['L22_ECART'] < 1))\n",
    "    & ((df['L26_ECART'] > -1) & (df['L26_ECART'] < 1))\n",
    "    & ((df['L27_ECART'] > -1) & (df['L27_ECART'] < 1))\n",
    ")\n",
    "\n",
    "df_filtered = df[mask]\n",
    "print(f\"Nombre de lignes correspondant au cas demandé : {len(df_filtered)}\")\n",
    "\n",
    "# Afficher quelques exemples\n",
    "if len(df_filtered) > 0:\n",
    "    print(df_filtered[['SIREN_DECLARANT', 'L31A_ECART', 'L14_ECART', 'L22_ECART', 'L26_ECART']].head())\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_cas_L31A_ecart_hors_1_L14_L22_L26_dans_1_2021.csv\"\n",
    "df_filtered.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "# Calculer les sommes\n",
    "somme_declare = df_filtered['CIR_TOTAL_DECLARE'].sum()\n",
    "somme_calcule = df_filtered['CIR_TOTAL_CALCULE'].sum()\n",
    "\n",
    "print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
    "print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cf3996c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier principal chargé: 4493 lignes\n",
      "\n",
      "Nombre de lignes restantes à analyser: 321\n",
      "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier principal\n",
    "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2021.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
    "\n",
    "# Charger tous les fichiers d'analyse précédents\n",
    "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')\n",
    "l7_egal_l8 = pd.read_csv(\"lignes_L7_egal_L8.csv\", sep=';', encoding='utf-8-sig')\n",
    "depenses_non0_cir0 = pd.read_csv(\"lignes_depenses_non0_cir_recherche_0.csv\", sep=';', encoding='utf-8-sig')\n",
    "analyse_l26a = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//analyse_L26A_vs_CIR_TOTAL.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_relatif_50_innov0_rech1 = pd.read_csv(\"lignes_ecart_relatif_50_innovation0_recherche1.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_total500 = pd.read_csv(\"lignes_ecart_total_entre_-500_et_500.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_moins_100 = pd.read_csv(\"lignes_ecart_relatif_moins_100.csv\", sep=';', encoding='utf-8-sig')\n",
    "innovation_egal_total = pd.read_csv(\"lignes_ecart_total_egal_innovation.csv\", sep=';', encoding='utf-8-sig')\n",
    "collection_egal_total = pd.read_csv(\"lignes_ecart_total_egal_collection.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_100_cir_declare_0 = pd.read_csv(\"lignes_ecart_100_cir_declare_0.csv\", sep=';', encoding='utf-8-sig')\n",
    "l6_ecart_hors_1 = pd.read_csv(\"lignes_ecart_total_egal_recherche_l6_ecart_hors_1.csv\", sep=';', encoding='utf-8-sig')\n",
    "cas_l26a = pd.read_csv(\"lignes_cas_L26A_ecart_hors_1_L14_L20_L21_dans_1.csv\", sep=';', encoding='utf-8-sig')\n",
    "\n",
    "# Identifier les SIREN à exclure\n",
    "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT'])\n",
    "siren_l7_l8 = set(l7_egal_l8['SIREN_DECLARANT'])\n",
    "siren_depenses_non0_cir0 = set(depenses_non0_cir0['SIREN_DECLARANT'])\n",
    "siren_analyse_l26a = set(analyse_l26a['SIREN_DECLARANT'])\n",
    "siren_ecart_relatif_50_innov0_rech1 = set(ecart_relatif_50_innov0_rech1['SIREN_DECLARANT'])\n",
    "siren_ecart_total500 = set(ecart_total500['SIREN_DECLARANT'])\n",
    "siren_ecart_moins_100 = set(ecart_moins_100['SIREN_DECLARANT'])\n",
    "siren_innovation_egal_total = set(innovation_egal_total['SIREN_DECLARANT'])\n",
    "siren_collection_egal_total = set(collection_egal_total['SIREN_DECLARANT'])\n",
    "siren_ecart_100_cir_declare_0 = set(ecart_100_cir_declare_0['SIREN_DECLARANT'])\n",
    "siren_l6_ecart_hors_1 = set(l6_ecart_hors_1['SIREN_DECLARANT'])\n",
    "siren_cas_l26a = set(cas_l26a['SIREN_DECLARANT'])\n",
    "\n",
    "# Combiner tous les SIREN à exclure (ajout du cas l6_ecart_hors_1)\n",
    "siren_a_exclure = siren_jeunes_docteurs | siren_l7_l8 | siren_depenses_non0_cir0 | \\\n",
    "                  siren_analyse_l26a | siren_ecart_relatif_50_innov0_rech1 | \\\n",
    "                  siren_ecart_total500 | siren_ecart_moins_100 | \\\n",
    "                  siren_innovation_egal_total | siren_collection_egal_total | \\\n",
    "                  siren_ecart_100_cir_declare_0 | siren_l6_ecart_hors_1 | siren_cas_l26a\n",
    "\n",
    "# Filtrer le DataFrame principal\n",
    "df_restant = df[\n",
    "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) &\n",
    "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
    "]\n",
    "\n",
    "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_restantes_a_analyser.csv\"\n",
    "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6af2e7f",
   "metadata": {},
   "source": [
    "# Correction Creance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9cc87e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** DÉBUT DU SCRIPT DE CORRECTION CIR 2021 ***\n",
      "Date et heure: 2025-06-11 14:15:55\n",
      "Fichier d'entrée: M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2021.csv\n",
      "Chargement et préparation des données depuis: M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2021.csv...\n",
      "Fichier principal chargé: 4,493 lignes\n",
      "Formatage des SIRENs...\n",
      "Conversion des colonnes numériques...\n",
      "Initialisation de la colonne 'CIR_TOTAL_CORRIGE'...\n",
      "Préparation des données terminée.\n",
      "\n",
      "Sommes avant corrections spécifiques:\n",
      "  - CIR Déclaré Total: 470,488,283.00 €\n",
      "  - CIR Calculé Total: 453,725,388.47 €\n",
      "  - CIR Corrigé Initial Total: 453,725,388.47 €\n",
      "\n",
      "--- Début de l'application des corrections spécifiques 2021 ---\n",
      "\n",
      "1. CORRECTION ERREURS DÉPENSES PERSONNEL (JEUNES DOCTEURS) 2021\n",
      "-> 2 lignes lues, 2 corrigées. Impact local: 87,933.81 €\n",
      "\n",
      "2. CORRECTION ERREUR L7 = L8 (FRAIS BREVETS) 2021\n",
      "\n",
      "3. CORRECTION CIR RECHERCHE MANQUANT/INCOHÉRENT 2021\n",
      "-> 18 lignes lues, 0 corrigées. Impact local: -65,519,439.00 €\n",
      "\n",
      "5. CORRECTION DOUBLEMENT SANS MOTIF (ÉCART ~50%) 2021\n",
      "\n",
      "6. CORRECTION PETIT ÉCART (-500 à 500 EUR) 2021\n",
      "-> 3 lignes lues, 3 corrigées. Impact local: -30.71 €\n",
      "\n",
      "7. CORRECTION PLAFOND PARTOUT (ÉCART -100%) 2021\n",
      "-> 446 lignes lues, 443 corrigées. Impact local: -12,611,199.57 €\n",
      "\n",
      "8. CORRECTION CIR INNOVATION MANQUANT (ÉCART = INNOVATION) 2021\n",
      "-> 643 lignes lues, 636 corrigées. Impact local: 25,115,174.06 €\n",
      "\n",
      "9. CORRECTION CIR COLLECTION MANQUANT (ÉCART = COLLECTION) 2021\n",
      "\n",
      "10. CORRECTION CIR DÉCLARÉ = 0 (ÉCART +100%) 2021\n",
      "-> 3 lignes lues, 3 corrigées. Impact local: 234,295.90 €\n",
      "\n",
      "11. CORRECTION ERREURS LIÉES À L6 - 2021\n",
      "\n",
      "13. VALEUR CALCULÉE PRIVILÉGIÉE POUR LE RESTE IDENTIFIÉ - 2021\n",
      "Info: Fichier intermédiaire 'lignes_restantes_a_analyser_2021.csv' non trouvé.\n",
      "\n",
      "--- Fin de l'application des corrections spécifiques 2021 ---\n",
      "Nombre total de modifications appliquées par les fonctions actives: 1,087\n",
      "Nombre de SIRENs uniques traités: 1,087\n",
      "\n",
      "--- Ajustement final : Mise à zéro des CIR corrigés négatifs ---\n",
      "Aucune valeur négative trouvée dans CIR_TOTAL_CORRIGE après corrections.\n",
      "\n",
      "Confirmation pour les lignes restées 'Non traité' (3,406):\n",
      "  - Aucune valeur négative parmi les lignes 'Non traité'.\n",
      "\n",
      "Sauvegarde du fichier corrigé sous: C:/Users/msamb/Documents/Calcul_Creance_CIR_Corrige_2021.csv\n",
      "Fichier sauvegardé avec succès.\n",
      "\n",
      "=====================================================\n",
      "                RÉSUMÉ FINAL 2021\n",
      "=====================================================\n",
      "Montant total CIR déclaré (Original):       470,488,283.00 €\n",
      "Montant total CIR calculé (Original):       453,725,388.47 €\n",
      "Montant total CIR après corrections:        453,738,653.93 €\n",
      "\n",
      "Écart initial (calculé - déclaré):        -16,762,894.53 €\n",
      "Écart final (corrigé - déclaré):          -16,749,629.07 €\n",
      "Réduction de l'écart absolu:              13,265.46 €\n",
      "  Écart relatif initial:                  -3.56%\n",
      "  Écart relatif final:                    -3.56%\n",
      "  Réduction relative de l'écart:          0.08%\n",
      "\n",
      "--- Détails par Type de Traitement Appliqué ---\n",
      "\n",
      "Nombre d'entreprises par type de traitement final:\n",
      "  - Err_PLAF_EVW                            :        443\n",
      "  - Err_dep_personnel                       :          2\n",
      "  - Err_petite                              :          3\n",
      "  - Non traité                              :      3,406\n",
      "  - err_cir_total_declarer                  :          3\n",
      "  - innov_manquant                          :        636\n",
      "\n",
      "Détails financiers par type de traitement final:\n",
      "\n",
      "Traitement: Err_PLAF_EVW\n",
      "  Nombre d'entreprises:                 443       \n",
      "  CIR déclaré (groupe):                      12,471,138.00 €\n",
      "  CIR corrigé final (groupe):                         0.43 €\n",
      "  Écart final (corrigé-déclaré groupe):     -12,471,137.57 €\n",
      "  Impact relatif final (groupe):                  -100.00%\n",
      "\n",
      "Traitement: Err_dep_personnel\n",
      "  Nombre d'entreprises:                 2         \n",
      "  CIR déclaré (groupe):                          43,074.00 €\n",
      "  CIR corrigé final (groupe):                   131,007.81 €\n",
      "  Écart final (corrigé-déclaré groupe):          87,933.81 €\n",
      "  Impact relatif final (groupe):                   204.15%\n",
      "\n",
      "Traitement: Err_petite\n",
      "  Nombre d'entreprises:                 3         \n",
      "  CIR déclaré (groupe):                         196,752.00 €\n",
      "  CIR corrigé final (groupe):                   196,721.29 €\n",
      "  Écart final (corrigé-déclaré groupe):             -30.71 €\n",
      "  Impact relatif final (groupe):                    -0.02%\n",
      "\n",
      "Traitement: Non traité\n",
      "  Nombre d'entreprises:                 3,406     \n",
      "  CIR déclaré (groupe):                     424,180,041.00 €\n",
      "  CIR corrigé final (groupe):               393,668,562.44 €\n",
      "  Écart final (corrigé-déclaré groupe):     -30,511,478.56 €\n",
      "  Impact relatif final (groupe):                    -7.19%\n",
      "\n",
      "Traitement: err_cir_total_declarer\n",
      "  Nombre d'entreprises:                 3         \n",
      "  CIR déclaré (groupe):                               0.00 €\n",
      "  CIR corrigé final (groupe):                   234,295.90 €\n",
      "  Écart final (corrigé-déclaré groupe):         234,295.90 €\n",
      "\n",
      "Traitement: innov_manquant\n",
      "  Nombre d'entreprises:                 636       \n",
      "  CIR déclaré (groupe):                      33,597,278.00 €\n",
      "  CIR corrigé final (groupe):                59,508,066.06 €\n",
      "  Écart final (corrigé-déclaré groupe):      25,910,788.06 €\n",
      "  Impact relatif final (groupe):                    77.12%\n",
      "\n",
      "=====================================================\n",
      "Traitement terminé pour 2021.\n",
      "=====================================================\n",
      "\n",
      "Script terminé avec succès.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# ===================================================================\n",
    "# FONCTIONS UTILITAIRES\n",
    "# ===================================================================\n",
    "\n",
    "def format_siren(siren):\n",
    "    \"\"\"Formate les SIREN pour avoir exactement 9 caractères\"\"\"\n",
    "    if pd.isna(siren):\n",
    "        return siren\n",
    "    siren_str = str(siren).strip()\n",
    "    # Gère les formats type '123456789.0'\n",
    "    if '.' in siren_str:\n",
    "        siren_str = siren_str.split('.')[0]\n",
    "    return siren_str.zfill(9)\n",
    "\n",
    "def convertir_en_nombre(valeur, defaut=0.0):\n",
    "    \"\"\"Convertit une valeur en nombre flottant de façon sécurisée\"\"\"\n",
    "    if pd.isna(valeur):\n",
    "        return defaut\n",
    "    valeur_str = str(valeur).strip()\n",
    "    if valeur_str == '':\n",
    "        return defaut\n",
    "    try:\n",
    "        # Remplace la virgule par un point pour la conversion décimale\n",
    "        return float(valeur_str.replace(',', '.'))\n",
    "    except ValueError:\n",
    "        # Retourne la valeur par défaut en cas d'erreur de conversion\n",
    "        return defaut\n",
    "    except Exception:\n",
    "         # Capture d'autres erreurs potentielles\n",
    "        return defaut\n",
    "\n",
    "# ===================================================================\n",
    "# CHARGEMENT ET PRÉPARATION DES DONNÉES\n",
    "# ===================================================================\n",
    "\n",
    "def charger_donnees(file_path=\"Calcul_Creance_CIR_2021.csv\"):\n",
    "    \"\"\"Charge et prépare les données du fichier CIR 2021\"\"\"\n",
    "    print(f\"Chargement et préparation des données depuis: {file_path}...\")\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig',\n",
    "                         converters={'SIREN_DECLARANT': str, 'SIREN_DEPOSANT': str},\n",
    "                         low_memory=False)\n",
    "        print(f\"Fichier principal chargé: {len(df):,} lignes\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERREUR: Fichier non trouvé: {file_path}.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"ERREUR lors du chargement du fichier principal: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "    print(\"Formatage des SIRENs...\")\n",
    "    if 'SIREN_DECLARANT' in df.columns:\n",
    "        df['SIREN_DECLARANT'] = df['SIREN_DECLARANT'].apply(format_siren)\n",
    "    else:\n",
    "        print(\"ERREUR CRITIQUE: Colonne 'SIREN_DECLARANT' non trouvée.\")\n",
    "        return None\n",
    "    if 'SIREN_DEPOSANT' in df.columns:\n",
    "        df['SIREN_DEPOSANT'] = df['SIREN_DEPOSANT'].apply(format_siren)\n",
    "\n",
    "    if 'TRAITEMENT_APPLIQUE' not in df.columns:\n",
    "        df['TRAITEMENT_APPLIQUE'] = \"Non traité\"\n",
    "    else:\n",
    "         # Assure que la colonne est de type string\n",
    "         df['TRAITEMENT_APPLIQUE'] = df['TRAITEMENT_APPLIQUE'].astype(str)\n",
    "\n",
    "    # Liste exhaustive des colonnes numériques à convertir (pour 2021)\n",
    "    numeric_cols = [\n",
    "        'L1_DOTATION_AMORT_IMMO', 'L2_DOTATION_AMORT_SINISTR', 'L3_DEPENSES_PERSONNEL_CHERCHEURS',\n",
    "        'L4_REMUNERATION_INVENTEURS', 'L5_DEPENSES_JEUNES_DOCTEURS', 'L6_AUTRES_DEP_FONCT_CALCULE',\n",
    "        'L7_TOTAL_DEP_FONCT_DECLARE', 'L7_TOTAL_DEP_FONCT_CALCULE', 'L8_FRAIS_BREVETS_COV',\n",
    "        'L9_DEPENSES_DEFENSE_BREVETS', 'L10_DOTATION_AMORT_BREVETS', 'L11_DEPENSES_NORMALISATION',\n",
    "        'L12_PRIMES_COTISATIONS_BRUT', 'L12_PRIMES_COTISATIONS_PLAFONNEES', 'L13_VEILLE_TECHNO_BRUT',\n",
    "        'L13_VEILLE_TECHNO_PLAFONNEE', 'L14_TOTAL_DEPENSES_INTERNES_CALCULE', 'L26_TOTAL_ST_PLAFONNE_CALCULE',\n",
    "        'L27_TOTAL_DEPENSES_RECHERCHE_CALCULE', 'L28A_SUBVENTIONS', 'L28B_SOMMES_ENCAISSEES_TIERS',\n",
    "        'L29_DEPENSES_CONSEIL_CIR', 'L30_REMBOURSEMENTS_SUBVENTIONS', 'L31A_MONTANT_NET_DEPENSES_CALCULE',\n",
    "        'L31B_MONTANT_NET_DEPENSES_DOM_CALCULE', 'CIR_RECHERCHE_CALCULE', 'CIR_COLLECTION_CALCULE',\n",
    "        'CIR_INNOVATION_CALCULE', 'CIR_TOTAL_DECLARE', 'CIR_TOTAL_CALCULE',\n",
    "        'CIR_TOTAL_ECART', 'ECART_RELATIF_POURCENT', 'CIR_RECHERCHE_ECART', 'CIR_INNOVATION_ECART',\n",
    "        'CIR_COLLECTION_ECART', 'L6_ECART', 'L14_ECART', 'L17_ECART', 'L20_ECART',\n",
    "        'L21_ECART', 'L22_ECART', 'L26_ECART', 'L27_ECART', 'L31A_ECART', 'L31B_ECART',\n",
    "        'CIR_TOTAL_CORRIGE' # Inclure si existe déjà\n",
    "    ]\n",
    "\n",
    "    print(\"Conversion des colonnes numériques...\")\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].apply(convertir_en_nombre)\n",
    "\n",
    "    # Initialisation de CIR_TOTAL_CORRIGE après les conversions\n",
    "    if 'CIR_TOTAL_CORRIGE' not in df.columns:\n",
    "        print(\"Initialisation de la colonne 'CIR_TOTAL_CORRIGE'...\")\n",
    "        if 'CIR_TOTAL_CALCULE' in df.columns:\n",
    "            df['CIR_TOTAL_CORRIGE'] = df['CIR_TOTAL_CALCULE'].copy()\n",
    "        else:\n",
    "            print(\"  Attention: 'CIR_TOTAL_CALCULE' non trouvé. 'CIR_TOTAL_CORRIGE' initialisé à 0.0.\")\n",
    "            df['CIR_TOTAL_CORRIGE'] = 0.0\n",
    "    else:\n",
    "        # Assurer qu'elle est bien numérique si elle existait\n",
    "        df['CIR_TOTAL_CORRIGE'] = df['CIR_TOTAL_CORRIGE'].apply(convertir_en_nombre)\n",
    "        print(\"La colonne 'CIR_TOTAL_CORRIGE' existait déjà et a été (re)convertie en numérique.\")\n",
    "\n",
    "    # Vérification finale des colonnes essentielles\n",
    "    essential_cols = ['SIREN_DECLARANT', 'CIR_TOTAL_DECLARE', 'CIR_TOTAL_CALCULE', 'CIR_TOTAL_CORRIGE']\n",
    "    for col in essential_cols:\n",
    "        if col not in df.columns:\n",
    "            print(f\"ERREUR CRITIQUE: Colonne essentielle '{col}' est manquante après chargement/préparation.\")\n",
    "            return None\n",
    "\n",
    "    print(\"Préparation des données terminée.\")\n",
    "    return df\n",
    "\n",
    "def charger_fichier_intermediaire(file_path, main_df_columns):\n",
    "    \"\"\"Charge un fichier intermédiaire, formate SIREN et convertit num.\"\"\"\n",
    "    try:\n",
    "        df_inter = pd.read_csv(file_path, sep=';', encoding='utf-8-sig',\n",
    "                               converters={'SIREN_DECLARANT': str, 'SIREN_DEPOSANT': str},\n",
    "                               low_memory=False)\n",
    "        if 'SIREN_DECLARANT' in df_inter.columns:\n",
    "            df_inter['SIREN_DECLARANT'] = df_inter['SIREN_DECLARANT'].apply(format_siren)\n",
    "        else:\n",
    "             print(f\"Attention: 'SIREN_DECLARANT' manquant dans '{file_path}'.\")\n",
    "             return pd.DataFrame(columns=main_df_columns)\n",
    "\n",
    "        numeric_cols_inter = [\n",
    "            'CIR_TOTAL_DECLARE', 'CIR_TOTAL_CALCULE', 'CIR_TOTAL_ECART',\n",
    "            'CIR_RECHERCHE_ECART', 'CIR_COLLECTION_ECART', 'CIR_INNOVATION_ECART'\n",
    "        ]\n",
    "        for col in numeric_cols_inter:\n",
    "            if col in df_inter.columns:\n",
    "                df_inter[col] = df_inter[col].apply(convertir_en_nombre)\n",
    "        if 'EST_EGAL' in df_inter.columns:\n",
    "             df_inter['EST_EGAL'] = df_inter['EST_EGAL'].apply(lambda x: str(x).strip().lower() == 'true')\n",
    "        return df_inter\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Info: Fichier intermédiaire '{file_path}' non trouvé.\")\n",
    "        return pd.DataFrame(columns=main_df_columns)\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur chargement fichier intermédiaire '{file_path}': {str(e)}\")\n",
    "        return pd.DataFrame(columns=main_df_columns)\n",
    "\n",
    "# ===================================================================\n",
    "# FONCTIONS DE CORRECTION (adaptées pour 2021)\n",
    "# ===================================================================\n",
    "\n",
    "def correction_erreurs_personnel(df, processed_sirens, fichier_intermediaire=\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\"):\n",
    "    \"\"\"Corrige les erreurs de dépenses de personnel (jeunes docteurs) pour 2021.\"\"\"\n",
    "    print(\"\\n1. CORRECTION ERREURS DÉPENSES PERSONNEL (JEUNES DOCTEURS) 2021\")\n",
    "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
    "    if df_error.empty: return 0\n",
    "    count = 0\n",
    "    before_sum = df_error['CIR_TOTAL_DECLARE'].sum() if 'CIR_TOTAL_DECLARE' in df_error.columns else 0.0\n",
    "    indices_traites_localement = []\n",
    "    for _, row in df_error.iterrows():\n",
    "        siren = row['SIREN_DECLARANT']\n",
    "        if siren in processed_sirens: continue\n",
    "        mask = df['SIREN_DECLARANT'] == siren\n",
    "        if not mask.any(): continue\n",
    "        idx = df.index[mask].tolist()[0]\n",
    "        l1_val=convertir_en_nombre(df.loc[idx,'L1_DOTATION_AMORT_IMMO']); l2_val=convertir_en_nombre(df.loc[idx,'L2_DOTATION_AMORT_SINISTR'])\n",
    "        l4_val=convertir_en_nombre(df.loc[idx,'L4_REMUNERATION_INVENTEURS']); l5_val=convertir_en_nombre(df.loc[idx,'L5_DEPENSES_JEUNES_DOCTEURS'])\n",
    "        l8_val=convertir_en_nombre(df.loc[idx,'L8_FRAIS_BREVETS_COV']); l9_val=convertir_en_nombre(df.loc[idx,'L9_DEPENSES_DEFENSE_BREVETS'])\n",
    "        l10_val=convertir_en_nombre(df.loc[idx,'L10_DOTATION_AMORT_BREVETS']); l11_val=convertir_en_nombre(df.loc[idx,'L11_DEPENSES_NORMALISATION'])\n",
    "        l12_brut_val=convertir_en_nombre(df.loc[idx,'L12_PRIMES_COTISATIONS_BRUT']); l13_brut_val=convertir_en_nombre(df.loc[idx,'L13_VEILLE_TECHNO_BRUT'])\n",
    "        l26_calcule_val=convertir_en_nombre(df.loc[idx,'L26_TOTAL_ST_PLAFONNE_CALCULE']); l28a_val=convertir_en_nombre(df.loc[idx,'L28A_SUBVENTIONS'])\n",
    "        l28b_val=convertir_en_nombre(df.loc[idx,'L28B_SOMMES_ENCAISSEES_TIERS']); l29_val=convertir_en_nombre(df.loc[idx,'L29_DEPENSES_CONSEIL_CIR'])\n",
    "        l30_val=convertir_en_nombre(df.loc[idx,'L30_REMBOURSEMENTS_SUBVENTIONS']); cir_coll_val=convertir_en_nombre(df.loc[idx,'CIR_COLLECTION_CALCULE'])\n",
    "        cir_inno_val=convertir_en_nombre(df.loc[idx,'CIR_INNOVATION_CALCULE'])\n",
    "        l31b_val=convertir_en_nombre(df.loc[idx,'L31B_MONTANT_NET_DEPENSES_DOM_CALCULE'])\n",
    "        df.loc[idx,'L3_DEPENSES_PERSONNEL_CHERCHEURS']=l2_val; df.loc[idx,'L2_DOTATION_AMORT_SINISTR']=0.0\n",
    "        dep_cherch_tech_updated=df.loc[idx,'L3_DEPENSES_PERSONNEL_CHERCHEURS']; l2_updated=df.loc[idx,'L2_DOTATION_AMORT_SINISTR']\n",
    "        autres_dep_fonct=(l1_val*0.75)+((dep_cherch_tech_updated+l4_val)*0.43)+l5_val; df.loc[idx,'L6_AUTRES_DEP_FONCT_CALCULE']=autres_dep_fonct\n",
    "        total_dep_fonct=l1_val+l2_updated+dep_cherch_tech_updated+l4_val+l5_val+autres_dep_fonct; df.loc[idx,'L7_TOTAL_DEP_FONCT_CALCULE']=total_dep_fonct\n",
    "        prim_cotiz_plaf=min(l12_brut_val,60000); dep_veil_techno_plaf=min(l13_brut_val,60000)\n",
    "        total_dep_internes=total_dep_fonct+l8_val+l9_val+l10_val+l11_val+prim_cotiz_plaf+dep_veil_techno_plaf; df.loc[idx,'L14_TOTAL_DEPENSES_INTERNES_CALCULE']=total_dep_internes\n",
    "        total_dep_recherche=total_dep_internes+l26_calcule_val; df.loc[idx,'L27_TOTAL_DEPENSES_RECHERCHE_CALCULE']=total_dep_recherche\n",
    "        montant_net=total_dep_recherche-l28a_val-l28b_val-l29_val+l30_val; df.loc[idx,'L31A_MONTANT_NET_DEPENSES_CALCULE']=montant_net\n",
    "        taux_dom,taux_non_dom=0.50,0.30\n",
    "        if 'L31B_MONTANT_NET_DEPENSES_DOM_CALCULE' in df.columns and l31b_val > 0 :\n",
    "             montant_net_non_dom = max(0, montant_net - l31b_val); cir_recherche = (montant_net_non_dom * taux_non_dom) + (l31b_val * taux_dom)\n",
    "        else: cir_recherche = montant_net * taux_non_dom\n",
    "        cir_recherche=max(0, cir_recherche); df.loc[idx,'CIR_RECHERCHE_CALCULE']=cir_recherche\n",
    "        cir_total=cir_recherche+cir_coll_val+cir_inno_val; df.loc[idx,'CIR_TOTAL_CALCULE']=cir_total\n",
    "        df.loc[idx,'CIR_TOTAL_CORRIGE']=cir_total; df.loc[idx,'TRAITEMENT_APPLIQUE']=\"Err_dep_personnel\"\n",
    "        processed_sirens.add(siren); indices_traites_localement.append(idx); count+=1\n",
    "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
    "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
    "    return count\n",
    "\n",
    "def correction_erreurs_frais_brevets(df, processed_sirens, fichier_intermediaire=\"lignes_L7_egal_L8.csv\"):\n",
    "    \"\"\"Corrige les erreurs où L7 (déclaré) est égal à L8 pour 2021.\"\"\"\n",
    "    print(\"\\n2. CORRECTION ERREUR L7 = L8 (FRAIS BREVETS) 2021\")\n",
    "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
    "    if df_error.empty: return 0\n",
    "    count = 0\n",
    "    before_sum = df_error['CIR_TOTAL_DECLARE'].sum() if 'CIR_TOTAL_DECLARE' in df_error.columns else 0.0\n",
    "    indices_traites_localement = []\n",
    "    for _, row in df_error.iterrows():\n",
    "        siren = row['SIREN_DECLARANT']\n",
    "        if siren in processed_sirens: continue\n",
    "        mask = df['SIREN_DECLARANT'] == siren\n",
    "        if not mask.any(): continue\n",
    "        idx = df.index[mask].tolist()[0]\n",
    "        l1_val=convertir_en_nombre(df.loc[idx,'L1_DOTATION_AMORT_IMMO']); l2_val=convertir_en_nombre(df.loc[idx,'L2_DOTATION_AMORT_SINISTR'])\n",
    "        l3_val=convertir_en_nombre(df.loc[idx,'L3_DEPENSES_PERSONNEL_CHERCHEURS']); l4_val=convertir_en_nombre(df.loc[idx,'L4_REMUNERATION_INVENTEURS'])\n",
    "        l5_val=convertir_en_nombre(df.loc[idx,'L5_DEPENSES_JEUNES_DOCTEURS']); l9_val=convertir_en_nombre(df.loc[idx,'L9_DEPENSES_DEFENSE_BREVETS'])\n",
    "        l10_val=convertir_en_nombre(df.loc[idx,'L10_DOTATION_AMORT_BREVETS']); l11_val=convertir_en_nombre(df.loc[idx,'L11_DEPENSES_NORMALISATION'])\n",
    "        l12_plaf_val=convertir_en_nombre(df.loc[idx,'L12_PRIMES_COTISATIONS_PLAFONNEES']); l13_plaf_val=convertir_en_nombre(df.loc[idx,'L13_VEILLE_TECHNO_PLAFONNEE'])\n",
    "        l26_calcule_val=convertir_en_nombre(df.loc[idx,'L26_TOTAL_ST_PLAFONNE_CALCULE']); l28a_val=convertir_en_nombre(df.loc[idx,'L28A_SUBVENTIONS'])\n",
    "        l28b_val=convertir_en_nombre(df.loc[idx,'L28B_SOMMES_ENCAISSEES_TIERS']); l29_val=convertir_en_nombre(df.loc[idx,'L29_DEPENSES_CONSEIL_CIR'])\n",
    "        l30_val=convertir_en_nombre(df.loc[idx,'L30_REMBOURSEMENTS_SUBVENTIONS']); cir_coll_val=convertir_en_nombre(df.loc[idx,'CIR_COLLECTION_CALCULE'])\n",
    "        cir_inno_val=convertir_en_nombre(df.loc[idx,'CIR_INNOVATION_CALCULE'])\n",
    "        l31b_val=convertir_en_nombre(df.loc[idx,'L31B_MONTANT_NET_DEPENSES_DOM_CALCULE'])\n",
    "        df.loc[idx, 'L8_FRAIS_BREVETS_COV'] = 0.0; l8_corrected_val = 0.0\n",
    "        autres_dep_fonct = (l1_val*0.75) + ((l3_val + l4_val)*0.43) + l5_val; df.loc[idx, 'L6_AUTRES_DEP_FONCT_CALCULE'] = autres_dep_fonct\n",
    "        total_dep_fonct = l1_val+l2_val+l3_val+l4_val+l5_val+autres_dep_fonct; df.loc[idx, 'L7_TOTAL_DEP_FONCT_CALCULE'] = total_dep_fonct\n",
    "        total_dep_internes = total_dep_fonct + l8_corrected_val + l9_val + l10_val + l11_val + l12_plaf_val + l13_plaf_val\n",
    "        df.loc[idx, 'L14_TOTAL_DEPENSES_INTERNES_CALCULE'] = total_dep_internes\n",
    "        total_dep_recherche = total_dep_internes + l26_calcule_val; df.loc[idx, 'L27_TOTAL_DEPENSES_RECHERCHE_CALCULE'] = total_dep_recherche\n",
    "        montant_net = total_dep_recherche - l28a_val - l28b_val - l29_val + l30_val; df.loc[idx, 'L31A_MONTANT_NET_DEPENSES_CALCULE'] = montant_net\n",
    "        taux_dom, taux_non_dom = 0.50, 0.30\n",
    "        if 'L31B_MONTANT_NET_DEPENSES_DOM_CALCULE' in df.columns and l31b_val > 0 :\n",
    "             montant_net_non_dom = max(0, montant_net - l31b_val); cir_recherche = (montant_net_non_dom * taux_non_dom) + (l31b_val * taux_dom)\n",
    "        else: cir_recherche = montant_net * taux_non_dom\n",
    "        cir_recherche = max(0, cir_recherche); df.loc[idx, 'CIR_RECHERCHE_CALCULE'] = cir_recherche\n",
    "        cir_total = cir_recherche + cir_coll_val + cir_inno_val; df.loc[idx, 'CIR_TOTAL_CALCULE'] = cir_total\n",
    "        df.loc[idx, 'CIR_TOTAL_CORRIGE'] = cir_total; df.loc[idx, 'TRAITEMENT_APPLIQUE'] = \"Err_Frais_BRV\"\n",
    "        processed_sirens.add(siren); indices_traites_localement.append(idx); count += 1\n",
    "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
    "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
    "    return count\n",
    "\n",
    "def correction_cir_recherche_manquant(df, processed_sirens, fichier_intermediaire=\"lignes_depenses_non0_cir_recherche_0.csv\"):\n",
    "    \"\"\"Corrige les cas où le CIR recherche déclaré est manquant ou incohérent pour 2021.\"\"\"\n",
    "    print(\"\\n3. CORRECTION CIR RECHERCHE MANQUANT/INCOHÉRENT 2021\")\n",
    "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
    "    if df_error.empty: return 0\n",
    "    count = 0\n",
    "    before_sum = df_error['CIR_TOTAL_DECLARE'].sum() if 'CIR_TOTAL_DECLARE' in df_error.columns else 0.0\n",
    "    indices_traites_localement = []\n",
    "    for _, row in df_error.iterrows():\n",
    "        siren = row['SIREN_DECLARANT']\n",
    "        if siren in processed_sirens: continue\n",
    "        mask = df['SIREN_DECLARANT'] == siren\n",
    "        if not mask.any(): continue\n",
    "        idx = df.index[mask].tolist()[0]\n",
    "        calculated_value = df.loc[idx, 'CIR_TOTAL_CALCULE']\n",
    "        df.loc[idx, 'CIR_TOTAL_CORRIGE'] = calculated_value; df.loc[idx, 'TRAITEMENT_APPLIQUE'] = \"Err_CIR_RECH\"\n",
    "        processed_sirens.add(siren); indices_traites_localement.append(idx); count += 1\n",
    "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
    "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
    "    return count\n",
    "\n",
    "\n",
    "\n",
    "def correction_doublement_sans_motif(df, processed_sirens, fichier_intermediaire=\"lignes_ecart_relatif_50_innovation0_recherche1.csv\"):\n",
    "    \"\"\"Corrige les erreurs de doublement apparent (écart relatif ~50%) pour 2021. Prend la moyenne.\"\"\"\n",
    "    print(\"\\n5. CORRECTION DOUBLEMENT SANS MOTIF (ÉCART ~50%) 2021\")\n",
    "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
    "    if df_error.empty: return 0\n",
    "    count = 0\n",
    "    before_sum = df_error['CIR_TOTAL_DECLARE'].sum() if 'CIR_TOTAL_DECLARE' in df_error.columns else 0.0\n",
    "    indices_traites_localement = []\n",
    "    for _, row in df_error.iterrows():\n",
    "        siren = row['SIREN_DECLARANT']\n",
    "        if siren in processed_sirens: continue\n",
    "        mask = df['SIREN_DECLARANT'] == siren\n",
    "        if not mask.any(): continue\n",
    "        idx = df.index[mask].tolist()[0]\n",
    "        declared = df.loc[idx, 'CIR_TOTAL_DECLARE']; calculated = df.loc[idx, 'CIR_TOTAL_CALCULE']\n",
    "        corrected = calculated if abs(declared) < 0.01 else (declared + calculated) / 2\n",
    "        df.loc[idx, 'CIR_TOTAL_CORRIGE'] = corrected; df.loc[idx, 'TRAITEMENT_APPLIQUE'] = \"Err_dbl_creance_totale\"\n",
    "        processed_sirens.add(siren); indices_traites_localement.append(idx); count += 1\n",
    "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
    "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
    "    return count\n",
    "\n",
    "def correction_ecart_petit(df, processed_sirens, fichier_intermediaire=\"lignes_ecart_total_entre_-500_et_500.csv\"):\n",
    "    \"\"\"Corrige les petits écarts (-500 à 500 EUR) en prenant la moyenne pour 2021.\"\"\"\n",
    "    print(\"\\n6. CORRECTION PETIT ÉCART (-500 à 500 EUR) 2021\")\n",
    "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
    "    if df_error.empty: return 0\n",
    "    count = 0\n",
    "    before_sum = df_error['CIR_TOTAL_DECLARE'].sum() if 'CIR_TOTAL_DECLARE' in df_error.columns else 0.0\n",
    "    indices_traites_localement = []\n",
    "    for _, row in df_error.iterrows():\n",
    "        siren = row['SIREN_DECLARANT']\n",
    "        if siren in processed_sirens: continue\n",
    "        mask = df['SIREN_DECLARANT'] == siren\n",
    "        if not mask.any(): continue\n",
    "        idx = df.index[mask].tolist()[0]\n",
    "        declared = df.loc[idx, 'CIR_TOTAL_DECLARE']; calculated = df.loc[idx, 'CIR_TOTAL_CALCULE']\n",
    "        corrected = (declared + calculated) / 2\n",
    "        df.loc[idx, 'CIR_TOTAL_CORRIGE'] = corrected; df.loc[idx, 'TRAITEMENT_APPLIQUE'] = \"Err_petite\"\n",
    "        processed_sirens.add(siren); indices_traites_localement.append(idx); count += 1\n",
    "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
    "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
    "    return count\n",
    "\n",
    "def correction_plafond_partout(df, processed_sirens, fichier_intermediaire=\"lignes_ecart_relatif_moins_100.csv\"):\n",
    "    \"\"\"Corrige les cas où l'écart est -100% (calculé=0), utilise la valeur calculée (0) pour 2021.\"\"\"\n",
    "    print(\"\\n7. CORRECTION PLAFOND PARTOUT (ÉCART -100%) 2021\")\n",
    "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
    "    if df_error.empty: return 0\n",
    "    count = 0\n",
    "    before_sum = df_error['CIR_TOTAL_DECLARE'].sum() if 'CIR_TOTAL_DECLARE' in df_error.columns else 0.0\n",
    "    indices_traites_localement = []\n",
    "    for _, row in df_error.iterrows():\n",
    "        siren = row['SIREN_DECLARANT']\n",
    "        if siren in processed_sirens: continue\n",
    "        mask = df['SIREN_DECLARANT'] == siren\n",
    "        if not mask.any(): continue\n",
    "        idx = df.index[mask].tolist()[0]\n",
    "        calculated_value = df.loc[idx, 'CIR_TOTAL_CALCULE'] # Should be ~0\n",
    "        df.loc[idx, 'CIR_TOTAL_CORRIGE'] = calculated_value; df.loc[idx, 'TRAITEMENT_APPLIQUE'] = \"Err_PLAF_EVW\"\n",
    "        processed_sirens.add(siren); indices_traites_localement.append(idx); count += 1\n",
    "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
    "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
    "    return count\n",
    "\n",
    "def correction_cir_innovation(df, processed_sirens, fichier_intermediaire=\"lignes_ecart_total_egal_innovation.csv\"):\n",
    "    \"\"\"Corrige les cas où l'écart total correspond au CIR Innovation calculé pour 2021.\"\"\"\n",
    "    print(\"\\n8. CORRECTION CIR INNOVATION MANQUANT (ÉCART = INNOVATION) 2021\")\n",
    "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
    "    if df_error.empty: return 0\n",
    "    count = 0\n",
    "    before_sum = df_error['CIR_TOTAL_DECLARE'].sum() if 'CIR_TOTAL_DECLARE' in df_error.columns else 0.0\n",
    "    indices_traites_localement = []\n",
    "    for _, row in df_error.iterrows():\n",
    "        siren = row['SIREN_DECLARANT']\n",
    "        if siren in processed_sirens: continue\n",
    "        mask = df['SIREN_DECLARANT'] == siren\n",
    "        if not mask.any(): continue\n",
    "        idx = df.index[mask].tolist()[0]\n",
    "        calculated_value = df.loc[idx, 'CIR_TOTAL_CALCULE']\n",
    "        df.loc[idx, 'CIR_TOTAL_CORRIGE'] = calculated_value; df.loc[idx, 'TRAITEMENT_APPLIQUE'] = \"innov_manquant\"\n",
    "        processed_sirens.add(siren); indices_traites_localement.append(idx); count += 1\n",
    "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
    "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
    "    return count\n",
    "\n",
    "def correction_cir_collection(df, processed_sirens, fichier_intermediaire=\"lignes_ecart_total_egal_collection.csv\"):\n",
    "    \"\"\"Corrige les cas où l'écart total correspond au CIR Collection calculé pour 2021.\"\"\"\n",
    "    print(\"\\n9. CORRECTION CIR COLLECTION MANQUANT (ÉCART = COLLECTION) 2021\")\n",
    "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
    "    if df_error.empty: return 0\n",
    "    count = 0\n",
    "    before_sum = df_error['CIR_TOTAL_DECLARE'].sum() if 'CIR_TOTAL_DECLARE' in df_error.columns else 0.0\n",
    "    indices_traites_localement = []\n",
    "    for _, row in df_error.iterrows():\n",
    "        siren = row['SIREN_DECLARANT']\n",
    "        if siren in processed_sirens: continue\n",
    "        mask = df['SIREN_DECLARANT'] == siren\n",
    "        if not mask.any(): continue\n",
    "        idx = df.index[mask].tolist()[0]\n",
    "        calculated_value = df.loc[idx, 'CIR_TOTAL_CALCULE']\n",
    "        df.loc[idx, 'CIR_TOTAL_CORRIGE'] = calculated_value; df.loc[idx, 'TRAITEMENT_APPLIQUE'] = \"collect_manquant\"\n",
    "        processed_sirens.add(siren); indices_traites_localement.append(idx); count += 1\n",
    "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
    "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
    "    return count\n",
    "\n",
    "def correction_cir_declare_zero(df, processed_sirens, fichier_intermediaire=\"lignes_ecart_100_cir_declare_0.csv\"):\n",
    "    \"\"\"Corrige les cas où le CIR déclaré est 0 mais le calculé est positif pour 2021.\"\"\"\n",
    "    print(\"\\n10. CORRECTION CIR DÉCLARÉ = 0 (ÉCART +100%) 2021\")\n",
    "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
    "    if df_error.empty: return 0\n",
    "    count = 0\n",
    "    before_sum = 0.0 # Déclaré est 0\n",
    "    indices_traites_localement = []\n",
    "    for _, row in df_error.iterrows():\n",
    "        siren = row['SIREN_DECLARANT']\n",
    "        if siren in processed_sirens: continue\n",
    "        mask = df['SIREN_DECLARANT'] == siren\n",
    "        if not mask.any(): continue\n",
    "        idx = df.index[mask].tolist()[0]\n",
    "        calculated_value = df.loc[idx, 'CIR_TOTAL_CALCULE']\n",
    "        df.loc[idx, 'CIR_TOTAL_CORRIGE'] = calculated_value; df.loc[idx, 'TRAITEMENT_APPLIQUE'] = \"err_cir_total_declarer\"\n",
    "        processed_sirens.add(siren); indices_traites_localement.append(idx); count += 1\n",
    "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
    "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
    "    return count\n",
    "\n",
    "def correction_erreurs_l6(df, processed_sirens, fichier_intermediaire=\"lignes_ecart_total_egal_recherche_l6_ecart_hors_1.csv\"):\n",
    "    \"\"\"Corrige les erreurs liées à la ligne L6 (Autres dépenses de fonctionnement) pour 2021.\"\"\"\n",
    "    print(\"\\n11. CORRECTION ERREURS LIÉES À L6 - 2021\")\n",
    "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
    "    if df_error.empty: return 0\n",
    "    count = 0\n",
    "    before_sum = df_error['CIR_TOTAL_DECLARE'].sum() if 'CIR_TOTAL_DECLARE' in df_error.columns else 0.0\n",
    "    indices_traites_localement = []\n",
    "    for _, row in df_error.iterrows():\n",
    "        siren = row['SIREN_DECLARANT']\n",
    "        if siren in processed_sirens: continue\n",
    "        mask = df['SIREN_DECLARANT'] == siren\n",
    "        if not mask.any(): continue\n",
    "        idx = df.index[mask].tolist()[0]\n",
    "        calculated_value = df.loc[idx, 'CIR_TOTAL_CALCULE']\n",
    "        df.loc[idx, 'CIR_TOTAL_CORRIGE'] = calculated_value; df.loc[idx, 'TRAITEMENT_APPLIQUE'] = \"err_l6\"\n",
    "        processed_sirens.add(siren); indices_traites_localement.append(idx); count += 1\n",
    "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
    "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
    "    return count\n",
    "\n",
    "\n",
    "\n",
    "def correction_valeur_calculee_reste(df, processed_sirens, fichier_intermediaire=\"lignes_restantes_a_analyser.csv\"):\n",
    "    \"\"\"Applique la valeur calculée aux cas restants identifiés pour 2021.\"\"\"\n",
    "    print(\"\\n13. VALEUR CALCULÉE PRIVILÉGIÉE POUR LE RESTE IDENTIFIÉ - 2021\")\n",
    "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
    "    if df_error.empty: return 0\n",
    "    count = 0\n",
    "    before_sum = df_error['CIR_TOTAL_DECLARE'].sum() if 'CIR_TOTAL_DECLARE' in df_error.columns else 0.0\n",
    "    indices_traites_localement = []\n",
    "    for _, row in df_error.iterrows():\n",
    "        siren = row['SIREN_DECLARANT']\n",
    "        if siren in processed_sirens: continue\n",
    "        mask = df['SIREN_DECLARANT'] == siren\n",
    "        if not mask.any(): continue\n",
    "        idx = df.index[mask].tolist()[0]\n",
    "        calculated_value = df.loc[idx, 'CIR_TOTAL_CALCULE']\n",
    "        df.loc[idx, 'CIR_TOTAL_CORRIGE'] = calculated_value\n",
    "        df.loc[idx, 'TRAITEMENT_APPLIQUE'] = \"Valeur calculée privilégiée(Reste)\"\n",
    "        processed_sirens.add(siren); indices_traites_localement.append(idx); count += 1\n",
    "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
    "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
    "    return count\n",
    "\n",
    "# ===================================================================\n",
    "# FONCTION PRINCIPALE (Orchestration - Pour 2021)\n",
    "# ===================================================================\n",
    "\n",
    "def corriger_cir(file_path=\"Calcul_Creance_CIR_2021.csv\"):\n",
    "    \"\"\"Fonction principale pour charger, corriger et sauvegarder le CIR 2021.\"\"\"\n",
    "    df = charger_donnees(file_path)\n",
    "    if df is None:\n",
    "        print(\"\\nArrêt du traitement.\")\n",
    "        return None\n",
    "\n",
    "    original_declared = df['CIR_TOTAL_DECLARE'].sum()\n",
    "    original_calculated = df['CIR_TOTAL_CALCULE'].sum()\n",
    "    initial_corrected_sum = df['CIR_TOTAL_CORRIGE'].sum()\n",
    "    print(f\"\\nSommes avant corrections spécifiques:\")\n",
    "    print(f\"  - CIR Déclaré Total: {original_declared:,.2f} €\")\n",
    "    print(f\"  - CIR Calculé Total: {original_calculated:,.2f} €\")\n",
    "    print(f\"  - CIR Corrigé Initial Total: {initial_corrected_sum:,.2f} €\")\n",
    "\n",
    "    processed_sirens = set()\n",
    "    total_corrected_count = 0\n",
    "\n",
    "    print(\"\\n--- Début de l'application des corrections spécifiques 2021 ---\")\n",
    "    # Liste des fonctions de correction et de leurs fichiers associés (pour 2021)\n",
    "    correction_definitions = [\n",
    "        (correction_erreurs_personnel, \"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\"), #1\n",
    "        (correction_erreurs_frais_brevets, \"lignes_L7_egal_L8.csv\"), #2\n",
    "        (correction_cir_recherche_manquant, \"lignes_depenses_non0_cir_recherche_0.csv\"), #3\n",
    "        (correction_doublement_sans_motif, \"lignes_ecart_relatif_50_innovation0_recherche1.csv\"), #5\n",
    "        (correction_ecart_petit, \"lignes_ecart_total_entre_-500_et_500.csv\"), #6\n",
    "        (correction_plafond_partout, \"lignes_ecart_relatif_moins_100.csv\"), #7\n",
    "        (correction_cir_innovation, \"lignes_ecart_total_egal_innovation.csv\"), #8\n",
    "        (correction_cir_collection, \"lignes_ecart_total_egal_collection.csv\"), #9\n",
    "        (correction_cir_declare_zero, \"lignes_ecart_100_cir_declare_0.csv\"), #10\n",
    "        (correction_erreurs_l6, \"lignes_ecart_total_egal_recherche_l6_ecart_hors_1.csv\"), #11\n",
    "        (correction_valeur_calculee_reste, \"lignes_restantes_a_analyser_2021.csv\") #13\n",
    "    ]\n",
    "\n",
    "    # Exécution séquentielle des corrections\n",
    "    for func, file in correction_definitions:\n",
    "        count = func(df, processed_sirens, file)\n",
    "        total_corrected_count += count\n",
    "\n",
    "    print(f\"\\n--- Fin de l'application des corrections spécifiques 2021 ---\")\n",
    "    print(f\"Nombre total de modifications appliquées par les fonctions actives: {total_corrected_count:,}\")\n",
    "    print(f\"Nombre de SIRENs uniques traités: {len(processed_sirens):,}\")\n",
    "\n",
    "    # --- Ajustement final : Mise à zéro des CIR corrigés négatifs ---\n",
    "    print(\"\\n--- Ajustement final : Mise à zéro des CIR corrigés négatifs ---\")\n",
    "    if 'CIR_TOTAL_CORRIGE' in df.columns:\n",
    "        # Assurer le type numérique avant la comparaison\n",
    "        if not pd.api.types.is_numeric_dtype(df['CIR_TOTAL_CORRIGE']):\n",
    "             df['CIR_TOTAL_CORRIGE'] = df['CIR_TOTAL_CORRIGE'].apply(convertir_en_nombre)\n",
    "\n",
    "        negative_mask = df['CIR_TOTAL_CORRIGE'] < 0\n",
    "        count_negative = negative_mask.sum()\n",
    "        if count_negative > 0:\n",
    "            sum_before_zeroing = df.loc[negative_mask, 'CIR_TOTAL_CORRIGE'].sum()\n",
    "            df.loc[negative_mask, 'CIR_TOTAL_CORRIGE'] = 0.0\n",
    "            print(f\"{count_negative:,} lignes avec CIR_TOTAL_CORRIGE négatif ont été mises à 0 (Impact: {-sum_before_zeroing:,.2f} €).\")\n",
    "        else: print(\"Aucune valeur négative trouvée dans CIR_TOTAL_CORRIGE après corrections.\")\n",
    "    else: print(\"Erreur: Colonne 'CIR_TOTAL_CORRIGE' non trouvée pour l'ajustement final.\")\n",
    "\n",
    "    # --- Finalisation des lignes 'Non traité' ---\n",
    "    mask_non_traite_final = df['TRAITEMENT_APPLIQUE'] == \"Non traité\"\n",
    "    count_non_traite = mask_non_traite_final.sum()\n",
    "    print(f\"\\nConfirmation pour les lignes restées 'Non traité' ({count_non_traite:,}):\")\n",
    "    if count_non_traite > 0:\n",
    "        # Assurer numérique et non-négatif\n",
    "        df.loc[mask_non_traite_final, 'CIR_TOTAL_CORRIGE'] = df.loc[mask_non_traite_final, 'CIR_TOTAL_CORRIGE'].apply(convertir_en_nombre)\n",
    "        neg_in_non_traite_mask = mask_non_traite_final & (df['CIR_TOTAL_CORRIGE'] < 0)\n",
    "        count_neg_in_non_traite = neg_in_non_traite_mask.sum()\n",
    "        if count_neg_in_non_traite > 0:\n",
    "             sum_neg_non_traite = df.loc[neg_in_non_traite_mask, 'CIR_TOTAL_CORRIGE'].sum()\n",
    "             df.loc[neg_in_non_traite_mask, 'CIR_TOTAL_CORRIGE'] = 0.0\n",
    "             print(f\"  - {count_neg_in_non_traite} de ces lignes étaient négatives et mises à 0 (impact: {-sum_neg_non_traite:,.2f} €).\")\n",
    "        else: print(\"  - Aucune valeur négative parmi les lignes 'Non traité'.\")\n",
    "    else: print(\"  - Aucune ligne marquée comme 'Non traité'.\")\n",
    "\n",
    "    # --- Calcul des totaux finaux ---\n",
    "    final_total_corrected = df['CIR_TOTAL_CORRIGE'].sum()\n",
    "\n",
    "    # --- Sauvegarde avec nouveau chemin local ---\n",
    "    output_file = \"C:/Users/msamb/Documents/Calcul_Creance_CIR_Corrige_2021.csv\"\n",
    "    print(f\"\\nSauvegarde du fichier corrigé sous: {output_file}\")\n",
    "    try:\n",
    "        df.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False, decimal='.')\n",
    "        print(f\"Fichier sauvegardé avec succès.\")\n",
    "    except Exception as e: \n",
    "        print(f\"ERREUR lors de la sauvegarde: {str(e)}\")\n",
    "\n",
    "    # --- Résumé Final ---\n",
    "    print(\"\\n=====================================================\")\n",
    "    print(\"                RÉSUMÉ FINAL 2021\")\n",
    "    print(\"=====================================================\")\n",
    "    print(f\"Montant total CIR déclaré (Original):       {original_declared:,.2f} €\")\n",
    "    print(f\"Montant total CIR calculé (Original):       {original_calculated:,.2f} €\")\n",
    "    print(f\"Montant total CIR après corrections:        {final_total_corrected:,.2f} €\")\n",
    "    initial_ecart = original_calculated - original_declared\n",
    "    final_ecart = final_total_corrected - original_declared\n",
    "    improvement = abs(initial_ecart) - abs(final_ecart)\n",
    "    print(f\"\\nÉcart initial (calculé - déclaré):        {initial_ecart:,.2f} €\")\n",
    "    print(f\"Écart final (corrigé - déclaré):          {final_ecart:,.2f} €\")\n",
    "    print(f\"Réduction de l'écart absolu:              {improvement:,.2f} €\")\n",
    "    if abs(original_declared) > 0.01:\n",
    "        print(f\"  Écart relatif initial:                  {initial_ecart / original_declared * 100:.2f}%\")\n",
    "        print(f\"  Écart relatif final:                    {final_ecart / original_declared * 100:.2f}%\")\n",
    "        if abs(initial_ecart) > 0.01: print(f\"  Réduction relative de l'écart:          {improvement / abs(initial_ecart) * 100:.2f}%\")\n",
    "    else: print(\"\\nCalculs relatifs non pertinents (CIR déclaré total proche de zéro).\")\n",
    "\n",
    "    print(\"\\n--- Détails par Type de Traitement Appliqué ---\")\n",
    "    if 'TRAITEMENT_APPLIQUE' in df.columns:\n",
    "        treatment_counts = df['TRAITEMENT_APPLIQUE'].value_counts().sort_index()\n",
    "        print(\"\\nNombre d'entreprises par type de traitement final:\")\n",
    "        for treatment, count in treatment_counts.items(): print(f\"  - {treatment:<40}: {count:10,}\")\n",
    "        print(\"\\nDétails financiers par type de traitement final:\")\n",
    "        treatment_order = treatment_counts.index.tolist()\n",
    "        for treatment in treatment_order:\n",
    "            subset = df[df['TRAITEMENT_APPLIQUE'] == treatment]\n",
    "            if len(subset) == 0: continue\n",
    "            declared_subset = subset['CIR_TOTAL_DECLARE'].sum()\n",
    "            corrected_subset = subset['CIR_TOTAL_CORRIGE'].sum()\n",
    "            ecart_final_subset = corrected_subset - declared_subset\n",
    "            print(f\"\\nTraitement: {treatment}\")\n",
    "            print(f\"  Nombre d'entreprises:                 {len(subset):<10,}\")\n",
    "            print(f\"  CIR déclaré (groupe):                 {declared_subset:>18,.2f} €\")\n",
    "            print(f\"  CIR corrigé final (groupe):           {corrected_subset:>18,.2f} €\")\n",
    "            print(f\"  Écart final (corrigé-déclaré groupe): {ecart_final_subset:>18,.2f} €\")\n",
    "            if abs(declared_subset) > 0.01:\n",
    "                impact_relatif = ecart_final_subset / declared_subset * 100\n",
    "                print(f\"  Impact relatif final (groupe):        {impact_relatif:>17.2f}%\")\n",
    "    else: print(\"\\nColonne 'TRAITEMENT_APPLIQUE' non trouvée.\")\n",
    "\n",
    "    print(\"\\n=====================================================\")\n",
    "    print(\"Traitement terminé pour 2021.\")\n",
    "    print(\"=====================================================\")\n",
    "    return df\n",
    "\n",
    "# ===================================================================\n",
    "# EXÉCUTION\n",
    "# ===================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Chemin adapté pour 2021\n",
    "    input_filename = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2021.csv\"\n",
    "    print(f\"*** DÉBUT DU SCRIPT DE CORRECTION CIR 2021 ***\")\n",
    "    # Affichage de la date et heure actuelles\n",
    "    current_time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"Date et heure: {current_time_str}\")\n",
    "    print(f\"Fichier d'entrée: {input_filename}\")\n",
    "    df_corrige = corriger_cir(input_filename)\n",
    "    if df_corrige is not None: print(\"\\nScript terminé avec succès.\")\n",
    "    else: print(\"\\nLe script n'a pas pu se terminer correctement.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be088387",
   "metadata": {},
   "source": [
    "# Fusion des 2 fichiers pour avoir toute les variables dont nous avons besoin pour l'etude "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "00418560",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de SIREN communs: 2997\n",
      "Nombre de SIREN uniques dans df_corrige: 2997\n",
      "Nombre de SIREN uniques dans df_init: 2997\n",
      "Nombre de lignes avec type_final non-null: 4493 sur 4493\n",
      "Nombre de lignes avec mere_final non-null: 1694 sur 4493\n",
      "Fichier sauvegardé avec succès avec les deux colonnes ajoutées.\n",
      "\n",
      "Exemples de résultats avec les deux colonnes ajoutées:\n",
      "      SIREN_DECLARANT  SIREN_DEPOSANT TRAITEMENT_APPLIQUE type_final  \\\n",
      "4372        900155003       900155003          Non traité        IND   \n",
      "2957        798561684       798561684        Err_PLAF_EVW        IND   \n",
      "635         399047752       399047752          Non traité        IND   \n",
      "876         435324280       435324280          Non traité        IND   \n",
      "3732        844238410       844238410          Non traité        IND   \n",
      "\n",
      "      mere_final  \n",
      "4372         NaN  \n",
      "2957         NaN  \n",
      "635          NaN  \n",
      "876          NaN  \n",
      "3732         NaN  \n",
      "\n",
      "Distribution des valeurs dans type_final:\n",
      "type_final\n",
      "IND      2799\n",
      "FILLE    1660\n",
      "MERE       34\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution des valeurs dans mere_final:\n",
      "mere_final\n",
      "552037806.0    980\n",
      "542051180.0    209\n",
      "356000000.0    131\n",
      "334270071.0     52\n",
      "395030844.0     31\n",
      "552120222.0     14\n",
      "842440778.0     10\n",
      "313483562.0      9\n",
      "775670417.0      8\n",
      "404435521.0      8\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Charger les fichiers originaux\n",
    "df_init = pd.read_excel(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//output//output_parquet//new_millesime_CIR_2021-suite_corrected_sans_doublon.xlsx\")\n",
    "df_corrige = pd.read_csv(\"C://Users//msamb//Documents//Calcul_Creance_CIR_Corrige_2021.csv\", \n",
    "                         sep=';', encoding='utf-8-sig', decimal='.', low_memory=False)\n",
    "\n",
    "# 2. Standardiser les SIREN déposants puisque c'est la meilleure correspondance\n",
    "def standardize_siren(siren):\n",
    "    \"\"\"Standardise le SIREN en supprimant tous les caractères non numériques et en complétant avec des zéros.\"\"\"\n",
    "    if pd.isna(siren):\n",
    "        return None\n",
    "    siren_str = str(siren).replace(' ', '').replace('-', '').replace('.', '')\n",
    "    # Supprimer tous les caractères non numériques\n",
    "    siren_str = ''.join(c for c in siren_str if c.isdigit())\n",
    "    # Garder seulement les 9 derniers chiffres pour les SIREN longs\n",
    "    if len(siren_str) > 9:\n",
    "        siren_str = siren_str[-9:]\n",
    "    # Compléter avec des zéros au début si nécessaire\n",
    "    return siren_str.zfill(9)\n",
    "\n",
    "# 3. Appliquer la standardisation\n",
    "df_init['siren_deposant_std'] = df_init['siren_deposant'].apply(standardize_siren)\n",
    "df_corrige['SIREN_DEPOSANT_STD'] = df_corrige['SIREN_DEPOSANT'].apply(standardize_siren)\n",
    "\n",
    "# 4. Vérifier la correspondance\n",
    "common_sirens = set(df_corrige['SIREN_DEPOSANT_STD']) & set(df_init['siren_deposant_std'])\n",
    "print(f\"Nombre de SIREN communs: {len(common_sirens)}\")\n",
    "print(f\"Nombre de SIREN uniques dans df_corrige: {df_corrige['SIREN_DEPOSANT_STD'].nunique()}\")\n",
    "print(f\"Nombre de SIREN uniques dans df_init: {df_init['siren_deposant_std'].nunique()}\")\n",
    "\n",
    "# 5. Créer les dictionnaires de correspondance pour les deux colonnes\n",
    "siren_to_type = dict(zip(df_init['siren_deposant_std'], df_init['type_final']))\n",
    "siren_to_mere = dict(zip(df_init['siren_deposant_std'], df_init['mere_final']))\n",
    "\n",
    "# 6. Appliquer les deux correspondances en même temps\n",
    "df_corrige['type_final'] = df_corrige['SIREN_DEPOSANT_STD'].map(siren_to_type)\n",
    "df_corrige['mere_final'] = df_corrige['SIREN_DEPOSANT_STD'].map(siren_to_mere)\n",
    "\n",
    "# 7. Vérifier les résultats\n",
    "type_non_null = df_corrige['type_final'].notna().sum()\n",
    "mere_non_null = df_corrige['mere_final'].notna().sum()\n",
    "print(f\"Nombre de lignes avec type_final non-null: {type_non_null} sur {len(df_corrige)}\")\n",
    "print(f\"Nombre de lignes avec mere_final non-null: {mere_non_null} sur {len(df_corrige)}\")\n",
    "\n",
    "# 8. Supprimer la colonne temporaire\n",
    "df_corrige = df_corrige.drop(columns=['SIREN_DEPOSANT_STD'])\n",
    "\n",
    "# 9. Sauvegarder le résultat\n",
    "df_corrige.to_csv(\"C://Users//msamb//Documents//Calcul_Creance_CIR_Corrige_Final_2021.csv\", \n",
    "                  sep=';', encoding='utf-8-sig', index=False)\n",
    "\n",
    "print(\"Fichier sauvegardé avec succès avec les deux colonnes ajoutées.\")\n",
    "\n",
    "# 10. Afficher des exemples des résultats\n",
    "print(\"\\nExemples de résultats avec les deux colonnes ajoutées:\")\n",
    "sample = df_corrige[['SIREN_DECLARANT', 'SIREN_DEPOSANT', 'TRAITEMENT_APPLIQUE', 'type_final', 'mere_final']].sample(5)\n",
    "print(sample)\n",
    "\n",
    "# 11. Afficher les distributions des valeurs\n",
    "print(\"\\nDistribution des valeurs dans type_final:\")\n",
    "print(df_corrige['type_final'].value_counts().head(10))\n",
    "\n",
    "print(\"\\nDistribution des valeurs dans mere_final:\")\n",
    "print(df_corrige['mere_final'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b77dbbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de SIREN qui sont déposants mais pas déclarants: 50\n",
      "DataFrame original: 4493 lignes\n",
      "Nouvelles lignes ajoutées: 50 lignes\n",
      "DataFrame final: 4543 lignes\n",
      "\n",
      "Fichier sauvegardé: C://Users//msamb//Documents//Calcul_Creance_CIR_Corrige_avec_deposants.csv\n",
      "\n",
      "Exemple d'une nouvelle ligne ajoutée:\n",
      "SIREN_DECLARANT              537685885\n",
      "SIREN_DEPOSANT               537685885\n",
      "TRAITEMENT_APPLIQUE    Déposant ajouté\n",
      "type_final                        MERE\n",
      "CIR_TOTAL_DECLARE                    0\n",
      "CIR_TOTAL_CALCULE                    0\n",
      "CIR_TOTAL_CORRIGE                    0\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 1. Charger le fichier corrigé existant\n",
    "df_corrige = pd.read_csv(\"C://Users//msamb//Documents//Calcul_Creance_CIR_Corrige_Final_2021.csv\", \n",
    "                         sep=';', encoding='utf-8-sig', low_memory=False)\n",
    "\n",
    "# 2. Standardiser et nettoyer les SIREN\n",
    "df_corrige['SIREN_DECLARANT_STD'] = df_corrige['SIREN_DECLARANT'].astype(str).str.replace(r'\\D', '', regex=True).str.strip().str.zfill(9)\n",
    "df_corrige['SIREN_DEPOSANT_STD'] = df_corrige['SIREN_DEPOSANT'].astype(str).str.replace(r'\\D', '', regex=True).str.strip().str.zfill(9)\n",
    "\n",
    "# 3. Créer les ensembles de SIREN déclarants et déposants\n",
    "set_declarants = set(df_corrige['SIREN_DECLARANT_STD'])\n",
    "set_deposants = set(df_corrige['SIREN_DEPOSANT_STD'])\n",
    "\n",
    "# 4. Identifier les SIREN qui sont déposants mais pas déclarants (en filtrant les SIREN non valides)\n",
    "#if siren and not (siren.strip('0') == '')\n",
    "deposants_non_declarants = {siren for siren in (set_deposants - set_declarants) }\n",
    "print(f\"Nombre de SIREN qui sont déposants mais pas déclarants: {len(deposants_non_declarants)}\")\n",
    "\n",
    "# 5. Créer les nouvelles lignes pour les déposants manquants\n",
    "new_rows = []\n",
    "\n",
    "for siren in deposants_non_declarants:\n",
    "    # Créer un dictionnaire pour la nouvelle ligne\n",
    "    new_row = {}\n",
    "    \n",
    "    # Copier la structure d'une ligne existante pour obtenir toutes les colonnes\n",
    "    for col in df_corrige.columns:\n",
    "        if col in ['SIREN_DECLARANT_STD', 'SIREN_DEPOSANT_STD']:\n",
    "            continue  # On n'inclut pas ces colonnes temporaires\n",
    "        \n",
    "        # Déterminer le type et la valeur appropriée\n",
    "        if col == 'SIREN_DECLARANT' or col == 'SIREN_DEPOSANT':\n",
    "            # Utiliser toujours le format chaîne pour éviter les problèmes\n",
    "            new_row[col] = siren\n",
    "        elif col == 'TRAITEMENT_APPLIQUE':\n",
    "            new_row[col] = 'Déposant ajouté'\n",
    "        elif col == 'type_final':  # Ajouter \"MERE\" dans la colonne type_retenu\n",
    "            new_row[col] = 'MERE'\n",
    "        elif col == 'DESIGNATION' or col == 'COMPLEMENT_DESIGNATION':\n",
    "            new_row[col] = '' # Champs texte vide\n",
    "        elif pd.api.types.is_numeric_dtype(df_corrige[col]):\n",
    "            # Pour les colonnes numériques, mettre 0\n",
    "            new_row[col] = 0\n",
    "        else:\n",
    "            # Pour les autres colonnes non numériques, mettre une valeur vide\n",
    "            new_row[col] = ''\n",
    "    \n",
    "    # Ajouter la ligne au tableau de nouvelles lignes\n",
    "    new_rows.append(new_row)\n",
    "\n",
    "# 6. Créer un DataFrame avec les nouvelles lignes\n",
    "if new_rows:\n",
    "    df_new_rows = pd.DataFrame(new_rows)\n",
    "    \n",
    "    # 7. Concaténer avec le DataFrame original\n",
    "    df_corrige_complet = pd.concat([df_corrige.drop(['SIREN_DECLARANT_STD', 'SIREN_DEPOSANT_STD'], axis=1),\n",
    "                                df_new_rows],\n",
    "                               ignore_index=True)\n",
    "    \n",
    "    # 8. Afficher des informations sur le résultat\n",
    "    print(f\"DataFrame original: {len(df_corrige)} lignes\")\n",
    "    print(f\"Nouvelles lignes ajoutées: {len(new_rows)} lignes\")\n",
    "    print(f\"DataFrame final: {len(df_corrige_complet)} lignes\")\n",
    "    \n",
    "    # 9. Sauvegarder le résultat\n",
    "    output_file = \"C://Users//msamb//Documents//Calcul_Creance_CIR_Corrige_avec_deposants.csv\"\n",
    "    df_corrige_complet.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "    print(f\"\\nFichier sauvegardé: {output_file}\")\n",
    "    \n",
    "    # 10. Afficher un exemple des nouvelles lignes\n",
    "    print(\"\\nExemple d'une nouvelle ligne ajoutée:\")\n",
    "    if not df_new_rows.empty:\n",
    "        cols_to_show = ['SIREN_DECLARANT', 'SIREN_DEPOSANT', 'TRAITEMENT_APPLIQUE', 'type_final', 'CIR_TOTAL_DECLARE', 'CIR_TOTAL_CALCULE', 'CIR_TOTAL_CORRIGE']\n",
    "        print(df_new_rows[cols_to_show].iloc[0])\n",
    "else:\n",
    "    print(\"Aucun déposant non déclarant trouvé, aucune ligne à ajouter.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739a220e",
   "metadata": {},
   "source": [
    "## Difference pour verifier si tous les deposants sont declarants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1052f2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de SIREN présents soit comme déclarant, soit comme déposant (mais pas les deux) : 1526\n",
      "Exemples de SIREN présents dans un seul ensemble : ['808233399', '537915357', '487474306', '437181217', '418736526']\n",
      "\n",
      "Nombre de SIREN qui sont uniquement déclarants : 1526\n",
      "Exemples: ['808233399', '537915357', '487474306', '437181217', '418736526']\n",
      "Nombre de SIREN qui sont uniquement déposants : 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier\n",
    "df = pd.read_csv(\"C://Users//msamb//Documents//Calcul_Creance_CIR_Corrige_avec_deposants.csv\", \n",
    "                 sep=';', encoding='utf-8-sig', low_memory=False)\n",
    "\n",
    "# Standardiser les SIREN (en string, 9 caractères, sans espaces)\n",
    "set_declarants = set(df['SIREN_DECLARANT'].astype(str).str.replace(r'\\D', '', regex=True).str.strip().str.zfill(9))\n",
    "set_deposants = set(df['SIREN_DEPOSANT'].astype(str).str.replace(r'\\D', '', regex=True).str.strip().str.zfill(9))\n",
    "\n",
    "# Différence symétrique (éléments dans l'un ou l'autre ensemble, mais pas les deux)\n",
    "difference_symetrique = set_declarants ^ set_deposants\n",
    "\n",
    "print(f\"Nombre de SIREN présents soit comme déclarant, soit comme déposant (mais pas les deux) : {len(difference_symetrique)}\")\n",
    "\n",
    "if len(difference_symetrique) == 0:\n",
    "    print(\"La différence symétrique est vide.\")\n",
    "else:\n",
    "    print(\"Exemples de SIREN présents dans un seul ensemble :\", list(difference_symetrique)[:5])\n",
    "    \n",
    "    # Si vous voulez aussi voir spécifiquement les SIREN qui sont uniquement déclarants\n",
    "    seulement_declarants = set_declarants - set_deposants\n",
    "    print(f\"\\nNombre de SIREN qui sont uniquement déclarants : {len(seulement_declarants)}\")\n",
    "    if len(seulement_declarants) > 0:\n",
    "        print(\"Exemples:\", list(seulement_declarants)[:5])\n",
    "    \n",
    "    # Et les SIREN qui sont uniquement déposants\n",
    "    seulement_deposants = set_deposants - set_declarants\n",
    "    print(f\"Nombre de SIREN qui sont uniquement déposants : {len(seulement_deposants)}\")\n",
    "    if len(seulement_deposants) > 0:\n",
    "        print(\"Exemples:\", list(seulement_deposants)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5eee1c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du fichier...\n",
      "Standardisation des SIREN...\n",
      "Calcul de la somme du CIR par déposant...\n",
      "Ajout de la nouvelle colonne au DataFrame...\n",
      "Attribution des valeurs selon le type...\n",
      "\n",
      "Nombre total d'entreprises: 4543\n",
      "Nombre de déposants uniques: 2997\n",
      "\n",
      "Distribution des valeurs cir_benef_total par type:\n",
      "             count           mean           std  min  25%        50%  \\\n",
      "type_final                                                             \n",
      "FILLE       1660.0       0.000000  0.000000e+00  0.0  0.0       0.00   \n",
      "IND         2799.0   42687.906049  6.096652e+05  0.0  0.0       0.00   \n",
      "MERE          84.0  939523.869524  4.764457e+06  0.0  0.0  125607.19   \n",
      "\n",
      "                    75%          max  \n",
      "type_final                            \n",
      "FILLE            0.0000         0.00  \n",
      "IND              0.0000  29833356.67  \n",
      "MERE        249960.1325  42695101.36  \n",
      "\n",
      "Top 5 des déposants (MERE) avec le plus grand total de CIR:\n",
      "      SIREN_DEPOSANT  cir_benef_total\n",
      "4505       552059024      42695101.36\n",
      "452        379041395      29833356.67\n",
      "1535       537444234       9708335.76\n",
      "553        524807369       7005461.67\n",
      "4536       525009809       4655471.39\n",
      "\n",
      "Fichier sauvegardé: C://Users//msamb//Documents//Calcul_Creance_CIR_avec_benef_total.csv\n",
      "\n",
      "Somme totale de CIR_TOTAL_CORRIGE: 453,738,653.93 €\n",
      "Somme totale de cir_benef_total (pour les MERE et IND): 198,403,454.07 €\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Charger le fichier\n",
    "print(\"Chargement du fichier...\")\n",
    "df = pd.read_csv(\"C://Users//msamb//Documents//Calcul_Creance_CIR_Corrige_avec_deposants.csv\", \n",
    "                 sep=';', encoding='utf-8-sig', low_memory=False)\n",
    "\n",
    "# 2. Standardiser les SIREN des déposants pour éviter les problèmes de format\n",
    "print(\"Standardisation des SIREN...\")\n",
    "df['SIREN_DEPOSANT_STD'] = df['SIREN_DEPOSANT'].astype(str).str.replace(r'\\D', '', regex=True).str.strip().str.zfill(9)\n",
    "\n",
    "# 3. Calculer la somme du CIR par déposant\n",
    "print(\"Calcul de la somme du CIR par déposant...\")\n",
    "# Utiliser CIR_TOTAL_CORRIGE qui est le montant final retenu après corrections\n",
    "cir_par_deposant = df.groupby('SIREN_DEPOSANT_STD')['CIR_TOTAL_CORRIGE'].sum().reset_index()\n",
    "cir_par_deposant.rename(columns={'CIR_TOTAL_CORRIGE': 'cir_benef_total_temp'}, inplace=True)\n",
    "\n",
    "# 4. Fusionner cette somme avec le DataFrame original\n",
    "print(\"Ajout de la nouvelle colonne au DataFrame...\")\n",
    "df = df.merge(cir_par_deposant, on='SIREN_DEPOSANT_STD', how='left')\n",
    "\n",
    "# 5. Mettre à zéro la colonne cir_benef_total pour toutes les lignes qui ne sont pas de type MERE\n",
    "print(\"Attribution des valeurs selon le type...\")\n",
    "# Créer la colonne finale 'cir_benef_total'\n",
    "df['cir_benef_total'] = 0.0  # Initialiser à zéro pour toutes les lignes\n",
    "\n",
    "# Mettre la somme calculée uniquement pour les lignes de type 'MERE' et 'IND'\n",
    "df.loc[df['type_final'] == 'MERE', 'cir_benef_total'] = df.loc[df['type_final'] == 'MERE', 'cir_benef_total_temp']\n",
    "df.loc[df['type_final'] == 'IND', 'cir_benef_total'] = df.loc[df['type_final'] == 'IND', 'cir_benef_total_temp']\n",
    "\n",
    "# Supprimer la colonne temporaire\n",
    "df.drop(['SIREN_DEPOSANT_STD', 'cir_benef_total_temp'], axis=1, inplace=True)\n",
    "\n",
    "# 6. Afficher quelques statistiques\n",
    "print(f\"\\nNombre total d'entreprises: {len(df)}\")\n",
    "print(f\"Nombre de déposants uniques: {df['SIREN_DEPOSANT'].nunique()}\")\n",
    "\n",
    "# Vérifier la distribution des valeurs cir_benef_total selon le type\n",
    "print(\"\\nDistribution des valeurs cir_benef_total par type:\")\n",
    "print(df.groupby('type_final')['cir_benef_total'].describe())\n",
    "\n",
    "# Trier par montant de cir_benef_total pour voir les déposants avec le plus grand total\n",
    "top_deposants = df[df['cir_benef_total'] > 0][['SIREN_DEPOSANT', 'cir_benef_total']].drop_duplicates().sort_values('cir_benef_total', ascending=False)\n",
    "print(\"\\nTop 5 des déposants (MERE) avec le plus grand total de CIR:\")\n",
    "print(top_deposants.head(5))\n",
    "\n",
    "# 7. Sauvegarder le résultat\n",
    "output_file = \"C://Users//msamb//Documents//Calcul_Creance_CIR_avec_benef_total.csv\"\n",
    "df.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "print(f\"\\nFichier sauvegardé: {output_file}\")\n",
    "\n",
    "# 8. Vérification - calcul de la somme totale de CIR\n",
    "total_cir_corrige = df['CIR_TOTAL_CORRIGE'].sum()\n",
    "total_cir_benef = df['cir_benef_total'].sum()\n",
    "print(f\"\\nSomme totale de CIR_TOTAL_CORRIGE: {total_cir_corrige:,.2f} €\")\n",
    "print(f\"Somme totale de cir_benef_total (pour les MERE et IND): {total_cir_benef:,.2f} €\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "95f45d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier sauvegardé: M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_avec_benef_total_final.csv\n",
      "\n",
      "Somme totale de CIR_TOTAL_CORRIGE: 453,738,653.93 €\n",
      "Somme totale de cir_benef_total: 453,738,653.93 €\n",
      "Différence entre les deux sommes: 0.00 €\n",
      "\n",
      "Nombre de SIREN déposants sans correspondance: 1\n",
      "Montant CIR pour ces SIREN: 0.00 € (0.00% du total)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier\n",
    "df = pd.read_csv(output_file, sep=';', encoding='utf-8-sig', low_memory=False)\n",
    "\n",
    "# Standardiser les SIREN des déposants et des déclarants\n",
    "df['SIREN_DEPOSANT_STD'] = df['SIREN_DEPOSANT'].astype(str).str.replace(r'\\D', '', regex=True).str.strip().str.zfill(9)\n",
    "df['SIREN_DECLARANT_STD'] = df['SIREN_DECLARANT'].astype(str).str.replace(r'\\D', '', regex=True).str.strip().str.zfill(9)\n",
    "\n",
    "# Créer une colonne pour la correspondance\n",
    "df['IS_MATCH'] = df['SIREN_DEPOSANT_STD'] == df['SIREN_DECLARANT_STD']\n",
    "\n",
    "# Calculer la somme du CIR par déposant\n",
    "cir_total_par_deposant = df.groupby('SIREN_DEPOSANT_STD')['CIR_TOTAL_CORRIGE'].sum().reset_index()\n",
    "cir_total_par_deposant.rename(columns={'CIR_TOTAL_CORRIGE': 'TOTAL_CIR'}, inplace=True)\n",
    "\n",
    "# Initialiser la nouvelle colonne\n",
    "df['cir_benef_total'] = 0.0\n",
    "\n",
    "# Méthode simplifiée: traiter chaque SIREN déposant séparément\n",
    "for siren in cir_total_par_deposant['SIREN_DEPOSANT_STD'].unique():\n",
    "    montant_total = cir_total_par_deposant.loc[cir_total_par_deposant['SIREN_DEPOSANT_STD'] == siren, 'TOTAL_CIR'].values[0]\n",
    "    \n",
    "    # Sélectionner toutes les lignes avec ce SIREN déposant\n",
    "    lignes_siren = df[df['SIREN_DEPOSANT_STD'] == siren]\n",
    "    \n",
    "    # Vérifier s'il y a des lignes correspondantes (SIREN_DEPOSANT = SIREN_DECLARANT)\n",
    "    lignes_match = lignes_siren[lignes_siren['IS_MATCH']]\n",
    "    \n",
    "    if len(lignes_match) > 0:\n",
    "        # S'il y a des correspondances, distribuer le montant également entre ces lignes\n",
    "        montant_par_ligne = montant_total / len(lignes_match)\n",
    "        df.loc[lignes_match.index, 'cir_benef_total'] = montant_par_ligne\n",
    "    else:\n",
    "        # S'il n'y a pas de correspondance, mettre le montant total sur la première ligne\n",
    "        df.loc[lignes_siren.index[0], 'cir_benef_total'] = montant_total\n",
    "\n",
    "# Vérification\n",
    "total_cir_corrige = df['CIR_TOTAL_CORRIGE'].sum()\n",
    "total_cir_benef = df['cir_benef_total'].sum()\n",
    "\n",
    "# Créer un fichier de vérification avec les totaux par SIREN déposant\n",
    "verification = df.groupby('SIREN_DEPOSANT_STD')[['CIR_TOTAL_CORRIGE', 'cir_benef_total']].sum()\n",
    "verification['difference'] = verification['CIR_TOTAL_CORRIGE'] - verification['cir_benef_total']\n",
    "verification.to_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//verification_totaux_par_siren.csv\", sep=';')\n",
    "\n",
    "# Comptage des SIREN sans correspondance\n",
    "siren_avec_match = df[df['IS_MATCH']]['SIREN_DEPOSANT_STD'].unique()\n",
    "siren_tous = df['SIREN_DEPOSANT_STD'].unique()\n",
    "siren_sans_match = set(siren_tous) - set(siren_avec_match)\n",
    "\n",
    "# Supprimer les colonnes temporaires avant de sauvegarder\n",
    "df = df.drop(['SIREN_DEPOSANT_STD', 'SIREN_DECLARANT_STD', 'IS_MATCH'], axis=1)\n",
    "\n",
    "# Sauvegarder le résultat\n",
    "output_file_final = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_avec_benef_total_final.csv\"\n",
    "df.to_csv(output_file_final, sep=';', encoding='utf-8-sig', index=False)\n",
    "\n",
    "print(f\"Fichier sauvegardé: {output_file_final}\")\n",
    "print(f\"\\nSomme totale de CIR_TOTAL_CORRIGE: {total_cir_corrige:,.2f} €\")\n",
    "print(f\"Somme totale de cir_benef_total: {total_cir_benef:,.2f} €\")\n",
    "print(f\"Différence entre les deux sommes: {total_cir_corrige - total_cir_benef:,.2f} €\")\n",
    "print(f\"\\nNombre de SIREN déposants sans correspondance: {len(siren_sans_match)}\")\n",
    "\n",
    "# Montant CIR pour les SIREN sans correspondance\n",
    "cir_sans_match = sum(verification.loc[[s for s in siren_sans_match if s in verification.index], 'CIR_TOTAL_CORRIGE'])\n",
    "print(f\"Montant CIR pour ces SIREN: {cir_sans_match:,.2f} € ({cir_sans_match/total_cir_corrige*100:.2f}% du total)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "301d6b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier sauvegardé avec succès: M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_avec_benef_total_final_renamed.csv\n",
      "Colonnes renommées: ['CIR_RECHERCHE_DECLARE', 'CIR_RECHERCHE_CALCULE', 'CIR_RECHERCHE_ECART', 'CIR_COLLECTION_DECLARE', 'CIR_COLLECTION_CALCULE', 'CIR_COLLECTION_ECART', 'CIR_INNOVATION_DECLARE', 'CIR_INNOVATION_CALCULE', 'CIR_INNOVATION_ECART', 'CIR_TOTAL_DECLARE', 'CIR_TOTAL_CALCULE', 'CIR_TOTAL_ECART', 'CIR_TOTAL_CORRIGE']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier CSV\n",
    "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_avec_benef_total_final.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "\n",
    "# Dictionnaire de renommage des colonnes\n",
    "renommage = {\n",
    "    # Renommage des colonnes CIR recherche\n",
    "    'CIR_RECHERCHE_DECLARE': 'crerd_gen_declare',\n",
    "    'CIR_RECHERCHE_CALCULE': 'crerd_gen_calcule',\n",
    "    'CIR_RECHERCHE_ECART': 'crerd_gen_ecart',\n",
    "    \n",
    "    # Renommage des colonnes CIR collection\n",
    "    'CIR_COLLECTION_DECLARE': 'crecoll_gen_declare',\n",
    "    'CIR_COLLECTION_CALCULE': 'crecoll_gen_calcule',\n",
    "    'CIR_COLLECTION_ECART': 'crecoll_gen_ecart',\n",
    "    \n",
    "    # Renommage des colonnes CIR innovation\n",
    "    'CIR_INNOVATION_DECLARE': 'creinno_gen_declare',\n",
    "    'CIR_INNOVATION_CALCULE': 'creinno_gen_calcule',\n",
    "    'CIR_INNOVATION_ECART': 'creinno_gen_ecart',\n",
    "    \n",
    "    # Renommage des colonnes CIR collaboratif\n",
    "    'CIR_COLLABORATIF_DECLARE': 'crecrc_declare',\n",
    "    'CIR_COLLABORATIF_CALCULE': 'crecrc_calcule',\n",
    "    'CIR_COLLABORATIF_ECART': 'crecrc_ecart',\n",
    "    \n",
    "    # Renommage des colonnes CIR total\n",
    "    'CIR_TOTAL_DECLARE': 'cretot_gen_declare',\n",
    "    'CIR_TOTAL_CALCULE': 'cretot_gen_calcule',\n",
    "    'CIR_TOTAL_ECART': 'cretot_gen_ecart',\n",
    "    'CIR_TOTAL_CORRIGE': 'cretot_gen_corrige'\n",
    "}\n",
    "\n",
    "# Appliquer le renommage (uniquement pour les colonnes qui existent)\n",
    "colonnes_existantes = {col: nouveau_nom for col, nouveau_nom in renommage.items() if col in df.columns}\n",
    "df = df.rename(columns=colonnes_existantes)\n",
    "\n",
    "# Sauvegarder le fichier avec les nouvelles colonnes\n",
    "output_file = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_avec_benef_total_final_renamed.csv\"\n",
    "df.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "\n",
    "print(f\"Fichier sauvegardé avec succès: {output_file}\")\n",
    "print(f\"Colonnes renommées: {list(colonnes_existantes.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7c18d2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de lignes: 4543\n",
      "Colonnes renommées: 13\n",
      "Calcul des montants bénéficiaires...\n",
      "  Calcul de cirrech_benef...\n",
      "  Calcul de cic_benef...\n",
      "  Calcul de cii_benef...\n",
      "  Colonne crecrc non trouvée, crecrc_benef initialisé à 0\n",
      "  Calcul de cirtot_benef...\n",
      "Vérification de la cohérence des montants...\n",
      "Écart entre cirtot_benef et cir_benef_total: 0.00\n",
      "Écart entre somme des composantes et total bénéficiaire: 344.23\n",
      "\n",
      "Vérification des totaux générés vs bénéficiaires:\n",
      "Type de crédit Généré         Bénéficiaire   Écart          Écart %   \n",
      "-----------------------------------------------------------------\n",
      "crerd_gen      414605137.83   414605137.83   -0.00          -0.00     %\n",
      "crecoll_gen    1544332.70     1544332.70     0.00           0.00      %\n",
      "creinno_gen    37589152.49    37589152.49    0.00           0.00      %\n",
      "cretot_gen     453738653.93   453738653.93   0.00           0.00      %\n",
      "Sauvegarde du fichier: M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_format_2021.csv\n",
      "Traitement terminé avec succès!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier avec les types de données spécifiés pour améliorer les performances\n",
    "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_avec_benef_total_final.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Nombre total de lignes: {len(df)}\")\n",
    "\n",
    "# 1. RENOMMER TOUTES LES COLONNES (opération rapide)\n",
    "renommage_complet = {\n",
    "    'CIR_RECHERCHE_DECLARE': 'crerd_gen_declare',\n",
    "    'CIR_RECHERCHE_CALCULE': 'crerd_gen',\n",
    "    'CIR_RECHERCHE_ECART': 'crerd_gen_ecart',\n",
    "    'CIR_COLLECTION_DECLARE': 'crecoll_gen_declare',\n",
    "    'CIR_COLLECTION_CALCULE': 'crecoll_gen',\n",
    "    'CIR_COLLECTION_ECART': 'crecoll_gen_ecart',\n",
    "    'CIR_INNOVATION_DECLARE': 'creinno_gen_declare',\n",
    "    'CIR_INNOVATION_CALCULE': 'creinno_gen',\n",
    "    'CIR_INNOVATION_ECART': 'creinno_gen_ecart',\n",
    "    'CIR_COLLABORATIF_DECLARE': 'crecrc_declare',\n",
    "    'CIR_COLLABORATIF_CALCULE': 'crecrc',\n",
    "    'CIR_COLLABORATIF_ECART': 'crecrc_ecart',\n",
    "    'CIR_TOTAL_DECLARE': 'cretot_gen_declare',\n",
    "    'CIR_TOTAL_CALCULE': 'cretot_gen_calcule',\n",
    "    'CIR_TOTAL_ECART': 'cretot_gen_ecart',\n",
    "    'CIR_TOTAL_CORRIGE': 'cretot_gen'\n",
    "}\n",
    "\n",
    "# Renommer uniquement les colonnes qui existent\n",
    "colonnes_existantes = {col: nouveau_nom for col, nouveau_nom in renommage_complet.items() if col in df.columns}\n",
    "df = df.rename(columns=colonnes_existantes)\n",
    "\n",
    "print(f\"Colonnes renommées: {len(colonnes_existantes)}\")\n",
    "\n",
    "# 2. CALCULER LES CRÉDITS BÉNÉFICIAIRES DE MANIÈRE OPTIMISÉE\n",
    "# Standardiser les SIREN une seule fois\n",
    "df['SIREN_DEPOSANT_STD'] = df['SIREN_DEPOSANT'].astype(str).str.replace(r'\\D', '', regex=True).str.zfill(9)\n",
    "df['SIREN_DECLARANT_STD'] = df['SIREN_DECLARANT'].astype(str).str.replace(r'\\D', '', regex=True).str.zfill(9)\n",
    "df['IS_MATCH'] = df['SIREN_DEPOSANT_STD'] == df['SIREN_DECLARANT_STD']\n",
    "\n",
    "# Version vectorisée et optimisée pour calculer les valeurs bénéficiaires\n",
    "def calculer_benef_optimise(df, colonne_source):\n",
    "    # Créer un DataFrame avec les informations essentielles\n",
    "    df_temp = df[['SIREN_DEPOSANT_STD', 'IS_MATCH', colonne_source]].copy()\n",
    "    \n",
    "    # Calculer la somme totale par déposant\n",
    "    sommes = df_temp.groupby('SIREN_DEPOSANT_STD')[colonne_source].sum().to_dict()\n",
    "    \n",
    "    # Créer une série pour stocker les résultats\n",
    "    resultats = pd.Series(index=df.index, dtype='float64')\n",
    "    \n",
    "    # Pour chaque SIREN déposant unique\n",
    "    for siren, montant in sommes.items():\n",
    "        # Lignes correspondant à ce SIREN\n",
    "        mask_siren = df['SIREN_DEPOSANT_STD'] == siren\n",
    "        \n",
    "        # Lignes où il y a correspondance\n",
    "        mask_match = mask_siren & df['IS_MATCH']\n",
    "        count_match = mask_match.sum()\n",
    "        \n",
    "        if count_match > 0:\n",
    "            # Distribuer le montant également entre les lignes correspondantes\n",
    "            resultats[mask_match] = montant / count_match\n",
    "        else:\n",
    "            # Première ligne du SIREN\n",
    "            if mask_siren.any():\n",
    "                idx = df[mask_siren].index[0]\n",
    "                resultats[idx] = montant\n",
    "    \n",
    "    return resultats\n",
    "\n",
    "# Calculer tous les bénéficiaires d'un coup pour gagner du temps\n",
    "print(\"Calcul des montants bénéficiaires...\")\n",
    "colonnes_source = ['crerd_gen', 'crecoll_gen', 'creinno_gen', 'crecrc', 'cretot_gen']\n",
    "colonnes_benef = ['cirrech_benef', 'cic_benef', 'cii_benef', 'crecrc_benef', 'cirtot_benef']\n",
    "\n",
    "for col_source, col_benef in zip(colonnes_source, colonnes_benef):\n",
    "    if col_source in df.columns:\n",
    "        print(f\"  Calcul de {col_benef}...\")\n",
    "        df[col_benef] = calculer_benef_optimise(df, col_source)\n",
    "    else:\n",
    "        print(f\"  Colonne {col_source} non trouvée, {col_benef} initialisé à 0\")\n",
    "        df[col_benef] = 0\n",
    "\n",
    "# 3. VÉRIFIER LA COHÉRENCE DES MONTANTS\n",
    "print(\"Vérification de la cohérence des montants...\")\n",
    "\n",
    "# Vérifier que cir_benef_total correspond à cirtot_benef (si présent)\n",
    "if 'cir_benef_total' in df.columns:\n",
    "    ecart_total = (df['cirtot_benef'] - df['cir_benef_total']).abs().sum()\n",
    "    print(f\"Écart entre cirtot_benef et cir_benef_total: {ecart_total:.2f}\")\n",
    "\n",
    "# Vérifier que la somme des composantes bénéficiaires égale le total bénéficiaire (vectorisé)\n",
    "df['somme_composantes_benef'] = df[['cirrech_benef', 'cic_benef', 'cii_benef', 'crecrc_benef']].fillna(0).sum(axis=1)\n",
    "ecart_composantes = (df['somme_composantes_benef'] - df['cirtot_benef']).abs().sum()\n",
    "print(f\"Écart entre somme des composantes et total bénéficiaire: {ecart_composantes:.2f}\")\n",
    "\n",
    "# Comparer les totaux (vectorisé)\n",
    "print(\"\\nVérification des totaux générés vs bénéficiaires:\")\n",
    "print(f\"{'Type de crédit':<15}{'Généré':<15}{'Bénéficiaire':<15}{'Écart':<15}{'Écart %':<10}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for col_gen, col_benef in zip(colonnes_source, colonnes_benef):\n",
    "    if col_gen in df.columns and col_benef in df.columns:\n",
    "        total_gen = df[col_gen].sum()\n",
    "        total_benef = df[col_benef].sum()\n",
    "        ecart = total_gen - total_benef\n",
    "        ecart_pct = 0 if total_gen == 0 else ecart / total_gen * 100\n",
    "        print(f\"{col_gen:<15}{total_gen:<15.2f}{total_benef:<15.2f}{ecart:<15.2f}{ecart_pct:<10.2f}%\")\n",
    "\n",
    "# Ajouter les variables pour les DOM-TOM en une seule opération vectorisée\n",
    "for col in ['crerd_genom', 'crecoll_genom', 'creinno_genom', 'cretot_genom']:\n",
    "    df[col] = 0\n",
    "\n",
    "# Supprimer les colonnes temporaires en une seule opération\n",
    "df = df.drop(['SIREN_DEPOSANT_STD', 'SIREN_DECLARANT_STD', 'IS_MATCH', 'somme_composantes_benef'], axis=1)\n",
    "\n",
    "# Sauvegarder le fichier\n",
    "output_file = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_format_2021.csv\"\n",
    "print(f\"Sauvegarde du fichier: {output_file}\")\n",
    "df.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "\n",
    "print(\"Traitement terminé avec succès!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "58140247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de lignes: 4543\n",
      "Colonnes disponibles: 181\n",
      "\n",
      "=== CALCUL DES CRÉDITS DOM-TOM ===\n",
      "Colonnes DOM R&D trouvées: ['L31B_MONTANT_NET_DEPENSES_DOM_DECLARE', 'L31B_MONTANT_NET_DEPENSES_DOM_CALCULE', 'L43B_CREDIT_IMPOT_RECHERCHE_DOM', 'L51B_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION_DOM', 'L52B_DEPENSES_RECHERCHE_DOM_LIMITE', 'L58B_CREDIT_IMPOT_RECHERCHE_DOM_PLUS_100M', 'L69B_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION_DOM_PLUS_100M']\n",
      "Colonnes DOM Collection trouvées: ['L38B_MONTANT_NET_COLLECTION_DOM_DECLARE', 'L38B_MONTANT_NET_COLLECTION_DOM_CALCULE', 'L51B_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION_DOM', 'L59B_MONTANT_NET_COLLECTION_DOM_PLUS_100M', 'L69B_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION_DOM_PLUS_100M']\n",
      "Colonnes DOM Innovation trouvées: ['L82B_MONTANT_NET_INNOVATION_DOM', 'L85B_CREDIT_IMPOT_INNOVATION_DOM']\n",
      "Pas de données DOM pour la recherche trouvées\n",
      "Pas de données DOM pour la collection trouvées\n",
      "CIR Innovation DOM+Corse calculé: 0.00 €\n",
      "CIR Total DOM calculé: 0.00 €\n",
      "\n",
      "=== CALCUL DES MONTANTS NETS BÉNÉFICIAIRES ===\n",
      "Colonne dépenses R&D trouvée: L31A_MONTANT_NET_DEPENSES_DECLARE\n",
      "Colonne dépenses Collection trouvée: L38A_MONTANT_NET_COLLECTION_DECLARE\n",
      "Colonne dépenses Innovation trouvée: L82A_MONTANT_NET_INNOVATION_DECLARE\n",
      "Calcul des montants nets des dépenses bénéficiaires:\n",
      "  Dépenses R&D: Calcul en cours...\n",
      "    Total généré: 1,758,290,034.00 € | Total bénéficiaire: 1,758,290,034.00 € | Écart: 0.00 €\n",
      "    Répartition: 755 avec correspondance, 0 sans correspondance\n",
      "  Dépenses Collection: Calcul en cours...\n",
      "    Total généré: 4,685,020.00 € | Total bénéficiaire: 4,685,020.00 € | Écart: 0.00 €\n",
      "    Répartition: 52 avec correspondance, 0 sans correspondance\n",
      "  Dépenses Innovation: Calcul en cours...\n",
      "    Total généré: 330,391,076.00 € | Total bénéficiaire: 330,391,076.00 € | Écart: 0.00 €\n",
      "    Répartition: 4 avec correspondance, 0 sans correspondance\n",
      "Montant total des dépenses bénéficiaires: 2,093,366,130.00 €\n",
      "\n",
      "=== CRÉATION DES INDICATRICES ===\n",
      "Indicatrices créées avec succès\n",
      "\n",
      "============================================================\n",
      "RAPPORT DÉTAILLÉ DE VÉRIFICATION DES DONNÉES\n",
      "============================================================\n",
      "\n",
      "1. MONTANTS NETS DES DÉPENSES BÉNÉFICIAIRES:\n",
      "   • Dépenses R&D bénéficiaires: 1,758,290,034.00 €\n",
      "   • Dépenses Collection bénéficiaires: 4,685,020.00 €\n",
      "   • Dépenses Innovation bénéficiaires: 330,391,076.00 €\n",
      "   • TOTAL dépenses bénéficiaires: 2,093,366,130.00 €\n",
      "\n",
      "2. CRÉDITS D'IMPÔT DOM-TOM:\n",
      "   • CIR Recherche DOM: 0.00 €\n",
      "   • CIR Collection DOM: 0.00 €\n",
      "   • CIR Innovation DOM: 0.00 €\n",
      "   • TOTAL CIR DOM: 0.00 €\n",
      "\n",
      "3. RÉPARTITION DES INDICATRICES:\n",
      "   • i_dep_rd    :    955 Oui ( 21.0%) |  3,588 Non ( 79.0%)\n",
      "   • i_dep_inno  :      5 Oui (  0.1%) |  4,538 Non ( 99.9%)\n",
      "   • i_dep_coll  :     38 Oui (  0.8%) |  4,505 Non ( 99.2%)\n",
      "   • i_bef       :    795 Oui ( 17.5%) |  3,748 Non ( 82.5%)\n",
      "   • i_bef_rech  :    751 Oui ( 16.5%) |  3,792 Non ( 83.5%)\n",
      "   • i_bef_inno  :    745 Oui ( 16.4%) |  3,798 Non ( 83.6%)\n",
      "   • i_bef_crc   :      0 Oui (  0.0%) |  4,543 Non (100.0%)\n",
      "   • i_bef_coll  :     39 Oui (  0.9%) |  4,504 Non ( 99.1%)\n",
      "\n",
      "4. VÉRIFICATIONS DE COHÉRENCE:\n",
      "   • Bénéficiaires totaux: 795\n",
      "   • Détail: Recherche 751 | Collection 39 | Innovation 745 | CRC 0\n",
      "   • Entreprises avec dépenses R&D mais sans bénéfice recherche: 249\n",
      "   • Entreprises avec dépenses Collection mais sans bénéfice collection: 0\n",
      "   • Entreprises avec dépenses Innovation mais sans bénéfice innovation: 4\n",
      "\n",
      "============================================================\n",
      "TRAITEMENT TERMINÉ AVEC SUCCÈS\n",
      "============================================================\n",
      "Fichier sauvegardé: M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_format_2021_complet.csv\n",
      "Nombre total de lignes: 4,543\n",
      "Nombre total de colonnes: 194\n",
      "Taille du fichier final: 881,342 cellules\n",
      "\n",
      "NOUVELLES COLONNES CRÉÉES (17):\n",
      "   1. crerd_genom\n",
      "   2. crecoll_genom\n",
      "   3. creinno_genom\n",
      "   4. cretot_genom\n",
      "   5. deprd_benef\n",
      "   6. depcoll_benef\n",
      "   7. depinno_benef\n",
      "   8. deptot_benef\n",
      "   9. i_dep_rd\n",
      "  10. i_dep_inno\n",
      "  11. i_dep_coll\n",
      "  12. i_bef\n",
      "  13. i_bef_rech\n",
      "  14. i_bef_inno\n",
      "  15. i_bef_crc\n",
      "  16. i_bef_coll\n",
      "  17. date_traitement\n",
      "\n",
      "Fichier prêt \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier obtenu précédemment\n",
    "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_format_2021.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Nombre total de lignes: {len(df)}\")\n",
    "print(f\"Colonnes disponibles: {len(df.columns)}\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n=== CALCUL DES CRÉDITS DOM-TOM ===\")\n",
    "\n",
    "# Rechercher les colonnes DOM spécifiques\n",
    "colonnes_dom_rd = [col for col in df.columns if 'DOM' in col and ('RECHERCHE' in col or 'DEPENSES' in col)]\n",
    "colonnes_dom_coll = [col for col in df.columns if 'DOM' in col and 'COLLECTION' in col]\n",
    "colonnes_dom_inno = [col for col in df.columns if 'DOM' in col and 'INNOVATION' in col]\n",
    "\n",
    "print(f\"Colonnes DOM R&D trouvées: {colonnes_dom_rd}\")\n",
    "print(f\"Colonnes DOM Collection trouvées: {colonnes_dom_coll}\")\n",
    "print(f\"Colonnes DOM Innovation trouvées: {colonnes_dom_inno}\")\n",
    "\n",
    "# Calculer les crédits DOM-TOM avec les taux spécifiques\n",
    "# CIR Recherche DOM : 50%\n",
    "if 'L26B_MONTANT_NET_DEPENSES_DOM_CALCULE' in df.columns:\n",
    "    df['crerd_genom'] = df['L26B_MONTANT_NET_DEPENSES_DOM_CALCULE'].fillna(0) * 0.50\n",
    "    print(f\"CIR Recherche DOM calculé: {df['crerd_genom'].sum():,.2f} €\")\n",
    "else:\n",
    "    df['crerd_genom'] = 0\n",
    "    print(\"Pas de données DOM pour la recherche trouvées\")\n",
    "\n",
    "# CIR Collection DOM : 50%\n",
    "col_coll_dom = next((col for col in df.columns if 'L33B' in col and 'DOM' in col), None)\n",
    "if col_coll_dom:\n",
    "    df['crecoll_genom'] = df[col_coll_dom].fillna(0) * 0.50\n",
    "    print(f\"CIR Collection DOM calculé: {df['crecoll_genom'].sum():,.2f} €\")\n",
    "else:\n",
    "    df['crecoll_genom'] = 0\n",
    "    print(\"Pas de données DOM pour la collection trouvées\")\n",
    "\n",
    "# CIR Innovation DOM : 60% + Corse\n",
    "col_inno_dom = next((col for col in df.columns if 'L76B' in col and 'DOM' in col), None)\n",
    "col_inno_corse_mpe = next((col for col in df.columns if 'L76C' in col and 'CORSE' in col), None)\n",
    "col_inno_corse_me = next((col for col in df.columns if 'L76D' in col and 'CORSE' in col), None)\n",
    "\n",
    "if col_inno_dom:\n",
    "    cii_dom = df[col_inno_dom].fillna(0) * 0.60\n",
    "else:\n",
    "    cii_dom = 0\n",
    "\n",
    "if col_inno_corse_mpe:\n",
    "    cii_corse_mpe = df[col_inno_corse_mpe].fillna(0) * 0.40\n",
    "else:\n",
    "    cii_corse_mpe = 0\n",
    "\n",
    "if col_inno_corse_me:\n",
    "    cii_corse_me = df[col_inno_corse_me].fillna(0) * 0.35\n",
    "else:\n",
    "    cii_corse_me = 0\n",
    "\n",
    "df['creinno_genom'] = cii_dom + cii_corse_mpe + cii_corse_me\n",
    "print(f\"CIR Innovation DOM+Corse calculé: {df['creinno_genom'].sum():,.2f} €\")\n",
    "\n",
    "# CIR Total DOM\n",
    "df['cretot_genom'] = df['crerd_genom'] + df['crecoll_genom'] + df['creinno_genom']\n",
    "print(f\"CIR Total DOM calculé: {df['cretot_genom'].sum():,.2f} €\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n=== CALCUL DES MONTANTS NETS BÉNÉFICIAIRES ===\")\n",
    "\n",
    "# Standardiser les SIREN pour assurer la cohérence\n",
    "df['SIREN_DEPOSANT_STD'] = df['SIREN_DEPOSANT'].astype(str).str.replace(r'\\D', '', regex=True).str.zfill(9)\n",
    "df['SIREN_DECLARANT_STD'] = df['SIREN_DECLARANT'].astype(str).str.replace(r'\\D', '', regex=True).str.zfill(9)\n",
    "df['IS_MATCH'] = df['SIREN_DEPOSANT_STD'] == df['SIREN_DECLARANT_STD']\n",
    "\n",
    "# Recherche automatique des colonnes de dépenses\n",
    "def trouver_colonne_depenses(patterns, description):\n",
    "    \"\"\"Trouve la meilleure colonne correspondant aux patterns donnés\"\"\"\n",
    "    for pattern in patterns:\n",
    "        colonnes_trouvees = [col for col in df.columns if pattern in col]\n",
    "        if colonnes_trouvees:\n",
    "            print(f\"Colonne {description} trouvée: {colonnes_trouvees[0]}\")\n",
    "            return colonnes_trouvees[0]\n",
    "    print(f\"Aucune colonne {description} trouvée\")\n",
    "    return None\n",
    "\n",
    "# Rechercher les colonnes de dépenses\n",
    "colonne_depenses_rd = trouver_colonne_depenses([\n",
    "    'L26A_MONTANT_NET_DEPENSES_CALCULE',\n",
    "    'L26A_MONTANT_NET_DEPENSES_DECLARE',\n",
    "    'MONTANT_NET_DEPENSES'\n",
    "], \"dépenses R&D\")\n",
    "\n",
    "col_dep_coll = trouver_colonne_depenses([\n",
    "    'L33A_MONTANT_NET_COLLECTION_CALCULE',\n",
    "    'L33A_MONTANT_NET_COLLECTION_DECLARE',\n",
    "    'MONTANT_NET_COLLECTION'\n",
    "], \"dépenses Collection\")\n",
    "\n",
    "col_dep_inno = trouver_colonne_depenses([\n",
    "    'L76A_MONTANT_NET_INNOVATION_CALCULE',\n",
    "    'L76A_MONTANT_NET_INNOVATION_DECLARE',\n",
    "    'MONTANT_NET_INNOVATION'\n",
    "], \"dépenses Innovation\")\n",
    "\n",
    "# Fonction optimisée pour calculer les montants nets bénéficiaires\n",
    "def calculer_benef_optimise(df, colonne_source, nom_calcul=\"\"):\n",
    "    \"\"\"Calcule les montants bénéficiaires de manière optimisée\"\"\"\n",
    "    if colonne_source is None or colonne_source not in df.columns:\n",
    "        print(f\"  {nom_calcul}: Colonne non trouvée, initialisation à 0\")\n",
    "        return pd.Series(0, index=df.index, dtype='float64')\n",
    "    \n",
    "    print(f\"  {nom_calcul}: Calcul en cours...\")\n",
    "    \n",
    "    # Créer un DataFrame temporaire avec les données essentielles\n",
    "    df_temp = df[['SIREN_DEPOSANT_STD', 'IS_MATCH', colonne_source]].copy()\n",
    "    df_temp[colonne_source] = df_temp[colonne_source].fillna(0)\n",
    "    \n",
    "    # Calculer la somme totale par déposant\n",
    "    sommes = df_temp.groupby('SIREN_DEPOSANT_STD')[colonne_source].sum().to_dict()\n",
    "    \n",
    "    # Créer une série pour stocker les résultats\n",
    "    resultats = pd.Series(0, index=df.index, dtype='float64')\n",
    "    \n",
    "    # Compteurs pour le rapport\n",
    "    count_match = 0\n",
    "    count_no_match = 0\n",
    "    \n",
    "    # Pour chaque SIREN déposant unique\n",
    "    for siren, montant in sommes.items():\n",
    "        if montant == 0:\n",
    "            continue\n",
    "            \n",
    "        # Identifier les lignes correspondant à ce SIREN\n",
    "        mask_siren = df['SIREN_DEPOSANT_STD'] == siren\n",
    "        \n",
    "        # Identifier les lignes où il y a correspondance (déclarant = déposant)\n",
    "        mask_match_siren = mask_siren & df['IS_MATCH']\n",
    "        nb_match = mask_match_siren.sum()\n",
    "        \n",
    "        if nb_match > 0:\n",
    "            # Distribuer le montant également entre les lignes correspondantes\n",
    "            resultats[mask_match_siren] = montant / nb_match\n",
    "            count_match += nb_match\n",
    "        else:\n",
    "            # Attribuer à la première ligne du SIREN s'il n'y a pas de correspondance\n",
    "            if mask_siren.any():\n",
    "                idx = df[mask_siren].index[0]\n",
    "                resultats[idx] = montant\n",
    "                count_no_match += 1\n",
    "    \n",
    "    total_benef = resultats.sum()\n",
    "    total_gen = df_temp[colonne_source].sum()\n",
    "    print(f\"    Total généré: {total_gen:,.2f} € | Total bénéficiaire: {total_benef:,.2f} € | Écart: {total_gen-total_benef:,.2f} €\")\n",
    "    print(f\"    Répartition: {count_match} avec correspondance, {count_no_match} sans correspondance\")\n",
    "    \n",
    "    return resultats\n",
    "\n",
    "# Calculer les montants nets des dépenses bénéficiaires\n",
    "print(\"Calcul des montants nets des dépenses bénéficiaires:\")\n",
    "df['deprd_benef'] = calculer_benef_optimise(df, colonne_depenses_rd, \"Dépenses R&D\")\n",
    "df['depcoll_benef'] = calculer_benef_optimise(df, col_dep_coll, \"Dépenses Collection\")\n",
    "df['depinno_benef'] = calculer_benef_optimise(df, col_dep_inno, \"Dépenses Innovation\")\n",
    "\n",
    "# Calculer le montant total des dépenses bénéficiaires\n",
    "df['deptot_benef'] = df['deprd_benef'] + df['depcoll_benef'] + df['depinno_benef']\n",
    "print(f\"Montant total des dépenses bénéficiaires: {df['deptot_benef'].sum():,.2f} €\")\n",
    "\n",
    "\n",
    "print(\"\\n=== CRÉATION DES INDICATRICES ===\")\n",
    "\n",
    "# i_dep_rd : \"Oui\" si dépenses R&D > 0\n",
    "if colonne_depenses_rd and colonne_depenses_rd in df.columns:\n",
    "    df['i_dep_rd'] = np.where(df[colonne_depenses_rd] > 0, \"Oui\", \"Non\")\n",
    "else:\n",
    "    df['i_dep_rd'] = \"Non\"\n",
    "\n",
    "# i_dep_inno : \"Oui\" si dépenses inno > 0\n",
    "if col_dep_inno and col_dep_inno in df.columns:\n",
    "    df['i_dep_inno'] = np.where(df[col_dep_inno] > 0, \"Oui\", \"Non\")\n",
    "else:\n",
    "    df['i_dep_inno'] = \"Non\"\n",
    "\n",
    "# i_dep_coll : \"Oui\" si dépenses collection > 0\n",
    "if col_dep_coll and col_dep_coll in df.columns:\n",
    "    df['i_dep_coll'] = np.where(df[col_dep_coll] > 0, \"Oui\", \"Non\")\n",
    "else:\n",
    "    df['i_dep_coll'] = \"Non\"\n",
    "\n",
    "# i_bef : \"Oui\" si bénéficiaire du CIR total\n",
    "df['i_bef'] = np.where(df['cirtot_benef'] > 0, \"Oui\", \"Non\")\n",
    "\n",
    "# i_bef_rech : \"Oui\" si bénéficiaire du CIR recherche\n",
    "df['i_bef_rech'] = np.where(df['cirrech_benef'] > 0, \"Oui\", \"Non\")\n",
    "\n",
    "# i_bef_inno : \"Oui\" si bénéficiaire du CII\n",
    "df['i_bef_inno'] = np.where(df['cii_benef'] > 0, \"Oui\", \"Non\")\n",
    "\n",
    "# i_bef_crc : \"Oui\" si bénéficiaire du CRC\n",
    "df['i_bef_crc'] = np.where(df['crecrc_benef'] > 0, \"Oui\", \"Non\")\n",
    "\n",
    "# i_bef_coll : \"Oui\" si bénéficiaire du CI collection\n",
    "df['i_bef_coll'] = np.where(df['cic_benef'] > 0, \"Oui\", \"Non\")\n",
    "\n",
    "print(\"Indicatrices créées avec succès\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RAPPORT DÉTAILLÉ DE VÉRIFICATION DES DONNÉES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Vérifier les totaux des montants nets de dépenses\n",
    "print(\"\\n1. MONTANTS NETS DES DÉPENSES BÉNÉFICIAIRES:\")\n",
    "print(f\"   • Dépenses R&D bénéficiaires: {df['deprd_benef'].sum():,.2f} €\")\n",
    "print(f\"   • Dépenses Collection bénéficiaires: {df['depcoll_benef'].sum():,.2f} €\")\n",
    "print(f\"   • Dépenses Innovation bénéficiaires: {df['depinno_benef'].sum():,.2f} €\")\n",
    "print(f\"   • TOTAL dépenses bénéficiaires: {df['deptot_benef'].sum():,.2f} €\")\n",
    "\n",
    "# Vérifier les totaux des crédits DOM-TOM\n",
    "print(\"\\n2. CRÉDITS D'IMPÔT DOM-TOM:\")\n",
    "print(f\"   • CIR Recherche DOM: {df['crerd_genom'].sum():,.2f} €\")\n",
    "print(f\"   • CIR Collection DOM: {df['crecoll_genom'].sum():,.2f} €\")\n",
    "print(f\"   • CIR Innovation DOM: {df['creinno_genom'].sum():,.2f} €\")\n",
    "print(f\"   • TOTAL CIR DOM: {df['cretot_genom'].sum():,.2f} €\")\n",
    "\n",
    "# Vérifier les comptes des indicatrices\n",
    "print(\"\\n3. RÉPARTITION DES INDICATRICES:\")\n",
    "indicatrices = ['i_dep_rd', 'i_dep_inno', 'i_dep_coll', 'i_bef', 'i_bef_rech', 'i_bef_inno', 'i_bef_crc', 'i_bef_coll']\n",
    "\n",
    "for indicatrice in indicatrices:\n",
    "    if indicatrice in df.columns:\n",
    "        count_oui = (df[indicatrice] == \"Oui\").sum()\n",
    "        count_non = (df[indicatrice] == \"Non\").sum()\n",
    "        pct_oui = count_oui/len(df)*100\n",
    "        pct_non = count_non/len(df)*100\n",
    "        print(f\"   • {indicatrice:<12}: {count_oui:>6,} Oui ({pct_oui:>5.1f}%) | {count_non:>6,} Non ({pct_non:>5.1f}%)\")\n",
    "\n",
    "# Vérification de cohérence des bénéficiaires\n",
    "print(\"\\n4. VÉRIFICATIONS DE COHÉRENCE:\")\n",
    "\n",
    "# Cohérence entre i_bef et les autres indicatrices bénéficiaires\n",
    "nb_benef_total = (df['i_bef'] == \"Oui\").sum()\n",
    "nb_benef_rech = (df['i_bef_rech'] == \"Oui\").sum()\n",
    "nb_benef_coll = (df['i_bef_coll'] == \"Oui\").sum()\n",
    "nb_benef_inno = (df['i_bef_inno'] == \"Oui\").sum()\n",
    "nb_benef_crc = (df['i_bef_crc'] == \"Oui\").sum()\n",
    "\n",
    "print(f\"   • Bénéficiaires totaux: {nb_benef_total:,}\")\n",
    "print(f\"   • Détail: Recherche {nb_benef_rech:,} | Collection {nb_benef_coll:,} | Innovation {nb_benef_inno:,} | CRC {nb_benef_crc:,}\")\n",
    "\n",
    "# Vérifier la cohérence entre dépenses et bénéfices\n",
    "coherence_rd = ((df['i_dep_rd'] == \"Oui\") & (df['i_bef_rech'] == \"Non\")).sum()\n",
    "coherence_coll = ((df['i_dep_coll'] == \"Oui\") & (df['i_bef_coll'] == \"Non\")).sum()\n",
    "coherence_inno = ((df['i_dep_inno'] == \"Oui\") & (df['i_bef_inno'] == \"Non\")).sum()\n",
    "\n",
    "print(f\"   • Entreprises avec dépenses R&D mais sans bénéfice recherche: {coherence_rd:,}\")\n",
    "print(f\"   • Entreprises avec dépenses Collection mais sans bénéfice collection: {coherence_coll:,}\")\n",
    "print(f\"   • Entreprises avec dépenses Innovation mais sans bénéfice innovation: {coherence_inno:,}\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 5. FINALISATION ET SAUVEGARDE\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# Supprimer les colonnes temporaires\n",
    "colonnes_temp = ['SIREN_DEPOSANT_STD', 'SIREN_DECLARANT_STD', 'IS_MATCH']\n",
    "for col in colonnes_temp:\n",
    "    if col in df.columns:\n",
    "        df = df.drop(col, axis=1)\n",
    "\n",
    "# Ajouter une colonne de contrôle avec la date de traitement\n",
    "from datetime import datetime\n",
    "df['date_traitement'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Sauvegarder le fichier avec les nouvelles colonnes\n",
    "output_file = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_format_2021_complet.csv\"\n",
    "df.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"TRAITEMENT TERMINÉ AVEC SUCCÈS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Fichier sauvegardé: {output_file}\")\n",
    "print(f\"Nombre total de lignes: {len(df):,}\")\n",
    "print(f\"Nombre total de colonnes: {len(df.columns):,}\")\n",
    "print(f\"Taille du fichier final: {len(df) * len(df.columns):,} cellules\")\n",
    "\n",
    "# Résumé des nouvelles colonnes créées\n",
    "nouvelles_colonnes = [\n",
    "    'crerd_genom', 'crecoll_genom', 'creinno_genom', 'cretot_genom',\n",
    "    'deprd_benef', 'depcoll_benef', 'depinno_benef', 'deptot_benef',\n",
    "    'i_dep_rd', 'i_dep_inno', 'i_dep_coll', 'i_bef', 'i_bef_rech', \n",
    "    'i_bef_inno', 'i_bef_crc', 'i_bef_coll', 'date_traitement'\n",
    "]\n",
    "\n",
    "print(f\"\\nNOUVELLES COLONNES CRÉÉES ({len(nouvelles_colonnes)}):\")\n",
    "for i, col in enumerate(nouvelles_colonnes, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\nFichier prêt \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59fa33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement et préparation de 'C://Users//msamb//Documents//StockUniteLegale_utf8.csv'...\n",
      "Colonnes de stock_ul_extract après préparation : ['SIREN_DECLARANT', 'dateCreationUniteLegale', 'trancheEffectifsUniteLegale', 'categorieEntreprise', 'denominationUniteLegale', 'denominationUsuelle1UniteLegale', 'denominationUsuelle2UniteLegale', 'denominationUsuelle3UniteLegale', 'activitePrincipaleUniteLegale', 'nicSiegeUniteLegale', 'nic', 'siret']\n",
      "Chargement de la base à siréniser depuis 'M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_format_2021_complet.csv'...\n",
      "Colonnes de base_a_sireniser : ['SIREN_DECLARANT', 'SIREN_DEPOSANT', 'DESIGNATION', 'L1_DOTATION_AMORT_IMMO', 'L2_DOTATION_AMORT_SINISTR', 'L3_DEPENSES_PERSONNEL_CHERCHEURS', 'L4_REMUNERATION_INVENTEURS', 'L5_DEPENSES_JEUNES_DOCTEURS', 'L6_AUTRES_DEP_FONCT_DECLARE', 'L6_AUTRES_DEP_FONCT_CALCULE', 'L6_ECART', 'L7_TOTAL_DEP_FONCT_DECLARE', 'L7_TOTAL_DEP_FONCT_CALCULE', 'L7_ECART', 'L8_FRAIS_BREVETS_COV', 'L9_DEPENSES_DEFENSE_BREVETS', 'L10_DOTATION_AMORT_BREVETS', 'L11_DEPENSES_NORMALISATION', 'L12_PRIMES_COTISATIONS_BRUT', 'L12_PRIMES_COTISATIONS_PLAFONNEES', 'L13_VEILLE_TECHNO_BRUT', 'L13_VEILLE_TECHNO_PLAFONNEE', 'L14_TOTAL_DEPENSES_INTERNES_DECLARE', 'L14_TOTAL_DEPENSES_INTERNES_CALCULE', 'L14_ECART', 'L15A_ST_PUB_LIES_FR', 'L15B_ST_PUB_LIES_ETR', 'L16A_ST_PUB_NON_LIES_FR', 'L16B_ST_PUB_NON_LIES_ETR', 'L17_TOTAL_ST_PUBLIQUE_DECLARE', 'L17_TOTAL_ST_PUBLIQUE_CALCULE', 'L17_ECART', 'L18A_ST_PRIV_LIES_FR', 'L18B_ST_PRIV_LIES_ETR', 'L19A_ST_PRIV_NON_LIES_FR', 'L19B_ST_PRIV_NON_LIES_ETR', 'L20_TOTAL_ST_PRIVEE_DECLARE', 'L20_TOTAL_ST_PRIVEE_CALCULE', 'L20_ECART', 'L21_PLAFOND_ST_PRIVEE_DECLARE', 'L21_PLAFOND_ST_PRIVEE_CALCULE', 'L21_ECART', 'L22_TOTAL_ST_DECLARE', 'L22_TOTAL_ST_CALCULE', 'L22_ECART', 'L23_PLAFOND_ORGANISMES_LIES_DECLARE', 'L23_PLAFOND_ORGANISMES_LIES_CALCULE', 'L23_ECART', 'L24_PLAFOND_ORG_NON_LIES_DECLARE', 'L24_PLAFOND_ORG_NON_LIES_CALCULE', 'L24_ECART', 'L25_PLAFOND_GENERAL_DECLARE', 'L25_PLAFOND_GENERAL_CALCULE', 'L25_ECART', 'L26_TOTAL_ST_PLAFONNE_DECLARE', 'L26_TOTAL_ST_PLAFONNE_CALCULE', 'L26_ECART', 'L27_TOTAL_DEPENSES_RECHERCHE_DECLARE', 'L27_TOTAL_DEPENSES_RECHERCHE_CALCULE', 'L27_ECART', 'L28A_SUBVENTIONS', 'L28B_SOMMES_ENCAISSEES_TIERS', 'L29_DEPENSES_CONSEIL_CIR', 'L30_REMBOURSEMENTS_SUBVENTIONS', 'L31A_MONTANT_NET_DEPENSES_DECLARE', 'L31A_MONTANT_NET_DEPENSES_CALCULE', 'L31A_ECART', 'L31B_MONTANT_NET_DEPENSES_DOM_DECLARE', 'L31B_MONTANT_NET_DEPENSES_DOM_CALCULE', 'L31B_ECART', 'L32_FRAIS_COLLECTION', 'L33_FRAIS_DEFENSE_DESSINS_BRUT', 'L33_FRAIS_DEFENSE_DESSINS_PLAFONNES', 'L34_TOTAL_DEPENSES_COLLECTION_DECLARE', 'L34_TOTAL_DEPENSES_COLLECTION_CALCULE', 'L34_ECART', 'L35_SUBVENTIONS_COLLECTION', 'L36_DEPENSES_CONSEIL_COLLECTION', 'L37_REMBOURSEMENTS_SUBVENTIONS_COLL', 'L38A_MONTANT_NET_COLLECTION_DECLARE', 'L38A_MONTANT_NET_COLLECTION_CALCULE', 'L38A_ECART', 'L38B_MONTANT_NET_COLLECTION_DOM_DECLARE', 'L38B_MONTANT_NET_COLLECTION_DOM_CALCULE', 'L38B_ECART', 'L39A_MONTANT_NET_TOTAL_RD_COLL', 'L39B_MONTANT_NET_TOTAL_RD_COLL_DOM', 'L41_CREDIT_IMPOT_RECHERCHE_MOINS_100M', 'L42_QUOTE_PART_RECHERCHE_SOC_PERSONNES', 'L43A_CREDIT_IMPOT_RECHERCHE_TOTAL', 'L43B_CREDIT_IMPOT_RECHERCHE_DOM', 'L45_CREDIT_IMPOT_COLLECTION_MOINS_100M', 'L46_QUOTE_PART_COLLECTION_SOC_PERSONNES', 'L47A_CREDIT_IMPOT_COLL_AVANT_PLAF', 'L47B_CREDIT_IMPOT_COLL_DOM_AVANT_PLAF', 'L48_AIDES_MINIMIS', 'L49_CUMUL_CREDIT_IMPOT_ET_AIDES', 'L50A_CREDIT_IMPOT_COLL_APRES_PLAF', 'L50B_CREDIT_IMPOT_COLL_DOM_APRES_PLAF', 'L51A_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION', 'L51B_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION_DOM', 'L52A_DEPENSES_RECHERCHE_LIMITE_100M', 'L52B_DEPENSES_RECHERCHE_DOM_LIMITE', 'L53_CIR_RECHERCHE_PREMIERE_TRANCHE', 'L54_DEPENSES_RECHERCHE_SUP_100M', 'L55_CIR_RECHERCHE_DEUXIEME_TRANCHE', 'L56_CIR_RECHERCHE_PLUS_100M', 'L57_QUOTE_PART_RECHERCHE_SOC_PERSONNES_PLUS_100M', 'L58A_CREDIT_IMPOT_RECHERCHE_TOTAL_PLUS_100M', 'L58B_CREDIT_IMPOT_RECHERCHE_DOM_PLUS_100M', 'L59A_MONTANT_NET_COLLECTION_PLUS_100M', 'L59B_MONTANT_NET_COLLECTION_DOM_PLUS_100M', 'L60_PLAFOND_DISPO_COLLECTION', 'L61_CIR_COLLECTION_PREMIERE_TRANCHE', 'L62_CIR_COLLECTION_DEUXIEME_TRANCHE', 'L63_CIR_COLLECTION_PLUS_100M', 'L64_QUOTE_PART_COLLECTION_SOC_PERSONNES_PLUS_100M', 'L65_CREDIT_IMPOT_COLL_AVANT_PLAF_PLUS_100M', 'L66_AIDES_MINIMIS_PLUS_100M', 'L67_CUMUL_CREDIT_IMPOT_ET_AIDES_PLUS_100M', 'L68A_CREDIT_IMPOT_COLL_APRES_PLAF_PLUS_100M', 'L68B_CREDIT_IMPOT_COLL_DOM_APRES_PLAF_PLUS_100M', 'L69A_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION_PLUS_100M', 'L69B_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION_DOM_PLUS_100M', 'L70_DOTATION_AMORT_IMMO_INNOVATION', 'L71_DEPENSES_PERSONNEL_INNOVATION', 'L72_AUTRES_DEPENSES_FONCT_INNOVATION', 'L73_FRAIS_BREVETS_INNOVATION', 'L74_FRAIS_DEFENSE_BREVETS_INNOVATION', 'L75_OPERATIONS_CONFIEES_INNOVATION', 'L76_TOTAL_DEPENSES_INNOVATION_DECLARE', 'L76_TOTAL_DEPENSES_INNOVATION_CALCULE', 'L76_ECART', 'L77_DEPENSES_INNOVATION_PLAFONNEES_DECLARE', 'L77_DEPENSES_INNOVATION_PLAFONNEES_CALCULE', 'L77_ECART', 'L78_SUBVENTIONS_INNOVATION', 'L79_PRESTATIONS_INNOVATION', 'L80_DEPENSES_CONSEIL_INNOVATION', 'L81_REMBOURSEMENTS_SUBVENTIONS_INNO', 'L82A_MONTANT_NET_INNOVATION_DECLARE', 'L82A_MONTANT_NET_INNOVATION_CALCULE', 'L82A_ECART', 'L82B_MONTANT_NET_INNOVATION_DOM', 'L82C_MONTANT_NET_INNOVATION_CORSE_MPE', 'L82D_MONTANT_NET_INNOVATION_CORSE_ME', 'L83_CREDIT_IMPOT_INNOVATION', 'L84_QUOTE_PART_INNOVATION_SOC_PERSONNES', 'L85A_TOTAL_CREDIT_IMPOT_INNOVATION', 'L85B_CREDIT_IMPOT_INNOVATION_DOM', 'L85C_CREDIT_IMPOT_INNOVATION_CORSE', 'L86A_TOTAL_CIR_RECH_COLL_INNO', 'L86B_TOTAL_CIR_RECH_COLL_INNO_DOM', 'crerd_gen_declare', 'crerd_gen', 'crerd_gen_ecart', 'crecoll_gen_declare', 'crecoll_gen', 'crecoll_gen_ecart', 'creinno_gen_declare', 'creinno_gen', 'creinno_gen_ecart', 'cretot_gen_declare', 'cretot_gen_calcule', 'cretot_gen_ecart', 'CORRESPONDANCE_CIR', 'ECART_RELATIF_POURCENT', 'TRAITEMENT_APPLIQUE', 'cretot_gen', 'type_final', 'mere_final', 'cir_benef_total', 'cirrech_benef', 'cic_benef', 'cii_benef', 'crecrc_benef', 'cirtot_benef', 'crerd_genom', 'crecoll_genom', 'creinno_genom', 'cretot_genom', 'deprd_benef', 'depcoll_benef', 'depinno_benef', 'deptot_benef', 'i_dep_rd', 'i_dep_inno', 'i_dep_coll', 'i_bef', 'i_bef_rech', 'i_bef_inno', 'i_bef_crc', 'i_bef_coll', 'date_traitement']\n",
      "\n",
      "Jonction de 'base_a_sireniser' avec 'stock_ul_extrait' sur la colonne 'SIREN_DECLARANT'...\n",
      "Nombre de lignes après la première jonction : 4543\n",
      "Chargement et préparation de la nomenclature 'C://Users//msamb//Documents//Nomenclature_secteur_sittar.xlsx'...\n",
      "Colonnes de nomenclature_sitar après préparation : ['activiteprincipaleunitelegale', 'secteur_dactivit', 'libell_code_ape_entreprise']\n",
      "\n",
      "Jonction avec 'nomenclature_sitar' sur la colonne APE (harmonisées)...\n",
      "Nombre de lignes après la seconde jonction : 4543\n",
      "Colonnes finales : ['SIREN_DECLARANT', 'SIREN_DEPOSANT', 'DESIGNATION', 'L1_DOTATION_AMORT_IMMO', 'L2_DOTATION_AMORT_SINISTR', 'L3_DEPENSES_PERSONNEL_CHERCHEURS', 'L4_REMUNERATION_INVENTEURS', 'L5_DEPENSES_JEUNES_DOCTEURS', 'L6_AUTRES_DEP_FONCT_DECLARE', 'L6_AUTRES_DEP_FONCT_CALCULE', 'L6_ECART', 'L7_TOTAL_DEP_FONCT_DECLARE', 'L7_TOTAL_DEP_FONCT_CALCULE', 'L7_ECART', 'L8_FRAIS_BREVETS_COV', 'L9_DEPENSES_DEFENSE_BREVETS', 'L10_DOTATION_AMORT_BREVETS', 'L11_DEPENSES_NORMALISATION', 'L12_PRIMES_COTISATIONS_BRUT', 'L12_PRIMES_COTISATIONS_PLAFONNEES', 'L13_VEILLE_TECHNO_BRUT', 'L13_VEILLE_TECHNO_PLAFONNEE', 'L14_TOTAL_DEPENSES_INTERNES_DECLARE', 'L14_TOTAL_DEPENSES_INTERNES_CALCULE', 'L14_ECART', 'L15A_ST_PUB_LIES_FR', 'L15B_ST_PUB_LIES_ETR', 'L16A_ST_PUB_NON_LIES_FR', 'L16B_ST_PUB_NON_LIES_ETR', 'L17_TOTAL_ST_PUBLIQUE_DECLARE', 'L17_TOTAL_ST_PUBLIQUE_CALCULE', 'L17_ECART', 'L18A_ST_PRIV_LIES_FR', 'L18B_ST_PRIV_LIES_ETR', 'L19A_ST_PRIV_NON_LIES_FR', 'L19B_ST_PRIV_NON_LIES_ETR', 'L20_TOTAL_ST_PRIVEE_DECLARE', 'L20_TOTAL_ST_PRIVEE_CALCULE', 'L20_ECART', 'L21_PLAFOND_ST_PRIVEE_DECLARE', 'L21_PLAFOND_ST_PRIVEE_CALCULE', 'L21_ECART', 'L22_TOTAL_ST_DECLARE', 'L22_TOTAL_ST_CALCULE', 'L22_ECART', 'L23_PLAFOND_ORGANISMES_LIES_DECLARE', 'L23_PLAFOND_ORGANISMES_LIES_CALCULE', 'L23_ECART', 'L24_PLAFOND_ORG_NON_LIES_DECLARE', 'L24_PLAFOND_ORG_NON_LIES_CALCULE', 'L24_ECART', 'L25_PLAFOND_GENERAL_DECLARE', 'L25_PLAFOND_GENERAL_CALCULE', 'L25_ECART', 'L26_TOTAL_ST_PLAFONNE_DECLARE', 'L26_TOTAL_ST_PLAFONNE_CALCULE', 'L26_ECART', 'L27_TOTAL_DEPENSES_RECHERCHE_DECLARE', 'L27_TOTAL_DEPENSES_RECHERCHE_CALCULE', 'L27_ECART', 'L28A_SUBVENTIONS', 'L28B_SOMMES_ENCAISSEES_TIERS', 'L29_DEPENSES_CONSEIL_CIR', 'L30_REMBOURSEMENTS_SUBVENTIONS', 'L31A_MONTANT_NET_DEPENSES_DECLARE', 'L31A_MONTANT_NET_DEPENSES_CALCULE', 'L31A_ECART', 'L31B_MONTANT_NET_DEPENSES_DOM_DECLARE', 'L31B_MONTANT_NET_DEPENSES_DOM_CALCULE', 'L31B_ECART', 'L32_FRAIS_COLLECTION', 'L33_FRAIS_DEFENSE_DESSINS_BRUT', 'L33_FRAIS_DEFENSE_DESSINS_PLAFONNES', 'L34_TOTAL_DEPENSES_COLLECTION_DECLARE', 'L34_TOTAL_DEPENSES_COLLECTION_CALCULE', 'L34_ECART', 'L35_SUBVENTIONS_COLLECTION', 'L36_DEPENSES_CONSEIL_COLLECTION', 'L37_REMBOURSEMENTS_SUBVENTIONS_COLL', 'L38A_MONTANT_NET_COLLECTION_DECLARE', 'L38A_MONTANT_NET_COLLECTION_CALCULE', 'L38A_ECART', 'L38B_MONTANT_NET_COLLECTION_DOM_DECLARE', 'L38B_MONTANT_NET_COLLECTION_DOM_CALCULE', 'L38B_ECART', 'L39A_MONTANT_NET_TOTAL_RD_COLL', 'L39B_MONTANT_NET_TOTAL_RD_COLL_DOM', 'L41_CREDIT_IMPOT_RECHERCHE_MOINS_100M', 'L42_QUOTE_PART_RECHERCHE_SOC_PERSONNES', 'L43A_CREDIT_IMPOT_RECHERCHE_TOTAL', 'L43B_CREDIT_IMPOT_RECHERCHE_DOM', 'L45_CREDIT_IMPOT_COLLECTION_MOINS_100M', 'L46_QUOTE_PART_COLLECTION_SOC_PERSONNES', 'L47A_CREDIT_IMPOT_COLL_AVANT_PLAF', 'L47B_CREDIT_IMPOT_COLL_DOM_AVANT_PLAF', 'L48_AIDES_MINIMIS', 'L49_CUMUL_CREDIT_IMPOT_ET_AIDES', 'L50A_CREDIT_IMPOT_COLL_APRES_PLAF', 'L50B_CREDIT_IMPOT_COLL_DOM_APRES_PLAF', 'L51A_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION', 'L51B_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION_DOM', 'L52A_DEPENSES_RECHERCHE_LIMITE_100M', 'L52B_DEPENSES_RECHERCHE_DOM_LIMITE', 'L53_CIR_RECHERCHE_PREMIERE_TRANCHE', 'L54_DEPENSES_RECHERCHE_SUP_100M', 'L55_CIR_RECHERCHE_DEUXIEME_TRANCHE', 'L56_CIR_RECHERCHE_PLUS_100M', 'L57_QUOTE_PART_RECHERCHE_SOC_PERSONNES_PLUS_100M', 'L58A_CREDIT_IMPOT_RECHERCHE_TOTAL_PLUS_100M', 'L58B_CREDIT_IMPOT_RECHERCHE_DOM_PLUS_100M', 'L59A_MONTANT_NET_COLLECTION_PLUS_100M', 'L59B_MONTANT_NET_COLLECTION_DOM_PLUS_100M', 'L60_PLAFOND_DISPO_COLLECTION', 'L61_CIR_COLLECTION_PREMIERE_TRANCHE', 'L62_CIR_COLLECTION_DEUXIEME_TRANCHE', 'L63_CIR_COLLECTION_PLUS_100M', 'L64_QUOTE_PART_COLLECTION_SOC_PERSONNES_PLUS_100M', 'L65_CREDIT_IMPOT_COLL_AVANT_PLAF_PLUS_100M', 'L66_AIDES_MINIMIS_PLUS_100M', 'L67_CUMUL_CREDIT_IMPOT_ET_AIDES_PLUS_100M', 'L68A_CREDIT_IMPOT_COLL_APRES_PLAF_PLUS_100M', 'L68B_CREDIT_IMPOT_COLL_DOM_APRES_PLAF_PLUS_100M', 'L69A_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION_PLUS_100M', 'L69B_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION_DOM_PLUS_100M', 'L70_DOTATION_AMORT_IMMO_INNOVATION', 'L71_DEPENSES_PERSONNEL_INNOVATION', 'L72_AUTRES_DEPENSES_FONCT_INNOVATION', 'L73_FRAIS_BREVETS_INNOVATION', 'L74_FRAIS_DEFENSE_BREVETS_INNOVATION', 'L75_OPERATIONS_CONFIEES_INNOVATION', 'L76_TOTAL_DEPENSES_INNOVATION_DECLARE', 'L76_TOTAL_DEPENSES_INNOVATION_CALCULE', 'L76_ECART', 'L77_DEPENSES_INNOVATION_PLAFONNEES_DECLARE', 'L77_DEPENSES_INNOVATION_PLAFONNEES_CALCULE', 'L77_ECART', 'L78_SUBVENTIONS_INNOVATION', 'L79_PRESTATIONS_INNOVATION', 'L80_DEPENSES_CONSEIL_INNOVATION', 'L81_REMBOURSEMENTS_SUBVENTIONS_INNO', 'L82A_MONTANT_NET_INNOVATION_DECLARE', 'L82A_MONTANT_NET_INNOVATION_CALCULE', 'L82A_ECART', 'L82B_MONTANT_NET_INNOVATION_DOM', 'L82C_MONTANT_NET_INNOVATION_CORSE_MPE', 'L82D_MONTANT_NET_INNOVATION_CORSE_ME', 'L83_CREDIT_IMPOT_INNOVATION', 'L84_QUOTE_PART_INNOVATION_SOC_PERSONNES', 'L85A_TOTAL_CREDIT_IMPOT_INNOVATION', 'L85B_CREDIT_IMPOT_INNOVATION_DOM', 'L85C_CREDIT_IMPOT_INNOVATION_CORSE', 'L86A_TOTAL_CIR_RECH_COLL_INNO', 'L86B_TOTAL_CIR_RECH_COLL_INNO_DOM', 'crerd_gen_declare', 'crerd_gen', 'crerd_gen_ecart', 'crecoll_gen_declare', 'crecoll_gen', 'crecoll_gen_ecart', 'creinno_gen_declare', 'creinno_gen', 'creinno_gen_ecart', 'cretot_gen_declare', 'cretot_gen_calcule', 'cretot_gen_ecart', 'CORRESPONDANCE_CIR', 'ECART_RELATIF_POURCENT', 'TRAITEMENT_APPLIQUE', 'cretot_gen', 'type_final', 'mere_final', 'cir_benef_total', 'cirrech_benef', 'cic_benef', 'cii_benef', 'crecrc_benef', 'cirtot_benef', 'crerd_genom', 'crecoll_genom', 'creinno_genom', 'cretot_genom', 'deprd_benef', 'depcoll_benef', 'depinno_benef', 'deptot_benef', 'i_dep_rd', 'i_dep_inno', 'i_dep_coll', 'i_bef', 'i_bef_rech', 'i_bef_inno', 'i_bef_crc', 'i_bef_coll', 'date_traitement', 'dateCreationUniteLegale', 'trancheEffectifsUniteLegale', 'categorieEntreprise', 'denominationUniteLegale', 'denominationUsuelle1UniteLegale', 'denominationUsuelle2UniteLegale', 'denominationUsuelle3UniteLegale', 'activitePrincipaleUniteLegale', 'nicSiegeUniteLegale', 'nic', 'siret', 'activiteprincipaleunitelegale', 'secteur_dactivit', 'libell_code_ape_entreprise']\n",
      "\n",
      "✓ Processus de sirénisation terminé.\n",
      "\n",
      "Aperçu du DataFrame final (base_finale_df) :\n",
      "  SIREN_DECLARANT  SIREN_DEPOSANT                      DESIGNATION  \\\n",
      "0       006720049         6720049              BORFLEX SERVICES NS   \n",
      "1       356000000       356000000                         LA POSTE   \n",
      "2       340012392       356000000                          GEOPOST   \n",
      "3       343266854       356000000                         SOMEPOST   \n",
      "4       409108115       356000000  SOCIETE DE TRAITEMENT DE PRESSE   \n",
      "\n",
      "   L1_DOTATION_AMORT_IMMO  L2_DOTATION_AMORT_SINISTR  \\\n",
      "0                     0.0                        0.0   \n",
      "1                     0.0                        0.0   \n",
      "2                     0.0                        0.0   \n",
      "3                     0.0                        0.0   \n",
      "4                     0.0                        0.0   \n",
      "\n",
      "   L3_DEPENSES_PERSONNEL_CHERCHEURS  L4_REMUNERATION_INVENTEURS  \\\n",
      "0                           68734.0                         0.0   \n",
      "1                         1345795.0                         0.0   \n",
      "2                               0.0                         0.0   \n",
      "3                               0.0                         0.0   \n",
      "4                               0.0                         0.0   \n",
      "\n",
      "   L5_DEPENSES_JEUNES_DOCTEURS  L6_AUTRES_DEP_FONCT_DECLARE  \\\n",
      "0                          0.0                      29556.0   \n",
      "1                          0.0                     578692.0   \n",
      "2                          0.0                          0.0   \n",
      "3                          0.0                          0.0   \n",
      "4                          0.0                          0.0   \n",
      "\n",
      "   L6_AUTRES_DEP_FONCT_CALCULE  ...  denominationUsuelle1UniteLegale  \\\n",
      "0                     29555.62  ...                              NaN   \n",
      "1                    578691.85  ...   DIRECTION GENERALE DE LA POSTE   \n",
      "2                         0.00  ...                              NaN   \n",
      "3                         0.00  ...                              NaN   \n",
      "4                         0.00  ...                              NaN   \n",
      "\n",
      "   denominationUsuelle2UniteLegale  denominationUsuelle3UniteLegale  \\\n",
      "0                              NaN                              NaN   \n",
      "1                              NaN                              NaN   \n",
      "2                              NaN                              NaN   \n",
      "3                              NaN                              NaN   \n",
      "4                              NaN                              NaN   \n",
      "\n",
      "   activitePrincipaleUniteLegale  nicSiegeUniteLegale    nic           siret  \\\n",
      "0                         70.10Z                00037  00037  00672004900037   \n",
      "1                         53.10Z                00048  00048  35600000000048   \n",
      "2                         70.10Z                00122  00122  34001239200122   \n",
      "3                         71.12B                00078  00078  34326685400078   \n",
      "4                         53.10Z                00141  00141  40910811500141   \n",
      "\n",
      "   activiteprincipaleunitelegale                         secteur_dactivit  \\\n",
      "0                         70.10Z                  ACTIVITES DES \"HOLDING\"   \n",
      "1                         53.10Z                          AUTRES SERVICES   \n",
      "2                         70.10Z                  ACTIVITES DES \"HOLDING\"   \n",
      "3                         71.12B  SERVICES D'ARCHITECTURE ET D'INGIENERIE   \n",
      "4                         53.10Z                          AUTRES SERVICES   \n",
      "\n",
      "                          libell_code_ape_entreprise  \n",
      "0                       Activités des sièges sociaux  \n",
      "1  Activités de poste dans le cadre d'une obligat...  \n",
      "2                       Activités des sièges sociaux  \n",
      "3                      Ingénierie, études techniques  \n",
      "4  Activités de poste dans le cadre d'une obligat...  \n",
      "\n",
      "[5 rows x 208 columns]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Ce script :\n",
    "1. Charge et prépare un fichier de référence des unités légales (StockUniteLegale).\n",
    "2. Charge une base de données principale à enrichir (\"base_a_sireniser\").\n",
    "3. Joint ces deux bases sur le numéro SIREN.\n",
    "4. Charge une nomenclature d'activités (Nomenclature Sittar).\n",
    "5. Joint le résultat précédent avec cette nomenclature sur le code APE.\n",
    "\n",
    "librairie pandas installée requis: pip install pandas openpyxl\n",
    "(openpyxl est nécessaire pour lire les fichiers Excel .xlsx)\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd # Librairie pour la manipulation de données\n",
    "import re           # Librairie pour les expressions régulières (nettoyage des noms de colonnes)\n",
    "# La librairie 'os' n'est plus nécessaire car on ne crée plus de dossier/fichiers de test.\n",
    "\n",
    "# --- Fonction Auxiliaire pour Nettoyer les Noms de Colonnes ---\n",
    "def nettoyer_noms_colonnes(df_a_nettoyer):\n",
    "    \"\"\"\n",
    "    Nettoie les noms de colonnes d'un DataFrame :\n",
    "    1. Convertit en minuscules.\n",
    "    2. Remplace les espaces et caractères spéciaux par des tirets bas ('_').\n",
    "    3. Supprime les tirets bas en début ou fin de nom.\n",
    "    Retourne un nouveau DataFrame avec les noms de colonnes nettoyés.\n",
    "    \"\"\"\n",
    "    df = df_a_nettoyer.copy() # Travailler sur une copie\n",
    "    nouveaux_noms = {}\n",
    "    for col in df.columns:\n",
    "        nouveau_nom = str(col).lower()\n",
    "        nouveau_nom = re.sub(r'\\s+', '_', nouveau_nom)\n",
    "        nouveau_nom = re.sub(r'[^a-z0-9_]', '', nouveau_nom)\n",
    "        nouveau_nom = re.sub(r'_+', '_', nouveau_nom)\n",
    "        nouveau_nom = nouveau_nom.strip('_')\n",
    "        nouveaux_noms[col] = nouveau_nom\n",
    "    df.rename(columns=nouveaux_noms, inplace=True)\n",
    "    return df\n",
    "\n",
    "# --- 1. Chargement et Préparation des Données 'StockUniteLegale' ---\n",
    "def charger_et_preparer_stock_ul(chemin_fichier_stock_ul):\n",
    "    \"\"\"\n",
    "    Charge et prépare les données du fichier 'StockUniteLegale'.\n",
    "    \"\"\"\n",
    "    print(f\"Chargement et préparation de '{chemin_fichier_stock_ul}'...\")\n",
    "    colonnes_a_garder = [\n",
    "        'siren', 'nicSiegeUniteLegale', 'denominationUniteLegale',\n",
    "        'denominationUsuelle1UniteLegale', 'denominationUsuelle2UniteLegale',\n",
    "        'denominationUsuelle3UniteLegale', 'dateCreationUniteLegale',\n",
    "        'activitePrincipaleUniteLegale', 'categorieEntreprise',\n",
    "        'trancheEffectifsUniteLegale'\n",
    "    ]\n",
    "    try:\n",
    "        stock_ul_df = pd.read_csv(chemin_fichier_stock_ul, \n",
    "                                  usecols=colonnes_a_garder, \n",
    "                                  dtype=str, \n",
    "                                  encoding='utf-8')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERREUR : Le fichier '{chemin_fichier_stock_ul}' est introuvable.\")\n",
    "        raise\n",
    "    except ValueError as e:\n",
    "        print(f\"ERREUR : Vérifiez que les colonnes {colonnes_a_garder} existent bien dans '{chemin_fichier_stock_ul}'. Détail : {e}\")\n",
    "        raise\n",
    "\n",
    "    stock_ul_df['nic'] = stock_ul_df['nicSiegeUniteLegale'].str.zfill(5)\n",
    "    stock_ul_df['siren'] = stock_ul_df['siren'].str.zfill(9)\n",
    "    stock_ul_df['siret'] = stock_ul_df['siren'] + stock_ul_df['nic']\n",
    "    stock_ul_df.rename(columns={'siren': 'SIREN_DECLARANT'}, inplace=True)\n",
    "    print(f\"Colonnes de stock_ul_extract après préparation : {stock_ul_df.columns.tolist()}\")\n",
    "    return stock_ul_df\n",
    "\n",
    "# --- Fonction pour Charger la 'base_a_sireniser' ---\n",
    "def charger_base_a_sireniser(chemin_fichier_base, nom_colonne_siren='SIREN_DECLARANT'):\n",
    "    \"\"\"\n",
    "    Charge les données de la 'base_a_sireniser'.\n",
    "    'nom_colonne_siren' doit être le nom de la colonne SIREN dans ce fichier.\n",
    "    \"\"\"\n",
    "    print(f\"Chargement de la base à siréniser depuis '{chemin_fichier_base}'...\")\n",
    "    try:\n",
    "        base_df = pd.read_csv(chemin_fichier_base,\n",
    "                      dtype={nom_colonne_siren: str}, \n",
    "                      encoding='utf-8',\n",
    "                      sep=';') # Ajoutez sep=';' ou le séparateur correct\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERREUR : Le fichier '{chemin_fichier_base}' est introuvable.\")\n",
    "        raise\n",
    "    except KeyError:\n",
    "        print(f\"ERREUR : La colonne '{nom_colonne_siren}' (spécifiée pour le SIREN) est introuvable dans '{chemin_fichier_base}'.\")\n",
    "        raise\n",
    "        \n",
    "    if nom_colonne_siren in base_df.columns:\n",
    "        base_df[nom_colonne_siren] = base_df[nom_colonne_siren].str.zfill(9)\n",
    "    print(f\"Colonnes de base_a_sireniser : {base_df.columns.tolist()}\")\n",
    "    return base_df\n",
    "\n",
    "# --- 3. Chargement et Préparation des Données de la 'Nomenclature Sittar' ---\n",
    "def charger_et_preparer_nomenclature(chemin_fichier_nomenclature, nom_original_col_ape='code_ape_entreprise'):\n",
    "    \"\"\"\n",
    "    Charge et prépare les données du fichier 'Nomenclature_secteur_sittar.xlsx'.\n",
    "    'nom_original_col_ape' est le nom original de la colonne du code APE dans le fichier Excel.\n",
    "    \"\"\"\n",
    "    print(f\"Chargement et préparation de la nomenclature '{chemin_fichier_nomenclature}'...\")\n",
    "    try:\n",
    "        nomenclature_df = pd.read_excel(chemin_fichier_nomenclature)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERREUR : Le fichier '{chemin_fichier_nomenclature}' est introuvable.\")\n",
    "        raise\n",
    "\n",
    "    nomenclature_df = nettoyer_noms_colonnes(nomenclature_df)\n",
    "    col_ape_nettoyee_candidate = nettoyer_noms_colonnes(pd.DataFrame(columns=[nom_original_col_ape])).columns[0]\n",
    "    nom_cible_col_ape_pour_jointure = 'activiteprincipaleunitelegale'\n",
    "\n",
    "    if col_ape_nettoyee_candidate in nomenclature_df.columns:\n",
    "        nomenclature_df.rename(columns={col_ape_nettoyee_candidate: nom_cible_col_ape_pour_jointure}, inplace=True)\n",
    "    elif nom_original_col_ape.lower() in nomenclature_df.columns and nom_original_col_ape.lower() != nom_cible_col_ape_pour_jointure :\n",
    "         nomenclature_df.rename(columns={nom_original_col_ape.lower(): nom_cible_col_ape_pour_jointure}, inplace=True)\n",
    "    elif nom_cible_col_ape_pour_jointure not in nomenclature_df.columns:\n",
    "        print(f\"Attention : Colonne APE ('{col_ape_nettoyee_candidate}' ou '{nom_original_col_ape.lower()}') non trouvée \"\n",
    "              f\"pour renommage en '{nom_cible_col_ape_pour_jointure}'. Colonnes dispo : {nomenclature_df.columns.tolist()}\")\n",
    "\n",
    "    if nom_cible_col_ape_pour_jointure in nomenclature_df.columns:\n",
    "        cols = [nom_cible_col_ape_pour_jointure] + [col for col in nomenclature_df.columns if col != nom_cible_col_ape_pour_jointure]\n",
    "        nomenclature_df = nomenclature_df[cols]\n",
    "    print(f\"Colonnes de nomenclature_sitar après préparation : {nomenclature_df.columns.tolist()}\")\n",
    "    return nomenclature_df\n",
    "\n",
    "# --- Processus Principal de Sirénisation ---\n",
    "def processus_principal_sirenisation():\n",
    "    \"\"\"\n",
    "    Fonction principale orchestrant le processus de sirénisation.\n",
    "    \"\"\"\n",
    "    # --- Configuration : Définissez vos chemins de fichiers ici ---\n",
    "    chemin_stock_ul = \"C://Users//msamb//Documents//StockUniteLegale_utf8.csv\"\n",
    "    chemin_base_a_sireniser = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_format_2021_complet.csv\"\n",
    "    nom_col_siren_dans_base = \"SIREN_DECLARANT\" \n",
    "    chemin_nomenclature_sittar = \"C://Users//msamb//Documents//Nomenclature_secteur_sittar.xlsx\"\n",
    "    nom_original_col_ape_nomenclature = \"Code APE Entreprise\"\n",
    "    # --- Fin de la Configuration ---\n",
    "\n",
    "    try:\n",
    "        # 1. Charger et préparer 'stock_ul_extract'\n",
    "        stock_ul_extrait_df = charger_et_preparer_stock_ul(chemin_stock_ul)\n",
    "\n",
    "        # 2. Charger 'base_a_sireniser'\n",
    "        base_a_sireniser_df = charger_base_a_sireniser(chemin_base_a_sireniser, nom_colonne_siren=nom_col_siren_dans_base)\n",
    "\n",
    "        # 3. Première jointure (sirénisation)\n",
    "        print(f\"\\nJonction de 'base_a_sireniser' avec 'stock_ul_extrait' sur la colonne '{nom_col_siren_dans_base}'...\")\n",
    "        base_finale_def_sirenise = pd.merge(\n",
    "            left=base_a_sireniser_df,\n",
    "            right=stock_ul_extrait_df,\n",
    "            left_on=nom_col_siren_dans_base,\n",
    "            right_on='SIREN_DECLARANT',\n",
    "            how='left'\n",
    "        )\n",
    "        print(f\"Nombre de lignes après la première jonction : {len(base_finale_def_sirenise)}\")\n",
    "\n",
    "        # 4. Charger et préparer 'nomenclature_sitar'\n",
    "        nomenclature_sitar_df = charger_et_preparer_nomenclature(\n",
    "            chemin_nomenclature_sittar, \n",
    "            nom_original_col_ape=nom_original_col_ape_nomenclature\n",
    "        )\n",
    "\n",
    "        # 5. Seconde jointure avec la nomenclature\n",
    "        cle_jointure_ape_base = 'activitePrincipaleUniteLegale'\n",
    "        cle_jointure_ape_nomenclature = 'activiteprincipaleunitelegale'\n",
    "\n",
    "        if cle_jointure_ape_base not in base_finale_def_sirenise.columns:\n",
    "            print(f\"ERREUR : Colonne '{cle_jointure_ape_base}' absente de la base après première jointure.\")\n",
    "            return\n",
    "        if cle_jointure_ape_nomenclature not in nomenclature_sitar_df.columns:\n",
    "            print(f\"ERREUR : Colonne '{cle_jointure_ape_nomenclature}' absente de la nomenclature préparée.\")\n",
    "            return\n",
    "\n",
    "        # Harmonisation des clés de jointure APE pour robustesse\n",
    "        base_finale_def_sirenise[cle_jointure_ape_base + '_pour_jointure'] = base_finale_def_sirenise[cle_jointure_ape_base].astype(str).str.strip().str.lower()\n",
    "        nomenclature_sitar_df[cle_jointure_ape_nomenclature + '_pour_jointure'] = nomenclature_sitar_df[cle_jointure_ape_nomenclature].astype(str).str.strip().str.lower()\n",
    "        \n",
    "        print(f\"\\nJonction avec 'nomenclature_sitar' sur la colonne APE (harmonisées)...\")\n",
    "        base_finale_df = pd.merge(\n",
    "            base_finale_def_sirenise,\n",
    "            nomenclature_sitar_df,\n",
    "            left_on=cle_jointure_ape_base + '_pour_jointure',\n",
    "            right_on=cle_jointure_ape_nomenclature + '_pour_jointure',\n",
    "            how='left',\n",
    "            suffixes=('_base', '_nomenclature')\n",
    "        )\n",
    "        \n",
    "        # Optionnel: supprimer les colonnes temporaires de jointure APE\n",
    "        base_finale_df.drop(columns=[cle_jointure_ape_base + '_pour_jointure', cle_jointure_ape_nomenclature + '_pour_jointure'], inplace=True, errors='ignore')\n",
    "        \n",
    "        print(f\"Nombre de lignes après la seconde jonction : {len(base_finale_df)}\")\n",
    "        print(f\"Colonnes finales : {base_finale_df.columns.tolist()}\")\n",
    "\n",
    "        print(\"\\n✓ Processus de sirénisation terminé.\")\n",
    "        print(\"\\nAperçu du DataFrame final (base_finale_df) :\")\n",
    "        print(base_finale_df.head())\n",
    "        base_finale_df.to_csv(\"C://Users//msamb//Documents//base_finale_sirenise_2021.csv\", sep=';', encoding='utf-8-sig', index=False)\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"ERREUR CRITIQUE : Un ou plusieurs fichiers d'entrée sont introuvables. Vérifiez les chemins dans la 'Configuration'.\")\n",
    "    except KeyError as e:\n",
    "        print(f\"ERREUR DE COLONNE (KeyError) : {e}. Vérifiez les noms de colonnes dans vos fichiers et la configuration.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Une erreur inattendue est survenue : {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# --- Point d'Entrée du Script ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Ce code est exécuté lorsque vous lancez le script directement.\n",
    "    \n",
    "    # Exécuter le processus principal de sirénisation.\n",
    "    # Assurez-vous d'avoir bien configuré les chemins et noms de colonnes\n",
    "    # dans la section 'Configuration' de la fonction 'processus_principal_sirenisation'.\n",
    "    processus_principal_sirenisation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "649f3829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de SIREN dans base_finale_sirenise_2021.csv : 4543\n",
      "Nombre de SIREN présents dans cir2021prov : 485\n",
      "Nombre de SIREN absents dans cir2021prov : 4058\n",
      "\n",
      "Statistiques des différences cretot_gen (base_2021 - cir2021prov) :\n",
      "Nombre de différences calculées : 485\n",
      "Différence moyenne : -123942.93\n",
      "Différence médiane : 11622.66\n",
      "Différence min : -10216618.00\n",
      "Différence max : 9607203.76\n",
      "Nombre de différences nulles (identiques) : 28\n",
      "Nombre de différences positives : 273\n",
      "Nombre de différences négatives : 184\n",
      "\n",
      "Exemples de SIREN absents dans cir2021prov :\n",
      "0    006720049\n",
      "2    340012392\n",
      "3    343266854\n",
      "4    409108115\n",
      "5    383960135\n",
      "Name: SIREN_DECLARANT_STD, dtype: object\n",
      "\n",
      "Exemples de différences calculées :\n",
      "   SIREN_DECLARANT_STD  cretot_gen  cretot_gen_cir2021prov  \\\n",
      "1            356000000   585721.16               1107030.0   \n",
      "7            421100645   183715.43                129644.0   \n",
      "9            424335693   224474.48                250784.0   \n",
      "44           320217144  1223501.90               1570709.0   \n",
      "45           314704057   384220.88                380276.0   \n",
      "\n",
      "   difference_cretot_gen  \n",
      "1             -521308.84  \n",
      "7               54071.43  \n",
      "9              -26309.52  \n",
      "44             -347207.1  \n",
      "45               3944.88  \n",
      "\n",
      "Fichier sauvegardé avec la colonne 'difference_cretot_gen'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger les deux fichiers\n",
    "df_base_final = pd.read_csv(\"C://Users//msamb//Documents//base_finale_sirenise_2021.csv\", sep=';', encoding='utf-8-sig')\n",
    "df_cir2021prov = pd.read_excel(\"M://str-dgri-gecir-donnees-fiscales//z_Statistiques Séries Demandes//2021//0_BASE_CIR2021prov_extr202306.xlsx\")\n",
    "\n",
    "# Standardiser les SIREN dans les deux fichiers (en string, 9 chiffres)\n",
    "df_base_final['SIREN_DECLARANT_STD'] = df_base_final['SIREN_DECLARANT'].astype(str).str.replace(r'\\D', '', regex=True).str.zfill(9)\n",
    "df_cir2021prov['SIREN_DECLARANT_STD'] = df_cir2021prov['siren'].astype(str).str.replace(r'\\D', '', regex=True).str.zfill(9)\n",
    "\n",
    "# Vérifier la présence des SIREN de base_final dans cir2021prov\n",
    "siren_cir2021prov = set(df_cir2021prov['SIREN_DECLARANT_STD'])\n",
    "df_base_final['present_dans_cir2021prov'] = df_base_final['SIREN_DECLARANT_STD'].isin(siren_cir2021prov)\n",
    "\n",
    "# Faire un left join pour récupérer les valeurs de cretot_gen du fichier cir2021prov\n",
    "df_merged = df_base_final.merge(\n",
    "    df_cir2021prov[['SIREN_DECLARANT_STD', 'cretot_gen']], \n",
    "    on='SIREN_DECLARANT_STD', \n",
    "    how='left', \n",
    "    suffixes=('', '_cir2021prov')\n",
    ")\n",
    "\n",
    "# Calculer la différence cretot_gen (base 2021) - cretot_gen (cir2021prov)\n",
    "# Seulement pour les SIREN présents dans les deux fichiers\n",
    "df_merged['difference_cretot_gen'] = None  # Initialiser avec None\n",
    "mask_present = df_merged['present_dans_cir2021prov'] == True\n",
    "\n",
    "# Calculer la différence seulement pour les lignes où les deux valeurs existent\n",
    "df_merged.loc[mask_present, 'difference_cretot_gen'] = (\n",
    "    df_merged.loc[mask_present, 'cretot_gen'] - \n",
    "    df_merged.loc[mask_present, 'cretot_gen_cir2021prov']\n",
    ")\n",
    "\n",
    "# Statistiques\n",
    "nb_total = len(df_merged)\n",
    "nb_present = df_merged['present_dans_cir2021prov'].sum()\n",
    "nb_absent = nb_total - nb_present\n",
    "\n",
    "print(f\"Nombre total de SIREN dans base_finale_sirenise_2021.csv : {nb_total}\")\n",
    "print(f\"Nombre de SIREN présents dans cir2021prov : {nb_present}\")\n",
    "print(f\"Nombre de SIREN absents dans cir2021prov : {nb_absent}\")\n",
    "\n",
    "# Statistiques sur les différences\n",
    "if nb_present > 0:\n",
    "    differences = df_merged.loc[mask_present, 'difference_cretot_gen'].dropna()\n",
    "    if len(differences) > 0:\n",
    "        print(f\"\\nStatistiques des différences cretot_gen (base_2021 - cir2021prov) :\")\n",
    "        print(f\"Nombre de différences calculées : {len(differences)}\")\n",
    "        print(f\"Différence moyenne : {differences.mean():.2f}\")\n",
    "        print(f\"Différence médiane : {differences.median():.2f}\")\n",
    "        print(f\"Différence min : {differences.min():.2f}\")\n",
    "        print(f\"Différence max : {differences.max():.2f}\")\n",
    "        print(f\"Nombre de différences nulles (identiques) : {(differences == 0).sum()}\")\n",
    "        print(f\"Nombre de différences positives : {(differences > 0).sum()}\")\n",
    "        print(f\"Nombre de différences négatives : {(differences < 0).sum()}\")\n",
    "\n",
    "# Afficher quelques exemples absents\n",
    "if nb_absent > 0:\n",
    "    print(\"\\nExemples de SIREN absents dans cir2021prov :\")\n",
    "    print(df_merged.loc[~df_merged['present_dans_cir2021prov'], 'SIREN_DECLARANT_STD'].head())\n",
    "\n",
    "# Afficher quelques exemples de différences\n",
    "if nb_present > 0:\n",
    "    print(\"\\nExemples de différences calculées :\")\n",
    "    exemples = df_merged.loc[mask_present, ['SIREN_DECLARANT_STD', 'cretot_gen', 'cretot_gen_cir2021prov', 'difference_cretot_gen']].head()\n",
    "    print(exemples)\n",
    "\n",
    "# Sauvegarder le résultat avec la nouvelle colonne\n",
    "df_merged.to_csv(\"C://Users//msamb//Documents//base_finale_sirenise_2021_verif_cir2021prov_avec_diff.csv\", sep=';', encoding='utf-8-sig', index=False)\n",
    "\n",
    "print(f\"\\nFichier sauvegardé avec la colonne 'difference_cretot_gen'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ed62b1",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50eac9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRANSFORMATION VERS FORMAT CIBLE\n",
      "==================================================\n",
      "Chargement : C://Users//msamb//Documents//base_finale_sirenise_2021.csv\n",
      "   4,543 lignes chargees\n",
      "Chargement complement : C://Users//msamb//Documents//new_millesime_CIR_2021-suite_corrected_sans_doublon.xlsx\n",
      "   Jointure effectuee - 4 colonnes recuperees\n",
      "Mapping des colonnes...\n",
      "Creation du dataframe final...\n",
      "Sauvegarde : C://Users//msamb//Documents//base_final_2021_suite_final.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\49172490.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[colonne] = mapping_complet[colonne]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RESULTATS:\n",
      "   Lignes creees: 4,619\n",
      "   Colonnes totales: 157\n",
      "ERREUR: name 'total_cols_100' is not defined\n",
      "Verifiez le chemin et le format de votre fichier\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def transformer_vers_format_cible(fichier_principal, fichier_complement=None, fichier_sortie=\"fichier_format_cible.csv\"):\n",
    "    \"\"\"\n",
    "    Transforme le fichier CIR vers le format cible exact\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"TRANSFORMATION VERS FORMAT CIBLE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. Ordre exact des colonnes demande\n",
    "    COLONNES_CIBLE = [\n",
    "        'siren', 'nom', 'siren_g', 'nom_g', 'type', 'caht', 'trannee', 'treff_benef', \n",
    "        'effectif', 'ch_tech', 'nb_jd', 'categorie', 'cat_jur', 'ape', 'sa_decl', \n",
    "        'ind_serv', 'cp', 'commune', 'dpt', 'old_region', 'region', 'pays_siege', \n",
    "        'deprd_decl', 'deprd_declom', 'depcoll_decl', 'depcoll_declom', 'depinno_decl', \n",
    "        'depinno_declom', 'deptot_decl', 'deptot_declom', 'deprd_benef', 'depcoll_benef', \n",
    "        'depinno_benef', 'deptot_benef', 'crerd_gen', 'crerd_genom', 'crecoll_gen', \n",
    "        'crecoll_genom', 'creinno_gen', 'creinno_genom', 'cretot_gen', 'cretot_genom', \n",
    "        'cirrech_benef', 'cic_benef', 'cii_benef', 'cirtot_benef', '_1', '_2', '_3', \n",
    "        '_4', '_5', '_6', '_7', '_8', '_9', '_10', '_11', '_12', '_13', '_14', '_15a', \n",
    "        '_15b', '_16a', '_16b', '_17', '_18a', '_18b', '_19a', '_19b', '_20', '_21', \n",
    "        '_22', '_23', '_24', '_25', '_26', '_27', '_28a', '_28b', '_29', '_30', '_31a', \n",
    "        '_31b', '_32', '_33', '_34', '_35', '_36', '_37', '_38a', '_38b', '_39a', \n",
    "        '_39b', '_40a', '_40b', '_41', '_42', '_43a', '_43b', '_44a', '_44b', '_45', \n",
    "        '_46', '_47a', '_47b', '_48', '_49', '_50a', '_50b', '_51a', '_51b', '_52a', \n",
    "        '_52b', '_53', '_54', '_55', '_56', '_57', '_58a', '_58b', '_59a', '_59b', \n",
    "        '_60', '_61', '_62', '_63', '_64', '_65', '_66', '_67', '_68a', '_68b', \n",
    "        '_69a', '_69b', '_70', '_71', '_72', '_73', '_74', '_75', '_76', '_77', \n",
    "        '_78', '_79', '_80', '_81', '_82a', '_82b', '_82c', '_82d', '_83', '_84', \n",
    "        '_85a', '_85b', '_85c', '_86a', '_86b'\n",
    "    ]\n",
    "    \n",
    "    # 2. Chargement du fichier principal\n",
    "    print(f\"Chargement : {fichier_principal}\")\n",
    "    df = pd.read_csv(fichier_principal, sep=';', encoding='utf-8-sig')\n",
    "    print(f\"   {len(df):,} lignes chargees\")\n",
    "    \n",
    "    # 3. Jointure avec fichier complement (si fourni)\n",
    "    if fichier_complement:\n",
    "        print(f\"Chargement complement : {fichier_complement}\")\n",
    "        try:\n",
    "            df_comp = pd.read_excel(fichier_complement)\n",
    "            # Standardiser les SIREN pour la jointure\n",
    "            df_comp['SIREN_STD'] = df_comp['siren_declarant'].astype(str).str.zfill(9)\n",
    "            df['SIREN_STD'] = df['SIREN_DECLARANT'].astype(str).str.zfill(9)\n",
    "            \n",
    "            # Selectionner les colonnes utiles du complement\n",
    "            colonnes_utiles = ['SIREN_STD', 'CAHT', 'NB_JD', 'NBR_CHERCH_TECH', 'NATUR_ESE']\n",
    "            colonnes_disponibles = [col for col in colonnes_utiles if col in df_comp.columns]\n",
    "            \n",
    "            df = df.merge(df_comp[colonnes_disponibles], on='SIREN_STD', how='left', suffixes=('', '_comp'))\n",
    "            print(f\"   Jointure effectuee - {len(colonnes_disponibles)-1} colonnes recuperees\")\n",
    "        except Exception as e:\n",
    "            print(f\"   Erreur jointure: {e}, continuation sans complement\")\n",
    "    \n",
    "    # 4. Fonctions utilitaires\n",
    "    def get_col_calcule(base_name):\n",
    "        \"\"\"Retourne la colonne CALCULE si elle existe, sinon DECLARE, sinon NaN\"\"\"\n",
    "        calcule = f\"{base_name}_CALCULE\"\n",
    "        declare = f\"{base_name}_DECLARE\"\n",
    "        if calcule in df.columns:\n",
    "            return df[calcule]\n",
    "        elif declare in df.columns:\n",
    "            return df[declare]\n",
    "        else:\n",
    "            return np.nan\n",
    "    \n",
    "    def get_col_safe(col_name):\n",
    "        \"\"\"Retourne la colonne si elle existe, sinon NaN\"\"\"\n",
    "        return df[col_name] if col_name in df.columns else np.nan\n",
    "    \n",
    "    # 5. Mapping des colonnes\n",
    "    print(\"Mapping des colonnes...\")\n",
    "    \n",
    "    # Mapping pour toutes les colonnes\n",
    "    mapping_complet = {\n",
    "        # Colonnes principales\n",
    "        'siren': get_col_safe('SIREN_DECLARANT'),\n",
    "        'nom': get_col_safe('DESIGNATION'),\n",
    "        'siren_g': get_col_safe('SIREN_DEPOSANT'),\n",
    "        'nom_g': get_col_safe('denominationUniteLegale'),\n",
    "        'type': get_col_safe('type_final'),\n",
    "        'caht': get_col_safe('CAHT'),  # Depuis le fichier complement\n",
    "        'trannee': get_col_safe('dateCreationUniteLegale'),\n",
    "        'treff_benef': get_col_safe('treff_benef'),\n",
    "        'effectif': get_col_safe('trancheEffectifsUniteLegale'),\n",
    "        'ch_tech': get_col_safe('NBR_CHERCH_TECH'),  # Depuis le fichier complement\n",
    "        'nb_jd': get_col_safe('NB_JD'),  # Depuis le fichier complement\n",
    "        'categorie': get_col_safe('categorieEntreprise'),\n",
    "        'cat_jur': get_col_safe('NATUR_ESE'),  # Depuis le fichier complement\n",
    "        'ape': get_col_safe('activitePrincipaleUniteLegale'),\n",
    "        'sa_decl': get_col_safe('secteur_dactivit'),\n",
    "        'ind_serv': np.nan,\n",
    "        'cp': np.nan,\n",
    "        'commune': np.nan,\n",
    "        'dpt': np.nan,\n",
    "        'old_region': np.nan,\n",
    "        'region': np.nan,\n",
    "        'pays_siege': 'FR',\n",
    "        'deprd_decl': np.nan,\n",
    "        'deprd_declom': np.nan,\n",
    "        'depcoll_decl': np.nan,\n",
    "        'depcoll_declom': np.nan,\n",
    "        'depinno_decl': np.nan,\n",
    "        'depinno_declom': np.nan,\n",
    "        'deptot_decl': np.nan,\n",
    "        'deptot_declom': np.nan,\n",
    "        'deprd_benef': get_col_safe('deprd_benef'),\n",
    "        'depcoll_benef': get_col_safe('depcoll_benef'),\n",
    "        'depinno_benef': get_col_safe('depinno_benef'),\n",
    "        'deptot_benef': get_col_safe('deptot_benef'),\n",
    "        'crerd_gen': get_col_safe('crerd_gen'),\n",
    "        'crerd_genom': get_col_safe('crerd_genom'),\n",
    "        'crecoll_gen': get_col_safe('crecoll_gen'),\n",
    "        'crecoll_genom': get_col_safe('crecoll_genom'),\n",
    "        'creinno_gen': get_col_safe('creinno_gen'),\n",
    "        'creinno_genom': get_col_safe('creinno_genom'),\n",
    "        'cretot_gen': get_col_safe('cretot_gen'),\n",
    "        'cretot_genom': get_col_safe('cretot_genom'),\n",
    "        'cirrech_benef': get_col_safe('cirrech_benef'),\n",
    "        'cic_benef': get_col_safe('cic_benef'),\n",
    "        'cii_benef': get_col_safe('cii_benef'),\n",
    "        'cirtot_benef': get_col_safe('cirtot_benef'),\n",
    "        \n",
    "        # Lignes formulaire - Priorite aux colonnes CALCULE\n",
    "        '_1': get_col_safe('L1_DOTATION_AMORT_IMMO'),\n",
    "        '_2': get_col_safe('L2_DOTATION_AMORT_SINISTR'),\n",
    "        '_3': get_col_safe('L3_DEPENSES_PERSONNEL_CHERCHEURS'),\n",
    "        '_4': get_col_safe('L4_REMUNERATION_INVENTEURS'),\n",
    "        '_5': get_col_safe('L5_DEPENSES_JEUNES_DOCTEURS'),\n",
    "        '_6': get_col_calcule('L6_AUTRES_DEP_FONCT'),\n",
    "        '_7': get_col_calcule('L7_TOTAL_DEP_FONCT'),\n",
    "        '_8': get_col_safe('L8_FRAIS_BREVETS_COV'),\n",
    "        '_9': get_col_safe('L9_DEPENSES_DEFENSE_BREVETS'),\n",
    "        '_10': get_col_safe('L10_DOTATION_AMORT_BREVETS'),\n",
    "        '_11': get_col_safe('L11_DEPENSES_NORMALISATION'),\n",
    "        '_12': get_col_safe('L12_PRIMES_COTISATIONS_BRUT'),\n",
    "        '_13': get_col_safe('L13_VEILLE_TECHNO_BRUT'),\n",
    "        '_14': get_col_calcule('L14_TOTAL_DEPENSES_INTERNES'),\n",
    "        '_15a': get_col_safe('L15A_ST_PUB_LIES_FR'),\n",
    "        '_15b': get_col_safe('L15B_ST_PUB_LIES_ETR'),\n",
    "        '_16a': get_col_safe('L16A_ST_PUB_NON_LIES_FR'),\n",
    "        '_16b': get_col_safe('L16B_ST_PUB_NON_LIES_ETR'),\n",
    "        '_17': get_col_calcule('L17_TOTAL_ST_PUBLIQUE'),\n",
    "        '_18a': get_col_safe('L18A_ST_PRIV_LIES_FR'),\n",
    "        '_18b': get_col_safe('L18B_ST_PRIV_LIES_ETR'),\n",
    "        '_19a': get_col_safe('L19A_ST_PRIV_NON_LIES_FR'),\n",
    "        '_19b': get_col_safe('L19B_ST_PRIV_NON_LIES_ETR'),\n",
    "        '_20': get_col_calcule('L20_TOTAL_ST_PRIVEE'),\n",
    "        '_21': get_col_calcule('L21_PLAFOND_ST_PRIVEE'),\n",
    "        '_22': get_col_calcule('L22_TOTAL_ST'),\n",
    "        '_23': get_col_calcule('L23_PLAFOND_ORGANISMES_LIES'),\n",
    "        '_24': get_col_calcule('L24_PLAFOND_ORG_NON_LIES'),\n",
    "        '_25': get_col_calcule('L25_PLAFOND_GENERAL'),\n",
    "        '_26': get_col_calcule('L26_TOTAL_ST_PLAFONNE'),\n",
    "        '_27': get_col_calcule('L27_TOTAL_DEPENSES_RECHERCHE'),\n",
    "        '_28a': get_col_safe('L28A_SUBVENTIONS'),\n",
    "        '_28b': get_col_safe('L28B_SOMMES_ENCAISSEES_TIERS'),\n",
    "        '_29': get_col_safe('L29_DEPENSES_CONSEIL_CIR'),\n",
    "        '_30': get_col_safe('L30_REMBOURSEMENTS_SUBVENTIONS'),\n",
    "        '_31a': get_col_calcule('L31A_MONTANT_NET_DEPENSES'),\n",
    "        '_31b': get_col_calcule('L31B_MONTANT_NET_DEPENSES_DOM'),\n",
    "        '_32': get_col_safe('L32_FRAIS_COLLECTION'),\n",
    "        '_33': get_col_safe('L33_FRAIS_DEFENSE_DESSINS_BRUT'),\n",
    "        '_34': get_col_calcule('L34_TOTAL_DEPENSES_COLLECTION'),\n",
    "        '_35': get_col_safe('L35_SUBVENTIONS_COLLECTION'),\n",
    "        '_36': get_col_safe('L36_DEPENSES_CONSEIL_COLLECTION'),\n",
    "        '_37': get_col_safe('L37_REMBOURSEMENTS_SUBVENTIONS_COLL'),\n",
    "        '_38a': get_col_calcule('L38A_MONTANT_NET_COLLECTION'),\n",
    "        '_38b': get_col_calcule('L38B_MONTANT_NET_COLLECTION_DOM'),\n",
    "        '_39a': get_col_safe('L39A_MONTANT_NET_TOTAL_RD_COLL'),\n",
    "        '_39b': get_col_safe('L39B_MONTANT_NET_TOTAL_RD_COLL_DOM'),\n",
    "        '_40a': get_col_calcule('L31A_MONTANT_NET_DEPENSES'),\n",
    "        '_40b': get_col_calcule('L31B_MONTANT_NET_DEPENSES_DOM'),\n",
    "        '_41': get_col_safe('L41_CREDIT_IMPOT_RECHERCHE_MOINS_100M'),\n",
    "        '_42': get_col_safe('L42_QUOTE_PART_RECHERCHE_SOC_PERSONNES'),\n",
    "        '_43a': get_col_calcule('L43A_CREDIT_IMPOT_RECHERCHE_TOTAL'),\n",
    "        '_43b': get_col_safe('L43B_CREDIT_IMPOT_RECHERCHE_DOM'),\n",
    "        '_44a': get_col_calcule('L38A_MONTANT_NET_COLLECTION'),\n",
    "        '_44b': get_col_calcule('L38B_MONTANT_NET_COLLECTION_DOM'),\n",
    "        '_45': get_col_safe('L45_CREDIT_IMPOT_COLLECTION_MOINS_100M'),\n",
    "        '_46': get_col_safe('L46_QUOTE_PART_COLLECTION_SOC_PERSONNES'),\n",
    "        '_47a': get_col_calcule('L47A_CREDIT_IMPOT_COLL_AVANT_PLAF'),\n",
    "        '_47b': get_col_safe('L47B_CREDIT_IMPOT_COLL_DOM_AVANT_PLAF'),\n",
    "        '_48': get_col_safe('L48_AIDES_MINIMIS'),\n",
    "        '_49': get_col_safe('L49_CUMUL_CREDIT_IMPOT_ET_AIDES'),\n",
    "        '_50a': get_col_calcule('L50A_CREDIT_IMPOT_COLL_APRES_PLAF'),\n",
    "        '_50b': get_col_safe('L50B_CREDIT_IMPOT_COLL_DOM_APRES_PLAF'),\n",
    "        '_51a': get_col_safe('L51A_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION'),\n",
    "        '_51b': get_col_safe('L51B_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION_DOM'),\n",
    "        '_52a': get_col_safe('L52A_DEPENSES_RECHERCHE_LIMITE_100M'),\n",
    "        '_52b': get_col_safe('L52B_DEPENSES_RECHERCHE_DOM_LIMITE'),\n",
    "        '_53': get_col_safe('L53_CIR_RECHERCHE_PREMIERE_TRANCHE'),\n",
    "        '_54': get_col_safe('L54_DEPENSES_RECHERCHE_SUP_100M'),\n",
    "        '_55': get_col_safe('L55_CIR_RECHERCHE_DEUXIEME_TRANCHE'),\n",
    "        '_56': get_col_safe('L56_CIR_RECHERCHE_PLUS_100M'),\n",
    "        '_57': get_col_safe('L57_QUOTE_PART_RECHERCHE_SOC_PERSONNES_PLUS_100M'),\n",
    "        '_58a': get_col_calcule('L58A_CREDIT_IMPOT_RECHERCHE_TOTAL_PLUS_100M'),\n",
    "        '_58b': get_col_safe('L58B_CREDIT_IMPOT_RECHERCHE_DOM_PLUS_100M'),\n",
    "        '_59a': get_col_safe('L59A_MONTANT_NET_COLLECTION_PLUS_100M'),\n",
    "        '_59b': get_col_safe('L59B_MONTANT_NET_COLLECTION_DOM_PLUS_100M'),\n",
    "        '_60': get_col_safe('L60_PLAFOND_DISPO_COLLECTION'),\n",
    "        '_61': get_col_safe('L61_CIR_COLLECTION_PREMIERE_TRANCHE'),\n",
    "        '_62': get_col_safe('L62_CIR_COLLECTION_DEUXIEME_TRANCHE'),\n",
    "        '_63': get_col_safe('L63_CIR_COLLECTION_PLUS_100M'),\n",
    "        '_64': get_col_safe('L64_QUOTE_PART_COLLECTION_SOC_PERSONNES_PLUS_100M'),\n",
    "        '_65': get_col_safe('L65_CREDIT_IMPOT_COLL_AVANT_PLAF_PLUS_100M'),\n",
    "        '_66': get_col_safe('L66_AIDES_MINIMIS_PLUS_100M'),\n",
    "        '_67': get_col_safe('L67_CUMUL_CREDIT_IMPOT_ET_AIDES_PLUS_100M'),\n",
    "        '_68a': get_col_calcule('L68A_CREDIT_IMPOT_COLL_APRES_PLAF_PLUS_100M'),\n",
    "        '_68b': get_col_safe('L68B_CREDIT_IMPOT_COLL_DOM_APRES_PLAF_PLUS_100M'),\n",
    "        '_69a': get_col_safe('L69A_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION_PLUS_100M'),\n",
    "        '_69b': get_col_safe('L69B_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION_DOM_PLUS_100M'),\n",
    "        '_70': get_col_safe('L70_DOTATION_AMORT_IMMO_INNOVATION'),\n",
    "        '_71': get_col_safe('L71_DEPENSES_PERSONNEL_INNOVATION'),\n",
    "        '_72': get_col_safe('L72_AUTRES_DEPENSES_FONCT_INNOVATION'),\n",
    "        '_73': get_col_safe('L73_FRAIS_BREVETS_INNOVATION'),\n",
    "        '_74': get_col_safe('L74_FRAIS_DEFENSE_BREVETS_INNOVATION'),\n",
    "        '_75': get_col_safe('L75_OPERATIONS_CONFIEES_INNOVATION'),\n",
    "        '_76': get_col_calcule('L76_TOTAL_DEPENSES_INNOVATION'),\n",
    "        '_77': get_col_calcule('L77_DEPENSES_INNOVATION_PLAFONNEES'),\n",
    "        '_78': get_col_safe('L78_SUBVENTIONS_INNOVATION'),\n",
    "        '_79': get_col_safe('L79_PRESTATIONS_INNOVATION'),\n",
    "        '_80': get_col_safe('L80_DEPENSES_CONSEIL_INNOVATION'),\n",
    "        '_81': get_col_safe('L81_REMBOURSEMENTS_SUBVENTIONS_INNO'),\n",
    "        '_82a': get_col_calcule('L82A_MONTANT_NET_INNOVATION'),\n",
    "        '_82b': get_col_safe('L82B_MONTANT_NET_INNOVATION_DOM'),\n",
    "        '_82c': get_col_safe('L82C_MONTANT_NET_INNOVATION_CORSE_MPE'),\n",
    "        '_82d': get_col_safe('L82D_MONTANT_NET_INNOVATION_CORSE_ME'),\n",
    "        '_83': get_col_safe('L83_CREDIT_IMPOT_INNOVATION'),\n",
    "        '_84': get_col_safe('L84_QUOTE_PART_INNOVATION_SOC_PERSONNES'),\n",
    "        '_85a': get_col_calcule('L85A_TOTAL_CREDIT_IMPOT_INNOVATION'),\n",
    "        '_85b': get_col_safe('L85B_CREDIT_IMPOT_INNOVATION_DOM'),\n",
    "        '_85c': get_col_safe('L85C_CREDIT_IMPOT_INNOVATION_CORSE'),\n",
    "        '_86a': get_col_safe('L86A_TOTAL_CIR_RECH_COLL_INNO'),\n",
    "        '_86b': get_col_safe('L86B_TOTAL_CIR_RECH_COLL_INNO_DOM')\n",
    "    }\n",
    "    \n",
    "    # 6. Creation du dataframe final dans l'ordre exact\n",
    "    print(\"Creation du dataframe final...\")\n",
    "    df_final = pd.DataFrame()\n",
    "    \n",
    "    for colonne in COLONNES_CIBLE:\n",
    "        df_final[colonne] = mapping_complet[colonne]\n",
    "    \n",
    "    # 7. Sauvegarde\n",
    "    print(f\"Sauvegarde : {fichier_sortie}\")\n",
    "    df_final.to_csv(fichier_sortie, sep=';', index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    # 8. Statistiques\n",
    "    total_cols = len(df_final.columns)\n",
    "    cols_avec_donnees = df_final.notna().any().sum()\n",
    "    \n",
    "    print(f\"\\nRESULTATS:\")\n",
    "    print(f\"   Lignes creees: {len(df_final):,}\")\n",
    "    print(f\"   Colonnes totales: {total_cols}\")\n",
    "    print(f\"   Colonnes avec donnees: {cols_avec_donnees}/{total_cols} ({cols_avec_donnees/total_cols_100:.1f}%)\")\n",
    "    print(f\"   Colonnes vides: {total_cols - cols_avec_donnees}\")\n",
    "    \n",
    "    # Detail des colonnes recuperees du complement\n",
    "    if fichier_complement:\n",
    "        colonnes_complement = ['caht', 'nb_jd', 'ch_tech', 'cat_jur']\n",
    "        cols_complement_remplies = sum(1 for col in colonnes_complement if df_final[col].notna().any())\n",
    "        print(f\"   Colonnes complement remplies: {cols_complement_remplies}/4\")\n",
    "    \n",
    "    print(f\"\\nTRANSFORMATION TERMINEE\")\n",
    "    print(f\"Fichier cree: {fichier_sortie}\")\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "# Script principal\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Parametres a modifier\n",
    "    FICHIER_PRINCIPAL = \"C://Users//msamb//Documents//base_finale_sirenise_2021.csv\"  # Remplacez par votre fichier\n",
    "    FICHIER_COMPLEMENT = \"C://Users//msamb//Documents//new_millesime_CIR_2021-suite_corrected_sans_doublon.xlsx\"  # Fichier complement\n",
    "    FICHIER_SORTIE = \"C://Users//msamb//Documents//base_final_2021_suite_final.csv\"  # Nom du fichier de sortie\n",
    "    \n",
    "    # Verification\n",
    "    if not os.path.exists(FICHIER_PRINCIPAL):\n",
    "        print(f\"ERREUR: Fichier principal non trouve: {FICHIER_PRINCIPAL}\")\n",
    "        print(\"Modifiez la variable FICHIER_PRINCIPAL avec le bon chemin\")\n",
    "        exit(1)\n",
    "    \n",
    "    if FICHIER_COMPLEMENT and not os.path.exists(FICHIER_COMPLEMENT):\n",
    "        print(f\"ATTENTION: Fichier complement non trouve: {FICHIER_COMPLEMENT}\")\n",
    "        print(\"Les colonnes caht, nb_jd, ch_tech, cat_jur resteront vides\")\n",
    "        FICHIER_COMPLEMENT = None\n",
    "    \n",
    "    # Transformation\n",
    "    try:\n",
    "        resultat = transformer_vers_format_cible(\n",
    "            fichier_principal=FICHIER_PRINCIPAL,\n",
    "            fichier_complement=FICHIER_COMPLEMENT,\n",
    "            fichier_sortie=FICHIER_SORTIE\n",
    "        )\n",
    "        \n",
    "        # Verification de l'ordre des colonnes\n",
    "        print(f\"\\nVERIFICATION:\")\n",
    "        print(f\"Nombre de colonnes: {len(resultat.columns)}\")\n",
    "        print(f\"Premieres colonnes: {list(resultat.columns[:10])}\")\n",
    "        print(f\"Dernieres colonnes: {list(resultat.columns[-5:])}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERREUR: {e}\")\n",
    "        print(\"Verifiez le chemin et le format de votre fichier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35384120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEMARRAGE DU PROCESSUS DE COMPLETION\n",
      "==================================================\n",
      "Transformations qui seront appliquées:\n",
      "- trannee: dates -> tranches simplifiées (ex: 'avant 1980', 'de 1980 à 1989'...)\n",
      "- treff_benef: codes -> libellés (ex: '41' -> '500 à 999 salariés')\n",
      "- cat_jur: codes -> libellés (ex: 5710 -> 'SAS')\n",
      "- dpt: codes -> noms (ex: 75 -> 'Paris')\n",
      "- old_region: ancienne région administrative\n",
      "- region: nouvelle région (réforme 2016)\n",
      "- pays_siege: 'FRANCE' par défaut\n",
      "==================================================\n",
      "COMPLETION DU FICHIER CIBLE AVEC STOCK SIRENE\n",
      "============================================================\n",
      "Chargement du fichier cible : C://Users//msamb//Documents//base_final_2021_suite_final.csv\n",
      "   4,619 lignes chargees\n",
      "Chargement du fichier StockUniteLegale : C://Users//msamb//Documents//StockUniteLegale_utf8.csv\n",
      "   28,236,992 unites legales chargees\n",
      "Preparation des donnees pour jointure...\n",
      "Jointure pour les SIREN principaux...\n",
      "Jointure pour les SIREN groupes...\n",
      "\n",
      "Chargement des donnees geographiques...\n",
      "Chargement du fichier StockEtablissement : C://Users//msamb//Documents//StockEtablissement_utf8.csv\n",
      "   1,937 etablissements sieges charges\n",
      "Completion et transformation des colonnes...\n",
      "   Transformation des tranches d'effectifs...\n",
      "   Transformation des dates de création en tranches d'années...\n",
      "   Transformation des catégories juridiques...\n",
      "   Completion des donnees geographiques...\n",
      "   Ajout des régions (anciennes et nouvelles)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\631115534.py:944: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['20 à 49 salariés' '10000 salariés et plus' '200 à 249 salariés' ...\n",
      " '50 à 99 salariés' '1 ou 2 salariés' nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_final.loc[mask_vide, colonne_cible] = df_final.loc[mask_vide, colonne_source]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\631115534.py:944: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['60370' '75015' '92130' ... '75009' nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_final.loc[mask_vide, colonne_cible] = df_final.loc[mask_vide, colonne_source]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\631115534.py:944: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['HERMES' 'PARIS' 'ISSY-LES-MOULINEAUX' ... 'PARIS' nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_final.loc[mask_vide, colonne_cible] = df_final.loc[mask_vide, colonne_source]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\631115534.py:944: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Oise' 'Paris' 'Hauts-de-Seine' ... 'Paris' nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_final.loc[mask_vide, colonne_cible] = df_final.loc[mask_vide, colonne_source]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\631115534.py:944: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['PICARDIE' 'ILE-DE-FRANCE' 'ILE-DE-FRANCE' ... 'ILE-DE-FRANCE' nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_final.loc[mask_vide, colonne_cible] = df_final.loc[mask_vide, colonne_source]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_16792\\631115534.py:944: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['HAUTS-DE-FRANCE' 'ILE-DE-FRANCE' 'ILE-DE-FRANCE' ... 'ILE-DE-FRANCE' nan\n",
      " nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_final.loc[mask_vide, colonne_cible] = df_final.loc[mask_vide, colonne_source]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistiques de completion:\n",
      "   nom: 3161 -> 4510 (+1349)\n",
      "   treff_benef: 0 -> 3020 (+3020)\n",
      "   trannee: 4619 -> 4619 (+0)\n",
      "   cat_jur: 396 -> 4619 (+4223)\n",
      "   nom_g: 4470 -> 4470 (+0)\n",
      "   cp: 0 -> 1982 (+1982)\n",
      "   commune: 0 -> 1982 (+1982)\n",
      "   dpt: 0 -> 1982 (+1982)\n",
      "   old_region: 0 -> 1972 (+1972)\n",
      "   region: 0 -> 1972 (+1972)\n",
      "   pays_siege: 4619 -> 4619 (+0)\n",
      "\n",
      "Sauvegarde : C://Users//msamb//Documents//base_final_2021_suite_final_complet_stock.csv\n",
      "\n",
      "COMPLETION TERMINEE\n",
      "Fichier sauvegarde : C://Users//msamb//Documents//base_final_2021_suite_final_complet_stock.csv\n",
      "\n",
      "VERIFICATION QUALITE:\n",
      "------------------------------\n",
      "   nom: 4510/4619 (97.6%)\n",
      "   treff_benef: 3020/4619 (65.4%)\n",
      "   trannee: 4619/4619 (100.0%)\n",
      "   cat_jur: 4619/4619 (100.0%)\n",
      "   nom_g: 4470/4619 (96.8%)\n",
      "   cp: 1982/4619 (42.9%)\n",
      "   commune: 1982/4619 (42.9%)\n",
      "   dpt: 1982/4619 (42.9%)\n",
      "   old_region: 1972/4619 (42.7%)\n",
      "   region: 1972/4619 (42.7%)\n",
      "   pays_siege: 4619/4619 (100.0%)\n",
      "\n",
      "Exemples de transformations:\n",
      "------------------------------\n",
      "\n",
      "Tranches d'années (simplifiées):\n",
      "trannee\n",
      "01/01/1900    51\n",
      "01/01/1949     1\n",
      "01/01/1954    15\n",
      "01/01/1955    14\n",
      "01/01/1956    18\n",
      "              ..\n",
      "31/12/1989     1\n",
      "31/12/1990     1\n",
      "31/12/1998     1\n",
      "31/12/2010     3\n",
      "31/12/2015     1\n",
      "Name: count, Length: 2642, dtype: int64\n",
      "\n",
      "Tranches d'effectifs:\n",
      "treff_benef\n",
      "1 ou 2 salariés           503\n",
      "20 à 49 salariés          449\n",
      "3 à 5 salariés            400\n",
      "10 à 19 salariés          359\n",
      "50 à 99 salariés          321\n",
      "100 à 199 salariés        264\n",
      "6 à 9 salariés            261\n",
      "250 à 499 salariés        117\n",
      "Unités non employeuses     94\n",
      "0 salarié                  75\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Catégories juridiques (Top 10):\n",
      "cat_jur\n",
      "SAS                                             2619\n",
      "SARL                                             850\n",
      "AUT                                              316\n",
      "Entrepreneur individuel                          158\n",
      "SA à conseil d'administration                    134\n",
      "Autre établissement public administratif         116\n",
      "LIE                                               71\n",
      "Société européenne                                57\n",
      "Autre personne morale de droit administratif      48\n",
      "Association déclarée                              39\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Régions (nouvelles) (Top 10):\n",
      "region\n",
      "ILE-DE-FRANCE                 649\n",
      "AUVERGNE-RHONE-ALPES          199\n",
      "NOUVELLE-AQUITAINE            142\n",
      "GRAND EST                     138\n",
      "HAUTS-DE-FRANCE               130\n",
      "OCCITANIE                     126\n",
      "PAYS DE LA LOIRE              111\n",
      "PROVENCE-ALPES-COTE D'AZUR    106\n",
      "NORMANDIE                      77\n",
      "BRETAGNE                       73\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Départements (Top 10):\n",
      "dpt\n",
      "Hauts-de-Seine      274\n",
      "Paris               183\n",
      "Nord                 65\n",
      "Bouches-du-Rhône     61\n",
      "Isère                59\n",
      "Gironde              56\n",
      "Rhône                55\n",
      "Loire-Atlantique     55\n",
      "Val-de-Marne         44\n",
      "Yvelines             42\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Pays:\n",
      "pays_siege\n",
      "FR    4619\n",
      "Name: count, dtype: int64\n",
      "\n",
      "SIREN non trouves dans StockUniteLegale: 1599\n",
      "Exemples:\n",
      "        siren                                  nom\n",
      "3   343266854                             SOMEPOST\n",
      "6   408900678                        SCI INTELIMMO\n",
      "8   632029302  LA BANQUE POSTALE CONSEIL EN ASSURA\n",
      "12  712034818                            SOFREPOST\n",
      "14  444420780               GEOPOST PARTICIPATIONS\n",
      "\n",
      "APERCU DU RESULTAT:\n",
      "------------------------------\n",
      "\n",
      "Données principales:\n",
      "       siren                              nom             treff_benef     trannee                                  cat_jur\n",
      "0    6720049              BORFLEX SERVICES NS        20 à 49 salariés  01/01/1967                                     SARL\n",
      "1  356000000                         LA POSTE  10000 salariés et plus  01/01/1991  SA nationale à conseil d'administration\n",
      "2  340012392                          GEOPOST      200 à 249 salariés  22/01/1987            SA à conseil d'administration\n",
      "3  343266854                         SOMEPOST                     NaN  24/12/1987                                      SAS\n",
      "4  409108115  SOCIETE DE TRAITEMENT DE PRESSE    1000 à 1999 salariés  01/10/1996                                      SAS\n",
      "\n",
      "Données géographiques:\n",
      "       siren     cp              commune             dpt     old_region           region pays_siege\n",
      "0    6720049  60370               HERMES            Oise       PICARDIE  HAUTS-DE-FRANCE         FR\n",
      "1  356000000  75015                PARIS           Paris  ILE-DE-FRANCE    ILE-DE-FRANCE         FR\n",
      "2  340012392  92130  ISSY-LES-MOULINEAUX  Hauts-de-Seine  ILE-DE-FRANCE    ILE-DE-FRANCE         FR\n",
      "3  343266854  75015                PARIS           Paris  ILE-DE-FRANCE    ILE-DE-FRANCE         FR\n",
      "4  409108115  94270   LE KREMLIN-BICETRE    Val-de-Marne  ILE-DE-FRANCE    ILE-DE-FRANCE         FR\n",
      "\n",
      "Processus termine avec succes.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Dictionnaire des régions par département\n",
    "REGIONS = {\n",
    "    # Auvergne-Rhône-Alpes\n",
    "    '01': ('RHONE-ALPES', 'AUVERGNE-RHONE-ALPES'),\n",
    "    '03': ('AUVERGNE', 'AUVERGNE-RHONE-ALPES'),\n",
    "    '07': ('RHONE-ALPES', 'AUVERGNE-RHONE-ALPES'),\n",
    "    '15': ('AUVERGNE', 'AUVERGNE-RHONE-ALPES'),\n",
    "    '26': ('RHONE-ALPES', 'AUVERGNE-RHONE-ALPES'),\n",
    "    '38': ('RHONE-ALPES', 'AUVERGNE-RHONE-ALPES'),\n",
    "    '42': ('RHONE-ALPES', 'AUVERGNE-RHONE-ALPES'),\n",
    "    '43': ('AUVERGNE', 'AUVERGNE-RHONE-ALPES'),\n",
    "    '63': ('AUVERGNE', 'AUVERGNE-RHONE-ALPES'),\n",
    "    '69': ('RHONE-ALPES', 'AUVERGNE-RHONE-ALPES'),\n",
    "    '73': ('RHONE-ALPES', 'AUVERGNE-RHONE-ALPES'),\n",
    "    '74': ('RHONE-ALPES', 'AUVERGNE-RHONE-ALPES'),\n",
    "    \n",
    "    # Bourgogne-Franche-Comté\n",
    "    '21': ('BOURGOGNE', 'BOURGOGNE-FRANCHE-COMTE'),\n",
    "    '25': ('FRANCHE-COMTE', 'BOURGOGNE-FRANCHE-COMTE'),\n",
    "    '39': ('FRANCHE-COMTE', 'BOURGOGNE-FRANCHE-COMTE'),\n",
    "    '58': ('BOURGOGNE', 'BOURGOGNE-FRANCHE-COMTE'),\n",
    "    '70': ('FRANCHE-COMTE', 'BOURGOGNE-FRANCHE-COMTE'),\n",
    "    '71': ('BOURGOGNE', 'BOURGOGNE-FRANCHE-COMTE'),\n",
    "    '89': ('BOURGOGNE', 'BOURGOGNE-FRANCHE-COMTE'),\n",
    "    '90': ('FRANCHE-COMTE', 'BOURGOGNE-FRANCHE-COMTE'),\n",
    "    \n",
    "    # Bretagne\n",
    "    '22': ('BRETAGNE', 'BRETAGNE'),\n",
    "    '29': ('BRETAGNE', 'BRETAGNE'),\n",
    "    '35': ('BRETAGNE', 'BRETAGNE'),\n",
    "    '56': ('BRETAGNE', 'BRETAGNE'),\n",
    "    \n",
    "    # Centre-Val de Loire\n",
    "    '18': ('CENTRE', 'CENTRE-VAL DE LOIRE'),\n",
    "    '28': ('CENTRE', 'CENTRE-VAL DE LOIRE'),\n",
    "    '36': ('CENTRE', 'CENTRE-VAL DE LOIRE'),\n",
    "    '37': ('CENTRE', 'CENTRE-VAL DE LOIRE'),\n",
    "    '41': ('CENTRE', 'CENTRE-VAL DE LOIRE'),\n",
    "    '45': ('CENTRE', 'CENTRE-VAL DE LOIRE'),\n",
    "    \n",
    "    # Corse\n",
    "    '2A': ('CORSE', 'CORSE'),\n",
    "    '2B': ('CORSE', 'CORSE'),\n",
    "    '20': ('CORSE', 'CORSE'),  # Cas général pour la Corse\n",
    "    \n",
    "    # Grand Est\n",
    "    '08': ('CHAMPAGNE-ARDENNE', 'GRAND EST'),\n",
    "    '10': ('CHAMPAGNE-ARDENNE', 'GRAND EST'),\n",
    "    '51': ('CHAMPAGNE-ARDENNE', 'GRAND EST'),\n",
    "    '52': ('CHAMPAGNE-ARDENNE', 'GRAND EST'),\n",
    "    '54': ('LORRAINE', 'GRAND EST'),\n",
    "    '55': ('LORRAINE', 'GRAND EST'),\n",
    "    '57': ('LORRAINE', 'GRAND EST'),\n",
    "    '67': ('ALSACE', 'GRAND EST'),\n",
    "    '68': ('ALSACE', 'GRAND EST'),\n",
    "    '88': ('LORRAINE', 'GRAND EST'),\n",
    "    \n",
    "    # Hauts-de-France\n",
    "    '02': ('PICARDIE', 'HAUTS-DE-FRANCE'),\n",
    "    '59': ('NORD-PAS-DE-CALAIS', 'HAUTS-DE-FRANCE'),\n",
    "    '60': ('PICARDIE', 'HAUTS-DE-FRANCE'),\n",
    "    '62': ('NORD-PAS-DE-CALAIS', 'HAUTS-DE-FRANCE'),\n",
    "    '80': ('PICARDIE', 'HAUTS-DE-FRANCE'),\n",
    "    \n",
    "    # Île-de-France\n",
    "    '75': ('ILE-DE-FRANCE', 'ILE-DE-FRANCE'),\n",
    "    '77': ('ILE-DE-FRANCE', 'ILE-DE-FRANCE'),\n",
    "    '78': ('ILE-DE-FRANCE', 'ILE-DE-FRANCE'),\n",
    "    '91': ('ILE-DE-FRANCE', 'ILE-DE-FRANCE'),\n",
    "    '92': ('ILE-DE-FRANCE', 'ILE-DE-FRANCE'),\n",
    "    '93': ('ILE-DE-FRANCE', 'ILE-DE-FRANCE'),\n",
    "    '94': ('ILE-DE-FRANCE', 'ILE-DE-FRANCE'),\n",
    "    '95': ('ILE-DE-FRANCE', 'ILE-DE-FRANCE'),\n",
    "    \n",
    "    # Normandie\n",
    "    '14': ('BASSE-NORMANDIE', 'NORMANDIE'),\n",
    "    '27': ('HAUTE-NORMANDIE', 'NORMANDIE'),\n",
    "    '50': ('BASSE-NORMANDIE', 'NORMANDIE'),\n",
    "    '61': ('BASSE-NORMANDIE', 'NORMANDIE'),\n",
    "    '76': ('HAUTE-NORMANDIE', 'NORMANDIE'),\n",
    "    \n",
    "    # Nouvelle-Aquitaine\n",
    "    '16': ('POITOU-CHARENTES', 'NOUVELLE-AQUITAINE'),\n",
    "    '17': ('POITOU-CHARENTES', 'NOUVELLE-AQUITAINE'),\n",
    "    '19': ('LIMOUSIN', 'NOUVELLE-AQUITAINE'),\n",
    "    '23': ('LIMOUSIN', 'NOUVELLE-AQUITAINE'),\n",
    "    '24': ('AQUITAINE', 'NOUVELLE-AQUITAINE'),\n",
    "    '33': ('AQUITAINE', 'NOUVELLE-AQUITAINE'),\n",
    "    '40': ('AQUITAINE', 'NOUVELLE-AQUITAINE'),\n",
    "    '47': ('AQUITAINE', 'NOUVELLE-AQUITAINE'),\n",
    "    '64': ('AQUITAINE', 'NOUVELLE-AQUITAINE'),\n",
    "    '79': ('POITOU-CHARENTES', 'NOUVELLE-AQUITAINE'),\n",
    "    '86': ('POITOU-CHARENTES', 'NOUVELLE-AQUITAINE'),\n",
    "    '87': ('LIMOUSIN', 'NOUVELLE-AQUITAINE'),\n",
    "    \n",
    "    # Occitanie\n",
    "    '09': ('MIDI-PYRENEES', 'OCCITANIE'),\n",
    "    '11': ('LANGUEDOC-ROUSSILLON', 'OCCITANIE'),\n",
    "    '12': ('MIDI-PYRENEES', 'OCCITANIE'),\n",
    "    '30': ('LANGUEDOC-ROUSSILLON', 'OCCITANIE'),\n",
    "    '31': ('MIDI-PYRENEES', 'OCCITANIE'),\n",
    "    '32': ('MIDI-PYRENEES', 'OCCITANIE'),\n",
    "    '34': ('LANGUEDOC-ROUSSILLON', 'OCCITANIE'),\n",
    "    '46': ('MIDI-PYRENEES', 'OCCITANIE'),\n",
    "    '48': ('LANGUEDOC-ROUSSILLON', 'OCCITANIE'),\n",
    "    '65': ('MIDI-PYRENEES', 'OCCITANIE'),\n",
    "    '66': ('LANGUEDOC-ROUSSILLON', 'OCCITANIE'),\n",
    "    '81': ('MIDI-PYRENEES', 'OCCITANIE'),\n",
    "    '82': ('MIDI-PYRENEES', 'OCCITANIE'),\n",
    "    \n",
    "    # Pays de la Loire\n",
    "    '44': ('PAYS DE LA LOIRE', 'PAYS DE LA LOIRE'),\n",
    "    '49': ('PAYS DE LA LOIRE', 'PAYS DE LA LOIRE'),\n",
    "    '53': ('PAYS DE LA LOIRE', 'PAYS DE LA LOIRE'),\n",
    "    '72': ('PAYS DE LA LOIRE', 'PAYS DE LA LOIRE'),\n",
    "    '85': ('PAYS DE LA LOIRE', 'PAYS DE LA LOIRE'),\n",
    "    \n",
    "    # Provence-Alpes-Côte d'Azur\n",
    "    '04': ('PROVENCE-ALPES-COTE D\\'AZUR', 'PROVENCE-ALPES-COTE D\\'AZUR'),\n",
    "    '05': ('PROVENCE-ALPES-COTE D\\'AZUR', 'PROVENCE-ALPES-COTE D\\'AZUR'),\n",
    "    '06': ('PROVENCE-ALPES-COTE D\\'AZUR', 'PROVENCE-ALPES-COTE D\\'AZUR'),\n",
    "    '13': ('PROVENCE-ALPES-COTE D\\'AZUR', 'PROVENCE-ALPES-COTE D\\'AZUR'),\n",
    "    '83': ('PROVENCE-ALPES-COTE D\\'AZUR', 'PROVENCE-ALPES-COTE D\\'AZUR'),\n",
    "    '84': ('PROVENCE-ALPES-COTE D\\'AZUR', 'PROVENCE-ALPES-COTE D\\'AZUR'),\n",
    "    \n",
    "    # DOM-TOM\n",
    "    '971': ('GUADELOUPE', 'GUADELOUPE'),\n",
    "    '972': ('MARTINIQUE', 'MARTINIQUE'),\n",
    "    '973': ('GUYANE', 'GUYANE'),\n",
    "    '974': ('LA REUNION', 'LA REUNION'),\n",
    "    '975': ('SAINT-PIERRE-ET-MIQUELON', 'SAINT-PIERRE-ET-MIQUELON'),\n",
    "    '976': ('MAYOTTE', 'MAYOTTE'),\n",
    "    '977': ('SAINT-BARTHELEMY', 'SAINT-BARTHELEMY'),\n",
    "    '978': ('SAINT-MARTIN', 'SAINT-MARTIN'),\n",
    "    '986': ('WALLIS-ET-FUTUNA', 'WALLIS-ET-FUTUNA'),\n",
    "    '987': ('POLYNESIE FRANCAISE', 'POLYNESIE FRANCAISE'),\n",
    "    '988': ('NOUVELLE-CALEDONIE', 'NOUVELLE-CALEDONIE')\n",
    "}\n",
    "\n",
    "# Dictionnaire des tranches d'effectifs\n",
    "TRANCHES_EFFECTIFS = {\n",
    "    '00': '0 salarié',\n",
    "    '01': '1 ou 2 salariés',\n",
    "    '02': '3 à 5 salariés',\n",
    "    '03': '6 à 9 salariés',\n",
    "    '11': '10 à 19 salariés',\n",
    "    '12': '20 à 49 salariés',\n",
    "    '21': '50 à 99 salariés',\n",
    "    '22': '100 à 199 salariés',\n",
    "    '31': '200 à 249 salariés',\n",
    "    '32': '250 à 499 salariés',\n",
    "    '41': '500 à 999 salariés',\n",
    "    '42': '1000 à 1999 salariés',\n",
    "    '51': '2000 à 4999 salariés',\n",
    "    '52': '5000 à 9999 salariés',\n",
    "    '53': '10000 salariés et plus',\n",
    "    'NN': 'Unités non employeuses',\n",
    "    # Ajout de codes alternatifs parfois utilisés\n",
    "    '0': '0 salarié',\n",
    "    '1': '1 ou 2 salariés',\n",
    "    '2': '3 à 5 salariés',\n",
    "    '3': '6 à 9 salariés',\n",
    "    '10': '10 à 19 salariés',\n",
    "    '20': '20 à 49 salariés',\n",
    "    '50': '50 à 99 salariés',\n",
    "    '100': '100 à 199 salariés',\n",
    "    '200': '200 à 249 salariés',\n",
    "    '250': '250 à 499 salariés',\n",
    "    '500': '500 à 999 salariés',\n",
    "    '1000': '1000 à 1999 salariés',\n",
    "    '2000': '2000 à 4999 salariés',\n",
    "    '5000': '5000 à 9999 salariés',\n",
    "    '10000': '10000 salariés et plus'\n",
    "}\n",
    "\n",
    "# Dictionnaire des départements français\n",
    "DEPARTEMENTS = {\n",
    "    '01': 'Ain', '02': 'Aisne', '03': 'Allier', '04': 'Alpes-de-Haute-Provence',\n",
    "    '05': 'Hautes-Alpes', '06': 'Alpes-Maritimes', '07': 'Ardèche', '08': 'Ardennes',\n",
    "    '09': 'Ariège', '10': 'Aube', '11': 'Aude', '12': 'Aveyron',\n",
    "    '13': 'Bouches-du-Rhône', '14': 'Calvados', '15': 'Cantal', '16': 'Charente',\n",
    "    '17': 'Charente-Maritime', '18': 'Cher', '19': 'Corrèze', '2A': 'Corse-du-Sud',\n",
    "    '2B': 'Haute-Corse', '21': 'Côte-d\\'Or', '22': 'Côtes-d\\'Armor', '23': 'Creuse',\n",
    "    '24': 'Dordogne', '25': 'Doubs', '26': 'Drôme', '27': 'Eure',\n",
    "    '28': 'Eure-et-Loir', '29': 'Finistère', '30': 'Gard', '31': 'Haute-Garonne',\n",
    "    '32': 'Gers', '33': 'Gironde', '34': 'Hérault', '35': 'Ille-et-Vilaine',\n",
    "    '36': 'Indre', '37': 'Indre-et-Loire', '38': 'Isère', '39': 'Jura',\n",
    "    '40': 'Landes', '41': 'Loir-et-Cher', '42': 'Loire', '43': 'Haute-Loire',\n",
    "    '44': 'Loire-Atlantique', '45': 'Loiret', '46': 'Lot', '47': 'Lot-et-Garonne',\n",
    "    '48': 'Lozère', '49': 'Maine-et-Loire', '50': 'Manche', '51': 'Marne',\n",
    "    '52': 'Haute-Marne', '53': 'Mayenne', '54': 'Meurthe-et-Moselle', '55': 'Meuse',\n",
    "    '56': 'Morbihan', '57': 'Moselle', '58': 'Nièvre', '59': 'Nord',\n",
    "    '60': 'Oise', '61': 'Orne', '62': 'Pas-de-Calais', '63': 'Puy-de-Dôme',\n",
    "    '64': 'Pyrénées-Atlantiques', '65': 'Hautes-Pyrénées', '66': 'Pyrénées-Orientales', '67': 'Bas-Rhin',\n",
    "    '68': 'Haut-Rhin', '69': 'Rhône', '70': 'Haute-Saône', '71': 'Saône-et-Loire',\n",
    "    '72': 'Sarthe', '73': 'Savoie', '74': 'Haute-Savoie', '75': 'Paris',\n",
    "    '76': 'Seine-Maritime', '77': 'Seine-et-Marne', '78': 'Yvelines', '79': 'Deux-Sèvres',\n",
    "    '80': 'Somme', '81': 'Tarn', '82': 'Tarn-et-Garonne', '83': 'Var',\n",
    "    '84': 'Vaucluse', '85': 'Vendée', '86': 'Vienne', '87': 'Haute-Vienne',\n",
    "    '88': 'Vosges', '89': 'Yonne', '90': 'Territoire de Belfort', '91': 'Essonne',\n",
    "    '92': 'Hauts-de-Seine', '93': 'Seine-Saint-Denis', '94': 'Val-de-Marne', '95': 'Val-d\\'Oise',\n",
    "    # DOM-TOM\n",
    "    '971': 'Guadeloupe', '972': 'Martinique', '973': 'Guyane', '974': 'La Réunion',\n",
    "    '975': 'Saint-Pierre-et-Miquelon', '976': 'Mayotte', '977': 'Saint-Barthélemy',\n",
    "    '978': 'Saint-Martin', '986': 'Wallis-et-Futuna', '987': 'Polynésie française',\n",
    "    '988': 'Nouvelle-Calédonie'\n",
    "}\n",
    "\n",
    "# Dictionnaire des pays en code ISO vers nom complet\n",
    "PAYS = {\n",
    "    'FR': 'FRANCE',\n",
    "    'BE': 'BELGIQUE',\n",
    "    'DE': 'ALLEMAGNE',\n",
    "    'IT': 'ITALIE',\n",
    "    'ES': 'ESPAGNE',\n",
    "    'GB': 'ROYAUME-UNI',\n",
    "    'CH': 'SUISSE',\n",
    "    'LU': 'LUXEMBOURG',\n",
    "    'NL': 'PAYS-BAS',\n",
    "    'PT': 'PORTUGAL',\n",
    "    'US': 'ÉTATS-UNIS',\n",
    "    'CA': 'CANADA',\n",
    "    'CN': 'CHINE',\n",
    "    'JP': 'JAPON',\n",
    "    'AU': 'AUSTRALIE',\n",
    "    'BR': 'BRÉSIL',\n",
    "    'IN': 'INDE',\n",
    "    'MX': 'MEXIQUE',\n",
    "    'RU': 'RUSSIE',\n",
    "    'KR': 'CORÉE DU SUD'\n",
    "}\n",
    "\n",
    "# Dictionnaire des catégories juridiques\n",
    "CATEGORIES_JURIDIQUES = {\n",
    "    '1000': 'Entrepreneur individuel',\n",
    "    '2110': 'Indivision',\n",
    "    '2120': 'Société créée de fait',\n",
    "    '2210': 'GIE',\n",
    "    '2220': 'GEIE',\n",
    "    '2310': 'Société en participation',\n",
    "    '2320': 'Société créée de fait',\n",
    "    '2385': 'Société d\\'exercice libéral',\n",
    "    '2400': 'Fiducie',\n",
    "    '2700': 'Paroisse hors zone concordataire',\n",
    "    '2900': 'Autre groupement de droit privé non doté de la personnalité morale',\n",
    "    '3110': 'Représentation ou agence commerciale d\\'état ou organisme public étranger',\n",
    "    '3120': 'Société commerciale étrangère',\n",
    "    '3205': 'Organisation internationale',\n",
    "    '3210': 'État collectivité ou établissement public étranger',\n",
    "    '3220': 'Société étrangère non immatriculée au RCS',\n",
    "    '3290': 'Autre personne morale de droit étranger',\n",
    "    '4110': 'Établissement public national à caractère industriel ou commercial',\n",
    "    '4120': 'Établissement public national à caractère administratif',\n",
    "    '4130': 'Exploitant public',\n",
    "    '4140': 'Établissement public local à caractère industriel ou commercial',\n",
    "    '4150': 'Régie d\\'une collectivité locale à caractère industriel ou commercial',\n",
    "    '4160': 'Institution Banque de France',\n",
    "    '5195': 'Caisse de crédit agricole mutuel',\n",
    "    '5196': 'Caisse de crédit mutuel',\n",
    "    '5202': 'Société européenne',\n",
    "    '5203': 'SCIC',\n",
    "    '5306': 'Société en commandite simple',\n",
    "    '5307': 'Société en commandite par actions',\n",
    "    '5308': 'Société en nom collectif',\n",
    "    '5309': 'Fiducie',\n",
    "    '5310': 'SCOP',\n",
    "    '5370': 'Société par actions simplifiée unipersonnelle',\n",
    "    '5385': 'Société d\\'exercice libéral',\n",
    "    '5410': 'SARL unipersonnelle',\n",
    "    '5415': 'SARL d\\'économie mixte',\n",
    "    '5422': 'SARL immobilière',\n",
    "    '5426': 'SARL de famille',\n",
    "    '5430': 'SARL d\\'attribution',\n",
    "    '5431': 'SARL mixte d\\'intérêt agricole',\n",
    "    '5432': 'SARL d\\'intérêt collectif agricole',\n",
    "    '5442': 'SARL d\\'attribution',\n",
    "    '5443': 'SARL coopérative de construction',\n",
    "    '5451': 'SARL coopérative de consommation',\n",
    "    '5453': 'SARL coopérative artisanale',\n",
    "    '5454': 'SARL coopérative d\\'intérêt maritime',\n",
    "    '5455': 'SARL coopérative de transport',\n",
    "    '5458': 'SARL coopérative ouvrière de production',\n",
    "    '5459': 'SARL union de sociétés coopératives',\n",
    "    '5460': 'Autre SARL coopérative',\n",
    "    '5485': 'Société d\\'exercice libéral à responsabilité limitée',\n",
    "    '5498': 'SARL unipersonnelle',\n",
    "    '5499': 'SARL',\n",
    "    '5505': 'SA à participation ouvrière à conseil d\\'administration',\n",
    "    '5510': 'SA nationale à conseil d\\'administration',\n",
    "    '5515': 'SA d\\'économie mixte à conseil d\\'administration',\n",
    "    '5520': 'SICAV',\n",
    "    '5522': 'SA immobilière d\\'investissement',\n",
    "    '5525': 'SA immobilière de gestion',\n",
    "    '5530': 'SA d\\'aménagement foncier et d\\'équipement rural',\n",
    "    '5531': 'SA mixte d\\'intérêt agricole',\n",
    "    '5532': 'SAFER',\n",
    "    '5542': 'SA d\\'attribution',\n",
    "    '5543': 'SA coopérative de construction',\n",
    "    '5546': 'SA de HLM',\n",
    "    '5547': 'Société anonyme de crédit immobilier',\n",
    "    '5548': 'SA de crédit-bail',\n",
    "    '5551': 'SA coopérative de consommation',\n",
    "    '5552': 'SA coopérative de commerçants-détaillants',\n",
    "    '5553': 'SA coopérative artisanale',\n",
    "    '5554': 'SA coopérative d\\'intérêt maritime',\n",
    "    '5555': 'SA coopérative de transport',\n",
    "    '5558': 'SA coopérative ouvrière de production',\n",
    "    '5559': 'SA union de sociétés coopératives',\n",
    "    '5560': 'Autre SA coopérative',\n",
    "    '5570': 'SCIC',\n",
    "    '5585': 'Société d\\'exercice libéral',\n",
    "    '5599': 'SA à conseil d\\'administration',\n",
    "    '5605': 'SA à participation ouvrière à directoire',\n",
    "    '5610': 'SA nationale à directoire',\n",
    "    '5615': 'SA d\\'économie mixte à directoire',\n",
    "    '5620': 'SICAV',\n",
    "    '5622': 'SA immobilière d\\'investissement',\n",
    "    '5625': 'SA immobilière de gestion',\n",
    "    '5630': 'SAFER',\n",
    "    '5631': 'SA mixte d\\'intérêt agricole',\n",
    "    '5632': 'SA d\\'intérêt collectif agricole',\n",
    "    '5642': 'SA d\\'attribution',\n",
    "    '5643': 'SA coopérative de construction',\n",
    "    '5646': 'SA de HLM',\n",
    "    '5647': 'SA de crédit immobilier',\n",
    "    '5648': 'SA de crédit-bail',\n",
    "    '5651': 'SA coopérative de consommation',\n",
    "    '5652': 'SA coopérative de commerçants-détaillants',\n",
    "    '5653': 'SA coopérative artisanale',\n",
    "    '5654': 'SA coopérative d\\'intérêt maritime',\n",
    "    '5655': 'SA coopérative de transport',\n",
    "    '5658': 'SA coopérative ouvrière de production',\n",
    "    '5659': 'SA union de sociétés coopératives',\n",
    "    '5660': 'Autre SA coopérative',\n",
    "    '5670': 'SCIC',\n",
    "    '5685': 'Société d\\'exercice libéral',\n",
    "    '5699': 'SA à directoire',\n",
    "    '5710': 'SAS',\n",
    "    '5720': 'SASU',\n",
    "    '5785': 'Société d\\'exercice libéral par actions simplifiée',\n",
    "    '5800': 'Société européenne',\n",
    "    '6100': 'Caisse d\\'épargne et de prévoyance',\n",
    "    '6210': 'GEIE',\n",
    "    '6220': 'GIE',\n",
    "    '6316': 'EPCI',\n",
    "    '6317': 'Secteur de commune',\n",
    "    '6318': 'ASA',\n",
    "    '6411': 'Commune et commune nouvelle',\n",
    "    '6412': 'Commune associée et commune déléguée',\n",
    "    '6413': 'Section de commune',\n",
    "    '6414': 'Ensemble urbain',\n",
    "    '6421': 'Région',\n",
    "    '6422': 'Département',\n",
    "    '6431': 'Métropole',\n",
    "    '6432': 'District urbain',\n",
    "    '6433': 'Communauté urbaine',\n",
    "    '6434': 'Métropole',\n",
    "    '6435': 'Syndicat communautaire',\n",
    "    '6436': 'Communauté de communes',\n",
    "    '6441': 'Commune et commune nouvelle',\n",
    "    '6442': 'Commune associée et commune déléguée',\n",
    "    '6443': 'Section de commune',\n",
    "    '6444': 'Ensemble urbain',\n",
    "    '6451': 'Syndicat intercommunal à vocation unique',\n",
    "    '6452': 'Syndicat intercommunal à vocation multiple',\n",
    "    '6453': 'Syndicat mixte fermé',\n",
    "    '6454': 'Syndicat mixte ouvert',\n",
    "    '6455': 'Autre établissement public local',\n",
    "    '6460': 'Régie personnalisée',\n",
    "    '6461': 'Institution interdépartementale ou entente',\n",
    "    '6462': 'Pôle métropolitain',\n",
    "    '6463': 'Pôle d\\'équilibre territorial et rural',\n",
    "    '6464': 'Syndicat mixte fermé',\n",
    "    '6465': 'Syndicat mixte ouvert',\n",
    "    '6466': 'Commune et commune nouvelle',\n",
    "    '6467': 'Communauté de villes',\n",
    "    '6468': 'Autre établissement public local',\n",
    "    '6469': 'Syndicat intercommunal ou mixte',\n",
    "    '6470': 'Autre établissement public local',\n",
    "    '6490': 'Autre collectivité territoriale',\n",
    "    '6499': 'Autre collectivité territoriale',\n",
    "    '6511': 'Syndicat de propriétaires',\n",
    "    '6512': 'ASL',\n",
    "    '6513': 'AFUL',\n",
    "    '6514': 'Syndicat de communes',\n",
    "    '6515': 'Pôle d\\'équilibre territorial et rural',\n",
    "    '6516': 'Syndicat mixte',\n",
    "    '6517': 'Commission syndicale',\n",
    "    '6518': 'Pôle métropolitain',\n",
    "    '6519': 'Société d\\'économie mixte',\n",
    "    '6520': 'Société publique locale',\n",
    "    '6521': 'AFU',\n",
    "    '6522': 'ASA',\n",
    "    '6523': 'ASCO',\n",
    "    '6524': 'Commission syndicale',\n",
    "    '6525': 'Association syndicale',\n",
    "    '6529': 'Autre groupement',\n",
    "    '6531': 'Commission de gestion des services publics',\n",
    "    '6532': 'Commission de gestion urbaine',\n",
    "    '6533': 'ASL',\n",
    "    '6534': 'AFUL',\n",
    "    '6535': 'ASCO',\n",
    "    '6536': 'Commission syndicale de gestion',\n",
    "    '6537': 'Centre communal d\\'action sociale',\n",
    "    '6538': 'Centre intercommunal d\\'action sociale',\n",
    "    '6539': 'Centre d\\'action sociale',\n",
    "    '6540': 'Autre établissement public administratif',\n",
    "    '6541': 'CROUS',\n",
    "    '6542': 'Caisse de crédit municipal',\n",
    "    '6543': 'Établissement d\\'hospitalisation',\n",
    "    '6544': 'Syndicat inter hospitalier',\n",
    "    '6545': 'Établissement public médico-social et social communal',\n",
    "    '6546': 'Établissement public médico-social et social intercommunal',\n",
    "    '6547': 'Établissement public médico-social et social départemental',\n",
    "    '6548': 'Établissement public médico-social et social interdépartemental',\n",
    "    '6549': 'Établissement public médico-social et social national',\n",
    "    '6551': 'Écoles',\n",
    "    '6552': 'Université',\n",
    "    '6553': 'Établissement public à caractère scientifique culturel et professionnel',\n",
    "    '6554': 'Autre établissement public d\\'enseignement',\n",
    "    '6555': 'OPH communal',\n",
    "    '6556': 'OPH intercommunal',\n",
    "    '6557': 'OPH départemental',\n",
    "    '6558': 'OPH interdépartemental',\n",
    "    '6559': 'OPH régional',\n",
    "    '6560': 'OPH national',\n",
    "    '6561': 'Autre établissement public administratif',\n",
    "    '6562': 'EPA',\n",
    "    '6563': 'DEL',\n",
    "    '6564': 'EPIC',\n",
    "    '6565': 'EPIC',\n",
    "    '6566': 'EPA',\n",
    "    '6567': 'EPA',\n",
    "    '6568': 'EPA',\n",
    "    '6569': 'EPA',\n",
    "    '6571': 'Service déconcentré de l\\'État à compétence territoriale',\n",
    "    '6572': 'Service déconcentré de l\\'État à compétence nationale',\n",
    "    '6573': 'Service central d\\'un ministère',\n",
    "    '6574': 'Service ministériel déconcentré à compétence régionale',\n",
    "    '6575': 'Service ministériel déconcentré à compétence départementale',\n",
    "    '6576': 'Service ministériel déconcentré à compétence infra-départementale',\n",
    "    '6577': 'Service ministériel déconcentré à compétence territoriale',\n",
    "    '6578': 'Service ministériel déconcentré à compétence nationale',\n",
    "    '6579': 'Autre service administratif',\n",
    "    '6580': 'Autre service administratif',\n",
    "    '6581': 'Organisme consulaire',\n",
    "    '6582': 'Établissement public des cultes d\\'Alsace-Moselle',\n",
    "    '6583': 'Établissement public administratif',\n",
    "    '6584': 'Groupement d\\'intérêt public',\n",
    "    '6585': 'Autre établissement public national administratif',\n",
    "    '6589': 'Groupement de coopération sanitaire',\n",
    "    '6595': 'Association syndicale autorisée',\n",
    "    '6596': 'Association foncière urbaine',\n",
    "    '6597': 'Association foncière de remembrement',\n",
    "    '6598': 'Association syndicale de propriétaires',\n",
    "    '6599': 'Autre personne morale de droit administratif',\n",
    "    '7111': 'Autorité constitutionnelle',\n",
    "    '7112': 'Autorité administrative indépendante',\n",
    "    '7113': 'Ministère',\n",
    "    '7120': 'Service central d\\'un ministère',\n",
    "    '7150': 'Service du ministère de la Défense',\n",
    "    '7160': 'Service déconcentré à compétence régionale',\n",
    "    '7171': 'Service déconcentré de l\\'État à compétence régionale',\n",
    "    '7172': 'Service déconcentré de l\\'État à compétence départementale',\n",
    "    '7179': 'Autre service déconcentré de l\\'État',\n",
    "    '7190': 'Échelon de contrôle',\n",
    "    '7210': 'Commune et commune nouvelle',\n",
    "    '7220': 'Département',\n",
    "    '7225': 'Collectivité et territoire d\\'Outre-Mer',\n",
    "    '7229': 'Collectivité territoriale',\n",
    "    '7230': 'Région',\n",
    "    '7312': 'Commune associée et commune déléguée',\n",
    "    '7313': 'Section de commune',\n",
    "    '7314': 'Ensemble urbain',\n",
    "    '7321': 'ASA',\n",
    "    '7322': 'AFUL',\n",
    "    '7323': 'AFU',\n",
    "    '7331': 'Établissement public local d\\'enseignement',\n",
    "    '7340': 'Pôle d\\'équilibre territorial et rural',\n",
    "    '7341': 'Secteur de commune',\n",
    "    '7342': 'District urbain',\n",
    "    '7343': 'Communauté urbaine',\n",
    "    '7344': 'Métropole',\n",
    "    '7345': 'Syndicat communautaire',\n",
    "    '7346': 'Communauté de communes',\n",
    "    '7347': 'Communauté de villes',\n",
    "    '7348': 'Communauté d\\'agglomération',\n",
    "    '7349': 'Autre établissement public local',\n",
    "    '7351': 'Institution interdépartementale ou entente',\n",
    "    '7352': 'Établissement public interdépartemental',\n",
    "    '7353': 'Syndicat interdépartemental',\n",
    "    '7354': 'Institution interdépartementale ou entente',\n",
    "    '7355': 'Institution interdépartementale ou entente',\n",
    "    '7356': 'Syndicat intercommunal à vocation unique',\n",
    "    '7357': 'Syndicat intercommunal à vocation multiple',\n",
    "    '7361': 'Centre régional de la propriété forestière',\n",
    "    '7362': 'Établissement public foncier',\n",
    "    '7363': 'Établissement public d\\'aménagement',\n",
    "    '7364': 'Établissement public d\\'aménagement et de restructuration',\n",
    "    '7365': 'Autre établissement public local de développement',\n",
    "    '7366': 'Syndicat mixte fermé',\n",
    "    '7367': 'Syndicat mixte ouvert',\n",
    "    '7371': 'OPH communal',\n",
    "    '7372': 'OPH intercommunal',\n",
    "    '7373': 'OPH départemental',\n",
    "    '7378': 'Régie d\\'une collectivité locale à caractère administratif',\n",
    "    '7379': 'Régie',\n",
    "    '7381': 'Organisme consulaire',\n",
    "    '7382': 'Établissement public des cultes d\\'Alsace-Moselle',\n",
    "    '7383': 'Établissement public local',\n",
    "    '7384': 'Établissement public local culturel',\n",
    "    '7385': 'Établissement public local social et médico-social',\n",
    "    '7389': 'Établissement public',\n",
    "    '7410': 'Groupement d\\'intérêt public',\n",
    "    '7420': 'Groupement d\\'intérêt public',\n",
    "    '7430': 'Établissement public',\n",
    "    '7440': 'Groupement de coopération sanitaire',\n",
    "    '7450': 'Établissement public',\n",
    "    '7460': 'Groupement d\\'intérêt public',\n",
    "    '7470': 'Groupement de coopération',\n",
    "    '7480': 'Autre personne morale de droit public',\n",
    "    '7490': 'Autre personne morale de droit public',\n",
    "    '8110': 'Régime général de la Sécurité sociale',\n",
    "    '8120': 'Régime spécial de Sécurité sociale',\n",
    "    '8130': 'Institution de retraite complémentaire',\n",
    "    '8140': 'Mutualité sociale agricole',\n",
    "    '8150': 'Régime maladie des non salariés',\n",
    "    '8160': 'Régime vieillesse des non salariés',\n",
    "    '8170': 'Régime d\\'assurance chômage',\n",
    "    '8190': 'Autre organisme de Sécurité sociale',\n",
    "    '8210': 'Mutuelle',\n",
    "    '8220': 'Société mutualiste',\n",
    "    '8290': 'Autre organisme mutualiste',\n",
    "    '8310': 'Comité d\\'entreprise',\n",
    "    '8311': 'Comité central d\\'entreprise',\n",
    "    '8410': 'Syndicat de salariés',\n",
    "    '8420': 'Syndicat patronal',\n",
    "    '8450': 'Ordre professionnel',\n",
    "    '8470': 'Centre technique industriel et comité professionnel du développement économique',\n",
    "    '8490': 'Autre organisme professionnel',\n",
    "    '8510': 'Institution de prévoyance',\n",
    "    '8520': 'Institution de retraite supplémentaire',\n",
    "    '9110': 'Syndicat de copropriété',\n",
    "    '9150': 'ASL',\n",
    "    '9210': 'Association non déclarée',\n",
    "    '9220': 'Association déclarée',\n",
    "    '9221': 'Association déclarée',\n",
    "    '9222': 'Association d\\'insertion par l\\'économique',\n",
    "    '9223': 'Association intermédiaire',\n",
    "    '9224': 'Groupement d\\'employeurs',\n",
    "    '9230': 'Association reconnue d\\'utilité publique',\n",
    "    '9240': 'Congrégation',\n",
    "    '9250': 'Association de droit local',\n",
    "    '9260': 'Association agréée',\n",
    "    '9300': 'Fondation',\n",
    "    '9900': 'Autre organisme privé',\n",
    "    '9970': 'Groupement de droit privé'\n",
    "}\n",
    "\n",
    "def convertir_date_en_tranche(date_creation):\n",
    "    \"\"\"\n",
    "    Convertit une date de création en tranche d'années simplifiée\n",
    "    Par exemple: 2005 -> \"de 2000 à 2009\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if pd.isna(date_creation) or date_creation == '':\n",
    "            return np.nan\n",
    "        \n",
    "        # Extraire l'année de la date\n",
    "        annee = int(str(date_creation)[:4])\n",
    "        \n",
    "        # Déterminer la tranche simplifiée\n",
    "        if annee < 1980:\n",
    "            return \"avant 1980\"\n",
    "        elif annee < 1990:\n",
    "            return \"de 1980 à 1989\"\n",
    "        elif annee < 2000:\n",
    "            return \"de 1990 à 1999\"\n",
    "        elif annee < 2010:\n",
    "            return \"de 2000 à 2009\"\n",
    "        elif annee < 2020:\n",
    "            return \"de 2010 à 2019\"\n",
    "        else:\n",
    "            return \"de 2020 à aujourd'hui\"\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def mapper_tranche_effectifs(code_tranche):\n",
    "    \"\"\"\n",
    "    Convertit le code tranche effectifs en libellé\n",
    "    \"\"\"\n",
    "    if pd.isna(code_tranche) or code_tranche == '':\n",
    "        return np.nan\n",
    "    \n",
    "    code_str = str(code_tranche).strip().upper()\n",
    "    \n",
    "    if code_str in TRANCHES_EFFECTIFS:\n",
    "        return TRANCHES_EFFECTIFS[code_str]\n",
    "    \n",
    "    # Si pas trouvé, essayer de deviner\n",
    "    try:\n",
    "        code_num = int(code_str)\n",
    "        if code_num == 0:\n",
    "            return '0 salarié'\n",
    "        elif code_num <= 2:\n",
    "            return '1 ou 2 salariés'\n",
    "        elif code_num <= 5:\n",
    "            return '3 à 5 salariés'\n",
    "        elif code_num <= 9:\n",
    "            return '6 à 9 salariés'\n",
    "        elif code_num <= 19:\n",
    "            return '10 à 19 salariés'\n",
    "        elif code_num <= 49:\n",
    "            return '20 à 49 salariés'\n",
    "        elif code_num <= 99:\n",
    "            return '50 à 99 salariés'\n",
    "        elif code_num <= 199:\n",
    "            return '100 à 199 salariés'\n",
    "        elif code_num <= 249:\n",
    "            return '200 à 249 salariés'\n",
    "        elif code_num <= 499:\n",
    "            return '250 à 499 salariés'\n",
    "        elif code_num <= 999:\n",
    "            return '500 à 999 salariés'\n",
    "        elif code_num <= 1999:\n",
    "            return '1000 à 1999 salariés'\n",
    "        elif code_num <= 4999:\n",
    "            return '2000 à 4999 salariés'\n",
    "        elif code_num <= 9999:\n",
    "            return '5000 à 9999 salariés'\n",
    "        else:\n",
    "            return '10000 salariés et plus'\n",
    "    except:\n",
    "        return code_str  # Retourner tel quel si impossible à convertir\n",
    "\n",
    "def mapper_regions(code_dept):\n",
    "    \"\"\"\n",
    "    Retourne old_region et region à partir du code département\n",
    "    \"\"\"\n",
    "    if pd.isna(code_dept) or code_dept == '':\n",
    "        return (np.nan, np.nan)\n",
    "    \n",
    "    code_str = str(code_dept).strip()\n",
    "    \n",
    "    # Gérer les codes à 3 chiffres pour les DOM-TOM\n",
    "    if len(code_str) == 3:\n",
    "        if code_str in REGIONS:\n",
    "            return REGIONS[code_str]\n",
    "    # Gérer les codes à 2 chiffres\n",
    "    elif len(code_str) == 2 or (len(code_str) == 1 and code_str.isdigit()):\n",
    "        code_str = code_str.zfill(2)\n",
    "        if code_str in REGIONS:\n",
    "            return REGIONS[code_str]\n",
    "    \n",
    "    return (np.nan, np.nan)\n",
    "\n",
    "def mapper_categorie_juridique(code_categorie):\n",
    "    \"\"\"\n",
    "    Convertit le code catégorie juridique en libellé\n",
    "    \"\"\"\n",
    "    if pd.isna(code_categorie) or code_categorie == '':\n",
    "        return np.nan\n",
    "    \n",
    "    code_str = str(code_categorie).zfill(4)\n",
    "    \n",
    "    # Si le code exact existe\n",
    "    if code_str in CATEGORIES_JURIDIQUES:\n",
    "        return CATEGORIES_JURIDIQUES[code_str]\n",
    "    \n",
    "    # Sinon, chercher avec les premiers chiffres\n",
    "    for i in range(3, 0, -1):\n",
    "        code_partiel = code_str[:i]\n",
    "        if code_partiel + '00' in CATEGORIES_JURIDIQUES:\n",
    "            return CATEGORIES_JURIDIQUES[code_partiel + '00']\n",
    "    \n",
    "    # Si toujours pas trouvé, essayer de mapper les codes les plus courants\n",
    "    if code_str.startswith('54'):\n",
    "        return 'SARL'\n",
    "    elif code_str.startswith('55'):\n",
    "        return 'Société anonyme'\n",
    "    elif code_str.startswith('57'):\n",
    "        return 'Société par actions simplifiée'\n",
    "    \n",
    "    return f\"Forme juridique non identifiée (code: {code_str})\"\n",
    "\n",
    "def mapper_departement(code_dept):\n",
    "    \"\"\"\n",
    "    Convertit le code département en nom complet\n",
    "    \"\"\"\n",
    "    if pd.isna(code_dept) or code_dept == '':\n",
    "        return np.nan\n",
    "    \n",
    "    code_str = str(code_dept).strip()\n",
    "    \n",
    "    # Gérer les codes à 3 chiffres pour les DOM-TOM\n",
    "    if len(code_str) == 3:\n",
    "        if code_str in DEPARTEMENTS:\n",
    "            return DEPARTEMENTS[code_str]\n",
    "    # Gérer les codes à 2 chiffres\n",
    "    elif len(code_str) == 2 or (len(code_str) == 1 and code_str.isdigit()):\n",
    "        code_str = code_str.zfill(2)\n",
    "        if code_str in DEPARTEMENTS:\n",
    "            return DEPARTEMENTS[code_str]\n",
    "    \n",
    "    return code_str  # Retourner le code si pas trouvé\n",
    "\n",
    "def mapper_pays(code_pays):\n",
    "    \"\"\"\n",
    "    Convertit le code pays en nom complet\n",
    "    \"\"\"\n",
    "    if pd.isna(code_pays) or code_pays == '':\n",
    "        return 'FRANCE'  # Par défaut FRANCE\n",
    "    \n",
    "    code_str = str(code_pays).strip().upper()\n",
    "    \n",
    "    # Si c'est déjà un nom complet connu\n",
    "    if code_str in ['FRANCE', 'BELGIQUE', 'ALLEMAGNE', 'ITALIE', 'ESPAGNE']:\n",
    "        return code_str\n",
    "    \n",
    "    # Si c'est le code FR, retourner FRANCE\n",
    "    if code_str == 'FR':\n",
    "        return 'FRANCE'\n",
    "    \n",
    "    # Si c'est un code ISO\n",
    "    if code_str in PAYS:\n",
    "        return PAYS[code_str]\n",
    "    \n",
    "    # Sinon retourner tel quel\n",
    "    return code_str\n",
    "\n",
    "def extraire_code_dept_du_cp(code_postal):\n",
    "    \"\"\"\n",
    "    Extrait le code département du code postal\n",
    "    \"\"\"\n",
    "    if pd.isna(code_postal) or code_postal == '':\n",
    "        return np.nan\n",
    "    \n",
    "    cp_str = str(code_postal).strip().zfill(5)\n",
    "    \n",
    "    # Cas spéciaux pour les DOM-TOM\n",
    "    if cp_str.startswith('971'):\n",
    "        return '971'\n",
    "    elif cp_str.startswith('972'):\n",
    "        return '972'\n",
    "    elif cp_str.startswith('973'):\n",
    "        return '973'\n",
    "    elif cp_str.startswith('974'):\n",
    "        return '974'\n",
    "    elif cp_str.startswith('975'):\n",
    "        return '975'\n",
    "    elif cp_str.startswith('976'):\n",
    "        return '976'\n",
    "    \n",
    "    # Cas spécial pour la Corse\n",
    "    if cp_str.startswith('20'):\n",
    "        # 20000-20199 et 20900-20999 = Corse du Sud (2A)\n",
    "        # 20200-20899 (sauf 20900-20999) = Haute-Corse (2B)\n",
    "        cp_num = int(cp_str)\n",
    "        if (20000 <= cp_num <= 20199) or (20900 <= cp_num <= 20999):\n",
    "            return '2A'\n",
    "        elif 20200 <= cp_num <= 20899:\n",
    "            return '2B'\n",
    "    \n",
    "    # Cas général : les 2 premiers chiffres\n",
    "    return cp_str[:2]\n",
    "\n",
    "def charger_stock_unite_legale(chemin_fichier_stock):\n",
    "    \"\"\"\n",
    "    Charge et prepare les donnees du fichier StockUniteLegale\n",
    "    \"\"\"\n",
    "    print(f\"Chargement du fichier StockUniteLegale : {chemin_fichier_stock}\")\n",
    "    \n",
    "    colonnes_a_garder = [\n",
    "        'siren', 'denominationUniteLegale', 'dateCreationUniteLegale',\n",
    "        'categorieEntreprise', 'trancheEffectifsUniteLegale',\n",
    "        'categorieJuridiqueUniteLegale'  # Ajout de cette colonne\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        stock_df = pd.read_csv(\n",
    "            chemin_fichier_stock,\n",
    "            usecols=colonnes_a_garder,\n",
    "            dtype=str,\n",
    "            encoding='utf-8'\n",
    "        )\n",
    "        \n",
    "        # Standardiser le SIREN\n",
    "        stock_df['siren'] = stock_df['siren'].str.zfill(9)\n",
    "        \n",
    "        print(f\"   {len(stock_df):,} unites legales chargees\")\n",
    "        return stock_df\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERREUR: Fichier StockUniteLegale non trouve : {chemin_fichier_stock}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"ERREUR lors du chargement : {e}\")\n",
    "        return None\n",
    "\n",
    "def charger_stock_etablissement(chemin_fichier_stock_etab, siren_list=None):\n",
    "    \"\"\"\n",
    "    Charge les donnees géographiques du fichier StockEtablissement\n",
    "    \"\"\"\n",
    "    print(f\"Chargement du fichier StockEtablissement : {chemin_fichier_stock_etab}\")\n",
    "    \n",
    "    colonnes_geo = [\n",
    "        'siren', 'siret', 'codePostalEtablissement', \n",
    "        'libelleCommuneEtablissement', 'codePaysEtrangerEtablissement',\n",
    "        'etablissementSiege'\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        # Si on a une liste de SIREN, on peut filtrer pour optimiser\n",
    "        if siren_list is not None:\n",
    "            # Charger par chunks pour les gros fichiers\n",
    "            chunks = []\n",
    "            for chunk in pd.read_csv(\n",
    "                chemin_fichier_stock_etab,\n",
    "                usecols=colonnes_geo,\n",
    "                dtype=str,\n",
    "                encoding='utf-8',\n",
    "                chunksize=100000\n",
    "            ):\n",
    "                # Filtrer seulement les sièges sociaux\n",
    "                chunk = chunk[chunk['etablissementSiege'] == 'true']\n",
    "                chunk['siren'] = chunk['siren'].str.zfill(9)\n",
    "                chunk_filtre = chunk[chunk['siren'].isin(siren_list)]\n",
    "                if len(chunk_filtre) > 0:\n",
    "                    chunks.append(chunk_filtre)\n",
    "            \n",
    "            if chunks:\n",
    "                stock_etab_df = pd.concat(chunks, ignore_index=True)\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            stock_etab_df = pd.read_csv(\n",
    "                chemin_fichier_stock_etab,\n",
    "                usecols=colonnes_geo,\n",
    "                dtype=str,\n",
    "                encoding='utf-8'\n",
    "            )\n",
    "            # Garder seulement les sièges sociaux\n",
    "            stock_etab_df = stock_etab_df[stock_etab_df['etablissementSiege'] == 'true']\n",
    "            stock_etab_df['siren'] = stock_etab_df['siren'].str.zfill(9)\n",
    "        \n",
    "        print(f\"   {len(stock_etab_df):,} etablissements sieges charges\")\n",
    "        return stock_etab_df\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"ATTENTION: Fichier StockEtablissement non trouve : {chemin_fichier_stock_etab}\")\n",
    "        print(\"Les donnees geographiques ne seront pas completees\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"ERREUR lors du chargement : {e}\")\n",
    "        return None\n",
    "\n",
    "def completer_fichier_cible_avec_stock(fichier_cible, chemin_stock, fichier_sortie=None, chemin_stock_etab=None):\n",
    "    \"\"\"\n",
    "    Complete le fichier cible avec les donnees du StockUniteLegale et StockEtablissement\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"COMPLETION DU FICHIER CIBLE AVEC STOCK SIRENE\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. Chargement du fichier cible\n",
    "    print(f\"Chargement du fichier cible : {fichier_cible}\")\n",
    "    try:\n",
    "        df_cible = pd.read_csv(fichier_cible, sep=';', encoding='utf-8-sig')\n",
    "        print(f\"   {len(df_cible):,} lignes chargees\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERREUR: Impossible de charger le fichier cible : {e}\")\n",
    "        return None\n",
    "    \n",
    "    # 2. Chargement du StockUniteLegale\n",
    "    stock_df = charger_stock_unite_legale(chemin_stock)\n",
    "    if stock_df is None:\n",
    "        return None\n",
    "    \n",
    "    # 3. Preparation des donnees pour la jointure\n",
    "    print(\"Preparation des donnees pour jointure...\")\n",
    "    \n",
    "    # Standardiser les SIREN dans le fichier cible\n",
    "    df_cible['siren_std'] = df_cible['siren'].astype(str).str.zfill(9)\n",
    "    df_cible['siren_g_std'] = df_cible['siren_g'].astype(str).str.zfill(9)\n",
    "    \n",
    "    # 4. Jointure pour les SIREN principaux\n",
    "    print(\"Jointure pour les SIREN principaux...\")\n",
    "    df_avec_siren = df_cible.merge(\n",
    "        stock_df,\n",
    "        left_on='siren_std',\n",
    "        right_on='siren',\n",
    "        how='left',\n",
    "        suffixes=('', '_stock_principal')\n",
    "    )\n",
    "    \n",
    "    # 5. Jointure pour les SIREN groupes (nom_g)\n",
    "    print(\"Jointure pour les SIREN groupes...\")\n",
    "    stock_groupe = stock_df[['siren', 'denominationUniteLegale']].copy()\n",
    "    stock_groupe.rename(columns={'denominationUniteLegale': 'nom_g_stock'}, inplace=True)\n",
    "    \n",
    "    df_final = df_avec_siren.merge(\n",
    "        stock_groupe,\n",
    "        left_on='siren_g_std',\n",
    "        right_on='siren',\n",
    "        how='left',\n",
    "        suffixes=('', '_groupe')\n",
    "    )\n",
    "    \n",
    "    # 6. Chargement et jointure avec StockEtablissement si disponible\n",
    "    if chemin_stock_etab and os.path.exists(chemin_stock_etab):\n",
    "        print(\"\\nChargement des donnees geographiques...\")\n",
    "        # Obtenir la liste des SIREN pour optimiser le chargement\n",
    "        siren_uniques = pd.concat([df_final['siren_std'], df_final['siren_g_std']]).unique()\n",
    "        \n",
    "        stock_etab_df = charger_stock_etablissement(chemin_stock_etab, siren_uniques)\n",
    "        \n",
    "        if stock_etab_df is not None:\n",
    "            # Jointure avec les données géographiques\n",
    "            df_final = df_final.merge(\n",
    "                stock_etab_df[['siren', 'codePostalEtablissement', 'libelleCommuneEtablissement', 'codePaysEtrangerEtablissement']],\n",
    "                left_on='siren_std',\n",
    "                right_on='siren',\n",
    "                how='left',\n",
    "                suffixes=('', '_etab')\n",
    "            )\n",
    "    \n",
    "    # 7. Completion et transformation des colonnes\n",
    "    print(\"Completion et transformation des colonnes...\")\n",
    "    \n",
    "    def completer_si_vide(colonne_cible, colonne_source):\n",
    "        \"\"\"Complete la colonne cible seulement si elle est vide\"\"\"\n",
    "        if colonne_cible not in df_final.columns:\n",
    "            df_final[colonne_cible] = np.nan\n",
    "        \n",
    "        mask_vide = (\n",
    "            df_final[colonne_cible].isna() | \n",
    "            (df_final[colonne_cible] == '') | \n",
    "            (df_final[colonne_cible] == 'nan')\n",
    "        )\n",
    "        df_final.loc[mask_vide, colonne_cible] = df_final.loc[mask_vide, colonne_source]\n",
    "    \n",
    "    # Completion des noms (denomination) pour les SIREN principaux\n",
    "    completer_si_vide('nom', 'denominationUniteLegale')\n",
    "    \n",
    "    # Transformation et completion tranche effectifs\n",
    "    print(\"   Transformation des tranches d'effectifs...\")\n",
    "    df_final['treff_transforme'] = df_final['trancheEffectifsUniteLegale'].apply(mapper_tranche_effectifs)\n",
    "    completer_si_vide('treff_benef', 'treff_transforme')\n",
    "    \n",
    "    # Transformation de la date de création en tranche d'années\n",
    "    print(\"   Transformation des dates de création en tranches d'années...\")\n",
    "    df_final['trannee_transforme'] = df_final['dateCreationUniteLegale'].apply(convertir_date_en_tranche)\n",
    "    completer_si_vide('trannee', 'trannee_transforme')\n",
    "    \n",
    "    # Transformation de la catégorie juridique\n",
    "    print(\"   Transformation des catégories juridiques...\")\n",
    "    df_final['cat_jur_transforme'] = df_final['categorieJuridiqueUniteLegale'].apply(mapper_categorie_juridique)\n",
    "    completer_si_vide('cat_jur', 'cat_jur_transforme')\n",
    "    \n",
    "    # Completion nom_g (toujours remplacer comme demande)\n",
    "    mask_siren_g_valide = df_final['nom_g_stock'].notna()\n",
    "    df_final.loc[mask_siren_g_valide, 'nom_g'] = df_final.loc[mask_siren_g_valide, 'nom_g_stock']\n",
    "    \n",
    "    # Completion des données géographiques si disponibles\n",
    "    if 'codePostalEtablissement' in df_final.columns:\n",
    "        print(\"   Completion des donnees geographiques...\")\n",
    "        \n",
    "        # Code postal\n",
    "        completer_si_vide('cp', 'codePostalEtablissement')\n",
    "        \n",
    "        # Commune\n",
    "        completer_si_vide('commune', 'libelleCommuneEtablissement')\n",
    "        \n",
    "        # Département - extraire du code postal et mapper\n",
    "        df_final['dpt_extrait'] = df_final['cp'].apply(extraire_code_dept_du_cp)\n",
    "        df_final['dpt_nom'] = df_final['dpt_extrait'].apply(mapper_departement)\n",
    "        completer_si_vide('dpt', 'dpt_nom')\n",
    "        \n",
    "        # Régions (old_region et region) basées sur le département\n",
    "        print(\"   Ajout des régions (anciennes et nouvelles)...\")\n",
    "        df_final[['old_region_calc', 'region_calc']] = df_final['dpt_extrait'].apply(\n",
    "            lambda x: pd.Series(mapper_regions(x))\n",
    "        )\n",
    "        completer_si_vide('old_region', 'old_region_calc')\n",
    "        completer_si_vide('region', 'region_calc')\n",
    "        \n",
    "        # Pays - toujours FRANCE et non FR\n",
    "        df_final['pays_code'] = df_final['codePaysEtrangerEtablissement'].fillna('FR')\n",
    "        df_final['pays_nom'] = df_final['pays_code'].apply(lambda x: 'FRANCE' if x == 'FR' else mapper_pays(x))\n",
    "        completer_si_vide('pays_siege', 'pays_nom')\n",
    "    else:\n",
    "        print(\"   ATTENTION: Donnees geographiques non disponibles (fichier StockEtablissement manquant)\")\n",
    "        # Si pas de données géographiques mais qu'on a des codes postaux existants\n",
    "        if 'cp' in df_final.columns:\n",
    "            # Essayer d'extraire le département du code postal existant\n",
    "            df_final['dpt_extrait'] = df_final['cp'].apply(extraire_code_dept_du_cp)\n",
    "            df_final['dpt_nom'] = df_final['dpt_extrait'].apply(mapper_departement)\n",
    "            completer_si_vide('dpt', 'dpt_nom')\n",
    "            \n",
    "            # Régions basées sur le département existant\n",
    "            df_final[['old_region_calc', 'region_calc']] = df_final['dpt_extrait'].apply(\n",
    "                lambda x: pd.Series(mapper_regions(x))\n",
    "            )\n",
    "            completer_si_vide('old_region', 'old_region_calc')\n",
    "            completer_si_vide('region', 'region_calc')\n",
    "        \n",
    "        # Si on n'a pas de pays_siege, mettre FRANCE par défaut\n",
    "        if 'pays_siege' not in df_final.columns:\n",
    "            df_final['pays_siege'] = 'FRANCE'\n",
    "        else:\n",
    "            mask_pays_vide = df_final['pays_siege'].isna() | (df_final['pays_siege'] == '')\n",
    "            df_final.loc[mask_pays_vide, 'pays_siege'] = 'FRANCE'\n",
    "    \n",
    "    # 8. Nettoyage des colonnes temporaires\n",
    "    colonnes_a_supprimer = [\n",
    "        'siren_std', 'siren_g_std', 'siren_stock_principal', 'siren_groupe', 'siren_etab',\n",
    "        'denominationUniteLegale', 'dateCreationUniteLegale', \n",
    "        'categorieEntreprise', 'trancheEffectifsUniteLegale', 'nom_g_stock',\n",
    "        'categorieJuridiqueUniteLegale', 'trannee_transforme', 'cat_jur_transforme',\n",
    "        'treff_transforme', 'codePostalEtablissement', 'libelleCommuneEtablissement', \n",
    "        'codePaysEtrangerEtablissement', 'dpt_extrait', 'dpt_nom', 'pays_code', \n",
    "        'pays_nom', 'old_region_calc', 'region_calc'\n",
    "    ]\n",
    "    \n",
    "    for col in colonnes_a_supprimer:\n",
    "        if col in df_final.columns:\n",
    "            df_final.drop(columns=[col], inplace=True)\n",
    "    \n",
    "    # 9. Statistiques de completion\n",
    "    print(\"\\nStatistiques de completion:\")\n",
    "    \n",
    "    colonnes_completees = ['nom', 'treff_benef', 'trannee', 'cat_jur', 'nom_g', 'cp', 'commune', 'dpt', 'old_region', 'region', 'pays_siege']\n",
    "    for colonne in colonnes_completees:\n",
    "        if colonne in df_final.columns:\n",
    "            avant = df_cible[colonne].notna().sum() if colonne in df_cible.columns else 0\n",
    "            apres = df_final[colonne].notna().sum()\n",
    "            ajoutes = apres - avant\n",
    "            print(f\"   {colonne}: {avant} -> {apres} (+{ajoutes})\")\n",
    "    \n",
    "    # 10. Sauvegarde\n",
    "    if fichier_sortie is None:\n",
    "        fichier_sortie = fichier_cible.replace('.csv', '_complete_stock.csv')\n",
    "    \n",
    "    print(f\"\\nSauvegarde : {fichier_sortie}\")\n",
    "    df_final.to_csv(fichier_sortie, sep=';', index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"\\nCOMPLETION TERMINEE\")\n",
    "    print(f\"Fichier sauvegarde : {fichier_sortie}\")\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "def verifier_qualite_completion(df_resultat):\n",
    "    \"\"\"\n",
    "    Verifie la qualite de la completion\n",
    "    \"\"\"\n",
    "    print(\"\\nVERIFICATION QUALITE:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    total_lignes = len(df_resultat)\n",
    "    colonnes_a_verifier = ['nom', 'treff_benef', 'trannee', 'cat_jur', 'nom_g', 'cp', 'commune', 'dpt', 'old_region', 'region', 'pays_siege']\n",
    "    \n",
    "    for col in colonnes_a_verifier:\n",
    "        if col in df_resultat.columns:\n",
    "            remplies = df_resultat[col].notna().sum()\n",
    "            pourcentage = (remplies / total_lignes) * 100\n",
    "            print(f\"   {col}: {remplies}/{total_lignes} ({pourcentage:.1f}%)\")\n",
    "    \n",
    "    # Afficher quelques exemples de transformations\n",
    "    print(\"\\nExemples de transformations:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    if 'trannee' in df_resultat.columns:\n",
    "        print(\"\\nTranches d'années (simplifiées):\")\n",
    "        print(df_resultat['trannee'].value_counts().sort_index())\n",
    "    \n",
    "    if 'treff_benef' in df_resultat.columns:\n",
    "        print(\"\\nTranches d'effectifs:\")\n",
    "        print(df_resultat['treff_benef'].value_counts().head(10))\n",
    "    \n",
    "    if 'cat_jur' in df_resultat.columns:\n",
    "        print(\"\\nCatégories juridiques (Top 10):\")\n",
    "        print(df_resultat['cat_jur'].value_counts().head(10))\n",
    "    \n",
    "    if 'region' in df_resultat.columns:\n",
    "        print(\"\\nRégions (nouvelles) (Top 10):\")\n",
    "        print(df_resultat['region'].value_counts().head(10))\n",
    "    \n",
    "    if 'dpt' in df_resultat.columns:\n",
    "        print(\"\\nDépartements (Top 10):\")\n",
    "        print(df_resultat['dpt'].value_counts().head(10))\n",
    "    \n",
    "    if 'pays_siege' in df_resultat.columns:\n",
    "        print(\"\\nPays:\")\n",
    "        pays_counts = df_resultat['pays_siege'].value_counts()\n",
    "        print(pays_counts.head(10) if len(pays_counts) > 10 else pays_counts)\n",
    "    \n",
    "    # Verification des SIREN non trouves\n",
    "    siren_non_trouves = df_resultat[df_resultat['treff_benef'].isna()]\n",
    "    if len(siren_non_trouves) > 0:\n",
    "        print(f\"\\nSIREN non trouves dans StockUniteLegale: {len(siren_non_trouves)}\")\n",
    "        print(\"Exemples:\")\n",
    "        colonnes_exemple = [col for col in ['siren', 'nom'] if col in df_resultat.columns]\n",
    "        if colonnes_exemple:\n",
    "            print(siren_non_trouves[colonnes_exemple].head())\n",
    "\n",
    "# Script principal\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # PARAMETRES A MODIFIER\n",
    "    FICHIER_CIBLE = \"C://Users//msamb//Documents//base_final_2021_suite_final.csv\"\n",
    "    FICHIER_STOCK = \"C://Users//msamb//Documents//StockUniteLegale_utf8.csv\"\n",
    "    FICHIER_STOCK_ETAB = \"C://Users//msamb//Documents//StockEtablissement_utf8.csv\"  # Optionnel\n",
    "    FICHIER_SORTIE = \"C://Users//msamb//Documents//base_final_2021_suite_final_complet_stock.csv\"\n",
    "    \n",
    "    print(\"DEMARRAGE DU PROCESSUS DE COMPLETION\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Transformations qui seront appliquées:\")\n",
    "    print(\"- trannee: dates -> tranches simplifiées (ex: 'avant 1980', 'de 1980 à 1989'...)\")\n",
    "    print(\"- treff_benef: codes -> libellés (ex: '41' -> '500 à 999 salariés')\")\n",
    "    print(\"- cat_jur: codes -> libellés (ex: 5710 -> 'SAS')\")\n",
    "    print(\"- dpt: codes -> noms (ex: 75 -> 'Paris')\")\n",
    "    print(\"- old_region: ancienne région administrative\")\n",
    "    print(\"- region: nouvelle région (réforme 2016)\")\n",
    "    print(\"- pays_siege: 'FRANCE' par défaut\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Verification de l'existence des fichiers\n",
    "    if not os.path.exists(FICHIER_CIBLE):\n",
    "        print(f\"ERREUR: Fichier cible non trouve : {FICHIER_CIBLE}\")\n",
    "        exit(1)\n",
    "    \n",
    "    if not os.path.exists(FICHIER_STOCK):\n",
    "        print(f\"ERREUR: Fichier StockUniteLegale non trouve : {FICHIER_STOCK}\")\n",
    "        print(\"Telechargez le fichier depuis : https://www.data.gouv.fr/fr/datasets/base-sirene-des-entreprises-et-de-leurs-etablissements-siren-siret/\")\n",
    "        exit(1)\n",
    "    \n",
    "    # Vérifier si le fichier StockEtablissement existe\n",
    "    if not os.path.exists(FICHIER_STOCK_ETAB):\n",
    "        print(f\"ATTENTION: Fichier StockEtablissement non trouve : {FICHIER_STOCK_ETAB}\")\n",
    "        print(\"Les donnees geographiques (cp, commune) ne pourront pas etre completees depuis SIRENE\")\n",
    "        print(\"Mais les departements seront deduits des codes postaux existants\")\n",
    "        FICHIER_STOCK_ETAB = None\n",
    "    \n",
    "    # Lancement de la completion\n",
    "    try:\n",
    "        df_complete = completer_fichier_cible_avec_stock(\n",
    "            fichier_cible=FICHIER_CIBLE,\n",
    "            chemin_stock=FICHIER_STOCK,\n",
    "            fichier_sortie=FICHIER_SORTIE,\n",
    "            chemin_stock_etab=FICHIER_STOCK_ETAB\n",
    "        )\n",
    "        \n",
    "        if df_complete is not None:\n",
    "            # Verification de la qualite\n",
    "            verifier_qualite_completion(df_complete)\n",
    "            \n",
    "            # Apercu du resultat\n",
    "            print(f\"\\nAPERCU DU RESULTAT:\")\n",
    "            print(\"-\" * 30)\n",
    "            colonnes_affichage = ['siren', 'nom', 'siren_g', 'nom_g', 'treff_benef', 'trannee', 'cat_jur', 'cp', 'commune', 'dpt', 'old_region', 'region', 'pays_siege']\n",
    "            colonnes_disponibles = [col for col in colonnes_affichage if col in df_complete.columns]\n",
    "            \n",
    "            if colonnes_disponibles:\n",
    "                # Afficher seulement quelques colonnes à la fois pour la lisibilité\n",
    "                print(\"\\nDonnées principales:\")\n",
    "                colonnes_principales = ['siren', 'nom', 'treff_benef', 'trannee', 'cat_jur']\n",
    "                colonnes_principales_dispo = [col for col in colonnes_principales if col in df_complete.columns]\n",
    "                if colonnes_principales_dispo:\n",
    "                    print(df_complete[colonnes_principales_dispo].head(5).to_string())\n",
    "                \n",
    "                print(\"\\nDonnées géographiques:\")\n",
    "                colonnes_geo = ['siren', 'cp', 'commune', 'dpt', 'old_region', 'region', 'pays_siege']\n",
    "                colonnes_geo_dispo = [col for col in colonnes_geo if col in df_complete.columns]\n",
    "                if colonnes_geo_dispo:\n",
    "                    print(df_complete[colonnes_geo_dispo].head(5).to_string())\n",
    "            \n",
    "            print(f\"\\nProcessus termine avec succes.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERREUR: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83dfb1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\msamb\\appdata\\local\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\msamb\\appdata\\local\\anaconda3\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\msamb\\appdata\\local\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\msamb\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\msamb\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\msamb\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\msamb\\appdata\\local\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\msamb\\appdata\\local\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas openpyxl numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af553321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCRIPT DE FUSION CIR 2021 - VERSION FINALE\n",
      "==================================================\n",
      "Ce script va:\n",
      "1. Pour les SIREN uniquement dans CIR: garder tel quel\n",
      "2. Pour les SIREN uniquement dans la base: garder tel quel\n",
      "3. Pour les SIREN mixtes:\n",
      "   - Prendre TOUTES les colonnes de la base\n",
      "   - SAUF 'type' qui vient du CIR\n",
      "   - Ajouter les 4 montants du prov21:\n",
      "     • cretot_gen\n",
      "     • crerd_gen\n",
      "     • crecoll_gen\n",
      "     • creinno_gen\n",
      "4. Ajouter une colonne 'source' pour la traçabilité\n",
      "==================================================\n",
      "\n",
      "Chargement du fichier CIR original pour comparaison...\n",
      "\n",
      "Chargement du fichier CIR original: M://str-dgri-gecir-donnees-fiscales//z_Statistiques Séries Demandes//2021//0_BASE_CIR2021prov_extr202306.xlsx\n",
      "   Format détecté: Excel (.xlsx)\n",
      "   28,810 lignes chargées\n",
      "   157 colonnes: siren, nom, siren_g, nom_g, type...\n",
      "\n",
      "======================================================================\n",
      "FUSION DES FICHIERS CIR 2021 - VERSION FINALE\n",
      "======================================================================\n",
      "\n",
      "Chargement du fichier CIR 2021 prov (ancien): M://str-dgri-gecir-donnees-fiscales//z_Statistiques Séries Demandes//2021//0_BASE_CIR2021prov_extr202306.xlsx\n",
      "   Format détecté: Excel (.xlsx)\n",
      "   28,810 lignes chargées\n",
      "   157 colonnes: siren, nom, siren_g, nom_g, type...\n",
      "\n",
      "Chargement du fichier Base complétée: C://Users//msamb//Documents//base_final_2021_suite_final_complet_stock.csv\n",
      "   Séparateur détecté: point-virgule (;)\n",
      "   4,619 lignes chargées\n",
      "   157 colonnes: siren, nom, siren_g, nom_g, type...\n",
      "\n",
      "Identification des colonnes SIREN...\n",
      "   Colonne SIREN dans CIR: 'siren'\n",
      "   Colonne SIREN dans Base: 'siren'\n",
      "\n",
      "Standardisation des SIREN...\n",
      "\n",
      "Transformation des dates en tranches d'années...\n",
      "   Échantillon après transformation:\n",
      "   []\n",
      "\n",
      "Vérification de l'unicité des SIREN...\n",
      "   ATTENTION: 11 SIREN en double dans la base - suppression...\n",
      "\n",
      "Analyse des données:\n",
      "   Lignes dans CIR (après dédoublonnage): 28,810\n",
      "   Lignes dans Base (après dédoublonnage): 4,523\n",
      "\n",
      "   SIREN présents dans les deux fichiers: 479\n",
      "   SIREN uniquement dans CIR: 28,331\n",
      "   SIREN uniquement dans Base: 4,044\n",
      "\n",
      "Création des DataFrames par groupe...\n",
      "\n",
      "Traitement des 479 SIREN mixtes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_2340\\1033389304.py:55: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(chemin_fichier, sep=';', encoding='utf-8-sig')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Colonne 'type' remplacée par celle du CIR\n",
      "   ✓ Montant cretot_gen du prov21 ajouté\n",
      "   ✓ Montant crerd_gen du prov21 ajouté\n",
      "   ✓ Montant crecoll_gen du prov21 ajouté\n",
      "   ✓ Montant creinno_gen du prov21 ajouté\n",
      "\n",
      "Alignement des colonnes...\n",
      "\n",
      "Fusion finale des trois groupes...\n",
      "\n",
      "Vérifications finales:\n",
      "   Nombre total de lignes: 32,854\n",
      "   Nombre de SIREN uniques: 32,854\n",
      "   ✓ Pas de doublons - Une seule ligne par SIREN\n",
      "\n",
      "Distribution des sources:\n",
      "source\n",
      "prov2021                   28331\n",
      "base_2021_suite             4044\n",
      "mixte_prov2021_base2021      479\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Vérification des tranches d'années:\n",
      "trannee\n",
      "de 2010 à 2019    12032\n",
      "de 2000 à 2009     6419\n",
      "de 1990 à 1999     3666\n",
      "de 1980 à 1989     2317\n",
      "avant 1980         2256\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Statistiques sur les montants prov21 ajoutés:\n",
      "   Montants cretot_gen renseignés: 479\n",
      "   Montants crerd_gen renseignés: 479\n",
      "   Montants crecoll_gen renseignés: 479\n",
      "   Montants creinno_gen renseignés: 479\n",
      "\n",
      "Sauvegarde du fichier fusionné : C://Users//msamb//Documents//cir_2021_prov_fusion_finale.xlsx\n",
      "✓ Fichier sauvegardé avec formatage : C://Users//msamb//Documents//cir_2021_prov_fusion_finale.xlsx\n",
      "\n",
      "✓ FUSION TERMINÉE AVEC SUCCÈS\n",
      "✓ Une seule ligne par SIREN\n",
      "✓ Pour les mixtes: données de la base + type du CIR + 4 montants du prov21\n",
      "\n",
      "==================================================\n",
      "COMPARAISON AVANT/APRÈS\n",
      "==================================================\n",
      "\n",
      "Nombre de lignes:\n",
      "   CIR original: 28,810\n",
      "   Fichier fusionné: 32,854\n",
      "   Différence: +4,044\n",
      "\n",
      "Taux de remplissage des colonnes:\n",
      "\n",
      "nom:\n",
      "   Avant: 28,810/28,810 (100.0%)\n",
      "   Après: 32,745/32,854 (99.7%)\n",
      "   Amélioration: -0.3 points\n",
      "\n",
      "cat_jur:\n",
      "   Avant: 28,810/28,810 (100.0%)\n",
      "   Après: 32,854/32,854 (100.0%)\n",
      "   Amélioration: +0.0 points\n",
      "\n",
      "trannee:\n",
      "   Avant: 28,810/28,810 (100.0%)\n",
      "   Après: 28,331/32,854 (86.2%)\n",
      "   Amélioration: -13.8 points\n",
      "\n",
      "commune:\n",
      "   Avant: 28,810/28,810 (100.0%)\n",
      "   Après: 30,263/32,854 (92.1%)\n",
      "   Amélioration: -7.9 points\n",
      "\n",
      "dpt:\n",
      "   Avant: 28,810/28,810 (100.0%)\n",
      "   Après: 30,263/32,854 (92.1%)\n",
      "   Amélioration: -7.9 points\n",
      "\n",
      "cp:\n",
      "   Avant: 28,810/28,810 (100.0%)\n",
      "   Après: 30,263/32,854 (92.1%)\n",
      "   Amélioration: -7.9 points\n",
      "\n",
      "treff_benef:\n",
      "   Avant: 28,810/28,810 (100.0%)\n",
      "   Après: 31,266/32,854 (95.2%)\n",
      "   Amélioration: -4.8 points\n",
      "\n",
      "old_region:\n",
      "   Avant: 28,810/28,810 (100.0%)\n",
      "   Après: 30,253/32,854 (92.1%)\n",
      "   Amélioration: -7.9 points\n",
      "\n",
      "region:\n",
      "   Avant: 28,810/28,810 (100.0%)\n",
      "   Après: 30,253/32,854 (92.1%)\n",
      "   Amélioration: -7.9 points\n",
      "\n",
      "pays_siege:\n",
      "   Avant: 28,810/28,810 (100.0%)\n",
      "   Après: 32,854/32,854 (100.0%)\n",
      "   Amélioration: +0.0 points\n",
      "\n",
      "✓ Processus terminé avec succès!\n",
      "✓ 32,854 lignes au total\n",
      "✓ Les 4 colonnes de montants prov21 ont été ajoutées:\n",
      "  - montant_cretot_gen_prov21\n",
      "  - montant_crerd_gen_prov21\n",
      "  - montant_crecoll_gen_prov21\n",
      "  - montant_creinno_gen_prov21\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import openpyxl\n",
    "from datetime import datetime\n",
    "\n",
    "def convertir_date_en_tranche(date_creation):\n",
    "    \"\"\"\n",
    "    Convertit une date de création en tranche d'années simplifiée\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if pd.isna(date_creation) or date_creation == '':\n",
    "            return np.nan\n",
    "        \n",
    "        # Si c'est déjà une tranche, la retourner\n",
    "        date_str = str(date_creation)\n",
    "        if 'avant' in date_str or 'de ' in date_str:\n",
    "            return date_creation\n",
    "        \n",
    "        # Extraire l'année de la date\n",
    "        if len(date_str) >= 4:\n",
    "            annee = int(date_str[:4])\n",
    "        else:\n",
    "            return np.nan\n",
    "        \n",
    "        # Déterminer la tranche simplifiée\n",
    "        if annee < 1980:\n",
    "            return \"avant 1980\"\n",
    "        elif annee < 1990:\n",
    "            return \"de 1980 à 1989\"\n",
    "        elif annee < 2000:\n",
    "            return \"de 1990 à 1999\"\n",
    "        elif annee < 2010:\n",
    "            return \"de 2000 à 2009\"\n",
    "        elif annee < 2020:\n",
    "            return \"de 2010 à 2019\"\n",
    "        else:\n",
    "            return \"de 2020 à aujourd'hui\"\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def charger_fichier_auto(chemin_fichier, nom_fichier=\"\"):\n",
    "    \"\"\"\n",
    "    Charge un fichier CSV ou Excel en détectant automatiquement le séparateur ou le format.\n",
    "    \"\"\"\n",
    "    print(f\"\\nChargement du fichier {nom_fichier}: {chemin_fichier}\")\n",
    "    try:\n",
    "        ext = os.path.splitext(chemin_fichier)[-1].lower()\n",
    "        if ext in [\".xls\", \".xlsx\"]:\n",
    "            df = pd.read_excel(chemin_fichier)\n",
    "            print(f\"   Format détecté: Excel ({ext})\")\n",
    "        elif ext == \".csv\":\n",
    "            df = pd.read_csv(chemin_fichier, sep=';', encoding='utf-8-sig', nrows=5)\n",
    "            if len(df.columns) > 1:\n",
    "                df = pd.read_csv(chemin_fichier, sep=';', encoding='utf-8-sig')\n",
    "                print(f\"   Séparateur détecté: point-virgule (;)\")\n",
    "            else:\n",
    "                df = pd.read_csv(chemin_fichier, sep=',', encoding='utf-8-sig')\n",
    "                print(f\"   Séparateur détecté: virgule (,)\")\n",
    "        else:\n",
    "            print(f\"   ERREUR: Format de fichier non supporté ({ext})\")\n",
    "            return None\n",
    "        print(f\"   {len(df):,} lignes chargées\")\n",
    "        print(f\"   {len(df.columns)} colonnes: {', '.join(df.columns[:5])}...\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"ERREUR lors du chargement: {e}\")\n",
    "        return None\n",
    "\n",
    "def remplacer_donnees_excel_modele(fichier_modele, fichier_nouveau, df):\n",
    "    \"\"\"\n",
    "    Copie le fichier Excel modèle, et remplace les données par celles de df,\n",
    "    en conservant les styles, formats, filtres, etc.\n",
    "    \"\"\"\n",
    "    wb = openpyxl.load_workbook(fichier_modele)\n",
    "    ws = wb.active\n",
    "\n",
    "    # Efface toutes les lignes de données sauf l'en-tête\n",
    "    ws.delete_rows(2, ws.max_row - 1)\n",
    "\n",
    "    # Insère les nouvelles lignes de données\n",
    "    for r_idx, row in enumerate(df.itertuples(index=False, name=None), start=2):\n",
    "        for c_idx, value in enumerate(row, start=1):\n",
    "            ws.cell(row=r_idx, column=c_idx, value=value)\n",
    "\n",
    "    # Enregistre le nouveau fichier\n",
    "    wb.save(fichier_nouveau)\n",
    "    print(f\"✓ Fichier sauvegardé avec formatage : {fichier_nouveau}\")\n",
    "\n",
    "def fusionner_fichiers_cir(fichier_cir_ancien, fichier_base_complete, fichier_sortie=None):\n",
    "    \"\"\"\n",
    "    Fusionne le fichier CIR ancien avec le fichier base complété.\n",
    "    Pour les mixtes : prend tout de la base sauf le type, et ajoute les montants du prov21\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"FUSION DES FICHIERS CIR 2021 - VERSION FINALE\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # 1. Chargement des fichiers\n",
    "    df_cir = charger_fichier_auto(fichier_cir_ancien, \"CIR 2021 prov (ancien)\")\n",
    "    if df_cir is None:\n",
    "        return None\n",
    "\n",
    "    df_base = charger_fichier_auto(fichier_base_complete, \"Base complétée\")\n",
    "    if df_base is None:\n",
    "        return None\n",
    "\n",
    "    # 2. Identification des colonnes SIREN\n",
    "    print(\"\\nIdentification des colonnes SIREN...\")\n",
    "    siren_col_cir = None\n",
    "    siren_col_base = None\n",
    "\n",
    "    for col in df_cir.columns:\n",
    "        if col.lower() in ['siren', 'siren_benef', 'num_siren']:\n",
    "            siren_col_cir = col\n",
    "            break\n",
    "\n",
    "    for col in df_base.columns:\n",
    "        if col.lower() in ['siren', 'siren_benef', 'num_siren']:\n",
    "            siren_col_base = col\n",
    "            break\n",
    "\n",
    "    if not siren_col_cir or not siren_col_base:\n",
    "        print(\"ERREUR: Colonne SIREN non trouvée\")\n",
    "        return None\n",
    "\n",
    "    print(f\"   Colonne SIREN dans CIR: '{siren_col_cir}'\")\n",
    "    print(f\"   Colonne SIREN dans Base: '{siren_col_base}'\")\n",
    "\n",
    "    # Renommer la colonne SIREN de la base si nécessaire\n",
    "    if siren_col_base != siren_col_cir:\n",
    "        df_base = df_base.rename(columns={siren_col_base: siren_col_cir})\n",
    "\n",
    "    # 3. Standardiser les SIREN\n",
    "    print(\"\\nStandardisation des SIREN...\")\n",
    "    df_cir['SIREN_STD'] = df_cir[siren_col_cir].astype(str).str.zfill(9)\n",
    "    df_base['SIREN_STD'] = df_base[siren_col_cir].astype(str).str.zfill(9)\n",
    "\n",
    "    # 4. Transformer les dates en tranches dans la base\n",
    "    print(\"\\nTransformation des dates en tranches d'années...\")\n",
    "    if 'trannee' in df_base.columns:\n",
    "        df_base['trannee'] = df_base['trannee'].apply(convertir_date_en_tranche)\n",
    "        print(\"   Échantillon après transformation:\")\n",
    "        print(f\"   {df_base['trannee'].dropna().head(5).tolist()}\")\n",
    "\n",
    "    # 5. Vérifier et éliminer les doublons\n",
    "    print(\"\\nVérification de l'unicité des SIREN...\")\n",
    "    doublons_cir = df_cir[df_cir['SIREN_STD'].duplicated()]['SIREN_STD'].nunique()\n",
    "    doublons_base = df_base[df_base['SIREN_STD'].duplicated()]['SIREN_STD'].nunique()\n",
    "    \n",
    "    if doublons_cir > 0:\n",
    "        print(f\"   ATTENTION: {doublons_cir} SIREN en double dans le CIR - suppression...\")\n",
    "        df_cir = df_cir.drop_duplicates(subset=['SIREN_STD'], keep='first')\n",
    "        \n",
    "    if doublons_base > 0:\n",
    "        print(f\"   ATTENTION: {doublons_base} SIREN en double dans la base - suppression...\")\n",
    "        df_base = df_base.drop_duplicates(subset=['SIREN_STD'], keep='first')\n",
    "\n",
    "    # 6. Analyse des données\n",
    "    print(\"\\nAnalyse des données:\")\n",
    "    print(f\"   Lignes dans CIR (après dédoublonnage): {len(df_cir):,}\")\n",
    "    print(f\"   Lignes dans Base (après dédoublonnage): {len(df_base):,}\")\n",
    "\n",
    "    # Identifier les groupes de SIREN\n",
    "    siren_cir = set(df_cir['SIREN_STD'])\n",
    "    siren_base = set(df_base['SIREN_STD'])\n",
    "    \n",
    "    siren_communs = siren_cir & siren_base\n",
    "    siren_cir_seuls = siren_cir - siren_base\n",
    "    siren_base_seuls = siren_base - siren_cir\n",
    "    \n",
    "    print(f\"\\n   SIREN présents dans les deux fichiers: {len(siren_communs):,}\")\n",
    "    print(f\"   SIREN uniquement dans CIR: {len(siren_cir_seuls):,}\")\n",
    "    print(f\"   SIREN uniquement dans Base: {len(siren_base_seuls):,}\")\n",
    "\n",
    "    # 7. Création des DataFrames pour chaque groupe\n",
    "    print(\"\\nCréation des DataFrames par groupe...\")\n",
    "    \n",
    "    # A. SIREN uniquement dans CIR (on garde tel quel)\n",
    "    df_cir_seuls = df_cir[df_cir['SIREN_STD'].isin(siren_cir_seuls)].copy()\n",
    "    df_cir_seuls['source'] = 'prov2021'\n",
    "    df_cir_seuls['montant_cretot_gen_prov21'] = np.nan\n",
    "    df_cir_seuls['montant_crerd_gen_prov21'] = np.nan\n",
    "    df_cir_seuls['montant_crecoll_gen_prov21'] = np.nan\n",
    "    df_cir_seuls['montant_creinno_gen_prov21'] = np.nan\n",
    "    \n",
    "    # B. SIREN uniquement dans la base (on garde tel quel)\n",
    "    df_base_seuls = df_base[df_base['SIREN_STD'].isin(siren_base_seuls)].copy()\n",
    "    df_base_seuls['source'] = 'base_2021_suite'\n",
    "    df_base_seuls['montant_cretot_gen_prov21'] = np.nan\n",
    "    df_base_seuls['montant_crerd_gen_prov21'] = np.nan\n",
    "    df_base_seuls['montant_crecoll_gen_prov21'] = np.nan\n",
    "    df_base_seuls['montant_creinno_gen_prov21'] = np.nan\n",
    "    \n",
    "    # C. SIREN communs (mixtes)\n",
    "    print(f\"\\nTraitement des {len(siren_communs):,} SIREN mixtes...\")\n",
    "    df_mixtes = df_base[df_base['SIREN_STD'].isin(siren_communs)].copy()\n",
    "    \n",
    "    # Pour les mixtes, on prend la base MAIS on remplace le type par celui du CIR\n",
    "    # et on ajoute les montants du CIR\n",
    "    df_cir_pour_mixtes = df_cir[df_cir['SIREN_STD'].isin(siren_communs)].set_index('SIREN_STD')\n",
    "    df_mixtes = df_mixtes.set_index('SIREN_STD')\n",
    "    \n",
    "    # Remplacer le type par celui du CIR\n",
    "    if 'type' in df_cir_pour_mixtes.columns and 'type' in df_mixtes.columns:\n",
    "        df_mixtes['type'] = df_cir_pour_mixtes['type']\n",
    "        print(\"   ✓ Colonne 'type' remplacée par celle du CIR\")\n",
    "    \n",
    "    # Ajouter les montants du prov21\n",
    "    if 'cretot_gen' in df_cir_pour_mixtes.columns:\n",
    "        df_mixtes['montant_cretot_gen_prov21'] = df_cir_pour_mixtes['cretot_gen']\n",
    "        print(\"   ✓ Montant cretot_gen du prov21 ajouté\")\n",
    "    else:\n",
    "        df_mixtes['montant_cretot_gen_prov21'] = np.nan\n",
    "        print(\"   ! Colonne cretot_gen non trouvée dans prov21\")\n",
    "    \n",
    "    if 'crerd_gen' in df_cir_pour_mixtes.columns:\n",
    "        df_mixtes['montant_crerd_gen_prov21'] = df_cir_pour_mixtes['crerd_gen']\n",
    "        print(\"   ✓ Montant crerd_gen du prov21 ajouté\")\n",
    "    else:\n",
    "        df_mixtes['montant_crerd_gen_prov21'] = np.nan\n",
    "        print(\"   ! Colonne crerd_gen non trouvée dans prov21\")\n",
    "    \n",
    "    if 'crecoll_gen' in df_cir_pour_mixtes.columns:\n",
    "        df_mixtes['montant_crecoll_gen_prov21'] = df_cir_pour_mixtes['crecoll_gen']\n",
    "        print(\"   ✓ Montant crecoll_gen du prov21 ajouté\")\n",
    "    else:\n",
    "        df_mixtes['montant_crecoll_gen_prov21'] = np.nan\n",
    "        print(\"   ! Colonne crecoll_gen non trouvée dans prov21\")\n",
    "    \n",
    "    if 'creinno_gen' in df_cir_pour_mixtes.columns:\n",
    "        df_mixtes['montant_creinno_gen_prov21'] = df_cir_pour_mixtes['creinno_gen']\n",
    "        print(\"   ✓ Montant creinno_gen du prov21 ajouté\")\n",
    "    else:\n",
    "        df_mixtes['montant_creinno_gen_prov21'] = np.nan\n",
    "        print(\"   ! Colonne creinno_gen non trouvée dans prov21\")\n",
    "    \n",
    "    df_mixtes['source'] = 'mixte_prov2021_base2021'\n",
    "    df_mixtes = df_mixtes.reset_index()\n",
    "    \n",
    "    # 8. Alignement des colonnes\n",
    "    print(\"\\nAlignement des colonnes...\")\n",
    "    \n",
    "    # Obtenir toutes les colonnes uniques\n",
    "    toutes_colonnes = set()\n",
    "    for df in [df_cir_seuls, df_base_seuls, df_mixtes]:\n",
    "        toutes_colonnes.update(df.columns)\n",
    "    \n",
    "    # Supprimer SIREN_STD de la liste (sera remplacé par la colonne SIREN originale)\n",
    "    toutes_colonnes.discard('SIREN_STD')\n",
    "    \n",
    "    # Ajouter les colonnes manquantes\n",
    "    for df in [df_cir_seuls, df_base_seuls, df_mixtes]:\n",
    "        for col in toutes_colonnes:\n",
    "            if col not in df.columns:\n",
    "                df[col] = np.nan\n",
    "    \n",
    "    # 9. Fusion finale\n",
    "    print(\"\\nFusion finale des trois groupes...\")\n",
    "    \n",
    "    # Supprimer SIREN_STD avant la concatenation\n",
    "    for df in [df_cir_seuls, df_base_seuls, df_mixtes]:\n",
    "        if 'SIREN_STD' in df.columns:\n",
    "            df.drop(columns=['SIREN_STD'], inplace=True)\n",
    "    \n",
    "    df_final = pd.concat([df_mixtes, df_cir_seuls, df_base_seuls], ignore_index=True)\n",
    "    \n",
    "    # 10. Vérifications finales\n",
    "    print(f\"\\nVérifications finales:\")\n",
    "    print(f\"   Nombre total de lignes: {len(df_final):,}\")\n",
    "    print(f\"   Nombre de SIREN uniques: {df_final[siren_col_cir].nunique():,}\")\n",
    "    \n",
    "    if len(df_final) != df_final[siren_col_cir].nunique():\n",
    "        print(\"   ATTENTION: Il reste des doublons!\")\n",
    "    else:\n",
    "        print(\"   ✓ Pas de doublons - Une seule ligne par SIREN\")\n",
    "    \n",
    "    print(\"\\nDistribution des sources:\")\n",
    "    print(df_final['source'].value_counts())\n",
    "    \n",
    "    # Vérifier trannee\n",
    "    if 'trannee' in df_final.columns:\n",
    "        print(\"\\nVérification des tranches d'années:\")\n",
    "        print(df_final['trannee'].value_counts().head())\n",
    "    \n",
    "    # Statistiques sur les montants ajoutés\n",
    "    print(\"\\nStatistiques sur les montants prov21 ajoutés:\")\n",
    "    montants_cretot = df_final[df_final['source'] == 'mixte_prov2021_base2021']['montant_cretot_gen_prov21'].notna().sum()\n",
    "    montants_crerd = df_final[df_final['source'] == 'mixte_prov2021_base2021']['montant_crerd_gen_prov21'].notna().sum()\n",
    "    montants_crecoll = df_final[df_final['source'] == 'mixte_prov2021_base2021']['montant_crecoll_gen_prov21'].notna().sum()\n",
    "    montants_creinno = df_final[df_final['source'] == 'mixte_prov2021_base2021']['montant_creinno_gen_prov21'].notna().sum()\n",
    "    print(f\"   Montants cretot_gen renseignés: {montants_cretot:,}\")\n",
    "    print(f\"   Montants crerd_gen renseignés: {montants_crerd:,}\")\n",
    "    print(f\"   Montants crecoll_gen renseignés: {montants_crecoll:,}\")\n",
    "    print(f\"   Montants creinno_gen renseignés: {montants_creinno:,}\")\n",
    "    \n",
    "    # 11. Réorganiser les colonnes\n",
    "    # Mettre source et les montants prov21 à la fin\n",
    "    colonnes_fin = ['source', 'montant_cretot_gen_prov21', 'montant_crerd_gen_prov21', \n",
    "                    'montant_crecoll_gen_prov21', 'montant_creinno_gen_prov21']\n",
    "    colonnes_debut = [col for col in df_final.columns if col not in colonnes_fin]\n",
    "    df_final = df_final[colonnes_debut + colonnes_fin]\n",
    "    \n",
    "    # 12. Sauvegarde\n",
    "    if fichier_sortie is None:\n",
    "        fichier_sortie = \"cir_2021_prov_fusion_finale.xlsx\"\n",
    "    else:\n",
    "        fichier_sortie = os.path.splitext(fichier_sortie)[0] + \".xlsx\"\n",
    "\n",
    "    print(f\"\\nSauvegarde du fichier fusionné : {fichier_sortie}\")\n",
    "    remplacer_donnees_excel_modele(fichier_cir_ancien, fichier_sortie, df_final)\n",
    "    \n",
    "    print(f\"\\n✓ FUSION TERMINÉE AVEC SUCCÈS\")\n",
    "    print(f\"✓ Une seule ligne par SIREN\")\n",
    "    print(f\"✓ Pour les mixtes: données de la base + type du CIR + 4 montants du prov21\")\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "def comparer_fichiers_avant_apres(df_cir_original, df_final):\n",
    "    \"\"\"\n",
    "    Compare les fichiers avant et après fusion\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"COMPARAISON AVANT/APRÈS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"\\nNombre de lignes:\")\n",
    "    print(f\"   CIR original: {len(df_cir_original):,}\")\n",
    "    print(f\"   Fichier fusionné: {len(df_final):,}\")\n",
    "    print(f\"   Différence: {len(df_final) - len(df_cir_original):+,}\")\n",
    "    \n",
    "    colonnes_a_comparer = ['nom', 'cat_jur', 'trannee', 'commune', 'dpt', 'cp', 'treff_benef', 'old_region', 'region', 'pays_siege']\n",
    "    \n",
    "    print(\"\\nTaux de remplissage des colonnes:\")\n",
    "    for col in colonnes_a_comparer:\n",
    "        if col in df_cir_original.columns and col in df_final.columns:\n",
    "            avant = df_cir_original[col].notna().sum()\n",
    "            apres = df_final[col].notna().sum()\n",
    "            taux_avant = (avant / len(df_cir_original)) * 100\n",
    "            taux_apres = (apres / len(df_final)) * 100\n",
    "            \n",
    "            print(f\"\\n{col}:\")\n",
    "            print(f\"   Avant: {avant:,}/{len(df_cir_original):,} ({taux_avant:.1f}%)\")\n",
    "            print(f\"   Après: {apres:,}/{len(df_final):,} ({taux_apres:.1f}%)\")\n",
    "            print(f\"   Amélioration: {taux_apres - taux_avant:+.1f} points\")\n",
    "\n",
    "# Script principal\n",
    "if __name__ == \"__main__\":\n",
    "    FICHIER_CIR_ANCIEN = \"M://str-dgri-gecir-donnees-fiscales//z_Statistiques Séries Demandes//2021//0_BASE_CIR2021prov_extr202306.xlsx\"\n",
    "    FICHIER_BASE_COMPLETE = \"C://Users//msamb//Documents//base_final_2021_suite_final_complet_stock.csv\"\n",
    "    FICHIER_SORTIE = \"C://Users//msamb//Documents//cir_2021_prov_fusion_finale.xlsx\"\n",
    "\n",
    "    print(\"SCRIPT DE FUSION CIR 2021 - VERSION FINALE\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"Ce script va:\")\n",
    "    print(\"1. Pour les SIREN uniquement dans CIR: garder tel quel\")\n",
    "    print(\"2. Pour les SIREN uniquement dans la base: garder tel quel\")\n",
    "    print(\"3. Pour les SIREN mixtes:\")\n",
    "    print(\"   - Prendre TOUTES les colonnes de la base\")\n",
    "    print(\"   - SAUF 'type' qui vient du CIR\")\n",
    "    print(\"   - Ajouter les 4 montants du prov21:\")\n",
    "    print(\"     • cretot_gen\")\n",
    "    print(\"     • crerd_gen\")\n",
    "    print(\"     • crecoll_gen\")\n",
    "    print(\"     • creinno_gen\")\n",
    "    print(\"4. Ajouter une colonne 'source' pour la traçabilité\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    if not os.path.exists(FICHIER_CIR_ANCIEN):\n",
    "        print(f\"\\nERREUR: Fichier CIR ancien non trouvé: {FICHIER_CIR_ANCIEN}\")\n",
    "        exit(1)\n",
    "    if not os.path.exists(FICHIER_BASE_COMPLETE):\n",
    "        print(f\"\\nERREUR: Fichier base complété non trouvé: {FICHIER_BASE_COMPLETE}\")\n",
    "        exit(1)\n",
    "\n",
    "    try:\n",
    "        print(\"\\nChargement du fichier CIR original pour comparaison...\")\n",
    "        df_cir_original = charger_fichier_auto(FICHIER_CIR_ANCIEN, \"CIR original\")\n",
    "\n",
    "        df_fusion = fusionner_fichiers_cir(\n",
    "            fichier_cir_ancien=FICHIER_CIR_ANCIEN,\n",
    "            fichier_base_complete=FICHIER_BASE_COMPLETE,\n",
    "            fichier_sortie=FICHIER_SORTIE\n",
    "        )\n",
    "\n",
    "        if df_fusion is not None and df_cir_original is not None:\n",
    "            comparer_fichiers_avant_apres(df_cir_original, df_fusion)\n",
    "            print(\"\\n✓ Processus terminé avec succès!\")\n",
    "            print(f\"✓ {len(df_fusion):,} lignes au total\")\n",
    "            print(f\"✓ Les 4 colonnes de montants prov21 ont été ajoutées:\")\n",
    "            print(f\"  - montant_cretot_gen_prov21\")\n",
    "            print(f\"  - montant_crerd_gen_prov21\")\n",
    "            print(f\"  - montant_crecoll_gen_prov21\")\n",
    "            print(f\"  - montant_creinno_gen_prov21\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nERREUR: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe86cb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparaison des montants (valeurs en euros) :\n",
      "\n",
      "cretot_gen   | Somme normale : 7 265 494 072 € | Corrigée : 7 320 514 209 € | Différence :   55 020 137 €\n",
      "crerd_gen    | Somme normale : 6 842 255 020 € | Corrigée : 6 907 150 378 € | Différence :   64 895 357 €\n",
      "crecoll_gen  | Somme normale :   30 483 111 € | Corrigée :   30 244 757 € | Différence :     -238 353 €\n",
      "creinno_gen  | Somme normale :  392 755 910 € | Corrigée :  383 118 887 € | Différence :   -9 637 023 €\n"
     ]
    }
   ],
   "source": [
    "import openpyxl\n",
    "import pandas as pd\n",
    "\n",
    "# Chargement du fichier Excel\n",
    "df = pd.read_excel(\"C://Users//msamb//Documents//cir_2021_prov_fusion_finale.xlsx\")\n",
    "\n",
    "# Liste des colonnes de crédits\n",
    "cre_list = [\"cretot_gen\", \"crerd_gen\", \"crecoll_gen\", \"creinno_gen\"]\n",
    "\n",
    "# Mapping vers les colonnes prov21 correspondantes\n",
    "prov_map = {\n",
    "    \"cretot_gen\": \"montant_cretot_gen_prov21\",\n",
    "    \"crerd_gen\": \"montant_crerd_gen_prov21\",\n",
    "    \"crecoll_gen\": \"montant_crecoll_gen_prov21\",\n",
    "    \"creinno_gen\": \"montant_creinno_gen_prov21\",\n",
    "}\n",
    "\n",
    "# 1. Somme \"normale\"\n",
    "somme_normale = df[cre_list].sum()\n",
    "\n",
    "# 2. Somme corrigée avec prov21 pour les \"mixte\"\n",
    "somme_corrigee = pd.Series(dtype=float)\n",
    "for col in cre_list:\n",
    "    prov_col = prov_map[col]\n",
    "    valeurs = df.apply(\n",
    "        lambda row: row[prov_col] if row[\"source\"] == \"mixte_prov2021_base2021\" and pd.notnull(row[prov_col]) else row[col],\n",
    "        axis=1\n",
    "    )\n",
    "    somme_corrigee[col] = valeurs.sum()\n",
    "\n",
    "# 3. Écart entre les deux\n",
    "ecart = somme_corrigee - somme_normale\n",
    "\n",
    "# 4. Mise en forme dans un DataFrame\n",
    "result = pd.DataFrame({\n",
    "    \"Somme_normale\": somme_normale,\n",
    "    \"Somme_corrigée\": somme_corrigee,\n",
    "    \"Différence\": ecart\n",
    "})\n",
    "\n",
    "# 5. Formatage pour affichage lisible\n",
    "def format_nombre(x):\n",
    "    return \"{:,.0f}\".format(x).replace(\",\", \" \").replace(\".0\", \"\") if pd.notnull(x) else \"\"\n",
    "\n",
    "# Affichage formaté\n",
    "print(\"\\nComparaison des montants (valeurs en euros) :\\n\")\n",
    "for index, row in result.iterrows():\n",
    "    normal = format_nombre(row[\"Somme_normale\"])\n",
    "    corrigee = format_nombre(row[\"Somme_corrigée\"])\n",
    "    diff = format_nombre(row[\"Différence\"])\n",
    "    print(f\"{index:<12} | Somme normale : {normal:>12} € | Corrigée : {corrigee:>12} € | Différence : {diff:>12} €\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
