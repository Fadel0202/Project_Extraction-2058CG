{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chemin absolu attendu pour le fichier Excel : M:\\str-dgri-gecir-donnees-fiscales\\x-pour MF-SAMB\\20250424\\extract_ligne_2069A 2022.xlsx\n",
            "Le fichier Excel existe ? True\n",
            "Chemin absolu attendu pour le fichier Parquet : M:\\str-dgri-gecir-donnees-fiscales\\x-pour MF-SAMB\\output\\output_parquet\\cir_millesime_2022_ss_dbls.parquet\n",
            "Le fichier Parquet existe ? True\n",
            "Chargement du fichier Excel M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//20250424//extract_ligne_2069A 2022.xlsx, feuille 'liste SIREN-dépenses'...\n",
            "Formatage des SIRENs du fichier Excel...\n",
            "Nombre total de SIRENs uniques dans le fichier Excel: 947\n",
            "Chargement du fichier Parquet M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//output//output_parquet//cir_millesime_2022_ss_dbls.parquet...\n",
            "Formatage des SIRENs du fichier Parquet (colonne 'siren_declarant')...\n",
            "⚠ 68 SIRENs du fichier Excel sont absents du fichier Parquet:\n",
            "        SIREN  montant RD\n",
            "7   319772745     37664.0\n",
            "12  325706422   2921064.0\n",
            "15  328170550     19382.0\n",
            "16  328898077    106493.0\n",
            "28  332484021     77949.0\n",
            "30  333060150     67429.0\n",
            "32  333622140    320513.0\n",
            "41  339012452     30127.0\n",
            "43  340949031     20836.0\n",
            "46  343460622     41786.0\n",
            "La liste complète des SIRENs manquants a été sauvegardée dans M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//sirens_manquants.csv\n",
            "\n",
            "Statistiques:\n",
            "- Nombre total de SIRENs dans le fichier Excel: 947\n",
            "- Nombre total de SIRENs dans le fichier Parquet: 27957\n",
            "- Nombre de SIRENs de l'Excel présents dans le Parquet: 879\n",
            "- Pourcentage de couverture: 92.82%\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def format_siren(siren):\n",
        "    \"\"\"Formate les SIREN pour avoir exactement 9 caractères en ajoutant des zéros au début si nécessaire\"\"\"\n",
        "    if pd.isna(siren):\n",
        "        return siren\n",
        "    \n",
        "    siren_str = str(siren).strip()\n",
        "    \n",
        "    # Si le SIREN a moins de 9 caractères, ajouter des zéros au début\n",
        "    if len(siren_str) < 9:\n",
        "        siren_str = siren_str.zfill(9)  # zfill ajoute des zéros au début jusqu'à atteindre la longueur spécifiée\n",
        "    \n",
        "    return siren_str\n",
        "\n",
        "def main():\n",
        "    # Chemin du fichier Excel\n",
        "    excel_file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//20250424//extract_ligne_2069A 2022.xlsx\"\n",
        "    \n",
        "    # Chemin du fichier Parquet\n",
        "    parquet_file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//output//output_parquet//cir_millesime_2022_ss_dbls.parquet\"\n",
        "    \n",
        "    # Vérification supplémentaire du chemin (debug)\n",
        "    print(f\"Chemin absolu attendu pour le fichier Excel : {os.path.abspath(excel_file_path)}\")\n",
        "    print(f\"Le fichier Excel existe ? {os.path.exists(excel_file_path)}\")\n",
        "    print(f\"Chemin absolu attendu pour le fichier Parquet : {os.path.abspath(parquet_file_path)}\")\n",
        "    print(f\"Le fichier Parquet existe ? {os.path.exists(parquet_file_path)}\")    \n",
        "    \n",
        "    # Vérifier si les fichiers existent\n",
        "    if not os.path.exists(excel_file_path):\n",
        "        print(f\"Erreur: Le fichier Excel {excel_file_path} n'existe pas.\")\n",
        "        return\n",
        "    \n",
        "    if not os.path.exists(parquet_file_path):\n",
        "        print(f\"Erreur: Le fichier Parquet {parquet_file_path} n'existe pas.\")\n",
        "        return\n",
        "    \n",
        "    try:\n",
        "        # Charger les données Excel, avec le nom de feuille corrigé\n",
        "        sheet_name = \"liste SIREN-dépenses\"\n",
        "        print(f\"Chargement du fichier Excel {excel_file_path}, feuille '{sheet_name}'...\")\n",
        "        \n",
        "        try:\n",
        "            excel_df = pd.read_excel(excel_file_path, sheet_name=sheet_name)\n",
        "        except ValueError as e:\n",
        "            print(f\"Erreur lors du chargement de la feuille '{sheet_name}': {e}\")\n",
        "            # Liste toutes les feuilles disponibles\n",
        "            xls = pd.ExcelFile(excel_file_path)\n",
        "            print(f\"Feuilles disponibles dans le fichier: {xls.sheet_names}\")\n",
        "            \n",
        "            # Essayer avec un nom similaire si disponible\n",
        "            alternative_names = [name for name in xls.sheet_names if 'siren' in name.lower()]\n",
        "            if alternative_names:\n",
        "                sheet_name = alternative_names[0]\n",
        "                print(f\"Tentative avec la feuille alternative: '{sheet_name}'\")\n",
        "                excel_df = pd.read_excel(excel_file_path, sheet_name=sheet_name)\n",
        "            else:\n",
        "                print(\"Aucune feuille alternative trouvée. Veuillez vérifier le nom exact de la feuille.\")\n",
        "                return\n",
        "        \n",
        "        # Vérifier que la colonne SIREN existe\n",
        "        if 'SIREN' not in excel_df.columns:\n",
        "            print(\"Erreur: La colonne 'SIREN' n'existe pas dans la feuille.\")\n",
        "            print(f\"Colonnes disponibles: {excel_df.columns.tolist()}\")\n",
        "            \n",
        "            # Chercher des colonnes similaires\n",
        "            potential_siren_cols = [col for col in excel_df.columns if 'siren' in col.lower()]\n",
        "            if potential_siren_cols:\n",
        "                siren_col_excel = potential_siren_cols[0]\n",
        "                print(f\"Utilisation de la colonne alternative '{siren_col_excel}' comme SIREN\")\n",
        "                excel_df['SIREN'] = excel_df[siren_col_excel]\n",
        "            else:\n",
        "                return\n",
        "        \n",
        "        # Formatage des SIRENs dans le fichier Excel\n",
        "        print(\"Formatage des SIRENs du fichier Excel...\")\n",
        "        excel_df['SIREN'] = excel_df['SIREN'].apply(format_siren)\n",
        "        \n",
        "        # Nombre total de SIRENs dans le fichier Excel\n",
        "        total_sirens_excel = len(excel_df['SIREN'].unique())\n",
        "        print(f\"Nombre total de SIRENs uniques dans le fichier Excel: {total_sirens_excel}\")\n",
        "        \n",
        "        # Charger les données Parquet\n",
        "        print(f\"Chargement du fichier Parquet {parquet_file_path}...\")\n",
        "        try:\n",
        "            parquet_df = pd.read_parquet(parquet_file_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Erreur lors du chargement du fichier Parquet: {e}\")\n",
        "            print(\"Vérifiez que le package pyarrow ou fastparquet est installé.\")\n",
        "            return\n",
        "        \n",
        "        # Vérifier la colonne SIREN dans le fichier Parquet\n",
        "        siren_col = None\n",
        "        potential_siren_cols = ['SIREN', 'SIREN_DECLARANT', 'siren', 'siren_declarant']\n",
        "        \n",
        "        for col in potential_siren_cols:\n",
        "            if col in parquet_df.columns:\n",
        "                siren_col = col\n",
        "                break\n",
        "        \n",
        "        if siren_col is None:\n",
        "            print(\"Erreur: Aucune colonne SIREN n'a été trouvée dans le fichier Parquet.\")\n",
        "            # Afficher les colonnes disponibles\n",
        "            print(f\"Colonnes disponibles dans le fichier Parquet: {parquet_df.columns.tolist()}\")\n",
        "            return\n",
        "        \n",
        "        # Formatage des SIRENs dans le fichier Parquet\n",
        "        print(f\"Formatage des SIRENs du fichier Parquet (colonne '{siren_col}')...\")\n",
        "        parquet_df[siren_col] = parquet_df[siren_col].apply(format_siren)\n",
        "        \n",
        "        # Convertir en ensembles pour une recherche plus rapide\n",
        "        sirens_excel = set(excel_df['SIREN'].unique())\n",
        "        sirens_parquet = set(parquet_df[siren_col].unique())\n",
        "        \n",
        "        # Vérifier quels SIRENs de l'Excel sont absents du Parquet\n",
        "        sirens_missing = sirens_excel - sirens_parquet\n",
        "        \n",
        "        # Résultats\n",
        "        if len(sirens_missing) == 0:\n",
        "            print(\"✓ Tous les SIRENs du fichier Excel sont présents dans le fichier Parquet.\")\n",
        "        else:\n",
        "            print(f\"⚠ {len(sirens_missing)} SIRENs du fichier Excel sont absents du fichier Parquet:\")\n",
        "            missing_df = excel_df[excel_df['SIREN'].isin(sirens_missing)].copy()\n",
        "            \n",
        "            # Afficher les 10 premiers SIRENs manquants avec leurs montants RD si disponible\n",
        "            montant_col = 'montant RD'\n",
        "            if montant_col in missing_df.columns:\n",
        "                print(missing_df[['SIREN', montant_col]].head(10))\n",
        "            else:\n",
        "                # Chercher une colonne qui pourrait contenir les montants\n",
        "                montant_cols = [col for col in missing_df.columns if 'montant' in col.lower() or 'rd' in col.lower()]\n",
        "                if montant_cols:\n",
        "                    print(missing_df[['SIREN', montant_cols[0]]].head(10))\n",
        "                else:\n",
        "                    print(missing_df['SIREN'].head(10).tolist())\n",
        "            \n",
        "            # Sauvegarder les SIRENs manquants dans un fichier CSV\n",
        "            output_file = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//sirens_manquants.csv\"\n",
        "            missing_df.to_csv(output_file, index=False)\n",
        "            print(f\"La liste complète des SIRENs manquants a été sauvegardée dans {output_file}\")\n",
        "        \n",
        "        # Statistiques supplémentaires\n",
        "        print(\"\\nStatistiques:\")\n",
        "        print(f\"- Nombre total de SIRENs dans le fichier Excel: {total_sirens_excel}\")\n",
        "        print(f\"- Nombre total de SIRENs dans le fichier Parquet: {len(sirens_parquet)}\")\n",
        "        print(f\"- Nombre de SIRENs de l'Excel présents dans le Parquet: {total_sirens_excel - len(sirens_missing)}\")\n",
        "        print(f\"- Pourcentage de couverture: {((total_sirens_excel - len(sirens_missing)) / total_sirens_excel) * 100:.2f}%\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        print(f\"Une erreur s'est produite: {e}\")\n",
        "        print(traceback.format_exc())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gycZG_qzS-F0"
      },
      "source": [
        "# Recalcule Creance pour toute les entreprises Comparaison Calcule vs Non Calcule (2022)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_parquet(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//output//output_parquet//cir_millesime_2022_ss_dbls.parquet\")\n",
        "df.to_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//output//output_parquet//cir_millesime_2022_ss_dbls.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "grzhozK3S-F1",
        "outputId": "22c3baae-e93e-4c98-aeaf-f31630863f43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nombre total d'entreprises: 27,957\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n",
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3507620946.py:1002: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_comparaison[col_dest] = df_num[col_orig]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fichier de comparaison détaillée créé: M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB\\Calcul_Creance_CIR.csv\n",
            "\n",
            "===== COMPARAISON CIR DÉCLARÉ VS RECALCULÉ =====\n",
            "\n",
            "Nombre total d'entreprises analysées: 27,957\n",
            "Nombre d'entreprises avec CIR déclaré: 27,233\n",
            "Nombre d'entreprises avec dépenses > 100M€: 21\n",
            "\n",
            "CIR TOTAL:\n",
            "CIR déclaré total: 8,874,600,095.00 €\n",
            "CIR recalculé total: 7,586,181,391.68 €\n",
            "Différence: -1,288,418,703.32 €\n",
            "Écart relatif: -14.52%\n",
            "\n",
            "ANALYSE DES ÉCARTS:\n",
            "Entreprises avec CIR conforme (écart ≤ 1€): 26,408 (94.46%)\n",
            "Entreprises avec CIR recalculé > CIR déclaré (écart > 1€): 541\n",
            "Montant total des écarts positifs: 30,076,612.92 €\n",
            "Entreprises avec CIR recalculé < CIR déclaré (écart < -1€): 1,008\n",
            "Montant total des écarts négatifs: -1,318,495,541.68 €\n",
            "\n",
            "DÉTAIL PAR COMPOSANTE DU CIR RECALCULÉ:\n",
            "CIR Recherche: 7,148,118,828.26 €\n",
            "CIR Collection: 30,130,760.00 €\n",
            "CIR Innovation: 399,154,891.22 €\n",
            "CIR Recherche Collaborative: 8,776,912.20 €\n",
            "\n",
            "Traitement terminé avec succès!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Charger les données\n",
        "df = pd.read_parquet(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//output//output_parquet//cir_millesime_2022_ss_dbls.parquet\")\n",
        "\n",
        "def convertir_en_nombre(valeur, defaut=0):\n",
        "    \"\"\"Convertit une valeur en nombre de façon sécurisée\"\"\"\n",
        "    if pd.isna(valeur) or valeur == '' or valeur is None:\n",
        "        return defaut\n",
        "    try:\n",
        "        return float(valeur)\n",
        "    except:\n",
        "        return defaut\n",
        "\n",
        "def comparer_cir_declare_recalcule():\n",
        "    \"\"\"Compare le CIR déclaré et le CIR recalculé\"\"\"\n",
        "    print(f\"Nombre total d'entreprises: {len(df):,}\")\n",
        "\n",
        "    # Colonnes nécessaires pour recalculer le CIR\n",
        "    colonnes = [\n",
        "        'siren_declarant', 'siren_deposant', 'DESIGN', 'COMPLT_DESIGN',\n",
        "        'MT_NET_DEP_RD', 'MT_NET_DEP_RD_DOM', 'MT_TOT_CIR_CI_COLL_CII',\n",
        "        'MT_CIR_RECH_YC_QP_MOINS_DE100', 'MT_CI_COLL_APRS_MINIMI', 'MT_CII_YC_QP', 'MTotal_CRC',\n",
        "        'DOT_AMORT_IMMO', 'DOT_AMORT_IMMO_SINISTR', 'DEP_CHERCH_TECH', 'REM_SAL_INV',\n",
        "        'DEP_JD', 'OTR_DEP_FONCT', 'FRAIS_BREV_COV', 'DEP_MAINT_BREV_COV',\n",
        "        'DOT_AMORT_BREV', 'DEP_NORMALI', 'PRIM_COTIZ', 'DEP_VEIL_TECHNO',\n",
        "        'MT_DEP_FONCT_TOT', 'MT_TOT_RD_1',\n",
        "        'DEP_EXT_LIE_FR', 'DEP_EXT_LIE_ETR', 'DEP_EXT_NON_LIE_FR', 'DEP_EXT_NON_LIE_ETR',\n",
        "        'MT_TOT_DEP_EXT_ORG_AGREE', 'PLAF_OP_EXT', 'MT_TOT_OP_SOUS_TRAIT',\n",
        "        'PLAF_OP_EXT_ORG_AGRE_LIE', 'PLAF_OP_EXT_ORG_AGRE_NON_LIE', 'PLAF_GNRL_DEP_EXT', 'MT_DEP_EXT_PLAF',\n",
        "        'MT_TOT_RD_2',\n",
        "        'MT_AID_SUBV', 'MT_ENC_PRESTA', 'MT_DEP_CONSEILS_CIR', 'REMBST_SUBV',\n",
        "        'FRAIS_COLL', 'FRAIS_DEF_DESSIN', 'MT_TOT_DEP_COLL', 'MT_AID_SUBV_COLL',\n",
        "        'MT_DEP_CONSEILS_CIR_COLL', 'REMBST_SUBV_COLL', 'MT_NET_DEP_COLL', 'MT_NET_DEP_COLL_DOM',\n",
        "        'DOT_AMORT_IMMO_INO', 'DEP_PERSONEL_INO', 'OTR_DEP_FONCT_INO', 'FRAIS_BREV_COV_INO',\n",
        "        'FRAIS_DEF_BREV_INO', 'OP_INOV_EXT', 'MT_TOT_DEP_INO', 'MT_TOT_DEP_INO_PLAF',\n",
        "        'MT_AID_SUBV_INO', 'MT_ENC_PRESTA_INO', 'MT_DEP_CONSEILS_CII', 'REMBST_SUBV_INO',\n",
        "        'MT_NET_DEP_INO', 'MT_NET_DEP_INO_DOM', 'MT_NET_DEP_INO_MPE_CORSE', 'MT_NET_DEP_INO_ME_CORSE',\n",
        "        'DEP_CRC', 'DEP_CRC_FR', 'DEP_CRC_ETR', 'DEP_CRC_PLAF', 'AIDE_PUB_CRC',\n",
        "        'AIDE_PUB_REMB_CRC', 'MT_NET_DEP_CRC', 'MT_NET_DEP_CRC_PME', 'MT_CRC','MT_QP_COLL_RECU_MOINS_DE100',\n",
        "        'MT_QP_CIR_RECU_BIS','MT_QP_COLL_RECU_BIS','MT_AIDE_MINIMI_COLL','MT_QP_CII','QP_MT_CRC','MT_CII_CORSE',\n",
        "        'MT_CI_COLL_APRS_MINIMI_DOM', 'MT_CI_COLL_APRES_MINIMI_PLUS_DE100_DOM', 'MT_QP_CIR_RECU', 'MT_AIDE_MINIMI_MOINS_DE100'\n",
        "    ]\n",
        "\n",
        "    # Convertir en numérique et créer une copie défragmentée\n",
        "    df_tmp = df.copy()\n",
        "    for col in colonnes:\n",
        "        if col in df_tmp.columns:\n",
        "            if col not in ['siren_declarant', 'siren_deposant', 'DESIGN', 'COMPLT_DESIGN']:\n",
        "                df_tmp[col] = df_tmp[col].apply(convertir_en_nombre)\n",
        "        else:\n",
        "            if col not in ['siren_declarant', 'siren_deposant', 'DESIGN', 'COMPLT_DESIGN']:\n",
        "                df_tmp[col] = 0\n",
        "\n",
        "    # Créer un dictionnaire pour stocker toutes les colonnes calculées\n",
        "    # et les ajouter en une seule fois à la fin pour éviter la fragmentation (afin d'éviter d'augmenter la complexité du code)\n",
        "    calc_columns = {}\n",
        "\n",
        "    ## I - DÉPENSES DE RECHERCHE (CIR-RECHERCHE)\n",
        "\n",
        "    # 1. Dépenses internes (Section I-A)\n",
        "\n",
        "    # Ligne 6: Autres dépenses de fonctionnement\n",
        "    calc_columns['LIGNE_6_CALC'] = (df_tmp['DOT_AMORT_IMMO'] * 0.75) + \\\n",
        "                               ((df_tmp['DEP_CHERCH_TECH'] + df_tmp['REM_SAL_INV']) * 0.43) + \\\n",
        "                               df_tmp['DEP_JD']\n",
        "\n",
        "    # Ligne 7: Total dépenses de fonctionnement\n",
        "    calc_columns['LIGNE_7_CALC'] = df_tmp['DOT_AMORT_IMMO'] + df_tmp['DOT_AMORT_IMMO_SINISTR'] + \\\n",
        "                               df_tmp['DEP_CHERCH_TECH'] + df_tmp['REM_SAL_INV'] + \\\n",
        "                               df_tmp['DEP_JD'] + calc_columns['LIGNE_6_CALC']\n",
        "\n",
        "\n",
        "    # Appliquer les plafonds pour les lignes concernées\n",
        "    # Ligne 11: Dépenses liées à la normalisation , utiliser directement la valeur renseignée\n",
        "    calc_columns['DEP_NORMALI_RECALC'] = df_tmp['DEP_NORMALI']  # Conserver la valeur telle quelle\n",
        "\n",
        "    # Ligne 12: Primes et cotisations (plafond 60 000 €)\n",
        "    calc_columns['PRIM_COTIZ_PLAFONNEES'] = np.minimum(df_tmp['PRIM_COTIZ'], 60000)\n",
        "\n",
        "    # Ligne 13: Dépenses de veille technologique (plafond 60 000 €)\n",
        "    calc_columns['DEP_VEIL_TECHNO_PLAFONNEES'] = np.minimum(df_tmp['DEP_VEIL_TECHNO'], 60000)\n",
        "\n",
        "\n",
        "    # Ligne 14: Total dépenses internes avec plafonds appliqués\n",
        "    calc_columns['LIGNE_14_CALC'] = calc_columns['LIGNE_7_CALC'] + df_tmp['FRAIS_BREV_COV'] + \\\n",
        "                                df_tmp['DEP_MAINT_BREV_COV'] + df_tmp['DOT_AMORT_BREV'] + \\\n",
        "                                calc_columns['DEP_NORMALI_RECALC'] + calc_columns['PRIM_COTIZ_PLAFONNEES'] + \\\n",
        "                                calc_columns['DEP_VEIL_TECHNO_PLAFONNEES']\n",
        "\n",
        "    # 2. Dépenses externalisées (Section I-B)\n",
        "\n",
        "    # Ligne 17: Total dépenses externalisées\n",
        "    calc_columns['LIGNE_17_CALC'] = df_tmp['DEP_EXT_LIE_FR'] + df_tmp['DEP_EXT_LIE_ETR'] + \\\n",
        "                                df_tmp['DEP_EXT_NON_LIE_FR'] + df_tmp['DEP_EXT_NON_LIE_ETR']\n",
        "\n",
        "    # Préparation pour les calculs complexes nécessitant des références à d'autres colonnes calculées\n",
        "    # Ajoutons temporairement les colonnes calculées au DataFrame\n",
        "    df_calc = pd.DataFrame(calc_columns)\n",
        "    df_calc_temp = pd.concat([df_tmp, df_calc], axis=1)\n",
        "\n",
        "    # Appliquer les plafonnements\n",
        "    # Ligne 18: Plafond global (3x dépenses internes)\n",
        "    calc_columns['LIGNE_18_CALC'] = np.minimum(df_calc_temp['LIGNE_17_CALC'], df_calc_temp['LIGNE_14_CALC'] * 3)\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_18_CALC'] = calc_columns['LIGNE_18_CALC']\n",
        "\n",
        "    # Pour les calculs complexes, utiliser des boucles au lieu de apply\n",
        "    # Ligne 19: Plafond pour organismes liés (2M€)\n",
        "    ligne_19_values = []\n",
        "    for _, row in df_calc_temp.iterrows():\n",
        "        dep_liees = row['DEP_EXT_LIE_FR'] + row['DEP_EXT_LIE_ETR']\n",
        "        plafond = min(row['LIGNE_18_CALC'], 2000000)\n",
        "        ligne_19_values.append(min(dep_liees, plafond))\n",
        "    calc_columns['LIGNE_19_CALC'] = np.array(ligne_19_values)\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_19_CALC'] = calc_columns['LIGNE_19_CALC']\n",
        "\n",
        "    # Ligne 20: Plafond pour organismes non liés (10M€)\n",
        "    ligne_20_values = []\n",
        "    for _, row in df_calc_temp.iterrows():\n",
        "        dep_non_liees = row['DEP_EXT_NON_LIE_FR'] + row['DEP_EXT_NON_LIE_ETR']\n",
        "        plafond_restant = min(row['LIGNE_18_CALC'] - row['LIGNE_19_CALC'], 10000000)\n",
        "        ligne_20_values.append(min(dep_non_liees, plafond_restant))\n",
        "    calc_columns['LIGNE_20_CALC'] = np.array(ligne_20_values)\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_20_CALC'] = calc_columns['LIGNE_20_CALC']\n",
        "\n",
        "    # Ligne 21: Total après plafonnements\n",
        "    ligne_21_values = []\n",
        "    for _, row in df_calc_temp.iterrows():\n",
        "        ligne_21_values.append(min(row['LIGNE_19_CALC'] + row['LIGNE_20_CALC'], 10000000))\n",
        "    calc_columns['LIGNE_21_CALC'] = np.array(ligne_21_values)\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_21_CALC'] = calc_columns['LIGNE_21_CALC']\n",
        "\n",
        "    # 3. Montant total et net (Section I-C)\n",
        "\n",
        "    # Ligne 22: Total dépenses\n",
        "    calc_columns['LIGNE_22_CALC'] = df_calc_temp['LIGNE_14_CALC'] + df_calc_temp['LIGNE_21_CALC']\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_22_CALC'] = calc_columns['LIGNE_22_CALC']\n",
        "\n",
        "    # Ligne 26a: Montant net\n",
        "    calc_columns['LIGNE_26A_CALC'] = df_calc_temp['LIGNE_22_CALC'] - df_tmp['MT_AID_SUBV'] - \\\n",
        "                                  df_tmp['MT_ENC_PRESTA'] - df_tmp['MT_DEP_CONSEILS_CIR'] + \\\n",
        "                                  df_tmp['REMBST_SUBV']\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_26A_CALC'] = calc_columns['LIGNE_26A_CALC']\n",
        "\n",
        "    # Ligne 26b: Utiliser la valeur de MT_NET_DEP_RD_DOM directement\n",
        "    calc_columns['LIGNE_26B_CALC'] = df_tmp['MT_NET_DEP_RD_DOM']\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_26B_CALC'] = calc_columns['LIGNE_26B_CALC']\n",
        "\n",
        "    ## II - DÉPENSES DE COLLECTION (CIR-COLLECTION)\n",
        "\n",
        "    # Ligne 28: Frais de défense des dessins et modèles (plafond 60 000 €)\n",
        "    calc_columns['FRAIS_DEF_DESSIN_PLAFONNES'] = np.minimum(df_tmp['FRAIS_DEF_DESSIN'], 60000)\n",
        "\n",
        "    # Ligne 29: Total des dépenses de collection\n",
        "    calc_columns['LIGNE_29_CALC'] = df_tmp['FRAIS_COLL'] + calc_columns['FRAIS_DEF_DESSIN_PLAFONNES']\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_29_CALC'] = calc_columns['LIGNE_29_CALC']\n",
        "\n",
        "    # Ligne 33a: Montant net des dépenses de collection\n",
        "    calc_columns['LIGNE_33A_CALC'] = df_calc_temp['LIGNE_29_CALC'] - df_tmp['MT_AID_SUBV_COLL'] - \\\n",
        "                                  df_tmp['MT_DEP_CONSEILS_CIR_COLL'] + df_tmp['REMBST_SUBV_COLL']\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_33A_CALC'] = calc_columns['LIGNE_33A_CALC']\n",
        "\n",
        "    # Ligne 33b: Utiliser la valeur de MT_NET_DEP_COLL_DOM directement\n",
        "    calc_columns['LIGNE_33B_CALC'] = df_tmp['MT_NET_DEP_COLL_DOM']\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_33B_CALC'] = calc_columns['LIGNE_33B_CALC']\n",
        "\n",
        "    # Ligne 34a: Montant net total des dépenses de recherche et de collection\n",
        "    calc_columns['LIGNE_34A_CALC'] = df_calc_temp['LIGNE_26A_CALC'] + df_calc_temp['LIGNE_33A_CALC']\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_34A_CALC'] = calc_columns['LIGNE_34A_CALC']\n",
        "\n",
        "    # Ligne 34b: Montant net total des dépenses de recherche et de collection DOM\n",
        "    calc_columns['LIGNE_34B_CALC'] = df_calc_temp['LIGNE_26B_CALC'] + df_calc_temp['LIGNE_33B_CALC']\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_34B_CALC'] = calc_columns['LIGNE_34B_CALC']\n",
        "\n",
        "    ## V - DÉPENSES DE RECHERCHE COLLABORATIVE (CRC)\n",
        "\n",
        "    # Vérifier si données disponibles pour la recherche collaborative\n",
        "    if all(col in df_tmp.columns for col in ['DEP_CRC', 'DEP_CRC_FR', 'DEP_CRC_ETR']):\n",
        "        # Dépenses éligibles\n",
        "        calc_columns['LIGNE_83_CALC'] = df_tmp['DEP_CRC_FR'] + df_tmp['DEP_CRC_ETR']\n",
        "\n",
        "        # Plafonnement à 6 000 000 €\n",
        "        calc_columns['LIGNE_84_CALC'] = np.minimum(calc_columns['LIGNE_83_CALC'], 6000000)\n",
        "\n",
        "        # Montant net des dépenses de recherche collaborative\n",
        "        calc_columns['MT_NET_DEP_CRC_CALC'] = calc_columns['LIGNE_84_CALC'] - df_tmp['AIDE_PUB_CRC'] + \\\n",
        "                                          df_tmp['AIDE_PUB_REMB_CRC']\n",
        "\n",
        "        # CRC selon les taux\n",
        "        calc_columns['LIGNE_89_CALC'] = ((calc_columns['MT_NET_DEP_CRC_CALC'] - df_tmp['MT_NET_DEP_CRC_PME']) * 0.4) + \\\n",
        "                                     (df_tmp['MT_NET_DEP_CRC_PME'] * 0.5)\n",
        "\n",
        "        calc_columns['CIR_COLLAB_RECALCULE'] = calc_columns['LIGNE_89_CALC']\n",
        "        calc_columns['LIGNE_87'] = calc_columns['MT_NET_DEP_CRC_CALC']\n",
        "    else:\n",
        "        # Si données non disponibles, mettre à 0\n",
        "        calc_columns['CIR_COLLAB_RECALCULE'] = np.zeros(len(df_tmp))\n",
        "        calc_columns['LIGNE_87'] = np.zeros(len(df_tmp))\n",
        "        calc_columns['LIGNE_89_CALC'] = np.zeros(len(df_tmp))\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    for col in ['CIR_COLLAB_RECALCULE', 'LIGNE_87', 'LIGNE_89_CALC']:\n",
        "        if col in calc_columns:\n",
        "            df_calc_temp[col] = calc_columns[col]\n",
        "\n",
        "    ## III - CALCUL DU CRÉDIT D'IMPÔT AU TITRE DES DÉPENSES DE RECHERCHE ET DE COLLECTION\n",
        "\n",
        "    # Identifier les entreprises <= 100M€ en utilisant la somme ligne 34a + ligne 87\n",
        "    calc_columns['DEPENSES_MOINS_100M'] = (df_calc_temp['LIGNE_34A_CALC'] + df_calc_temp['LIGNE_87']) <= 100000000\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['DEPENSES_MOINS_100M'] = calc_columns['DEPENSES_MOINS_100M']\n",
        "\n",
        "    # A. Dépenses <= 100 000 000 €\n",
        "\n",
        "    # CIR Recherche pour entreprises <= 100M€\n",
        "    ligne_36_values = []\n",
        "    for _, row in df_calc_temp.iterrows():\n",
        "        if row['DEPENSES_MOINS_100M']:\n",
        "            ligne_36_values.append((row['LIGNE_26A_CALC'] - row['LIGNE_26B_CALC']) * 0.3 +\n",
        "                      row['LIGNE_26B_CALC'] * 0.5)\n",
        "        else:\n",
        "            ligne_36_values.append(0)\n",
        "    calc_columns['LIGNE_36_CALC'] = np.array(ligne_36_values)\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_36_CALC'] = calc_columns['LIGNE_36_CALC']\n",
        "\n",
        "    # Ligne 37: Quote-part de crédit d'impôt résultant de la participation sociétés de personnes\n",
        "    calc_columns['LIGNE_37'] = df_tmp['MT_QP_CIR_RECU']\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_37'] = calc_columns['LIGNE_37']\n",
        "\n",
        "    # Calcul ligne 38a: Montant du crédit d'impôt pour dépenses de recherche\n",
        "    calc_columns['LIGNE_38A_CALC'] = df_calc_temp['LIGNE_36_CALC'] + df_calc_temp['LIGNE_37']\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_38A_CALC'] = calc_columns['LIGNE_38A_CALC']\n",
        "\n",
        "    # Calcul ligne 38b: Montant du CIR pour dépenses de recherche DOM\n",
        "    calc_columns['LIGNE_38B_CALC'] = df_calc_temp['LIGNE_26B_CALC'] * 0.5  # Taux de 50% pour DOM\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_38B_CALC'] = calc_columns['LIGNE_38B_CALC']\n",
        "\n",
        "    # CIR Collection pour entreprises <= 100M€ (avant plafond de minimis)\n",
        "    ligne_40_values = []\n",
        "    for _, row in df_calc_temp.iterrows():\n",
        "        if row['DEPENSES_MOINS_100M']:\n",
        "            ligne_40_values.append((row['LIGNE_33A_CALC'] - row['LIGNE_33B_CALC']) * 0.3 +\n",
        "                      row['LIGNE_33B_CALC'] * 0.5)\n",
        "        else:\n",
        "            ligne_40_values.append(0)\n",
        "    calc_columns['LIGNE_40_CALC'] = np.array(ligne_40_values)\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_40_CALC'] = calc_columns['LIGNE_40_CALC']\n",
        "\n",
        "    # Ligne 41: Quote-part de crédit d'impôt collection résultant de la participation sociétés de personnes\n",
        "    # Nous supposons qu'elle est à 0 car elle n'est pas calculable avec les données disponibles\n",
        "    calc_columns['LIGNE_41'] = df_tmp['MT_QP_COLL_RECU_MOINS_DE100']\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_41'] = calc_columns['LIGNE_41']\n",
        "\n",
        "    # Calcul ligne 42a: Montant total du crédit d'impôt pour dépenses de collection avant plafonnement\n",
        "    calc_columns['LIGNE_42A_CALC'] = df_calc_temp['LIGNE_40_CALC'] + df_calc_temp['LIGNE_41']\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_42A_CALC'] = calc_columns['LIGNE_42A_CALC']\n",
        "\n",
        "    # Calcul ligne 42b: Montant du crédit collection DOM avant plafonnement\n",
        "    calc_columns['LIGNE_42B_CALC'] = df_calc_temp['LIGNE_33B_CALC'] * 0.5  # Taux de 50% pour DOM\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_42B_CALC'] = calc_columns['LIGNE_42B_CALC']\n",
        "\n",
        "    # Ligne 43: Montant des aides de minimis\n",
        "    calc_columns['LIGNE_43'] = df_tmp['MT_AIDE_MINIMI_MOINS_DE100']\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_43'] = calc_columns['LIGNE_43']\n",
        "\n",
        "    # Calcul ligne 44: Montant cumulé du crédit d'impôt et des aides de minimis\n",
        "    calc_columns['LIGNE_44'] = df_calc_temp['LIGNE_42A_CALC'] + df_calc_temp['LIGNE_43']\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_44'] = calc_columns['LIGNE_44']\n",
        "\n",
        "    # Calcul ligne 45a: Montant du crédit d'impôt pour dépenses de collection après plafonnement\n",
        "    ligne_45a_values = []\n",
        "    for _, row in df_calc_temp.iterrows():\n",
        "        if row['LIGNE_43'] >= 200000:  # Si aides de minimis déjà à 200k€\n",
        "            ligne_45a_values.append(0)\n",
        "        elif row['LIGNE_44'] < 200000:  # Si cumul < 200k€\n",
        "            ligne_45a_values.append(row['LIGNE_42A_CALC'])\n",
        "        else:  # Si dépassement\n",
        "            ligne_45a_values.append(200000 - row['LIGNE_43'])\n",
        "    calc_columns['LIGNE_45A_CALC'] = np.array(ligne_45a_values)\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_45A_CALC'] = calc_columns['LIGNE_45A_CALC']\n",
        "\n",
        "    # ligne 45b: Montant du crédit collection DOM après plafonnement\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_45B_CALC'] = df_tmp['MT_CI_COLL_APRS_MINIMI_DOM']\n",
        "\n",
        "    # Calcul ligne 46a: Montant total du crédit d'impôt au titre des dépenses de recherche et de collection\n",
        "    calc_columns['LIGNE_46A_CALC'] = df_calc_temp['LIGNE_38A_CALC'] + df_calc_temp['LIGNE_45A_CALC']\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_46A_CALC'] = calc_columns['LIGNE_46A_CALC']\n",
        "\n",
        "    # Calcul ligne 46b: Montant du crédit d'impôt recherche et collection exposées dans DOM\n",
        "    calc_columns['LIGNE_46B_CALC'] = df_calc_temp['LIGNE_38B_CALC'] + df_calc_temp['LIGNE_45B_CALC']\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_46B_CALC'] = calc_columns['LIGNE_46B_CALC']\n",
        "\n",
        "    # B. Dépenses > 100 000 000 €\n",
        "\n",
        "    # Identifier les entreprises > 100M€\n",
        "    calc_columns['DEPENSES_PLUS_100M'] = ~df_calc_temp['DEPENSES_MOINS_100M']\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['DEPENSES_PLUS_100M'] = calc_columns['DEPENSES_PLUS_100M']\n",
        "\n",
        "    # Limiter les dépenses à 100M€ - dépenses recherche collaborative\n",
        "    ligne_47a_values = []\n",
        "    for _, row in df_calc_temp.iterrows():\n",
        "        if row['DEPENSES_PLUS_100M']:\n",
        "            ligne_47a_values.append(min(row['LIGNE_26A_CALC'], 100000000 - row['LIGNE_87']))\n",
        "        else:\n",
        "            ligne_47a_values.append(0)\n",
        "    calc_columns['LIGNE_47A_CALC'] = np.array(ligne_47a_values)\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_47A_CALC'] = calc_columns['LIGNE_47A_CALC']\n",
        "\n",
        "    # Proportion DOM dans la limite des 100M€ (ligne 47b)\n",
        "    ligne_47b_values = []\n",
        "    for _, row in df_calc_temp.iterrows():\n",
        "        if row['DEPENSES_PLUS_100M']:\n",
        "            ligne_47b_values.append(min(row['LIGNE_26B_CALC'], 100000000 - row['LIGNE_87']))\n",
        "        else:\n",
        "            ligne_47b_values.append(0)\n",
        "    calc_columns['LIGNE_47B_CALC'] = np.array(ligne_47b_values)\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_47B_CALC'] = calc_columns['LIGNE_47B_CALC']\n",
        "\n",
        "    # Calcul CIR recherche première tranche (ligne 48)\n",
        "    ligne_48_values = []\n",
        "    for _, row in df_calc_temp.iterrows():\n",
        "        if row['DEPENSES_PLUS_100M']:\n",
        "            ligne_48_values.append((row['LIGNE_47A_CALC'] - row['LIGNE_47B_CALC']) * 0.3 +\n",
        "                           row['LIGNE_47B_CALC'] * 0.5)\n",
        "        else:\n",
        "            ligne_48_values.append(0)\n",
        "    calc_columns['LIGNE_48_CALC'] = np.array(ligne_48_values)\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_48_CALC'] = calc_columns['LIGNE_48_CALC']\n",
        "\n",
        "    # Dépenses > 100M€ (ligne 49)\n",
        "    ligne_49_values = []\n",
        "    for _, row in df_calc_temp.iterrows():\n",
        "        if row['DEPENSES_PLUS_100M']:\n",
        "            ligne_49_values.append(max(0, row['LIGNE_26A_CALC'] - (100000000 - row['LIGNE_87'])))\n",
        "        else:\n",
        "            ligne_49_values.append(0)\n",
        "    calc_columns['LIGNE_49_CALC'] = np.array(ligne_49_values)\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_49_CALC'] = calc_columns['LIGNE_49_CALC']\n",
        "\n",
        "    # CIR recherche deuxième tranche (au-delà de 100M€) (ligne 50)\n",
        "    calc_columns['LIGNE_50_CALC'] = df_calc_temp['LIGNE_49_CALC'] * 0.05\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_50_CALC'] = calc_columns['LIGNE_50_CALC']\n",
        "\n",
        "    # CIR recherche total pour entreprises > 100M€ (ligne 51)\n",
        "    calc_columns['LIGNE_51_CALC'] = df_calc_temp['LIGNE_48_CALC'] + df_calc_temp['LIGNE_50_CALC']\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_51_CALC'] = calc_columns['LIGNE_51_CALC']\n",
        "\n",
        "    # Ligne 52: Quote-part de crédit d'impôt recherche résultant de la participation sociétés de personnes\n",
        "    calc_columns['LIGNE_52'] = df_tmp['MT_QP_CIR_RECU_BIS']\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_52'] = calc_columns['LIGNE_52']\n",
        "\n",
        "    # Calcul ligne 53a: Montant du crédit d'impôt pour dépenses de recherche >100M€\n",
        "    calc_columns['LIGNE_53A_CALC'] = df_calc_temp['LIGNE_51_CALC'] + df_calc_temp['LIGNE_52']\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_53A_CALC'] = calc_columns['LIGNE_53A_CALC']\n",
        "\n",
        "    # Calcul ligne 53b: Montant du crédit d'impôt pour dépenses de recherche DOM >100M€\n",
        "    # Comme pour 38b, c'est 50% des dépenses DOM dans la limite du plafond\n",
        "    calc_columns['LIGNE_53B_CALC'] = df_calc_temp['LIGNE_47B_CALC'] * 0.5\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_53B_CALC'] = calc_columns['LIGNE_53B_CALC']\n",
        "\n",
        "    # Calcul CIR collection pour entreprises > 100M€\n",
        "\n",
        "    # Ligne 54a: Montant net total des dépenses de collection\n",
        "    calc_columns['LIGNE_54A_CALC'] = df_calc_temp['LIGNE_33A_CALC']\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_54A_CALC'] = calc_columns['LIGNE_54A_CALC']\n",
        "\n",
        "    # Ligne 54b: Montant net total des dépenses de collection DOM\n",
        "    calc_columns['LIGNE_54B_CALC'] = df_calc_temp['LIGNE_33B_CALC']\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_54B_CALC'] = calc_columns['LIGNE_54B_CALC']\n",
        "\n",
        "    # Plafond disponible après dépenses recherche (ligne 55)\n",
        "    ligne_55_values = []\n",
        "    for _, row in df_calc_temp.iterrows():\n",
        "        if row['DEPENSES_PLUS_100M']:\n",
        "            ligne_55_values.append(max(0, 100000000 - row['LIGNE_87'] - row['LIGNE_47A_CALC']))\n",
        "        else:\n",
        "            ligne_55_values.append(0)\n",
        "    calc_columns['LIGNE_55_CALC'] = np.array(ligne_55_values)\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_55_CALC'] = calc_columns['LIGNE_55_CALC']\n",
        "\n",
        "    # CIR collection première tranche (ligne 56)\n",
        "    ligne_56_values = []\n",
        "    for _, row in df_calc_temp.iterrows():\n",
        "        if row['DEPENSES_PLUS_100M']:\n",
        "            dep_coll_plaf = min(row['LIGNE_54A_CALC'], row['LIGNE_55_CALC'])\n",
        "            dep_coll_dom_plaf = min(row['LIGNE_54B_CALC'], row['LIGNE_55_CALC'])\n",
        "            ligne_56_values.append((dep_coll_plaf - dep_coll_dom_plaf) * 0.3 + dep_coll_dom_plaf * 0.5)\n",
        "        else:\n",
        "            ligne_56_values.append(0)\n",
        "    calc_columns['LIGNE_56_CALC'] = np.array(ligne_56_values)\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_56_CALC'] = calc_columns['LIGNE_56_CALC']\n",
        "\n",
        "    # CIR collection deuxième tranche (ligne 57)\n",
        "    ligne_57_values = []\n",
        "    for _, row in df_calc_temp.iterrows():\n",
        "        if row['DEPENSES_PLUS_100M']:\n",
        "            ligne_57_values.append(max(0, row['LIGNE_54A_CALC'] - row['LIGNE_55_CALC']) * 0.05)\n",
        "        else:\n",
        "            ligne_57_values.append(0)\n",
        "    calc_columns['LIGNE_57_CALC'] = np.array(ligne_57_values)\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_57_CALC'] = calc_columns['LIGNE_57_CALC']\n",
        "\n",
        "    # CIR collection avant plafonnement de minimis (ligne 58)\n",
        "    calc_columns['LIGNE_58_CALC'] = df_calc_temp['LIGNE_56_CALC'] + df_calc_temp['LIGNE_57_CALC']\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_58_CALC'] = calc_columns['LIGNE_58_CALC']\n",
        "\n",
        "    # Ligne 59: Quote-part de crédit d'impôt collection résultant de la participation sociétés de personnes\n",
        "    calc_columns['LIGNE_59'] = df_tmp['MT_QP_COLL_RECU_BIS']\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_59'] = calc_columns['LIGNE_59']\n",
        "\n",
        "    # Ligne 60: Montant du crédit d'impôt collection avant plafonnement de minimis\n",
        "    calc_columns['LIGNE_60'] = df_calc_temp['LIGNE_58_CALC'] + df_calc_temp['LIGNE_59']\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_60'] = calc_columns['LIGNE_60']\n",
        "\n",
        "    # Ligne 61: Montant des aides de minimis\n",
        "    calc_columns['LIGNE_61'] = df_tmp['MT_AIDE_MINIMI_COLL']\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_61'] = calc_columns['LIGNE_61']\n",
        "\n",
        "    # Ligne 62: Montant cumulé du crédit d'impôt et des aides de minimis\n",
        "    calc_columns['LIGNE_62'] = df_calc_temp['LIGNE_60'] + df_calc_temp['LIGNE_61']\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_62'] = calc_columns['LIGNE_62']\n",
        "\n",
        "    # Ligne 63a: Montant du crédit d'impôt pour dépenses de collection après plafonnement\n",
        "    ligne_63a_values = []\n",
        "    for _, row in df_calc_temp.iterrows():\n",
        "        if row['LIGNE_61'] >= 200000:  # Si aides de minimis déjà à 200k€\n",
        "            ligne_63a_values.append(0)\n",
        "        elif row['LIGNE_62'] < 200000:  # Si cumul < 200k€\n",
        "            ligne_63a_values.append(row['LIGNE_60'])\n",
        "        else:  # Si dépassement\n",
        "            ligne_63a_values.append(200000 - row['LIGNE_61'])\n",
        "    calc_columns['LIGNE_63A_CALC'] = np.array(ligne_63a_values)\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_63A_CALC'] = calc_columns['LIGNE_63A_CALC']\n",
        "\n",
        "    # Ligne 63b: Montant du crédit d'impôt pour dépenses de collection DOM après plafonnement\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_63B_CALC'] = df_tmp['MT_CI_COLL_APRES_MINIMI_PLUS_DE100_DOM']\n",
        "\n",
        "    # Ligne 64a: Montant total du crédit d'impôt au titre des dépenses de recherche et de collection\n",
        "    calc_columns['LIGNE_64A_CALC'] = df_calc_temp['LIGNE_53A_CALC'] + df_calc_temp['LIGNE_63A_CALC']\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_64A_CALC'] = calc_columns['LIGNE_64A_CALC']\n",
        "\n",
        "    # Ligne 64b: Montant du crédit d'impôt recherche et collection exposées dans DOM\n",
        "    calc_columns['LIGNE_64B_CALC'] = df_calc_temp['LIGNE_53B_CALC'] + df_calc_temp['LIGNE_63B_CALC']\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_64B_CALC'] = calc_columns['LIGNE_64B_CALC']\n",
        "\n",
        "    # Somme du CIR recherche selon le cas (<=100M€ ou >100M€)\n",
        "    cir_recherche_values = []\n",
        "    for _, row in df_calc_temp.iterrows():\n",
        "        if row['DEPENSES_MOINS_100M']:\n",
        "            cir_recherche_values.append(row['LIGNE_38A_CALC'])\n",
        "        else:\n",
        "            cir_recherche_values.append(row['LIGNE_53A_CALC'])\n",
        "    calc_columns['CIR_RECHERCHE_RECALCULE'] = np.array(cir_recherche_values)\n",
        "\n",
        "    # Somme du CIR collection après plafonnement de minimis selon le cas\n",
        "    cir_collection_values = []\n",
        "    for _, row in df_calc_temp.iterrows():\n",
        "        if row['DEPENSES_MOINS_100M']:\n",
        "            cir_collection_values.append(row['LIGNE_45A_CALC'])\n",
        "        else:\n",
        "            cir_collection_values.append(row['LIGNE_63A_CALC'])\n",
        "    calc_columns['CIR_COLLECTION_RECALCULE'] = np.array(cir_collection_values)\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    for col in ['CIR_RECHERCHE_RECALCULE', 'CIR_COLLECTION_RECALCULE']:\n",
        "        df_calc_temp[col] = calc_columns[col]\n",
        "\n",
        "    ## IV - DÉPENSES D'INNOVATION (CIR-INNOVATION)\n",
        "\n",
        "    # Vérifier si les données d'innovation sont disponibles\n",
        "    if all(col in df_tmp.columns for col in ['DOT_AMORT_IMMO_INO', 'DEP_PERSONEL_INO']):\n",
        "        # Autres dépenses de fonctionnement\n",
        "        calc_columns['LIGNE_67_CALC'] = (df_tmp['DOT_AMORT_IMMO_INO'] * 0.75) + \\\n",
        "                                     (df_tmp['DEP_PERSONEL_INO'] * 0.43)\n",
        "\n",
        "        # Total dépenses d'innovation\n",
        "        calc_columns['LIGNE_71_CALC'] = df_tmp['DOT_AMORT_IMMO_INO'] + df_tmp['DEP_PERSONEL_INO'] + \\\n",
        "                                     calc_columns['LIGNE_67_CALC'] + df_tmp['FRAIS_BREV_COV_INO'] + \\\n",
        "                                     df_tmp['FRAIS_DEF_BREV_INO'] + df_tmp['OP_INOV_EXT']\n",
        "\n",
        "        # Plafonnement à 400 000 €\n",
        "        calc_columns['LIGNE_72_CALC'] = np.minimum(calc_columns['LIGNE_71_CALC'], 400000)\n",
        "\n",
        "        # Montant net des dépenses d'innovation\n",
        "        calc_columns['LIGNE_77A_CALC'] = calc_columns['LIGNE_72_CALC'] - df_tmp['MT_AID_SUBV_INO'] - \\\n",
        "                                       df_tmp['MT_ENC_PRESTA_INO'] - df_tmp['MT_DEP_CONSEILS_CII'] + \\\n",
        "                                       df_tmp['REMBST_SUBV_INO']\n",
        "\n",
        "        # Calcul des parts DOM et Corse\n",
        "        calc_columns['LIGNE_77B_CALC'] = df_tmp['MT_NET_DEP_INO_DOM']\n",
        "        calc_columns['LIGNE_77C_CALC'] = df_tmp['MT_NET_DEP_INO_MPE_CORSE']\n",
        "        calc_columns['LIGNE_77D_CALC'] = df_tmp['MT_NET_DEP_INO_ME_CORSE']\n",
        "\n",
        "        # Mise à jour du DataFrame temporaire\n",
        "        for col in ['LIGNE_67_CALC', 'LIGNE_71_CALC', 'LIGNE_72_CALC', 'LIGNE_77A_CALC',\n",
        "                    'LIGNE_77B_CALC', 'LIGNE_77C_CALC', 'LIGNE_77D_CALC']:\n",
        "            df_calc_temp[col] = calc_columns[col]\n",
        "\n",
        "        # CIR Innovation selon les taux\n",
        "        calc_columns['LIGNE_78_CALC'] = ((df_calc_temp['LIGNE_77A_CALC'] - df_calc_temp['LIGNE_77B_CALC'] -\n",
        "                                      df_calc_temp['LIGNE_77C_CALC'] - df_calc_temp['LIGNE_77D_CALC']) * 0.2) + \\\n",
        "                                     (df_calc_temp['LIGNE_77B_CALC'] * 0.4) + \\\n",
        "                                     (df_calc_temp['LIGNE_77C_CALC'] * 0.4) + \\\n",
        "                                     (df_calc_temp['LIGNE_77D_CALC'] * 0.35)\n",
        "\n",
        "        # Ligne 79: Quote-part de crédit d'impôt innovation résultant de la participation sociétés de personnes\n",
        "        calc_columns['LIGNE_79'] = df_tmp['MT_QP_CII']\n",
        "\n",
        "        # Ligne 80a: Montant total du crédit d'impôt au titre des dépenses d'innovation\n",
        "        calc_columns['LIGNE_80A_CALC'] = calc_columns['LIGNE_78_CALC'] + calc_columns['LIGNE_79']\n",
        "\n",
        "        # Ligne 80b: Montant du crédit d'impôt pour dépenses d'innovation DOM\n",
        "        calc_columns['LIGNE_80B_CALC'] = df_tmp['MT_CII_YC_QP_DOM']\n",
        "\n",
        "        # Ligne 80c: Montant du crédit d'impôt pour dépenses d'innovation Corse\n",
        "        calc_columns['LIGNE_80C_CALC'] = df_tmp['MT_CII_CORSE']\n",
        "\n",
        "        calc_columns['CIR_INNOVATION_RECALCULE'] = calc_columns['LIGNE_80A_CALC']\n",
        "    else:\n",
        "        # Si données non disponibles, mettre à 0 (afin d'éviter des erreurs)\n",
        "        calc_columns['CIR_INNOVATION_RECALCULE'] = np.zeros(len(df_tmp))\n",
        "        calc_columns['LIGNE_78_CALC'] = np.zeros(len(df_tmp))\n",
        "        calc_columns['LIGNE_79'] = np.zeros(len(df_tmp))\n",
        "        calc_columns['LIGNE_80A_CALC'] = np.zeros(len(df_tmp))\n",
        "        calc_columns['LIGNE_80B_CALC'] = np.zeros(len(df_tmp))\n",
        "        calc_columns['LIGNE_80C_CALC'] = np.zeros(len(df_tmp))\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    for col in ['CIR_INNOVATION_RECALCULE', 'LIGNE_78_CALC', 'LIGNE_79', 'LIGNE_80A_CALC',\n",
        "               'LIGNE_80B_CALC', 'LIGNE_80C_CALC']:\n",
        "        if col in calc_columns:\n",
        "            df_calc_temp[col] = calc_columns[col]\n",
        "\n",
        "    # Ligne 81a: Montant total du crédit d'impôt au titre des dépenses de recherche, de collection et d'innovation\n",
        "    ligne_81a_values = []\n",
        "    for _, row in df_calc_temp.iterrows():\n",
        "        if row['DEPENSES_MOINS_100M']:\n",
        "            ligne_81a_values.append(row['LIGNE_46A_CALC'] + row['LIGNE_80A_CALC'])\n",
        "        else:\n",
        "            ligne_81a_values.append(row['LIGNE_64A_CALC'] + row['LIGNE_80A_CALC'])\n",
        "    calc_columns['LIGNE_81A_CALC'] = np.array(ligne_81a_values)\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_81A_CALC'] = calc_columns['LIGNE_81A_CALC']\n",
        "\n",
        "    # Ligne 81b: Montant du crédit d'impôt recherche, collection et innovation DOM\n",
        "    ligne_81b_values = []\n",
        "    for _, row in df_calc_temp.iterrows():\n",
        "        if row['DEPENSES_MOINS_100M']:\n",
        "            ligne_81b_values.append(row['LIGNE_46B_CALC'] + row['LIGNE_80B_CALC'])\n",
        "        else:\n",
        "            ligne_81b_values.append(row['LIGNE_64B_CALC'] + row['LIGNE_80B_CALC'])\n",
        "    calc_columns['LIGNE_81B_CALC'] = np.array(ligne_81b_values)\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_81B_CALC'] = calc_columns['LIGNE_81B_CALC']\n",
        "\n",
        "\n",
        "    # Calcul ligne 90: Quote-part de crédit d'impôt résultant de la participation sociétés de personnes\n",
        "    calc_columns['LIGNE_90'] = df_tmp['QP_MT_CRC']\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_90'] = calc_columns['LIGNE_90']\n",
        "\n",
        "    # Calcul ligne 91: Montant total du crédit d'impôt au titre des dépenses de recherche collaborative\n",
        "    calc_columns['LIGNE_91_CALC'] = df_calc_temp['LIGNE_89_CALC'] + df_calc_temp['LIGNE_90']\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['LIGNE_91_CALC'] = calc_columns['LIGNE_91_CALC']\n",
        "\n",
        "## ===========================================================\n",
        "    ## TOTAL DU CRÉDIT D'IMPÔT FINAL (CIR + CII + CRC)\n",
        "    ## ===========================================================\n",
        "\n",
        "    # Rappel des composantes à additionner :\n",
        "    # CIR R&C = CIR_RECHERCHE_RECALCULE + CIR_COLLECTION_RECALCULE (déjà calculés)\n",
        "    # CII Total = CIR_INNOVATION_RECALCULE (basé sur L80a) (déjà calculé)\n",
        "    # CRC Total = LIGNE_91_CALC (L89 + L90) (déjà calculé)\n",
        "\n",
        "    # Initialiser le total avec les composantes Recherche et Collection\n",
        "    calc_columns['CIR_TOTAL_RECALCULE'] = calc_columns['CIR_RECHERCHE_RECALCULE'] + \\\n",
        "                                          calc_columns['CIR_COLLECTION_RECALCULE']\n",
        "\n",
        "    # Ajouter la composante Innovation (CII) si elle a été calculée\n",
        "    # (La variable CIR_INNOVATION_RECALCULE contient déjà L80a = L78 + L79)\n",
        "    if 'CIR_INNOVATION_RECALCULE' in calc_columns:\n",
        "        # S'assurer que la valeur n'est pas NaN avant d'ajouter\n",
        "        calc_columns['CIR_TOTAL_RECALCULE'] += np.nan_to_num(calc_columns['CIR_INNOVATION_RECALCULE'])\n",
        "\n",
        "    # Ajouter la composante Collaborative (CRC) TOTALE (Ligne 91) si elle a été calculée\n",
        "    # *** C'est la ligne corrigée pour utiliser L91 au lieu de L89 dans la somme ***\n",
        "    if 'LIGNE_91_CALC' in calc_columns:\n",
        "        # S'assurer que la valeur n'est pas NaN avant d'ajouter\n",
        "        calc_columns['CIR_TOTAL_RECALCULE'] += np.nan_to_num(calc_columns['LIGNE_91_CALC'])\n",
        "\n",
        "    # Optionnel mais recommandé : Mettre à jour df_calc_temp si CIR_TOTAL_RECALCULE est utilisé dans des étapes ultérieures\n",
        "    # (par exemple pour le calcul de l'écart final)\n",
        "    # Vérifier si la colonne existe déjà avant d'affecter pour éviter KeyError si non initialisée\n",
        "    if 'CIR_TOTAL_RECALCULE' not in df_calc_temp.columns:\n",
        "         df_calc_temp['CIR_TOTAL_RECALCULE'] = 0 # Ou une initialisation appropriée\n",
        "    df_calc_temp['CIR_TOTAL_RECALCULE'] = calc_columns['CIR_TOTAL_RECALCULE']\n",
        "\n",
        "    # ANALYSE DES ÉCARTS\n",
        "\n",
        "    # Écarts sur toutes les lignes recalculées\n",
        "    # 1. Dépenses internes\n",
        "    calc_columns['ECART_LIGNE_6'] = calc_columns['LIGNE_6_CALC'] - df_tmp['OTR_DEP_FONCT']\n",
        "    calc_columns['ECART_LIGNE_7'] = calc_columns['LIGNE_7_CALC'] - df_tmp['MT_DEP_FONCT_TOT']\n",
        "    calc_columns['ECART_LIGNE_14'] = calc_columns['LIGNE_14_CALC'] - df_tmp['MT_TOT_RD_1']\n",
        "\n",
        "    # 2. Dépenses externalisées\n",
        "    calc_columns['ECART_LIGNE_17'] = calc_columns['LIGNE_17_CALC'] - df_tmp['MT_TOT_DEP_EXT_ORG_AGREE']\n",
        "    calc_columns['ECART_LIGNE_18'] = calc_columns['LIGNE_18_CALC'] - df_tmp['PLAF_OP_EXT']\n",
        "    calc_columns['ECART_LIGNE_19'] = calc_columns['LIGNE_19_CALC'] - df_tmp['PLAF_OP_EXT_ORG_AGRE_LIE']\n",
        "    calc_columns['ECART_LIGNE_20'] = calc_columns['LIGNE_20_CALC'] - df_tmp['PLAF_OP_EXT_ORG_AGRE_NON_LIE']\n",
        "    calc_columns['ECART_LIGNE_21'] = calc_columns['LIGNE_21_CALC'] - df_tmp['MT_DEP_EXT_PLAF']\n",
        "\n",
        "    # 3. Montant total et net\n",
        "    calc_columns['ECART_LIGNE_22'] = calc_columns['LIGNE_22_CALC'] - df_tmp['MT_TOT_RD_2']\n",
        "    calc_columns['ECART_LIGNE_26A'] = calc_columns['LIGNE_26A_CALC'] - df_tmp['MT_NET_DEP_RD']\n",
        "    calc_columns['ECART_LIGNE_26B'] = calc_columns['LIGNE_26B_CALC'] - df_tmp['MT_NET_DEP_RD_DOM']\n",
        "\n",
        "    # 4. Dépenses de collection\n",
        "    calc_columns['ECART_LIGNE_29'] = calc_columns['LIGNE_29_CALC'] - df_tmp['MT_TOT_DEP_COLL']\n",
        "    calc_columns['ECART_LIGNE_33A'] = calc_columns['LIGNE_33A_CALC'] - df_tmp['MT_NET_DEP_COLL']\n",
        "    calc_columns['ECART_LIGNE_33B'] = calc_columns['LIGNE_33B_CALC'] - df_tmp['MT_NET_DEP_COLL_DOM']\n",
        "\n",
        "    # 5. Innovation\n",
        "    if all(col in df_tmp.columns for col in ['MT_TOT_DEP_INO', 'MT_TOT_DEP_INO_PLAF', 'MT_NET_DEP_INO']):\n",
        "        calc_columns['ECART_LIGNE_71'] = calc_columns['LIGNE_71_CALC'] - df_tmp['MT_TOT_DEP_INO']\n",
        "        calc_columns['ECART_LIGNE_72'] = calc_columns['LIGNE_72_CALC'] - df_tmp['MT_TOT_DEP_INO_PLAF']\n",
        "        calc_columns['ECART_LIGNE_77A'] = calc_columns['LIGNE_77A_CALC'] - df_tmp['MT_NET_DEP_INO']\n",
        "\n",
        "    # 6. Collaboratif\n",
        "    if all(col in df_tmp.columns for col in ['DEP_CRC_PLAF', 'MT_NET_DEP_CRC']):\n",
        "        calc_columns['ECART_LIGNE_84'] = calc_columns['LIGNE_84_CALC'] - df_tmp['DEP_CRC_PLAF']\n",
        "        calc_columns['ECART_MT_NET_DEP_CRC'] = calc_columns['MT_NET_DEP_CRC_CALC'] - df_tmp['MT_NET_DEP_CRC']\n",
        "\n",
        "    # 7. Crédits d'impôt\n",
        "    calc_columns['ECART_CIR_RECHERCHE'] = calc_columns['CIR_RECHERCHE_RECALCULE'] - df_tmp['MT_CIR_RECH_YC_QP_MOINS_DE100']\n",
        "    calc_columns['ECART_CIR_COLLECTION'] = calc_columns['CIR_COLLECTION_RECALCULE'] - df_tmp['MT_CI_COLL_APRS_MINIMI']\n",
        "\n",
        "    if 'CIR_INNOVATION_RECALCULE' in df_calc_temp.columns:\n",
        "        calc_columns['ECART_CIR_INNOVATION'] = df_calc_temp['CIR_INNOVATION_RECALCULE'] - df_tmp['MT_CII_YC_QP']\n",
        "    else:\n",
        "        calc_columns['ECART_CIR_INNOVATION'] = -df_tmp['MT_CII_YC_QP']\n",
        "\n",
        "    if 'CIR_COLLAB_RECALCULE' in df_calc_temp.columns:\n",
        "        calc_columns['ECART_CIR_COLLAB'] = df_calc_temp['CIR_COLLAB_RECALCULE'] - df_tmp['MT_CRC']\n",
        "    else:\n",
        "        calc_columns['ECART_CIR_COLLAB'] = -df_tmp['MT_CRC']\n",
        "\n",
        "    # Écart total CIR\n",
        "    calc_columns['ECART_CIR'] = df_calc_temp['CIR_TOTAL_RECALCULE'] - df_tmp['MT_TOT_CIR_CI_COLL_CII']\n",
        "\n",
        "    # Mise à jour du DataFrame temporaire\n",
        "    df_calc_temp['ECART_CIR'] = calc_columns['ECART_CIR']\n",
        "\n",
        "    # Indicateur de correspondance (avec seuil de tolérance de 1)\n",
        "    correspondance_values = []\n",
        "    for ecart in calc_columns['ECART_CIR']:\n",
        "        if abs(ecart) <= 1:\n",
        "            correspondance_values.append(\"Oui\")\n",
        "        else:\n",
        "            correspondance_values.append(\"Non\")\n",
        "    calc_columns['CORRESPONDANCE'] = np.array(correspondance_values)\n",
        "\n",
        "    # Écart relatif\n",
        "    ecart_relatif_values = []\n",
        "    for i, row in df_calc_temp.iterrows():\n",
        "        if row['MT_TOT_CIR_CI_COLL_CII'] > 0:\n",
        "            ecart_relatif_values.append((row['ECART_CIR'] / row['MT_TOT_CIR_CI_COLL_CII'] * 100))\n",
        "        else:\n",
        "            ecart_relatif_values.append(100 if row['ECART_CIR'] > 0 else 0)\n",
        "    calc_columns['ECART_RELATIF'] = np.array(ecart_relatif_values)\n",
        "\n",
        "    # Création du DataFrame final avec toutes les colonnes calculées\n",
        "    # (cela évite la fragmentation du DataFrame)\n",
        "    df_calc_final = pd.DataFrame(calc_columns)\n",
        "\n",
        "    # Création du DataFrame final pour l'analyse\n",
        "    df_num = pd.concat([df_tmp, df_calc_final], axis=1)\n",
        "\n",
        "\n",
        "    ## CRÉATION DU FICHIER DE COMPARAISON DÉTAILLÉ\n",
        "\n",
        "\n",
        "    # Préparation du dictionnaire de mapping pour la sortie\n",
        "    # Structure: 'colonne_originale': 'nom_colonne_sortie'\n",
        "    mapping_colonnes = {\n",
        "        # Colonnes d'identification\n",
        "        'siren_declarant': 'SIREN_DECLARANT',\n",
        "        'siren_deposant': 'SIREN_DEPOSANT',\n",
        "        'DESIGN': 'DESIGNATION',\n",
        "        'COMPLT_DESIGN': 'COMPLEMENT_DESIGNATION',\n",
        "\n",
        "        # I-A. Dépenses internes\n",
        "        'DOT_AMORT_IMMO': 'L1_DOTATION_AMORT_IMMO',\n",
        "        'DOT_AMORT_IMMO_SINISTR': 'L2_DOTATION_AMORT_SINISTR',\n",
        "        'DEP_CHERCH_TECH': 'L3_DEPENSES_PERSONNEL_CHERCHEURS',\n",
        "        'REM_SAL_INV': 'L4_REMUNERATION_INVENTEURS',\n",
        "        'DEP_JD': 'L5_DEPENSES_JEUNES_DOCTEURS',\n",
        "        'OTR_DEP_FONCT': 'L6_AUTRES_DEP_FONCT_DECLARE',\n",
        "        'LIGNE_6_CALC': 'L6_AUTRES_DEP_FONCT_CALCULE',\n",
        "        'ECART_LIGNE_6': 'L6_ECART',\n",
        "        'MT_DEP_FONCT_TOT': 'L7_TOTAL_DEP_FONCT_DECLARE',\n",
        "        'LIGNE_7_CALC': 'L7_TOTAL_DEP_FONCT_CALCULE',\n",
        "        'ECART_LIGNE_7': 'L7_ECART',\n",
        "        'FRAIS_BREV_COV': 'L8_FRAIS_BREVETS_COV',\n",
        "        'DEP_MAINT_BREV_COV': 'L9_DEPENSES_DEFENSE_BREVETS',\n",
        "        'DOT_AMORT_BREV': 'L10_DOTATION_AMORT_BREVETS',\n",
        "        'DEP_NORMALI': 'L11_DEPENSES_NORMALISATION_BRUT',\n",
        "        'DEP_NORMALI_RECALC': 'L11_DEPENSES_NORMALISATION_DECLARE',\n",
        "        'PRIM_COTIZ': 'L12_PRIMES_COTISATIONS_BRUT',\n",
        "        'PRIM_COTIZ_PLAFONNEES': 'L12_PRIMES_COTISATIONS_PLAFONNEES',\n",
        "        'DEP_VEIL_TECHNO': 'L13_VEILLE_TECHNO_BRUT',\n",
        "        'DEP_VEIL_TECHNO_PLAFONNEES': 'L13_VEILLE_TECHNO_PLAFONNEE',\n",
        "        'MT_TOT_RD_1': 'L14_TOTAL_DEPENSES_INTERNES_DECLARE',\n",
        "        'LIGNE_14_CALC': 'L14_TOTAL_DEPENSES_INTERNES_CALCULE',\n",
        "        'ECART_LIGNE_14': 'L14_ECART',\n",
        "\n",
        "        # I-B. Dépenses externalisées\n",
        "        'DEP_EXT_LIE_FR': 'L15A_DEPENSES_ORG_LIES_FR',\n",
        "        'DEP_EXT_LIE_ETR': 'L15B_DEPENSES_ORG_LIES_ETR',\n",
        "        'DEP_EXT_NON_LIE_FR': 'L16A_DEPENSES_ORG_NON_LIES_FR',\n",
        "        'DEP_EXT_NON_LIE_ETR': 'L16B_DEPENSES_ORG_NON_LIES_ETR',\n",
        "        'MT_TOT_DEP_EXT_ORG_AGREE': 'L17_TOTAL_DEP_EXTERNALISEES_DECLARE',\n",
        "        'LIGNE_17_CALC': 'L17_TOTAL_DEP_EXTERNALISEES_CALCULE',\n",
        "        'ECART_LIGNE_17': 'L17_ECART',\n",
        "        'PLAF_OP_EXT': 'L18_PLAFOND_GLOBAL_DECLARE',\n",
        "        'LIGNE_18_CALC': 'L18_PLAFOND_GLOBAL_CALCULE',\n",
        "        'ECART_LIGNE_18': 'L18_ECART',\n",
        "        'PLAF_OP_EXT_ORG_AGRE_LIE': 'L19_PLAFOND_ORG_LIES_DECLARE',\n",
        "        'LIGNE_19_CALC': 'L19_PLAFOND_ORG_LIES_CALCULE',\n",
        "        'ECART_LIGNE_19': 'L19_ECART',\n",
        "        'PLAF_OP_EXT_ORG_AGRE_NON_LIE': 'L20_PLAFOND_ORG_NON_LIES_DECLARE',\n",
        "        'LIGNE_20_CALC': 'L20_PLAFOND_ORG_NON_LIES_CALCULE',\n",
        "        'ECART_LIGNE_20': 'L20_ECART',\n",
        "        'MT_DEP_EXT_PLAF': 'L21_TOTAL_DEP_EXT_PLAFONNEES_DECLARE',\n",
        "        'LIGNE_21_CALC': 'L21_TOTAL_DEP_EXT_PLAFONNEES_CALCULE',\n",
        "        'ECART_LIGNE_21': 'L21_ECART',\n",
        "\n",
        "        # I-C. Montant total et net\n",
        "        'MT_TOT_RD_2': 'L22_TOTAL_DEPENSES_RECHERCHE_DECLARE',\n",
        "        'LIGNE_22_CALC': 'L22_TOTAL_DEPENSES_RECHERCHE_CALCULE',\n",
        "        'ECART_LIGNE_22': 'L22_ECART',\n",
        "        'MT_AID_SUBV': 'L23A_SUBVENTIONS',\n",
        "        'MT_ENC_PRESTA': 'L23B_SOMMES_ENCAISSEES_TIERS',\n",
        "        'MT_DEP_CONSEILS_CIR': 'L24_DEPENSES_CONSEIL_CIR',\n",
        "        'REMBST_SUBV': 'L25_REMBOURSEMENTS_SUBVENTIONS',\n",
        "        'MT_NET_DEP_RD': 'L26A_MONTANT_NET_DEPENSES_DECLARE',\n",
        "        'LIGNE_26A_CALC': 'L26A_MONTANT_NET_DEPENSES_CALCULE',\n",
        "        'ECART_LIGNE_26A': 'L26A_ECART',\n",
        "        'MT_NET_DEP_RD_DOM': 'L26B_MONTANT_NET_DEPENSES_DOM_DECLARE',\n",
        "        'LIGNE_26B_CALC': 'L26B_MONTANT_NET_DEPENSES_DOM_CALCULE',\n",
        "        'ECART_LIGNE_26B': 'L26B_ECART',\n",
        "\n",
        "        # II. Dépenses de collection\n",
        "        'FRAIS_COLL': 'L27_FRAIS_COLLECTION',\n",
        "        'FRAIS_DEF_DESSIN': 'L28_FRAIS_DEFENSE_DESSINS_BRUT',\n",
        "        'FRAIS_DEF_DESSIN_PLAFONNES': 'L28_FRAIS_DEFENSE_DESSINS_PLAFONNES',\n",
        "        'MT_TOT_DEP_COLL': 'L29_TOTAL_DEPENSES_COLLECTION_DECLARE',\n",
        "        'LIGNE_29_CALC': 'L29_TOTAL_DEPENSES_COLLECTION_CALCULE',\n",
        "        'ECART_LIGNE_29': 'L29_ECART',\n",
        "        'MT_AID_SUBV_COLL': 'L30_SUBVENTIONS_COLLECTION',\n",
        "        'MT_DEP_CONSEILS_CIR_COLL': 'L31_DEPENSES_CONSEIL_COLLECTION',\n",
        "        'REMBST_SUBV_COLL': 'L32_REMBOURSEMENTS_SUBVENTIONS_COLL',\n",
        "        'MT_NET_DEP_COLL': 'L33A_MONTANT_NET_COLLECTION_DECLARE',\n",
        "        'LIGNE_33A_CALC': 'L33A_MONTANT_NET_COLLECTION_CALCULE',\n",
        "        'ECART_LIGNE_33A': 'L33A_ECART',\n",
        "        'MT_NET_DEP_COLL_DOM': 'L33B_MONTANT_NET_COLLECTION_DOM_DECLARE',\n",
        "        'LIGNE_33B_CALC': 'L33B_MONTANT_NET_COLLECTION_DOM_CALCULE',\n",
        "        'ECART_LIGNE_33B': 'L33B_ECART',\n",
        "        'LIGNE_34A_CALC': 'L34A_MONTANT_NET_TOTAL_RD_COLL',\n",
        "        'LIGNE_34B_CALC': 'L34B_MONTANT_NET_TOTAL_RD_COLL_DOM',\n",
        "\n",
        "        # III. Calcul CIR Recherche et Collection\n",
        "        'LIGNE_36_CALC': 'L36_CREDIT_IMPOT_RECHERCHE_MOINS_100M',\n",
        "        'LIGNE_37': 'L37_QUOTE_PART_RECHERCHE_SOC_PERSONNES',\n",
        "        'LIGNE_38A_CALC': 'L38A_CREDIT_IMPOT_RECHERCHE_TOTAL',\n",
        "        'LIGNE_38B_CALC': 'L38B_CREDIT_IMPOT_RECHERCHE_DOM',\n",
        "        'LIGNE_40_CALC': 'L40_CREDIT_IMPOT_COLLECTION_MOINS_100M',\n",
        "        'LIGNE_41': 'L41_QUOTE_PART_COLLECTION_SOC_PERSONNES',\n",
        "        'LIGNE_42A_CALC': 'L42A_CREDIT_IMPOT_COLL_AVANT_PLAF',\n",
        "        'LIGNE_42B_CALC': 'L42B_CREDIT_IMPOT_COLL_DOM_AVANT_PLAF',\n",
        "        'LIGNE_43': 'L43_AIDES_MINIMIS',\n",
        "        'LIGNE_44': 'L44_CUMUL_CREDIT_IMPOT_ET_AIDES',\n",
        "        'LIGNE_45A_CALC': 'L45A_CREDIT_IMPOT_COLL_APRES_PLAF',\n",
        "        'LIGNE_45B_CALC': 'L45B_CREDIT_IMPOT_COLL_DOM_APRES_PLAF',\n",
        "        'LIGNE_46A_CALC': 'L46A_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION',\n",
        "        'LIGNE_46B_CALC': 'L46B_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION_DOM',\n",
        "        'LIGNE_47A_CALC': 'L47A_DEPENSES_RECHERCHE_LIMITE_100M',\n",
        "        'LIGNE_47B_CALC': 'L47B_DEPENSES_RECHERCHE_DOM_LIMITE',\n",
        "        'LIGNE_48_CALC': 'L48_CIR_RECHERCHE_PREMIERE_TRANCHE',\n",
        "        'LIGNE_49_CALC': 'L49_DEPENSES_RECHERCHE_SUP_100M',\n",
        "        'LIGNE_50_CALC': 'L50_CIR_RECHERCHE_DEUXIEME_TRANCHE',\n",
        "        'LIGNE_51_CALC': 'L51_CIR_RECHERCHE_PLUS_100M',\n",
        "        'LIGNE_52': 'L52_QUOTE_PART_RECHERCHE_SOC_PERSONNES_PLUS_100M',\n",
        "        'LIGNE_53A_CALC': 'L53A_CREDIT_IMPOT_RECHERCHE_TOTAL_PLUS_100M',\n",
        "        'LIGNE_53B_CALC': 'L53B_CREDIT_IMPOT_RECHERCHE_DOM_PLUS_100M',\n",
        "        'LIGNE_54A_CALC': 'L54A_MONTANT_NET_COLLECTION_PLUS_100M',\n",
        "        'LIGNE_54B_CALC': 'L54B_MONTANT_NET_COLLECTION_DOM_PLUS_100M',\n",
        "        'LIGNE_55_CALC': 'L55_PLAFOND_DISPO_COLLECTION',\n",
        "        'LIGNE_56_CALC': 'L56_CIR_COLLECTION_PREMIERE_TRANCHE',\n",
        "        'LIGNE_57_CALC': 'L57_CIR_COLLECTION_DEUXIEME_TRANCHE',\n",
        "        'LIGNE_58_CALC': 'L58_CIR_COLLECTION_PLUS_100M',\n",
        "        'LIGNE_59': 'L59_QUOTE_PART_COLLECTION_SOC_PERSONNES_PLUS_100M',\n",
        "        'LIGNE_60': 'L60_CREDIT_IMPOT_COLL_AVANT_PLAF_PLUS_100M',\n",
        "        'LIGNE_61': 'L61_AIDES_MINIMIS_PLUS_100M',\n",
        "        'LIGNE_62': 'L62_CUMUL_CREDIT_IMPOT_ET_AIDES_PLUS_100M',\n",
        "        'LIGNE_63A_CALC': 'L63A_CREDIT_IMPOT_COLL_APRES_PLAF_PLUS_100M',\n",
        "        'LIGNE_63B_CALC': 'L63B_CREDIT_IMPOT_COLL_DOM_APRES_PLAF_PLUS_100M',\n",
        "        'LIGNE_64A_CALC': 'L64A_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION_PLUS_100M',\n",
        "        'LIGNE_64B_CALC': 'L64B_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION_DOM_PLUS_100M',\n",
        "\n",
        "        # IV. Dépenses d'innovation\n",
        "        'DOT_AMORT_IMMO_INO': 'L65_DOTATION_AMORT_IMMO_INNOVATION',\n",
        "        'DEP_PERSONEL_INO': 'L66_DEPENSES_PERSONNEL_INNOVATION',\n",
        "        'LIGNE_67_CALC': 'L67_AUTRES_DEP_FONCT_INNOVATION',\n",
        "        'FRAIS_BREV_COV_INO': 'L68_FRAIS_BREVETS_INNOVATION',\n",
        "        'FRAIS_DEF_BREV_INO': 'L69_FRAIS_DEFENSE_BREVETS_INNOVATION',\n",
        "        'OP_INOV_EXT': 'L70_OPERATIONS_CONFIEES_INNOVATION',\n",
        "        'MT_TOT_DEP_INO': 'L71_TOTAL_DEPENSES_INNOVATION_DECLARE',\n",
        "        'LIGNE_71_CALC': 'L71_TOTAL_DEPENSES_INNOVATION_CALCULE',\n",
        "        'ECART_LIGNE_71': 'L71_ECART',\n",
        "        'MT_TOT_DEP_INO_PLAF': 'L72_DEPENSES_INNOVATION_PLAFONNEES_DECLARE',\n",
        "        'LIGNE_72_CALC': 'L72_DEPENSES_INNOVATION_PLAFONNEES_CALCULE',\n",
        "        'ECART_LIGNE_72': 'L72_ECART',\n",
        "        'MT_AID_SUBV_INO': 'L73_SUBVENTIONS_INNOVATION',\n",
        "        'MT_ENC_PRESTA_INO': 'L74_PRESTATIONS_INNOVATION',\n",
        "        'MT_DEP_CONSEILS_CII': 'L75_DEPENSES_CONSEIL_INNOVATION',\n",
        "        'REMBST_SUBV_INO': 'L76_REMBOURSEMENTS_SUBVENTIONS_INNO',\n",
        "        'MT_NET_DEP_INO': 'L77A_MONTANT_NET_INNOVATION_DECLARE',\n",
        "        'LIGNE_77A_CALC': 'L77A_MONTANT_NET_INNOVATION_CALCULE',\n",
        "        'ECART_LIGNE_77A': 'L77A_ECART',\n",
        "        'MT_NET_DEP_INO_DOM': 'L77B_MONTANT_NET_INNOVATION_DOM',\n",
        "        'MT_NET_DEP_INO_MPE_CORSE': 'L77C_MONTANT_NET_INNOVATION_CORSE_MPE',\n",
        "        'MT_NET_DEP_INO_ME_CORSE': 'L77D_MONTANT_NET_INNOVATION_CORSE_ME',\n",
        "        'LIGNE_78_CALC': 'L78_CREDIT_IMPOT_INNOVATION',\n",
        "        'LIGNE_79': 'L79_QUOTE_PART_INNOVATION_SOC_PERSONNES',\n",
        "        'LIGNE_80A_CALC': 'L80A_TOTAL_CREDIT_IMPOT_INNOVATION',\n",
        "        'LIGNE_80B_CALC': 'L80B_CREDIT_IMPOT_INNOVATION_DOM',\n",
        "        'LIGNE_80C_CALC': 'L80C_CREDIT_IMPOT_INNOVATION_CORSE',\n",
        "        'LIGNE_81A_CALC': 'L81A_TOTAL_CIR_RECH_COLL_INNO',\n",
        "        'LIGNE_81B_CALC': 'L81B_TOTAL_CIR_RECH_COLL_INNO_DOM',\n",
        "\n",
        "        # V. Recherche collaborative\n",
        "        'DEP_CRC': 'L82_DEPENSES_RECHERCHE_COLLABORATIVE',\n",
        "        'DEP_CRC_FR': 'L83A_DEPENSES_RC_FRANCE',\n",
        "        'DEP_CRC_ETR': 'L83B_DEPENSES_RC_ETRANGER',\n",
        "        'LIGNE_83_CALC': 'L83_TOTAL_DEPENSES_RC',\n",
        "        'DEP_CRC_PLAF': 'L84_DEPENSES_RC_PLAFONNEES_DECLARE',\n",
        "        'LIGNE_84_CALC': 'L84_DEPENSES_RC_PLAFONNEES_CALCULE',\n",
        "        'ECART_LIGNE_84': 'L84_ECART',\n",
        "        'AIDE_PUB_CRC': 'L85_AIDES_PUBLIQUES_RC',\n",
        "        'AIDE_PUB_REMB_CRC': 'L86_REMBOURSEMENTS_AIDES_RC',\n",
        "        'MT_NET_DEP_CRC': 'L87_MONTANT_NET_RC_DECLARE',\n",
        "        'MT_NET_DEP_CRC_CALC': 'L87_MONTANT_NET_RC_CALCULE',\n",
        "        'ECART_MT_NET_DEP_CRC': 'L87_ECART',\n",
        "        'MT_NET_DEP_CRC_PME': 'L88_MONTANT_NET_RC_PME',\n",
        "        'LIGNE_89_CALC': 'L89_CREDIT_IMPOT_RC',\n",
        "        'LIGNE_90': 'L90_QUOTE_PART_RC_SOC_PERSONNES',\n",
        "        'LIGNE_91_CALC': 'L91_MONTANT_TOTAL_CIR_RECHERCHE_COLLABORATIVE',\n",
        "\n",
        "        # Crédits d'impôt par composante\n",
        "        'MT_CIR_RECH_YC_QP_MOINS_DE100': 'CIR_RECHERCHE_DECLARE',\n",
        "        'CIR_RECHERCHE_RECALCULE': 'CIR_RECHERCHE_CALCULE',\n",
        "        'ECART_CIR_RECHERCHE': 'CIR_RECHERCHE_ECART',\n",
        "\n",
        "        'MT_CI_COLL_APRS_MINIMI': 'CIR_COLLECTION_DECLARE',\n",
        "        'CIR_COLLECTION_RECALCULE': 'CIR_COLLECTION_CALCULE',\n",
        "        'ECART_CIR_COLLECTION': 'CIR_COLLECTION_ECART',\n",
        "\n",
        "        'MT_CII_YC_QP': 'CIR_INNOVATION_DECLARE',\n",
        "        'CIR_INNOVATION_RECALCULE': 'CIR_INNOVATION_CALCULE',\n",
        "        'ECART_CIR_INNOVATION': 'CIR_INNOVATION_ECART',\n",
        "\n",
        "        'MT_CRC': 'CIR_COLLABORATIF_DECLARE',\n",
        "        'CIR_COLLAB_RECALCULE': 'CIR_COLLABORATIF_CALCULE',\n",
        "        'ECART_CIR_COLLAB': 'CIR_COLLABORATIF_ECART',\n",
        "\n",
        "        # CIR Total\n",
        "        'MT_TOT_CIR_CI_COLL_CII': 'CIR_TOTAL_DECLARE',\n",
        "        'CIR_TOTAL_RECALCULE': 'CIR_TOTAL_CALCULE',\n",
        "        'ECART_CIR': 'CIR_TOTAL_ECART',\n",
        "\n",
        "        # Indicateurs\n",
        "        'CORRESPONDANCE': 'CORRESPONDANCE_CIR',\n",
        "        'ECART_RELATIF': 'ECART_RELATIF_POURCENT'\n",
        "    }\n",
        "\n",
        "    # Création du DataFrame de comparaison\n",
        "    df_comparaison = pd.DataFrame()\n",
        "\n",
        "    # Copier chaque colonne si elle existe\n",
        "    for col_orig, col_dest in mapping_colonnes.items():\n",
        "        if col_orig in df_num.columns:\n",
        "            df_comparaison[col_dest] = df_num[col_orig]\n",
        "        else:\n",
        "            # Ne pas ajouter les colonnes qui n'existent pas\n",
        "            pass\n",
        "\n",
        "    # Concaténation de la désignation et du complément si disponible\n",
        "    if 'COMPLEMENT_DESIGNATION' in df_comparaison.columns:\n",
        "        df_comparaison['DESIGNATION'] = df_comparaison.apply(\n",
        "            lambda x: f\"{x['DESIGNATION']} {x['COMPLEMENT_DESIGNATION']}\" if pd.notna(x['COMPLEMENT_DESIGNATION']) else x['DESIGNATION'],\n",
        "            axis=1\n",
        "        )\n",
        "        df_comparaison.drop('COMPLEMENT_DESIGNATION', axis=1, inplace=True)\n",
        "\n",
        "    # Formatage des montants\n",
        "    montant_cols = [col for col in df_comparaison.columns if col not in ['SIREN_DECLARANT', 'SIREN_DEPOSANT', 'DESIGNATION', 'CORRESPONDANCE_CIR']]\n",
        "    for col in montant_cols:\n",
        "        df_comparaison[col] = df_comparaison[col].round(2)\n",
        "\n",
        "    # Sauvegarde du fichier de sortie\n",
        "    output_filename = f\"Calcul_Creance_CIR.csv\"\n",
        "    output_path = os.path.join(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB\", output_filename)\n",
        "\n",
        "    df_comparaison.to_csv(output_path, index=False, sep=';', encoding='utf-8-sig')\n",
        "\n",
        "    print(f\"\\nFichier de comparaison détaillée créé: {output_path}\")\n",
        "\n",
        "    # RÉSULTATS\n",
        "\n",
        "    # Somme des CIR déclarés\n",
        "    cir_declare_total = df_tmp['MT_TOT_CIR_CI_COLL_CII'].sum()\n",
        "\n",
        "    # Somme des CIR recalculés\n",
        "    cir_recalcule_total = df_calc_final['CIR_TOTAL_RECALCULE'].sum()\n",
        "\n",
        "    # Nombre d'entreprises\n",
        "    nb_entreprises_avec_cir = len(df_tmp[df_tmp['MT_TOT_CIR_CI_COLL_CII'] > 0])\n",
        "    nb_entreprises_plus_100m = df_calc_final['DEPENSES_PLUS_100M'].sum()\n",
        "\n",
        "    # Classement des écarts\n",
        "    ecarts_positifs = df_num[df_num['ECART_CIR'] > 1]  # Plus de 1 en plus\n",
        "    ecarts_negatifs = df_num[df_num['ECART_CIR'] < -1]  # Plus de 1 en moins\n",
        "    ecarts_conformes = df_num[abs(df_num['ECART_CIR']) <= 1]  # Différence de 1 ou moins\n",
        "\n",
        "    # AFFICHAGE DES RÉSULTATS\n",
        "    print(\"\\n===== COMPARAISON CIR DÉCLARÉ VS RECALCULÉ =====\")\n",
        "\n",
        "    print(f\"\\nNombre total d'entreprises analysées: {len(df_num):,}\")\n",
        "    print(f\"Nombre d'entreprises avec CIR déclaré: {nb_entreprises_avec_cir:,}\")\n",
        "    print(f\"Nombre d'entreprises avec dépenses > 100M€: {nb_entreprises_plus_100m:,}\")\n",
        "\n",
        "    print(f\"\\nCIR TOTAL:\")\n",
        "    print(f\"CIR déclaré total: {cir_declare_total:,.2f} €\")\n",
        "    print(f\"CIR recalculé total: {cir_recalcule_total:,.2f} €\")\n",
        "\n",
        "    difference = cir_recalcule_total - cir_declare_total\n",
        "    print(f\"Différence: {difference:,.2f} €\")\n",
        "    if cir_declare_total > 0:\n",
        "        print(f\"Écart relatif: {difference/cir_declare_total*100:.2f}%\")\n",
        "\n",
        "    print(f\"\\nANALYSE DES ÉCARTS:\")\n",
        "    print(f\"Entreprises avec CIR conforme (écart ≤ 1€): {len(ecarts_conformes):,} ({len(ecarts_conformes)/len(df_num)*100:.2f}%)\")\n",
        "\n",
        "    print(f\"Entreprises avec CIR recalculé > CIR déclaré (écart > 1€): {len(ecarts_positifs):,}\")\n",
        "    print(f\"Montant total des écarts positifs: {ecarts_positifs['ECART_CIR'].sum():,.2f} €\")\n",
        "\n",
        "    print(f\"Entreprises avec CIR recalculé < CIR déclaré (écart < -1€): {len(ecarts_negatifs):,}\")\n",
        "    print(f\"Montant total des écarts négatifs: {ecarts_negatifs['ECART_CIR'].sum():,.2f} €\")\n",
        "\n",
        "    # Détail par composante du CIR\n",
        "    print(f\"\\nDÉTAIL PAR COMPOSANTE DU CIR RECALCULÉ:\")\n",
        "    print(f\"CIR Recherche: {df_num['CIR_RECHERCHE_RECALCULE'].sum():,.2f} €\")\n",
        "    print(f\"CIR Collection: {df_num['CIR_COLLECTION_RECALCULE'].sum():,.2f} €\")\n",
        "\n",
        "    if 'CIR_INNOVATION_RECALCULE' in df_num.columns:\n",
        "        print(f\"CIR Innovation: {df_num['CIR_INNOVATION_RECALCULE'].sum():,.2f} €\")\n",
        "    else:\n",
        "        print(f\"CIR Innovation: 0.00 €\")\n",
        "\n",
        "    if 'CIR_COLLAB_RECALCULE' in df_num.columns:\n",
        "        print(f\"CIR Recherche Collaborative: {df_num['CIR_COLLAB_RECALCULE'].sum():,.2f} €\")\n",
        "    else:\n",
        "        print(f\"CIR Recherche Collaborative: 0.00 €\")\n",
        "\n",
        "    return df_comparaison\n",
        "\n",
        "# Exécuter le calcul\n",
        "try:\n",
        "    df_resultat = comparer_cir_declare_recalcule()\n",
        "    print(\"\\nTraitement terminé avec succès!\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nErreur: {type(e).__name__}: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY4e9HddyCMg"
      },
      "source": [
        "# Difference Creance Déclarer vs Calculé"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FfiBB9-yKme"
      },
      "source": [
        "## Crc manquant\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "qozsJxLZS-F2",
        "outputId": "1928e12d-3f20-44e1-9a96-249afd670bd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nombre total d'entreprises: 27957\n",
            "Nombre d'entreprises avec écarts (CORRESPONDANCE_CIR = 'Non'): 1549\n",
            "\n",
            "Exemples de SIREN_DECLARANT avant correction:\n",
            "  005520325 (type: <class 'str'>, longueur: 9)\n",
            "  005580436 (type: <class 'str'>, longueur: 9)\n",
            "  005680145 (type: <class 'str'>, longueur: 9)\n",
            "  006380042 (type: <class 'str'>, longueur: 9)\n",
            "  006580195 (type: <class 'str'>, longueur: 9)\n",
            "\n",
            "Nombre de SIREN n'ayant pas exactement 9 caractères: 0\n",
            "\n",
            "Exemples de SIREN_DECLARANT après correction:\n",
            "  005520325 (type: <class 'str'>, longueur: 9)\n",
            "  005580436 (type: <class 'str'>, longueur: 9)\n",
            "  005680145 (type: <class 'str'>, longueur: 9)\n",
            "  006380042 (type: <class 'str'>, longueur: 9)\n",
            "  006580195 (type: <class 'str'>, longueur: 9)\n",
            "Nombre de SIREN n'ayant pas exactement 9 caractères après correction: 0\n",
            "\n",
            "Nombre d'entreprises avec CRC apparemment manquant dans le montant déclaré: 12412\n",
            "\n",
            "Résultats après correction:\n",
            "Nombre d'entreprises avec écarts avant correction: 1549\n",
            "Nombre d'entreprises avec écarts après correction: 1530\n",
            "Nombre d'écarts résolus par l'ajout du CRC: 19 (1.23%)\n",
            "\n",
            "Exemples d'entreprises où l'écart a été résolu par l'ajout du CRC:\n",
            "\n",
            "Exemple 1: nan (SIREN: 330318270)\n",
            "  CIR déclaré original: 53394.00\n",
            "  CIR déclaré corrigé: 53394.00\n",
            "  CIR calculé: 53393.00\n",
            "  Écart original: -1.00\n",
            "  Écart corrigé: -1.00\n",
            "  CRC calculé: 0.0\n",
            "\n",
            "Exemple 2: SARL (SIREN: 332565035)\n",
            "  CIR déclaré original: 260061.00\n",
            "  CIR déclaré corrigé: 271386.00\n",
            "  CIR calculé: 271385.15\n",
            "  Écart original: 11324.15\n",
            "  Écart corrigé: -0.85\n",
            "  CRC calculé: 11325.0\n",
            "\n",
            "Exemple 3: SARL (SIREN: 482027240)\n",
            "  CIR déclaré original: 50341.00\n",
            "  CIR déclaré corrigé: 57211.00\n",
            "  CIR calculé: 57210.68\n",
            "  Écart original: 6869.68\n",
            "  Écart corrigé: -0.32\n",
            "  CRC calculé: 6870.0\n",
            "\n",
            "Fichier original mis à jour: M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR.csv\n",
            "- Format des SIREN corrigé\n",
            "- CRC manquant ajouté au montant déclaré\n",
            "\n",
            "Il reste 1530 entreprises avec des écarts à analyser.\n",
            "\n",
            "Principales sources d'écarts restants:\n",
            "1. L26A_ECART: 641 entreprises (41.90%)\n",
            "2. CIR_RECHERCHE_ECART: 628 entreprises (41.05%)\n",
            "3. L22_ECART: 610 entreprises (39.87%)\n",
            "4. CIR_INNOVATION_ECART: 366 entreprises (23.92%)\n",
            "5. L21_ECART: 350 entreprises (22.88%)\n",
            "\n",
            "Recherche d'autres patterns d'écarts similaires:\n",
            "  • Possible CIR Innovation manquant: 19 entreprises\n",
            "  • Possible CIR Collection manquant: 24 entreprises\n",
            "\n",
            "Fichier original mis à jour: M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR.csv\n",
            "- Format des SIREN corrigé\n",
            "- CRC manquant ajouté au montant déclaré\n",
            "\n",
            "Il reste 1530 entreprises avec des écarts à analyser.\n",
            "\n",
            "Principales sources d'écarts restants:\n",
            "1. L26A_ECART: 641 entreprises (41.90%)\n",
            "2. CIR_RECHERCHE_ECART: 628 entreprises (41.05%)\n",
            "3. L22_ECART: 610 entreprises (39.87%)\n",
            "4. CIR_INNOVATION_ECART: 366 entreprises (23.92%)\n",
            "5. L21_ECART: 350 entreprises (22.88%)\n",
            "\n",
            "Recherche d'autres patterns d'écarts similaires:\n",
            "  • Possible CIR Innovation manquant: 19 entreprises\n",
            "  • Possible CIR Collection manquant: 24 entreprises\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Fonction pour formater les SIREN correctement\n",
        "def format_siren(siren):\n",
        "    \"\"\"Formate les SIREN pour avoir exactement 9 caractères en ajoutant des zéros au début si nécessaire\"\"\"\n",
        "    if pd.isna(siren):\n",
        "        return siren\n",
        "\n",
        "    siren_str = str(siren).strip()\n",
        "\n",
        "    # Si le SIREN a moins de 9 caractères, ajouter des zéros au début\n",
        "    if len(siren_str) < 9:\n",
        "        siren_str = siren_str.zfill(9)  # zfill ajoute des zéros au début jusqu'à atteindre la longueur spécifiée\n",
        "\n",
        "    return siren_str\n",
        "\n",
        "# Charger le fichier CSV avec converters pour traiter SIREN comme du texte\n",
        "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR.csv\"\n",
        "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig',\n",
        "                converters={'SIREN_DECLARANT': str, 'SIREN_DEPOSANT': str})\n",
        "\n",
        "print(f\"Nombre total d'entreprises: {len(df)}\")\n",
        "print(f\"Nombre d'entreprises avec écarts (CORRESPONDANCE_CIR = 'Non'): {len(df[df['CORRESPONDANCE_CIR'] == 'Non'])}\")\n",
        "\n",
        "# 1. Corriger le format des SIREN\n",
        "if 'SIREN_DECLARANT' in df.columns:\n",
        "    # Afficher quelques exemples de SIREN avant correction\n",
        "    print(\"\\nExemples de SIREN_DECLARANT avant correction:\")\n",
        "    for siren in df['SIREN_DECLARANT'].head(5):\n",
        "        print(f\"  {siren} (type: {type(siren)}, longueur: {len(str(siren))})\")\n",
        "\n",
        "    # Identifier les SIREN qui n'ont pas 9 caractères\n",
        "    siren_lengths = df['SIREN_DECLARANT'].apply(lambda x: len(str(x)) if pd.notna(x) else 0)\n",
        "    unusual_siren_count = (siren_lengths != 9).sum()\n",
        "    print(f\"\\nNombre de SIREN n'ayant pas exactement 9 caractères: {unusual_siren_count}\")\n",
        "\n",
        "    # Appliquer la correction aux SIREN\n",
        "    df['SIREN_DECLARANT'] = df['SIREN_DECLARANT'].apply(format_siren)\n",
        "\n",
        "    # Si la colonne SIREN_DEPOSANT existe également, la corriger\n",
        "    if 'SIREN_DEPOSANT' in df.columns:\n",
        "        df['SIREN_DEPOSANT'] = df['SIREN_DEPOSANT'].apply(format_siren)\n",
        "\n",
        "    # Vérifier les SIREN après correction\n",
        "    print(\"\\nExemples de SIREN_DECLARANT après correction:\")\n",
        "    for siren in df['SIREN_DECLARANT'].head(5):\n",
        "        print(f\"  {siren} (type: {type(siren)}, longueur: {len(str(siren))})\")\n",
        "\n",
        "    # Vérifier qu'il n'y a plus de SIREN avec une longueur incorrecte\n",
        "    siren_lengths_after = df['SIREN_DECLARANT'].apply(lambda x: len(str(x)) if pd.notna(x) else 0)\n",
        "    unusual_siren_count_after = (siren_lengths_after != 9).sum()\n",
        "    print(f\"Nombre de SIREN n'ayant pas exactement 9 caractères après correction: {unusual_siren_count_after}\")\n",
        "\n",
        "# 2. Identifier les cas où l'écart est dû au CRC manquant\n",
        "tolerance = 1.0  # 1€ de tolérance\n",
        "\n",
        "# Créer un masque pour identifier les cas où l'écart correspond au CRC calculé\n",
        "mask_crc_missing = (\n",
        "    # Cas où l'écart est positif (montant calculé > montant déclaré)\n",
        "    (df['CIR_TOTAL_ECART'] > 0) &\n",
        "    # L'écart est approximativement égal au CRC calculé\n",
        "    (abs(df['CIR_TOTAL_ECART'] - df['CIR_COLLABORATIF_CALCULE']) < tolerance) &\n",
        "    # Le CRC déclaré est nul ou très petit comparé au CRC calculé\n",
        "    ((df['CIR_COLLABORATIF_DECLARE'].isna()) |\n",
        "     (df['CIR_COLLABORATIF_DECLARE'] == 0) |\n",
        "     (df['CIR_COLLABORATIF_CALCULE'] > df['CIR_COLLABORATIF_DECLARE'] * 1.5))\n",
        ")\n",
        "\n",
        "# Compter les cas identifiés\n",
        "count_crc_missing = mask_crc_missing.sum()\n",
        "print(f\"\\nNombre d'entreprises avec CRC apparemment manquant dans le montant déclaré: {count_crc_missing}\")\n",
        "\n",
        "# 3. Sauvegarder les valeurs originales (pour information uniquement)\n",
        "df['CIR_TOTAL_DECLARE_ORIGINAL'] = df['CIR_TOTAL_DECLARE'].copy()\n",
        "df['CIR_TOTAL_ECART_ORIGINAL'] = df['CIR_TOTAL_ECART'].copy()\n",
        "df['CORRESPONDANCE_CIR_ORIGINAL'] = df['CORRESPONDANCE_CIR'].copy()\n",
        "\n",
        "# 4. Corriger directement le montant déclaré en ajoutant le CRC calculé\n",
        "df.loc[mask_crc_missing, 'CIR_TOTAL_DECLARE'] = df.loc[mask_crc_missing, 'CIR_TOTAL_DECLARE'] + df.loc[mask_crc_missing, 'CIR_COLLABORATIF_CALCULE']\n",
        "\n",
        "# 5. Recalculer l'écart\n",
        "df['CIR_TOTAL_ECART'] = df['CIR_TOTAL_CALCULE'] - df['CIR_TOTAL_DECLARE']\n",
        "\n",
        "# 6. Mettre à jour la correspondance\n",
        "df['CORRESPONDANCE_CIR'] = np.where(abs(df['CIR_TOTAL_ECART']) <= 1, \"Oui\", \"Non\")\n",
        "\n",
        "# 7. Analyser les résultats\n",
        "count_original_non = (df['CORRESPONDANCE_CIR_ORIGINAL'] == 'Non').sum()\n",
        "count_corrected_non = (df['CORRESPONDANCE_CIR'] == 'Non').sum()\n",
        "count_fixed = count_original_non - count_corrected_non\n",
        "\n",
        "print(f\"\\nRésultats après correction:\")\n",
        "print(f\"Nombre d'entreprises avec écarts avant correction: {count_original_non}\")\n",
        "print(f\"Nombre d'entreprises avec écarts après correction: {count_corrected_non}\")\n",
        "print(f\"Nombre d'écarts résolus par l'ajout du CRC: {count_fixed} ({count_fixed/count_original_non*100:.2f}%)\")\n",
        "\n",
        "# 8. Exemples d'entreprises corrigées (pour information uniquement)\n",
        "print(\"\\nExemples d'entreprises où l'écart a été résolu par l'ajout du CRC:\")\n",
        "df_resolved = df[(df['CORRESPONDANCE_CIR_ORIGINAL'] == 'Non') & (df['CORRESPONDANCE_CIR'] == 'Oui')].copy()\n",
        "if len(df_resolved) > 0:\n",
        "    sample_size = min(3, len(df_resolved))\n",
        "    for i, (_, row) in enumerate(df_resolved.head(sample_size).iterrows(), 1):\n",
        "        print(f\"\\nExemple {i}: {row.get('DESIGNATION', 'N/A')} (SIREN: {row.get('SIREN_DECLARANT', 'N/A')})\")\n",
        "        print(f\"  CIR déclaré original: {row['CIR_TOTAL_DECLARE_ORIGINAL']:.2f}\")\n",
        "        print(f\"  CIR déclaré corrigé: {row['CIR_TOTAL_DECLARE']:.2f}\")\n",
        "        print(f\"  CIR calculé: {row['CIR_TOTAL_CALCULE']:.2f}\")\n",
        "        print(f\"  Écart original: {row['CIR_TOTAL_ECART_ORIGINAL']:.2f}\")\n",
        "        print(f\"  Écart corrigé: {row['CIR_TOTAL_ECART']:.2f}\")\n",
        "        print(f\"  CRC calculé: {row.get('CIR_COLLABORATIF_CALCULE', 'N/A')}\")\n",
        "\n",
        "# 9. Supprimer les colonnes originales pour ne garder que les valeurs corrigées\n",
        "df = df.drop(['CIR_TOTAL_DECLARE_ORIGINAL', 'CIR_TOTAL_ECART_ORIGINAL', 'CORRESPONDANCE_CIR_ORIGINAL'], axis=1)\n",
        "\n",
        "# 10. Écraser le fichier original avec les données corrigées\n",
        "# S'assurer que les SIREN sont toujours formatés comme du texte lors de l'export\n",
        "df.to_csv(file_path, sep=';', encoding='utf-8-sig', index=False)\n",
        "\n",
        "print(f\"\\nFichier original mis à jour: {file_path}\")\n",
        "print(f\"- Format des SIREN corrigé\")\n",
        "print(f\"- CRC manquant ajouté au montant déclaré\")\n",
        "\n",
        "# 11. Résumé des écarts restants\n",
        "if count_corrected_non > 0:\n",
        "    print(f\"\\nIl reste {count_corrected_non} entreprises avec des écarts à analyser.\")\n",
        "\n",
        "    # Identifier les principales sources d'écarts restants\n",
        "    df_remaining_ecarts = df[df['CORRESPONDANCE_CIR'] == 'Non']\n",
        "\n",
        "    # Obtenir toutes les colonnes d'écart\n",
        "    ecart_cols = [col for col in df.columns if '_ECART' in col and col != 'CIR_TOTAL_ECART' and col != 'ECART_RELATIF_POURCENT']\n",
        "\n",
        "    # Compter les écarts significatifs par colonne\n",
        "    ecart_counts = {}\n",
        "    for col in ecart_cols:\n",
        "        if col in df_remaining_ecarts.columns:\n",
        "            non_zero = df_remaining_ecarts[abs(df_remaining_ecarts[col]) > 1]\n",
        "            if len(non_zero) > 0:\n",
        "                ecart_counts[col] = len(non_zero)\n",
        "\n",
        "    # Afficher les 5 principales sources d'écarts\n",
        "    sorted_ecarts = sorted(ecart_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "    if sorted_ecarts:\n",
        "        print(\"\\nPrincipales sources d'écarts restants:\")\n",
        "        for i, (col, count) in enumerate(sorted_ecarts[:5], 1):\n",
        "            pct = count / count_corrected_non * 100\n",
        "            print(f\"{i}. {col}: {count} entreprises ({pct:.2f}%)\")\n",
        "\n",
        "    # Rechercher d'autres cas potentiels similaires au problème du CRC\n",
        "    print(\"\\nRecherche d'autres patterns d'écarts similaires:\")\n",
        "\n",
        "    # 1. Cas où l'écart correspond au CIR Innovation\n",
        "    if 'CIR_INNOVATION_CALCULE' in df_remaining_ecarts.columns:\n",
        "        innovation_missing = (\n",
        "            (df_remaining_ecarts['CIR_TOTAL_ECART'] > 0) &\n",
        "            (abs(df_remaining_ecarts['CIR_TOTAL_ECART'] - df_remaining_ecarts['CIR_INNOVATION_CALCULE']) < tolerance)\n",
        "        )\n",
        "        count_innovation = innovation_missing.sum()\n",
        "        if count_innovation > 0:\n",
        "            print(f\"  • Possible CIR Innovation manquant: {count_innovation} entreprises\")\n",
        "\n",
        "    # 2. Cas où l'écart correspond au CIR Collection\n",
        "    if 'CIR_COLLECTION_CALCULE' in df_remaining_ecarts.columns:\n",
        "        collection_missing = (\n",
        "            (df_remaining_ecarts['CIR_TOTAL_ECART'] > 0) &\n",
        "            (abs(df_remaining_ecarts['CIR_TOTAL_ECART'] - df_remaining_ecarts['CIR_COLLECTION_CALCULE']) < tolerance)\n",
        "        )\n",
        "        count_collection = collection_missing.sum()\n",
        "        if count_collection > 0:\n",
        "            print(f\"  • Possible CIR Collection manquant: {count_collection} entreprises\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhDGROBNzc9d"
      },
      "source": [
        "## Erreur depense personnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "k9Uvor6SS-F6",
        "outputId": "e6027902-84f4-4d44-a2ad-bb5942a97c4e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3028750523.py:5: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR.csv\", sep=';', encoding='utf-8-sig')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fichier chargé: 27957 lignes\n",
            "Nombre de lignes à corriger: 16\n",
            "\n",
            "Résultats de la correction:\n",
            "Somme CIR_TOTAL_DECLARE: 7,170,745.00 €\n",
            "Somme CIR_TOTAL_CALCULE avant correction: 6,298,270.92 €\n",
            "Somme CIR_TOTAL_CALCULE après correction: 7,706,819.31 €\n",
            "Écart avant correction: -872,474.08 €\n",
            "Écart après correction: 536,074.31 €\n",
            "\n",
            "Fichier corrigé sauvegardé: lignes_restantes_a_analyser_corrigees.csv\n",
            "\n",
            "Fichier corrigé sauvegardé: lignes_restantes_a_analyser_corrigees.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Charger le fichier original\n",
        "df = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR.csv\", sep=';', encoding='utf-8-sig')\n",
        "print(f\"Fichier chargé: {len(df)} lignes\")\n",
        "\n",
        "# Identifier les lignes concernées (ajout du critère correspondance)\n",
        "mask = (\n",
        "    (df['L3_DEPENSES_PERSONNEL_CHERCHEURS'] == 0.0) &\n",
        "    (df['L2_DOTATION_AMORT_SINISTR'] != 0.0) &\n",
        "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
        ")\n",
        "indices_to_update = df[mask].index\n",
        "print(f\"Nombre de lignes à corriger: {len(indices_to_update)}\")\n",
        "\n",
        "\n",
        "# Sauvegarder les valeurs originales pour analyse\n",
        "cir_calcule_avant = df.loc[indices_to_update, 'CIR_TOTAL_CALCULE'].copy()\n",
        "\n",
        "# Pour chaque ligne à corriger\n",
        "for idx in indices_to_update:\n",
        "    # 1. Transférer la valeur de dotation aux amortissements sinistrés vers dépenses de personnel\n",
        "    val_amort_sinistr = df.at[idx, 'L2_DOTATION_AMORT_SINISTR']\n",
        "    df.at[idx, 'L3_DEPENSES_PERSONNEL_CHERCHEURS'] = val_amort_sinistr\n",
        "    df.at[idx, 'L2_DOTATION_AMORT_SINISTR'] = 0.0\n",
        "\n",
        "    # 2. Recalculer la ligne 6 (autres dépenses de fonctionnement)\n",
        "    dot_amort_immo = df.at[idx, 'L1_DOTATION_AMORT_IMMO']\n",
        "    dep_cherch_tech = df.at[idx, 'L3_DEPENSES_PERSONNEL_CHERCHEURS']  # Nouvelle valeur\n",
        "    rem_sal_inv = df.at[idx, 'L4_REMUNERATION_INVENTEURS']\n",
        "    dep_jd = df.at[idx, 'L5_DEPENSES_JEUNES_DOCTEURS']\n",
        "\n",
        "    autres_dep_fonct = (dot_amort_immo * 0.75) + ((dep_cherch_tech + rem_sal_inv) * 0.43) + dep_jd\n",
        "    df.at[idx, 'L6_AUTRES_DEP_FONCT_CALCULE'] = autres_dep_fonct\n",
        "\n",
        "    # 3. Recalculer la ligne 7 (total dépenses de fonctionnement)\n",
        "    total_dep_fonct = dot_amort_immo + 0.0 + dep_cherch_tech + rem_sal_inv + dep_jd + autres_dep_fonct\n",
        "    df.at[idx, 'L7_TOTAL_DEP_FONCT_CALCULE'] = total_dep_fonct\n",
        "\n",
        "    # 4. Recalculer la ligne 14 (total dépenses internes)\n",
        "    frais_brev_cov = df.at[idx, 'L8_FRAIS_BREVETS_COV']\n",
        "    dep_maint_brev_cov = df.at[idx, 'L9_DEPENSES_DEFENSE_BREVETS']\n",
        "    dot_amort_brev = df.at[idx, 'L10_DOTATION_AMORT_BREVETS']\n",
        "    dep_normali = df.at[idx, 'L11_DEPENSES_NORMALISATION_DECLARE']\n",
        "    prim_cotiz = min(df.at[idx, 'L12_PRIMES_COTISATIONS_BRUT'], 60000)\n",
        "    dep_veil_techno = min(df.at[idx, 'L13_VEILLE_TECHNO_BRUT'], 60000)\n",
        "\n",
        "    total_dep_internes = total_dep_fonct + frais_brev_cov + dep_maint_brev_cov + dot_amort_brev + dep_normali + prim_cotiz + dep_veil_techno\n",
        "    df.at[idx, 'L14_TOTAL_DEPENSES_INTERNES_CALCULE'] = total_dep_internes\n",
        "\n",
        "    # 5. Recalculer la ligne 22 (total dépenses de recherche)\n",
        "    total_dep_ext = df.at[idx, 'L21_TOTAL_DEP_EXT_PLAFONNEES_CALCULE']\n",
        "    total_dep_recherche = total_dep_internes + total_dep_ext\n",
        "    df.at[idx, 'L22_TOTAL_DEPENSES_RECHERCHE_CALCULE'] = total_dep_recherche\n",
        "\n",
        "    # 6. Recalculer la ligne 26A (montant net des dépenses)\n",
        "    mt_aid_subv = df.at[idx, 'L23A_SUBVENTIONS']\n",
        "    mt_enc_presta = df.at[idx, 'L23B_SOMMES_ENCAISSEES_TIERS']\n",
        "    mt_dep_conseils_cir = df.at[idx, 'L24_DEPENSES_CONSEIL_CIR']\n",
        "    rembst_subv = df.at[idx, 'L25_REMBOURSEMENTS_SUBVENTIONS']\n",
        "\n",
        "    montant_net = total_dep_recherche - mt_aid_subv - mt_enc_presta - mt_dep_conseils_cir + rembst_subv\n",
        "    df.at[idx, 'L26A_MONTANT_NET_DEPENSES_CALCULE'] = montant_net\n",
        "\n",
        "    # 7. Recalculer le CIR recherche (30% du montant net)\n",
        "    cir_recherche = montant_net * 0.30\n",
        "    df.at[idx, 'CIR_RECHERCHE_CALCULE'] = cir_recherche\n",
        "\n",
        "    # 8. Recalculer le CIR total\n",
        "    cir_collection = df.at[idx, 'CIR_COLLECTION_CALCULE']\n",
        "    cir_innovation = df.at[idx, 'CIR_INNOVATION_CALCULE']\n",
        "    cir_collaboratif = df.at[idx, 'CIR_COLLABORATIF_CALCULE']\n",
        "\n",
        "    cir_total = cir_recherche + cir_collection + cir_innovation + cir_collaboratif\n",
        "    df.at[idx, 'CIR_TOTAL_CALCULE'] = cir_total\n",
        "\n",
        "    # 9. Recalculer l'écart et mettre à jour la correspondance\n",
        "    ecart_cir = cir_total - df.at[idx, 'CIR_TOTAL_DECLARE']\n",
        "    df.at[idx, 'CIR_TOTAL_ECART'] = ecart_cir\n",
        "    df.at[idx, 'CORRESPONDANCE_CIR'] = \"Oui\" if abs(ecart_cir) <= 1 else \"Non\"\n",
        "\n",
        "# Afficher les résultats\n",
        "somme_declare = df.loc[indices_to_update, 'CIR_TOTAL_DECLARE'].sum()\n",
        "somme_calcule_avant = cir_calcule_avant.sum()\n",
        "somme_calcule_apres = df.loc[indices_to_update, 'CIR_TOTAL_CALCULE'].sum()\n",
        "\n",
        "print(f\"\\nRésultats de la correction:\")\n",
        "print(f\"Somme CIR_TOTAL_DECLARE: {somme_declare:,.2f} €\")\n",
        "print(f\"Somme CIR_TOTAL_CALCULE avant correction: {somme_calcule_avant:,.2f} €\")\n",
        "print(f\"Somme CIR_TOTAL_CALCULE après correction: {somme_calcule_apres:,.2f} €\")\n",
        "print(f\"Écart avant correction: {somme_calcule_avant - somme_declare:,.2f} €\")\n",
        "print(f\"Écart après correction: {somme_calcule_apres - somme_declare:,.2f} €\")\n",
        "\n",
        "# Sauvegarder le fichier corrigé\n",
        "df.to_csv(\"lignes_restantes_a_analyser_corrigees.csv\", sep=';', encoding='utf-8-sig', index=False)\n",
        "print(f\"\\nFichier corrigé sauvegardé: lignes_restantes_a_analyser_corrigees.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00YyJRuozv5N"
      },
      "source": [
        "### mise à jour ligne restante"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "rzdo8KPMS-F6",
        "outputId": "a1bfbfdf-33b8-464d-f7ca-c7a0560febc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fichier chargé: 27957 lignes\n",
            "Nombre de lignes après filtrage: 16\n",
            "Somme CIR_TOTAL_DECLARE : 7,170,745.00 €\n",
            "Somme CIR_TOTAL_CALCULE : 6,298,270.92 €\n",
            "Résultats exportés dans: lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\n",
            "\n",
            "Aperçu des données trouvées:\n",
            "Nombre d'entreprises: 16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\585773094.py:4: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR.csv\", sep=';', encoding='utf-8-sig')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Charger le fichier\n",
        "df = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR.csv\", sep=';', encoding='utf-8-sig')\n",
        "print(f\"Fichier chargé: {len(df)} lignes\")\n",
        "\n",
        "# Appliquer les filtres :\n",
        "# - L5_DEPENSES_JEUNES_DOCTEURS = 0.0\n",
        "# - L2_DOTATION_AMORT_SINISTR différent de 0.0\n",
        "df_filtered = df[\n",
        "    (df['L3_DEPENSES_PERSONNEL_CHERCHEURS'] == 0.0) &\n",
        "    (df['L2_DOTATION_AMORT_SINISTR'] != 0.0) &\n",
        "    (df['CORRESPONDANCE_CIR'] == \"Non\") \n",
        "]\n",
        "\n",
        "print(f\"Nombre de lignes après filtrage: {len(df_filtered)}\")\n",
        "\n",
        "# Exporter les résultats\n",
        "output_file = \"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\"\n",
        "df_filtered.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
        "# Calculer les sommes\n",
        "somme_declare = df_filtered['CIR_TOTAL_DECLARE'].sum()\n",
        "somme_calcule = df_filtered['CIR_TOTAL_CALCULE'].sum()\n",
        "\n",
        "print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
        "print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
        "print(f\"Résultats exportés dans: {output_file}\")\n",
        "\n",
        "# Afficher quelques statistiques sur les lignes trouvées\n",
        "if len(df_filtered) > 0:\n",
        "    print(\"\\nAperçu des données trouvées:\")\n",
        "    print(f\"Nombre d'entreprises: {len(df_filtered)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\2105814575.py:5: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fichier principal chargé: 27957 lignes\n",
            "\n",
            "Nombre de lignes restantes à analyser: 1514\n",
            "Résultats exportés dans: lignes_restantes_a_analyser.csv\n",
            "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Charger le fichier principal\n",
        "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR.csv\"\n",
        "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
        "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
        "\n",
        "# Charger les fichiers d'analyse précédents\n",
        "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')  # Nouveau fichier\n",
        "\n",
        "# Identifier les SIREN à exclure\n",
        "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT'])  # Nouveau set\n",
        "\n",
        "# Combiner tous les SIREN à exclure\n",
        "siren_a_exclure =  siren_jeunes_docteurs  # Ajout du nouveau set\n",
        "\n",
        "# Filtrer le DataFrame principal\n",
        "# - Exclure les SIREN déjà analysés\n",
        "# - Garder uniquement les lignes où CORRESPONDANCE_CIR est \"Non\"\n",
        "df_restant = df[\n",
        "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) & \n",
        "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
        "]\n",
        "\n",
        "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
        "\n",
        "# Exporter les résultats\n",
        "output_file = \"lignes_restantes_a_analyser.csv\"\n",
        "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
        "print(f\"Résultats exportés dans: {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSj2hlXH0Nbn"
      },
      "source": [
        "## Erreur DEP Fonctionnement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "TB4JH6yBS-F8",
        "outputId": "5066845f-1f3d-4965-ddcf-724bc04b0af0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fichier chargé: 1514 lignes\n",
            "Nombre de lignes à corriger: 1\n",
            "\n",
            "Résumé des corrections :\n",
            "Somme L7_TOTAL_DEP_FONCT_DECLARE avant correction: 6,056,576.00 €\n",
            "Somme L7_TOTAL_DEP_FONCT_CALCULE après correction: 6,056,575.55 €\n",
            "Différence sur L7: -0.45 €\n",
            "\n",
            "Impact sur le CIR :\n",
            "Somme CIR_TOTAL_DECLARE: 1,846,082.00 €\n",
            "Somme CIR_TOTAL_CALCULE avant correction: 3,663,054.16 €\n",
            "Somme CIR_TOTAL_CALCULE après correction: 3,663,054.17 €\n",
            "Écart avant correction: 1,816,972.16 €\n",
            "Écart après correction: 1,816,972.17 €\n",
            "Amélioration de l'écart: -0.00 €\n",
            "\n",
            "Nombre de lignes où la correspondance est passée de 'Non' à 'Oui': 0\n",
            "\n",
            "Fichier corrigé sauvegardé: lignes_restantes_a_analyser_corrigees_L7L8.csv\n",
            "\n",
            "Exemples de modifications significatives:\n",
            "SIREN: 521474445\n",
            "  Désignation: TEHTRI-SECURITY SAS NS\n",
            "  L7 avant: 6,056,576.00 €\n",
            "  L7 après: 6,056,575.55 €\n",
            "  CIR avant: 3,663,054.16 €\n",
            "  CIR après: 3,663,054.17 €\n",
            "  Impact: 0.00 € (0.00%)\n",
            "\n",
            "\n",
            "Fichier corrigé sauvegardé: lignes_restantes_a_analyser_corrigees_L7L8.csv\n",
            "\n",
            "Exemples de modifications significatives:\n",
            "SIREN: 521474445\n",
            "  Désignation: TEHTRI-SECURITY SAS NS\n",
            "  L7 avant: 6,056,576.00 €\n",
            "  L7 après: 6,056,575.55 €\n",
            "  CIR avant: 3,663,054.16 €\n",
            "  CIR après: 3,663,054.17 €\n",
            "  Impact: 0.00 € (0.00%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Charger le fichier original\n",
        "file_path = \"lignes_restantes_a_analyser.csv\"\n",
        "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
        "print(f\"Fichier chargé: {len(df)} lignes\")\n",
        "\n",
        "# Identifier les lignes à corriger\n",
        "mask = (df['L7_TOTAL_DEP_FONCT_DECLARE'] == df['L8_FRAIS_BREVETS_COV']) & (df['L7_TOTAL_DEP_FONCT_DECLARE'] != 0.0)\n",
        "indices_to_update = df[mask].index\n",
        "print(f\"Nombre de lignes à corriger: {len(indices_to_update)}\")\n",
        "\n",
        "# Sauvegarder les valeurs originales pour analyse\n",
        "cir_calcule_avant = df.loc[indices_to_update, 'CIR_TOTAL_CALCULE'].copy()\n",
        "l7_original = df.loc[indices_to_update, 'L7_TOTAL_DEP_FONCT_DECLARE'].copy()\n",
        "\n",
        "# Pour chaque ligne à corriger\n",
        "for idx in indices_to_update:\n",
        "    # 1. Calculer correctement le montant de la ligne 7 (total dépenses de fonctionnement)\n",
        "    dot_amort_immo = df.at[idx, 'L1_DOTATION_AMORT_IMMO']\n",
        "    dot_amort_sinistr = df.at[idx, 'L2_DOTATION_AMORT_SINISTR']\n",
        "    dep_cherch_tech = df.at[idx, 'L3_DEPENSES_PERSONNEL_CHERCHEURS']\n",
        "    rem_sal_inv = df.at[idx, 'L4_REMUNERATION_INVENTEURS']\n",
        "    dep_jd = df.at[idx, 'L5_DEPENSES_JEUNES_DOCTEURS']\n",
        "\n",
        "    # Calculer L6 si nécessaire\n",
        "    autres_dep_fonct = (dot_amort_immo * 0.75) + ((dep_cherch_tech + rem_sal_inv) * 0.43) + dep_jd\n",
        "\n",
        "    # Mettre à jour L6 calculé\n",
        "    df.at[idx, 'L6_AUTRES_DEP_FONCT_CALCULE'] = autres_dep_fonct\n",
        "\n",
        "    # Calculer le vrai montant de L7\n",
        "    total_dep_fonct = dot_amort_immo + dot_amort_sinistr + dep_cherch_tech + rem_sal_inv + dep_jd + autres_dep_fonct\n",
        "\n",
        "    # 2. Mettre à jour L7\n",
        "    df.at[idx, 'L7_TOTAL_DEP_FONCT_CALCULE'] = total_dep_fonct # laisser L7 tel quel (inchangé)\n",
        "\n",
        "    # Garder L8_FRAIS_BREVETS_COV tel quel (inchangé)\n",
        "    frais_brev_cov = df.at[idx, 'L8_FRAIS_BREVETS_COV'] # mettre à 0\n",
        "\n",
        "    # 3. Recalculer la ligne 14 (total dépenses internes)\n",
        "    dep_maint_brev_cov = df.at[idx, 'L9_DEPENSES_DEFENSE_BREVETS']\n",
        "    dot_amort_brev = df.at[idx, 'L10_DOTATION_AMORT_BREVETS']\n",
        "    dep_normali = df.at[idx, 'L11_DEPENSES_NORMALISATION_DECLARE']\n",
        "    prim_cotiz = df.at[idx, 'L12_PRIMES_COTISATIONS_PLAFONNEES']\n",
        "    dep_veil_techno = df.at[idx, 'L13_VEILLE_TECHNO_PLAFONNEE']\n",
        "\n",
        "    total_dep_internes = total_dep_fonct + frais_brev_cov + dep_maint_brev_cov + dot_amort_brev + dep_normali + prim_cotiz + dep_veil_techno\n",
        "    df.at[idx, 'L14_TOTAL_DEPENSES_INTERNES_CALCULE'] = total_dep_internes\n",
        "\n",
        "    # 4. Recalculer la ligne 22 (total dépenses de recherche)\n",
        "    total_dep_ext = df.at[idx, 'L21_TOTAL_DEP_EXT_PLAFONNEES_CALCULE']\n",
        "    total_dep_recherche = total_dep_internes + total_dep_ext\n",
        "    df.at[idx, 'L22_TOTAL_DEPENSES_RECHERCHE_CALCULE'] = total_dep_recherche\n",
        "\n",
        "    # 5. Recalculer la ligne 26A (montant net des dépenses)\n",
        "    mt_aid_subv = df.at[idx, 'L23A_SUBVENTIONS']\n",
        "    mt_enc_presta = df.at[idx, 'L23B_SOMMES_ENCAISSEES_TIERS']\n",
        "    mt_dep_conseils_cir = df.at[idx, 'L24_DEPENSES_CONSEIL_CIR']\n",
        "    rembst_subv = df.at[idx, 'L25_REMBOURSEMENTS_SUBVENTIONS']\n",
        "\n",
        "    montant_net = total_dep_recherche - mt_aid_subv - mt_enc_presta - mt_dep_conseils_cir + rembst_subv\n",
        "    df.at[idx, 'L26A_MONTANT_NET_DEPENSES_CALCULE'] = montant_net\n",
        "\n",
        "    # 6. Récupérer le montant DOM pour le calcul du CIR\n",
        "    montant_net_dom = df.at[idx, 'L26B_MONTANT_NET_DEPENSES_DOM_CALCULE']\n",
        "\n",
        "    # 7. Recalculer le CIR recherche (30% ou 50% selon localisation)\n",
        "    cir_recherche = ((montant_net - montant_net_dom) * 0.30) + (montant_net_dom * 0.50)\n",
        "    df.at[idx, 'CIR_RECHERCHE_CALCULE'] = cir_recherche\n",
        "\n",
        "    # 8. Recalculer le CIR total\n",
        "    cir_collection = df.at[idx, 'CIR_COLLECTION_CALCULE']\n",
        "    cir_innovation = df.at[idx, 'CIR_INNOVATION_CALCULE']\n",
        "    cir_collaboratif = df.at[idx, 'CIR_COLLABORATIF_CALCULE']\n",
        "\n",
        "    cir_total = cir_recherche + cir_collection + cir_innovation + cir_collaboratif\n",
        "    df.at[idx, 'CIR_TOTAL_CALCULE'] = cir_total\n",
        "\n",
        "    # 9. Recalculer l'écart et mettre à jour la correspondance\n",
        "    ecart_cir = cir_total - df.at[idx, 'CIR_TOTAL_DECLARE']\n",
        "    df.at[idx, 'CIR_TOTAL_ECART'] = ecart_cir\n",
        "    df.at[idx, 'CORRESPONDANCE_CIR'] = \"Oui\" if abs(ecart_cir) <= 1 else \"Non\"\n",
        "\n",
        "# Afficher le résumé des modifications\n",
        "l7_corrige = df.loc[indices_to_update, 'L7_TOTAL_DEP_FONCT_CALCULE']\n",
        "somme_declare = df.loc[indices_to_update, 'CIR_TOTAL_DECLARE'].sum()\n",
        "somme_calcule_avant = cir_calcule_avant.sum()\n",
        "somme_calcule_apres = df.loc[indices_to_update, 'CIR_TOTAL_CALCULE'].sum()\n",
        "\n",
        "print(f\"\\nRésumé des corrections :\")\n",
        "print(f\"Somme L7_TOTAL_DEP_FONCT_DECLARE avant correction: {l7_original.sum():,.2f} €\")\n",
        "print(f\"Somme L7_TOTAL_DEP_FONCT_CALCULE après correction: {l7_corrige.sum():,.2f} €\")\n",
        "print(f\"Différence sur L7: {l7_corrige.sum() - l7_original.sum():,.2f} €\")\n",
        "\n",
        "print(f\"\\nImpact sur le CIR :\")\n",
        "print(f\"Somme CIR_TOTAL_DECLARE: {somme_declare:,.2f} €\")\n",
        "print(f\"Somme CIR_TOTAL_CALCULE avant correction: {somme_calcule_avant:,.2f} €\")\n",
        "print(f\"Somme CIR_TOTAL_CALCULE après correction: {somme_calcule_apres:,.2f} €\")\n",
        "print(f\"Écart avant correction: {somme_calcule_avant - somme_declare:,.2f} €\")\n",
        "print(f\"Écart après correction: {somme_calcule_apres - somme_declare:,.2f} €\")\n",
        "print(f\"Amélioration de l'écart: {abs(somme_calcule_avant - somme_declare) - abs(somme_calcule_apres - somme_declare):,.2f} €\")\n",
        "\n",
        "# Compter les lignes où la correspondance s'est améliorée\n",
        "count_improved = 0\n",
        "for idx in indices_to_update:\n",
        "    if df.at[idx, 'CORRESPONDANCE_CIR'] == \"Oui\" and abs(cir_calcule_avant[idx] - df.at[idx, 'CIR_TOTAL_DECLARE']) > 1:\n",
        "        count_improved += 1\n",
        "\n",
        "print(f\"\\nNombre de lignes où la correspondance est passée de 'Non' à 'Oui': {count_improved}\")\n",
        "\n",
        "# Sauvegarder le fichier corrigé\n",
        "df.to_csv(\"lignes_restantes_a_analyser_corrigees_L7L8.csv\", sep=';', encoding='utf-8-sig', index=False)\n",
        "print(f\"\\nFichier corrigé sauvegardé: lignes_restantes_a_analyser_corrigees_L7L8.csv\")\n",
        "\n",
        "# Afficher des exemples de modifications\n",
        "print(\"\\nExemples de modifications significatives:\")\n",
        "# Calculer l'impact en pourcentage sur le CIR\n",
        "df_impact = pd.DataFrame({\n",
        "    'SIREN': df.loc[indices_to_update, 'SIREN_DECLARANT'],\n",
        "    'Désignation': df.loc[indices_to_update, 'DESIGNATION'],\n",
        "    'L7 avant': l7_original,\n",
        "    'L7 après': l7_corrige,\n",
        "    'CIR avant': cir_calcule_avant,\n",
        "    'CIR après': df.loc[indices_to_update, 'CIR_TOTAL_CALCULE'],\n",
        "    'Impact': abs(df.loc[indices_to_update, 'CIR_TOTAL_CALCULE'] - cir_calcule_avant)\n",
        "})\n",
        "\n",
        "# Afficher les 5 cas avec le plus grand impact en valeur absolue\n",
        "for _, row in df_impact.sort_values('Impact', ascending=False).head(5).iterrows():\n",
        "    print(f\"SIREN: {row['SIREN']}\")\n",
        "    print(f\"  Désignation: {row['Désignation']}\")\n",
        "    print(f\"  L7 avant: {row['L7 avant']:,.2f} €\")\n",
        "    print(f\"  L7 après: {row['L7 après']:,.2f} €\")\n",
        "    print(f\"  CIR avant: {row['CIR avant']:,.2f} €\")\n",
        "    print(f\"  CIR après: {row['CIR après']:,.2f} €\")\n",
        "    print(f\"  Impact: {row['Impact']:,.2f} € ({row['Impact']/row['CIR avant']*100 if row['CIR avant'] != 0 else 0:.2f}%)\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCok0Sxw0YQe"
      },
      "source": [
        "### ligne liée au erreur dep fonctionnement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "cSs_yVJhS-F7",
        "outputId": "71a974ed-c5f8-4672-925e-534cbd71ad48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fichier chargé: 1514 lignes\n",
            "Nombre de lignes où L7_TOTAL_DEP_FONCT_DECLARE = L8_FRAIS_BREVETS_COV: 1\n",
            "Somme CIR_TOTAL_DECLARE : 1,846,082.00 €\n",
            "Somme CIR_TOTAL_CALCULE : 3,663,054.16 €\n",
            "Résultats exportés dans: lignes_L7_egal_L8.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Charger le fichier des lignes restantes\n",
        "file_path = \"lignes_restantes_a_analyser.csv\"\n",
        "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
        "print(f\"Fichier chargé: {len(df)} lignes\")\n",
        "\n",
        "# Filtrer les lignes où L7_TOTAL_DEP_FONCT_DECLARE = L8_FRAIS_BREVETS_COV\n",
        "df_filtered = df[(df['L7_TOTAL_DEP_FONCT_DECLARE'] == df['L8_FRAIS_BREVETS_COV']) & (df['L7_TOTAL_DEP_FONCT_DECLARE'] != 0.0)]\n",
        "\n",
        "print(f\"Nombre de lignes où L7_TOTAL_DEP_FONCT_DECLARE = L8_FRAIS_BREVETS_COV: {len(df_filtered)}\")\n",
        "\n",
        "# Exporter les résultats\n",
        "output_file = \"lignes_L7_egal_L8.csv\"\n",
        "df_filtered.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
        "# Calculer les sommes\n",
        "somme_declare = df_filtered['CIR_TOTAL_DECLARE'].sum()\n",
        "somme_calcule = df_filtered['CIR_TOTAL_CALCULE'].sum()\n",
        "\n",
        "print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
        "print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
        "print(f\"Résultats exportés dans: {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3477145.py:5: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fichier principal chargé: 27957 lignes\n",
            "\n",
            "Nombre de lignes restantes à analyser: 1513\n",
            "Résultats exportés dans: lignes_restantes_a_analyser.csv\n",
            "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Charger le fichier principal\n",
        "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR.csv\"\n",
        "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
        "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
        "\n",
        "# Charger les fichiers d'analyse précédents\n",
        "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')  # Nouveau fichier\n",
        "l7_egal_l8 = pd.read_csv(\"lignes_L7_egal_L8.csv\", sep=';', encoding='utf-8-sig')\n",
        "\n",
        "# Identifier les SIREN à exclure\n",
        "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT']) \n",
        "siren_l7_l8 = set(l7_egal_l8['SIREN_DECLARANT'])\n",
        "\n",
        "# Combiner tous les SIREN à exclure\n",
        "siren_a_exclure =  siren_jeunes_docteurs | siren_l7_l8 \n",
        "\n",
        "# Filtrer le DataFrame principal\n",
        "# - Exclure les SIREN déjà analysés\n",
        "# - Garder uniquement les lignes où CORRESPONDANCE_CIR est \"Non\"\n",
        "df_restant = df[\n",
        "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) & \n",
        "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
        "]\n",
        "\n",
        "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
        "\n",
        "# Exporter les résultats\n",
        "output_file = \"lignes_restantes_a_analyser.csv\"\n",
        "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
        "print(f\"Résultats exportés dans: {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Erreur Cir Recherche"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fichier chargé: 1513 lignes\n",
            "Nombre de lignes après filtrage: 23\n",
            "Somme CIR_TOTAL_DECLARE : 95,803,865.00 €\n",
            "Somme CIR_TOTAL_CALCULE : 102,591,496.33 €\n",
            "Résultats exportés dans: lignes_depenses_non0_cir_recherche_0.csv\n",
            "\n",
            "Aperçu des données trouvées:\n",
            "Nombre d'entreprises: 23\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Charger le fichier\n",
        "df = pd.read_csv(\"lignes_restantes_a_analyser.csv\", sep=';', encoding='utf-8-sig')\n",
        "print(f\"Fichier chargé: {len(df)} lignes\")\n",
        "\n",
        "# Appliquer les filtres :\n",
        "# - L22_TOTAL_DEPENSES_RECHERCHE_DECLARE différent de 0.0\n",
        "# - CIR_RECHERCHE_DECLARE = 0.0\n",
        "df_filtered = df[\n",
        "    (df['L22_TOTAL_DEPENSES_RECHERCHE_DECLARE'] != 0.0) &\n",
        "    (df['CIR_RECHERCHE_DECLARE'] == 0.0)\n",
        "]\n",
        "\n",
        "print(f\"Nombre de lignes après filtrage: {len(df_filtered)}\")\n",
        "\n",
        "# Exporter les résultats\n",
        "output_file = \"lignes_depenses_non0_cir_recherche_0.csv\"\n",
        "df_filtered.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
        "# Calculer les sommes\n",
        "somme_declare = df_filtered['CIR_TOTAL_DECLARE'].sum()\n",
        "somme_calcule = df_filtered['CIR_TOTAL_CALCULE'].sum()\n",
        "\n",
        "print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
        "print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
        "print(f\"Résultats exportés dans: {output_file}\")\n",
        "\n",
        "# Afficher quelques statistiques sur les lignes trouvées\n",
        "if len(df_filtered) > 0:\n",
        "    print(\"\\nAperçu des données trouvées:\")\n",
        "    print(f\"Nombre d'entreprises: {len(df_filtered)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\661988201.py:5: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fichier principal chargé: 27957 lignes\n",
            "\n",
            "Nombre de lignes restantes à analyser: 1490\n",
            "Résultats exportés dans: lignes_restantes_a_analyser.csv\n",
            "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Charger le fichier principal\n",
        "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR.csv\"\n",
        "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
        "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
        "\n",
        "# Charger les fichiers d'analyse précédents\n",
        "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')\n",
        "l7_egal_l8 = pd.read_csv(\"lignes_L7_egal_L8.csv\", sep=';', encoding='utf-8-sig')\n",
        "depenses_non0_cir0 = pd.read_csv(\"lignes_depenses_non0_cir_recherche_0.csv\", sep=';', encoding='utf-8-sig')\n",
        "\n",
        "# Identifier les SIREN à exclure\n",
        "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT'])\n",
        "siren_l7_l8 = set(l7_egal_l8['SIREN_DECLARANT'])\n",
        "siren_depenses_non0_cir0 = set(depenses_non0_cir0['SIREN_DECLARANT'])\n",
        "\n",
        "# Combiner tous les SIREN à exclure (ajout du nouveau cas)\n",
        "siren_a_exclure = siren_jeunes_docteurs | siren_l7_l8  | siren_depenses_non0_cir0\n",
        "\n",
        "# Filtrer le DataFrame principal\n",
        "df_restant = df[\n",
        "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) &\n",
        "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
        "]\n",
        "\n",
        "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
        "\n",
        "# Exporter les résultats\n",
        "output_file = \"lignes_restantes_a_analyser.csv\"\n",
        "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
        "print(f\"Résultats exportés dans: {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXcHl07405Pe"
      },
      "source": [
        "## Erreur depense Externalisée"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "7AFVOxEOS-F5",
        "outputId": "885f90ce-1a6f-4703-dea2-5783be868a20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fichier chargé: 1490 lignes\n",
            "Nombre de lignes extraites: 379\n",
            "Lignes exportées dans: lignes_ecart_cir_recherche_externalise.csv\n",
            "Lignes exportées dans: lignes_ecart_cir_recherche_externalise.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Chemin du fichier\n",
        "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//lignes_restantes_a_analyser.csv\"\n",
        "\n",
        "# Charger le fichier\n",
        "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
        "print(f\"Fichier chargé: {len(df)} lignes\")\n",
        "\n",
        "# Colonnes d'écart pour les dépenses externalisées\n",
        "colonnes_ext = ['L17_ECART', 'L18_ECART', 'L19_ECART', 'L20_ECART', 'L21_ECART']\n",
        "\n",
        "# Extraire les lignes qui répondent à tous les critères\n",
        "mask_correspondance = df['CORRESPONDANCE_CIR'] == \"Non\"\n",
        "mask_cir = df['CIR_RECHERCHE_ECART'] != 0\n",
        "mask_ext = df[colonnes_ext].abs().sum(axis=1) > 0\n",
        "\n",
        "# Combiner tous les filtres\n",
        "df_resultat = df[mask_correspondance & mask_cir & mask_ext]\n",
        "\n",
        "print(f\"Nombre de lignes extraites: {len(df_resultat)}\")\n",
        "\n",
        "# Exporter vers un fichier CSV\n",
        "output_file = \"lignes_ecart_cir_recherche_externalise.csv\"\n",
        "df_resultat.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
        "print(f\"Lignes exportées dans: {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "aa4PW_ZMS-F5",
        "outputId": "a6727172-a70c-4c73-866b-ff41a84d6ff1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fichier chargé: 379 lignes\n",
            "\n",
            "Résultats de l'analyse:\n",
            "- Nombre de lignes où L26A_ECART = CIR_TOTAL_ECART / 3: 365 sur 379\n",
            "- Pourcentage: 96.31%\n",
            "\n",
            "Exemples où L26A_ECART = CIR_TOTAL_ECART / 3:\n",
            "SIREN: 7080757, L26A_ECART: -5278.76, CIR_TOTAL_ECART/3: -527.8766666666667\n",
            "Nombre de lignes où L26A_ECART = CIR_TOTAL_ECART / 3: 365\n",
            "Somme CIR_TOTAL_DECLARE : 310,677,342.00 €\n",
            "Somme CIR_TOTAL_CALCULE : 262,878,908.93 €\n",
            "Résultats exportés dans: lignes_L26A_egal_CIR_TOTAL_div_3.csv\n",
            "SIREN: 46750014, L26A_ECART: 205970.78, CIR_TOTAL_ECART/3: 20597.07666666666\n",
            "Nombre de lignes où L26A_ECART = CIR_TOTAL_ECART / 3: 365\n",
            "Somme CIR_TOTAL_DECLARE : 310,677,342.00 €\n",
            "Somme CIR_TOTAL_CALCULE : 262,878,908.93 €\n",
            "Résultats exportés dans: lignes_L26A_egal_CIR_TOTAL_div_3.csv\n",
            "SIREN: 46750014, L26A_ECART: 205970.78, CIR_TOTAL_ECART/3: 20597.07666666666\n",
            "Nombre de lignes où L26A_ECART = CIR_TOTAL_ECART / 3: 365\n",
            "Somme CIR_TOTAL_DECLARE : 310,677,342.00 €\n",
            "Somme CIR_TOTAL_CALCULE : 262,878,908.93 €\n",
            "Résultats exportés dans: lignes_L26A_egal_CIR_TOTAL_div_3.csv\n",
            "SIREN: 60502291, L26A_ECART: -807936.0, CIR_TOTAL_ECART/3: -80793.66666666667\n",
            "Nombre de lignes où L26A_ECART = CIR_TOTAL_ECART / 3: 365\n",
            "Somme CIR_TOTAL_DECLARE : 310,677,342.00 €\n",
            "Somme CIR_TOTAL_CALCULE : 262,878,908.93 €\n",
            "Résultats exportés dans: lignes_L26A_egal_CIR_TOTAL_div_3.csv\n",
            "SIREN: 60502291, L26A_ECART: -807936.0, CIR_TOTAL_ECART/3: -80793.66666666667\n",
            "Nombre de lignes où L26A_ECART = CIR_TOTAL_ECART / 3: 365\n",
            "Somme CIR_TOTAL_DECLARE : 310,677,342.00 €\n",
            "Somme CIR_TOTAL_CALCULE : 262,878,908.93 €\n",
            "Résultats exportés dans: lignes_L26A_egal_CIR_TOTAL_div_3.csv\n",
            "SIREN: 61200226, L26A_ECART: -12200.07, CIR_TOTAL_ECART/3: -1219.84\n",
            "Nombre de lignes où L26A_ECART = CIR_TOTAL_ECART / 3: 365\n",
            "Somme CIR_TOTAL_DECLARE : 310,677,342.00 €\n",
            "Somme CIR_TOTAL_CALCULE : 262,878,908.93 €\n",
            "Résultats exportés dans: lignes_L26A_egal_CIR_TOTAL_div_3.csv\n",
            "SIREN: 61200226, L26A_ECART: -12200.07, CIR_TOTAL_ECART/3: -1219.84\n",
            "Nombre de lignes où L26A_ECART = CIR_TOTAL_ECART / 3: 365\n",
            "Somme CIR_TOTAL_DECLARE : 310,677,342.00 €\n",
            "Somme CIR_TOTAL_CALCULE : 262,878,908.93 €\n",
            "Résultats exportés dans: lignes_L26A_egal_CIR_TOTAL_div_3.csv\n",
            "SIREN: 301053682, L26A_ECART: 34000.45, CIR_TOTAL_ECART/3: 3400.1466666666674\n",
            "Nombre de lignes où L26A_ECART = CIR_TOTAL_ECART / 3: 365\n",
            "Somme CIR_TOTAL_DECLARE : 310,677,342.00 €\n",
            "Somme CIR_TOTAL_CALCULE : 262,878,908.93 €\n",
            "Résultats exportés dans: lignes_L26A_egal_CIR_TOTAL_div_3.csv\n",
            "SIREN: 301053682, L26A_ECART: 34000.45, CIR_TOTAL_ECART/3: 3400.1466666666674\n",
            "Nombre de lignes où L26A_ECART = CIR_TOTAL_ECART / 3: 365\n",
            "Somme CIR_TOTAL_DECLARE : 310,677,342.00 €\n",
            "Somme CIR_TOTAL_CALCULE : 262,878,908.93 €\n",
            "Résultats exportés dans: lignes_L26A_egal_CIR_TOTAL_div_3.csv\n",
            "\n",
            "Exemples où L26A_ECART ≠ CIR_TOTAL_ECART / 3:\n",
            "SIREN: 301272811, L26A_ECART: -0.14, CIR_TOTAL_ECART/3: 3999.8866666666777, Ratio: -0.0000\n",
            "SIREN: 325194165, L26A_ECART: -37409.91, CIR_TOTAL_ECART/3: 5996.41, Ratio: -0.6239\n",
            "SIREN: 388250797, L26A_ECART: 0.1, CIR_TOTAL_ECART/3: -423504.62333333335, Ratio: -0.0000\n",
            "SIREN: 400286688, L26A_ECART: 0.83, CIR_TOTAL_ECART/3: -424496.05, Ratio: -0.0000\n",
            "SIREN: 450580394, L26A_ECART: 10513.65, CIR_TOTAL_ECART/3: -21874.266666666666, Ratio: -0.0481\n",
            "Somme CIR_TOTAL_DECLARE : 310,677,342.00 €\n",
            "Somme CIR_TOTAL_CALCULE : 262,878,908.93 €\n",
            "Résultats exportés dans: lignes_L26A_egal_CIR_TOTAL_div_3.csv\n",
            "\n",
            "Exemples où L26A_ECART ≠ CIR_TOTAL_ECART / 3:\n",
            "SIREN: 301272811, L26A_ECART: -0.14, CIR_TOTAL_ECART/3: 3999.8866666666777, Ratio: -0.0000\n",
            "SIREN: 325194165, L26A_ECART: -37409.91, CIR_TOTAL_ECART/3: 5996.41, Ratio: -0.6239\n",
            "SIREN: 388250797, L26A_ECART: 0.1, CIR_TOTAL_ECART/3: -423504.62333333335, Ratio: -0.0000\n",
            "SIREN: 400286688, L26A_ECART: 0.83, CIR_TOTAL_ECART/3: -424496.05, Ratio: -0.0000\n",
            "SIREN: 450580394, L26A_ECART: 10513.65, CIR_TOTAL_ECART/3: -21874.266666666666, Ratio: -0.0481\n",
            "\n",
            "Résultats détaillés exportés dans: analyse_L26A_vs_CIR_TOTAL.csv\n",
            "\n",
            "Résultats détaillés exportés dans: analyse_L26A_vs_CIR_TOTAL.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Charger le fichier CSV généré précédemment\n",
        "fichier = \"lignes_ecart_cir_recherche_externalise.csv\"\n",
        "df = pd.read_csv(fichier, sep=';', encoding='utf-8-sig')\n",
        "print(f\"Fichier chargé: {len(df)} lignes\")\n",
        "\n",
        "# Convertir les colonnes en numérique pour s'assurer que les calculs seront corrects\n",
        "df['L26A_ECART'] = pd.to_numeric(df['L26A_ECART'], errors='coerce')\n",
        "df['CIR_TOTAL_ECART'] = pd.to_numeric(df['CIR_TOTAL_ECART'], errors='coerce')\n",
        "\n",
        "# Créer une colonne pour vérifier si L26A_ECART = CIR_TOTAL_ECART / 0.3\n",
        "# Permettre une petite marge d'erreur pour les arrondis (0.1%)\n",
        "df['RATIO'] = df['L26A_ECART'] / (df['CIR_TOTAL_ECART'] / 0.3)\n",
        "df['EST_EGAL'] = np.isclose(df['RATIO'], 1, rtol=1)  # Tolérance relative de 0.1%\n",
        "\n",
        "# Compter combien de lignes respectent cette relation\n",
        "nb_egal = df['EST_EGAL'].sum()\n",
        "pourcentage = (nb_egal / len(df)) * 100\n",
        "\n",
        "print(f\"\\nRésultats de l'analyse:\")\n",
        "print(f\"- Nombre de lignes où L26A_ECART = CIR_TOTAL_ECART / 3: {nb_egal} sur {len(df)}\")\n",
        "print(f\"- Pourcentage: {pourcentage:.2f}%\")\n",
        "\n",
        "# Afficher quelques exemples où la relation est respectée\n",
        "print(\"\\nExemples où L26A_ECART = CIR_TOTAL_ECART / 3:\")\n",
        "exemples_egal = df[df['EST_EGAL']].head(5)\n",
        "for _, row in exemples_egal.iterrows():\n",
        "    print(f\"SIREN: {row['SIREN_DECLARANT']}, L26A_ECART: {row['L26A_ECART']}, CIR_TOTAL_ECART/3: {row['CIR_TOTAL_ECART']/3}\")\n",
        "    # Filtrer uniquement les lignes où L26A_ECART = CIR_TOTAL_ECART / 3 est vrai\n",
        "    df_resultat = df[df['EST_EGAL']]\n",
        "\n",
        "    # Afficher le nombre de lignes correspondantes\n",
        "    print(f\"Nombre de lignes où L26A_ECART = CIR_TOTAL_ECART / 3: {len(df_resultat)}\")\n",
        "\n",
        "    # Exporter les résultats filtrés dans un fichier CSV\n",
        "    df_resultat.to_csv(\"lignes_L26A_egal_CIR_TOTAL_div_3.csv\", sep=';', encoding='utf-8-sig', index=False)\n",
        "    # Calculer les sommes\n",
        "    somme_declare = df_resultat['CIR_TOTAL_DECLARE'].sum()\n",
        "    somme_calcule = df_resultat['CIR_TOTAL_CALCULE'].sum()\n",
        "\n",
        "    print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
        "    print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
        "    print(f\"Résultats exportés dans: lignes_L26A_egal_CIR_TOTAL_div_3.csv\")\n",
        "# Afficher quelques exemples où la relation n'est pas respectée\n",
        "print(\"\\nExemples où L26A_ECART ≠ CIR_TOTAL_ECART / 3:\")\n",
        "exemples_different = df[~df['EST_EGAL']].head(5)\n",
        "for _, row in exemples_different.iterrows():\n",
        "    print(f\"SIREN: {row['SIREN_DECLARANT']}, L26A_ECART: {row['L26A_ECART']}, CIR_TOTAL_ECART/3: {row['CIR_TOTAL_ECART']/3}, Ratio: {row['RATIO']:.4f}\")\n",
        "\n",
        "# Exporter les résultats avec la colonne d'analyse supplémentaire\n",
        "df.to_csv(\"analyse_L26A_vs_CIR_TOTAL.csv\", sep=';', encoding='utf-8-sig', index=False)\n",
        "print(f\"\\nRésultats détaillés exportés dans: analyse_L26A_vs_CIR_TOTAL.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3365988388.py:5: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fichier principal chargé: 27957 lignes\n",
            "\n",
            "Nombre de lignes restantes à analyser: 1111\n",
            "Résultats exportés dans: lignes_restantes_a_analyser.csv\n",
            "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Charger le fichier principal\n",
        "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR.csv\"\n",
        "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
        "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
        "\n",
        "# Charger les fichiers d'analyse précédents\n",
        "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')\n",
        "l7_egal_l8 = pd.read_csv(\"lignes_L7_egal_L8.csv\", sep=';', encoding='utf-8-sig')\n",
        "depenses_non0_cir0 = pd.read_csv(\"lignes_depenses_non0_cir_recherche_0.csv\", sep=';', encoding='utf-8-sig')\n",
        "analyse_l26a = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//analyse_L26A_vs_CIR_TOTAL.csv\", sep=';', encoding='utf-8-sig')\n",
        "\n",
        "# Identifier les SIREN à exclure\n",
        "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT'])\n",
        "siren_l7_l8 = set(l7_egal_l8['SIREN_DECLARANT'])\n",
        "siren_depenses_non0_cir0 = set(depenses_non0_cir0['SIREN_DECLARANT'])\n",
        "siren_analyse_l26a = set(analyse_l26a['SIREN_DECLARANT'])\n",
        "\n",
        "# Combiner tous les SIREN à exclure (ajout du cas analyse_L26A_vs_CIR_TOTAL.csv)\n",
        "siren_a_exclure = siren_jeunes_docteurs | siren_l7_l8 | siren_depenses_non0_cir0 | siren_analyse_l26a\n",
        "\n",
        "# Filtrer le DataFrame principal\n",
        "df_restant = df[\n",
        "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) &\n",
        "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
        "]\n",
        "\n",
        "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
        "\n",
        "# Exporter les résultats\n",
        "output_file = \"lignes_restantes_a_analyser.csv\"\n",
        "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
        "print(f\"Résultats exportés dans: {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqZI-TkG2ian"
      },
      "source": [
        "## Erreur doublement sans motif de la créance total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fichier chargé: 1111 lignes\n",
            "Lignes extraites: 181\n",
            "Somme CIR_TOTAL_DECLARE : 121,956,843.00 €\n",
            "Somme CIR_TOTAL_CALCULE : 60,978,422.26 €\n",
            "Résultats exportés dans: lignes_ecart_relatif_50_innovation0_recherche1.csv\n",
            "Somme CIR_TOTAL_DECLARE : 121,956,843.00 €\n",
            "Somme CIR_TOTAL_CALCULE : 60,978,422.26 €\n",
            "Résultats exportés dans: lignes_ecart_relatif_50_innovation0_recherche1.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Charger le fichier des lignes restantes\n",
        "file_path = \"lignes_restantes_a_analyser.csv\"\n",
        "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
        "print(f\"Fichier chargé: {len(df)} lignes\")\n",
        "\n",
        "# Filtrer selon les critères :\n",
        "# - ECART_RELATIF_POURCENT == -50 ou 50\n",
        "# - CIR_INNOVATION_ECART == 0\n",
        "# - CIR_RECHERCHE_ECART entre -1 et 1 inclus\n",
        "mask = (\n",
        "    df['ECART_RELATIF_POURCENT'].isin([-50.0, 50.0]) &\n",
        "    (df['CIR_INNOVATION_ECART'] == 0.0) &\n",
        "    (df['CIR_RECHERCHE_ECART'].between(-1, 1))\n",
        ")\n",
        "\n",
        "df_filtered = df[mask]\n",
        "print(f\"Lignes extraites: {len(df_filtered)}\")\n",
        "\n",
        "# Exporter les résultats\n",
        "output_file = \"lignes_ecart_relatif_50_innovation0_recherche1.csv\"\n",
        "df_filtered.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
        "# Calculer les sommes\n",
        "somme_declare = df_filtered['CIR_TOTAL_DECLARE'].sum()\n",
        "somme_calcule = df_filtered['CIR_TOTAL_CALCULE'].sum()\n",
        "\n",
        "print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
        "print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
        "print(f\"Résultats exportés dans: {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\2558383557.py:5: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fichier principal chargé: 27957 lignes\n",
            "\n",
            "Nombre de lignes restantes à analyser: 930\n",
            "\n",
            "Nombre de lignes restantes à analyser: 930\n",
            "Résultats exportés dans: lignes_restantes_a_analyser.csv\n",
            "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Charger le fichier principal\n",
        "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR.csv\"\n",
        "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
        "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
        "\n",
        "# Charger les fichiers d'analyse précédents\n",
        "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')\n",
        "l7_egal_l8 = pd.read_csv(\"lignes_L7_egal_L8.csv\", sep=';', encoding='utf-8-sig')\n",
        "depenses_non0_cir0 = pd.read_csv(\"lignes_depenses_non0_cir_recherche_0.csv\", sep=';', encoding='utf-8-sig')\n",
        "analyse_l26a = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//analyse_L26A_vs_CIR_TOTAL.csv\", sep=';', encoding='utf-8-sig')\n",
        "ecart_relatif_50_innov0_rech1 = pd.read_csv(\"lignes_ecart_relatif_50_innovation0_recherche1.csv\", sep=';', encoding='utf-8-sig')\n",
        "\n",
        "# Identifier les SIREN à exclure\n",
        "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT'])\n",
        "siren_l7_l8 = set(l7_egal_l8['SIREN_DECLARANT'])\n",
        "siren_depenses_non0_cir0 = set(depenses_non0_cir0['SIREN_DECLARANT'])\n",
        "siren_analyse_l26a = set(analyse_l26a['SIREN_DECLARANT'])\n",
        "siren_ecart_relatif_50_innov0_rech1 = set(ecart_relatif_50_innov0_rech1['SIREN_DECLARANT'])\n",
        "\n",
        "# Combiner tous les SIREN à exclure (ajout du cas analyse_L26A_vs_CIR_TOTAL.csv)\n",
        "siren_a_exclure = siren_jeunes_docteurs | siren_l7_l8 | siren_depenses_non0_cir0 | siren_analyse_l26a | siren_ecart_relatif_50_innov0_rech1\n",
        "\n",
        "# Filtrer le DataFrame principal\n",
        "df_restant = df[\n",
        "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) &\n",
        "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
        "]\n",
        "\n",
        "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
        "\n",
        "# Exporter les résultats\n",
        "output_file = \"lignes_restantes_a_analyser.csv\"\n",
        "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
        "print(f\"Résultats exportés dans: {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moyHJ0iM27VA"
      },
      "source": [
        "## erreur diff Cir total compris entre -500 et 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fichier chargé: 930 lignes\n",
            "Nombre de lignes extraites: 240\n",
            "Somme CIR_TOTAL_DECLARE : 53,889,844.00 €\n",
            "Somme CIR_TOTAL_CALCULE : 53,895,084.56 €\n",
            "Résultats exportés dans: lignes_ecart_total_entre_-500_et_500.csv\n",
            "Somme CIR_TOTAL_DECLARE : 53,889,844.00 €\n",
            "Somme CIR_TOTAL_CALCULE : 53,895,084.56 €\n",
            "Résultats exportés dans: lignes_ecart_total_entre_-500_et_500.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Charger le fichier des lignes restantes à analyser\n",
        "file_path = \"lignes_restantes_a_analyser.csv\"\n",
        "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
        "print(f\"Fichier chargé: {len(df)} lignes\")\n",
        "\n",
        "# Filtrer les lignes où CIR_TOTAL_ECART est entre -500 et 500 et CORRESPONDANCE_CIR == \"Non\"\n",
        "mask_ecart = df['CIR_TOTAL_ECART'].between(-500, 500) & df['CORRESPONDANCE_CIR'].eq(\"Non\")\n",
        "df_resultat = df[mask_ecart]\n",
        "\n",
        "print(f\"Nombre de lignes extraites: {len(df_resultat)}\")\n",
        "\n",
        "# Exporter les résultats\n",
        "output_file = \"lignes_ecart_total_entre_-500_et_500.csv\"\n",
        "df_resultat.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
        "# Calculer les sommes\n",
        "somme_declare = df_resultat['CIR_TOTAL_DECLARE'].sum()\n",
        "somme_calcule = df_resultat['CIR_TOTAL_CALCULE'].sum()\n",
        "\n",
        "print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
        "print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
        "print(f\"Résultats exportés dans: {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\1236064935.py:5: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fichier principal chargé: 27957 lignes\n",
            "\n",
            "Nombre de lignes restantes à analyser: 690\n",
            "\n",
            "Nombre de lignes restantes à analyser: 690\n",
            "Résultats exportés dans: lignes_restantes_a_analyser.csv\n",
            "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Charger le fichier principal\n",
        "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR.csv\"\n",
        "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
        "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
        "\n",
        "# Charger les fichiers d'analyse précédents\n",
        "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')\n",
        "l7_egal_l8 = pd.read_csv(\"lignes_L7_egal_L8.csv\", sep=';', encoding='utf-8-sig')\n",
        "depenses_non0_cir0 = pd.read_csv(\"lignes_depenses_non0_cir_recherche_0.csv\", sep=';', encoding='utf-8-sig')\n",
        "analyse_l26a = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//analyse_L26A_vs_CIR_TOTAL.csv\", sep=';', encoding='utf-8-sig')\n",
        "ecart_relatif_50_innov0_rech1 = pd.read_csv(\"lignes_ecart_relatif_50_innovation0_recherche1.csv\", sep=';', encoding='utf-8-sig')\n",
        "ecart_total500 = pd.read_csv(\"lignes_ecart_total_entre_-500_et_500.csv\", sep=';', encoding='utf-8-sig')\n",
        "\n",
        "# Identifier les SIREN à exclure\n",
        "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT'])\n",
        "siren_l7_l8 = set(l7_egal_l8['SIREN_DECLARANT'])\n",
        "siren_depenses_non0_cir0 = set(depenses_non0_cir0['SIREN_DECLARANT'])\n",
        "siren_analyse_l26a = set(analyse_l26a['SIREN_DECLARANT'])\n",
        "siren_ecart_relatif_50_innov0_rech1 = set(ecart_relatif_50_innov0_rech1['SIREN_DECLARANT'])\n",
        "siren_ecart_total500 = set(ecart_total500['SIREN_DECLARANT'])\n",
        "\n",
        "# Combiner tous les SIREN à exclure (ajout du cas lignes_ecart_total_entre_-500_et_500.csv)\n",
        "siren_a_exclure = siren_jeunes_docteurs | siren_l7_l8 | siren_depenses_non0_cir0 | siren_analyse_l26a | siren_ecart_relatif_50_innov0_rech1 | siren_ecart_total500\n",
        "\n",
        "# Filtrer le DataFrame principal\n",
        "df_restant = df[\n",
        "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) &\n",
        "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
        "]\n",
        "\n",
        "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
        "\n",
        "# Exporter les résultats\n",
        "output_file = \"lignes_restantes_a_analyser.csv\"\n",
        "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
        "print(f\"Résultats exportés dans: {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpCUoEEM5Cbm"
      },
      "source": [
        "## Plafond Partout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "-WDKEmppS-F7",
        "outputId": "b88364ec-bb95-4b83-9aac-0aafb211971f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fichier chargé: 690 lignes\n",
            "Nombre de lignes avec ECART_RELATIF_POURCENT = -100: 45\n",
            "Somme CIR_TOTAL_DECLARE : 1,130,244,774.00 €\n",
            "Somme CIR_TOTAL_CALCULE : 0.00 €\n",
            "Résultats exportés dans: lignes_ecart_relatif_moins_100.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Charger le fichier avec les 703 lignes restantes\n",
        "file_path = \"lignes_restantes_a_analyser.csv\"\n",
        "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
        "print(f\"Fichier chargé: {len(df)} lignes\")\n",
        "\n",
        "# Filtrer les lignes où ECART_RELATIF_POURCENT est égal à -100\n",
        "df_ecart_negatif = df[df['ECART_RELATIF_POURCENT'] == -100]\n",
        "print(f\"Nombre de lignes avec ECART_RELATIF_POURCENT = -100: {len(df_ecart_negatif)}\")\n",
        "\n",
        "# Exporter les résultats dans un fichier CSV\n",
        "output_file = \"lignes_ecart_relatif_moins_100.csv\"\n",
        "df_ecart_negatif.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
        "# Calculer les sommes\n",
        "somme_declare = df_ecart_negatif['CIR_TOTAL_DECLARE'].sum()\n",
        "somme_calcule = df_ecart_negatif['CIR_TOTAL_CALCULE'].sum()\n",
        "\n",
        "print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
        "print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
        "print(f\"Résultats exportés dans: {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\2882612865.py:5: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fichier principal chargé: 27957 lignes\n",
            "\n",
            "Nombre de lignes restantes à analyser: 645\n",
            "\n",
            "Nombre de lignes restantes à analyser: 645\n",
            "Résultats exportés dans: lignes_restantes_a_analyser.csv\n",
            "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Charger le fichier principal\n",
        "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR.csv\"\n",
        "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
        "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
        "\n",
        "# Charger les fichiers d'analyse précédents\n",
        "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')\n",
        "l7_egal_l8 = pd.read_csv(\"lignes_L7_egal_L8.csv\", sep=';', encoding='utf-8-sig')\n",
        "depenses_non0_cir0 = pd.read_csv(\"lignes_depenses_non0_cir_recherche_0.csv\", sep=';', encoding='utf-8-sig')\n",
        "analyse_l26a = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//analyse_L26A_vs_CIR_TOTAL.csv\", sep=';', encoding='utf-8-sig')\n",
        "ecart_relatif_50_innov0_rech1 = pd.read_csv(\"lignes_ecart_relatif_50_innovation0_recherche1.csv\", sep=';', encoding='utf-8-sig')\n",
        "ecart_total500 = pd.read_csv(\"lignes_ecart_total_entre_-500_et_500.csv\", sep=';', encoding='utf-8-sig')\n",
        "ecart_moins_100 = pd.read_csv(\"lignes_ecart_relatif_moins_100.csv\", sep=';', encoding='utf-8-sig')\n",
        "\n",
        "# Identifier les SIREN à exclure\n",
        "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT'])\n",
        "siren_l7_l8 = set(l7_egal_l8['SIREN_DECLARANT'])\n",
        "siren_depenses_non0_cir0 = set(depenses_non0_cir0['SIREN_DECLARANT'])\n",
        "siren_analyse_l26a = set(analyse_l26a['SIREN_DECLARANT'])\n",
        "siren_ecart_relatif_50_innov0_rech1 = set(ecart_relatif_50_innov0_rech1['SIREN_DECLARANT'])\n",
        "siren_ecart_total500 = set(ecart_total500['SIREN_DECLARANT'])\n",
        "siren_ecart_moins_100 = set(ecart_moins_100['SIREN_DECLARANT'])\n",
        "\n",
        "# Combiner tous les SIREN à exclure (ajout du cas lignes_ecart_relatif_moins_100.csv)\n",
        "siren_a_exclure = siren_jeunes_docteurs | siren_l7_l8 | siren_depenses_non0_cir0 | \\\n",
        "                  siren_analyse_l26a | siren_ecart_relatif_50_innov0_rech1 | \\\n",
        "                  siren_ecart_total500 | siren_ecart_moins_100\n",
        "\n",
        "# Filtrer le DataFrame principal\n",
        "df_restant = df[\n",
        "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) &\n",
        "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
        "]\n",
        "\n",
        "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
        "\n",
        "# Exporter les résultats\n",
        "output_file = \"lignes_restantes_a_analyser.csv\"\n",
        "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
        "print(f\"Résultats exportés dans: {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eHvKFTz4sMe"
      },
      "source": [
        "## Erreur Cir innovation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "hlnPcTAXS-F9",
        "outputId": "4cb7ba1e-46c0-4e63-bfb9-1780b892395c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fichier chargé: 645 lignes\n",
            "\n",
            "Nombre de lignes où CIR_TOTAL_ECART = CIR_INNOVATION_ECART (±1): 245\n",
            "\n",
            "Exemples :\n",
            "SIREN: 71802698\n",
            "CIR_TOTAL_ECART: 29651.05\n",
            "CIR_INNOVATION_ECART: 29651.05\n",
            "SIREN: 318291564\n",
            "CIR_TOTAL_ECART: -2191.06\n",
            "CIR_INNOVATION_ECART: -2191.06\n",
            "SIREN: 323378851\n",
            "CIR_TOTAL_ECART: 1174.65\n",
            "CIR_INNOVATION_ECART: 1174.65\n",
            "SIREN: 323540641\n",
            "CIR_TOTAL_ECART: 1906.06\n",
            "CIR_INNOVATION_ECART: 1906.00\n",
            "SIREN: 331099499\n",
            "CIR_TOTAL_ECART: -1253.73\n",
            "CIR_INNOVATION_ECART: -1253.73\n",
            "Somme CIR_TOTAL_DECLARE : 18,696,070.00 €\n",
            "Somme CIR_TOTAL_CALCULE : 16,240,495.23 €\n",
            "\n",
            "Résultats exportés dans: lignes_ecart_total_egal_innovation.csv\n",
            "Somme CIR_TOTAL_DECLARE : 18,696,070.00 €\n",
            "Somme CIR_TOTAL_CALCULE : 16,240,495.23 €\n",
            "\n",
            "Résultats exportés dans: lignes_ecart_total_egal_innovation.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Charger le fichier des lignes restantes\n",
        "file_path = \"lignes_restantes_a_analyser.csv\"\n",
        "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
        "print(f\"Fichier chargé: {len(df)} lignes\")\n",
        "\n",
        "# Filtrer les lignes où CIR_TOTAL_ECART = CIR_INNOVATION_ECART (±1)\n",
        "mask = np.isclose(df['CIR_TOTAL_ECART'], df['CIR_INNOVATION_ECART'], atol=1.0)\n",
        "df_filtered = df[mask]\n",
        "\n",
        "print(f\"\\nNombre de lignes où CIR_TOTAL_ECART = CIR_INNOVATION_ECART (±1): {len(df_filtered)}\")\n",
        "\n",
        "# Afficher quelques exemples\n",
        "if len(df_filtered) > 0:\n",
        "    print(\"\\nExemples :\")\n",
        "    for _, row in df_filtered.head().iterrows():\n",
        "        print(f\"SIREN: {row['SIREN_DECLARANT']}\")\n",
        "        print(f\"CIR_TOTAL_ECART: {row['CIR_TOTAL_ECART']:.2f}\")\n",
        "        print(f\"CIR_INNOVATION_ECART: {row['CIR_INNOVATION_ECART']:.2f}\")\n",
        "\n",
        "# Exporter les résultats\n",
        "output_file = \"lignes_ecart_total_egal_innovation.csv\"\n",
        "df_filtered.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
        "# Calculer les sommes\n",
        "somme_declare = df_filtered['CIR_TOTAL_DECLARE'].sum()\n",
        "somme_calcule = df_filtered['CIR_TOTAL_CALCULE'].sum()\n",
        "\n",
        "print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
        "print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
        "print(f\"\\nRésultats exportés dans: {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\987456505.py:5: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fichier principal chargé: 27957 lignes\n",
            "\n",
            "Nombre de lignes restantes à analyser: 400\n",
            "\n",
            "Nombre de lignes restantes à analyser: 400\n",
            "Résultats exportés dans: lignes_restantes_a_analyser.csv\n",
            "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Charger le fichier principal\n",
        "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR.csv\"\n",
        "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
        "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
        "\n",
        "# Charger les fichiers d'analyse précédents\n",
        "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')\n",
        "l7_egal_l8 = pd.read_csv(\"lignes_L7_egal_L8.csv\", sep=';', encoding='utf-8-sig')\n",
        "depenses_non0_cir0 = pd.read_csv(\"lignes_depenses_non0_cir_recherche_0.csv\", sep=';', encoding='utf-8-sig')\n",
        "analyse_l26a = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//analyse_L26A_vs_CIR_TOTAL.csv\", sep=';', encoding='utf-8-sig')\n",
        "ecart_relatif_50_innov0_rech1 = pd.read_csv(\"lignes_ecart_relatif_50_innovation0_recherche1.csv\", sep=';', encoding='utf-8-sig')\n",
        "ecart_total500 = pd.read_csv(\"lignes_ecart_total_entre_-500_et_500.csv\", sep=';', encoding='utf-8-sig')\n",
        "ecart_moins_100 = pd.read_csv(\"lignes_ecart_relatif_moins_100.csv\", sep=';', encoding='utf-8-sig')\n",
        "innovation_egal_total = pd.read_csv(\"lignes_ecart_total_egal_innovation.csv\", sep=';', encoding='utf-8-sig')\n",
        "\n",
        "# Identifier les SIREN à exclure\n",
        "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT'])\n",
        "siren_l7_l8 = set(l7_egal_l8['SIREN_DECLARANT'])\n",
        "siren_depenses_non0_cir0 = set(depenses_non0_cir0['SIREN_DECLARANT'])\n",
        "siren_analyse_l26a = set(analyse_l26a['SIREN_DECLARANT'])\n",
        "siren_ecart_relatif_50_innov0_rech1 = set(ecart_relatif_50_innov0_rech1['SIREN_DECLARANT'])\n",
        "siren_ecart_total500 = set(ecart_total500['SIREN_DECLARANT'])\n",
        "siren_ecart_moins_100 = set(ecart_moins_100['SIREN_DECLARANT'])\n",
        "siren_innovation_egal_total = set(innovation_egal_total['SIREN_DECLARANT'])\n",
        "\n",
        "# Combiner tous les SIREN à exclure (ajout du cas innovation_egal_total)\n",
        "siren_a_exclure = siren_jeunes_docteurs | siren_l7_l8 | siren_depenses_non0_cir0 | \\\n",
        "                  siren_analyse_l26a | siren_ecart_relatif_50_innov0_rech1 | \\\n",
        "                  siren_ecart_total500 | siren_ecart_moins_100 | \\\n",
        "                  siren_innovation_egal_total\n",
        "\n",
        "# Filtrer le DataFrame principal\n",
        "df_restant = df[\n",
        "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) &\n",
        "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
        "]\n",
        "\n",
        "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
        "\n",
        "# Exporter les résultats\n",
        "output_file = \"lignes_restantes_a_analyser.csv\"\n",
        "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
        "print(f\"Résultats exportés dans: {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juqLSVKC5aJ_"
      },
      "source": [
        "## Erreur Cir Collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "W6Gz3p4sS-F8",
        "outputId": "66a21f3a-40d5-4d77-c091-686aee9f14cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fichier chargé: 400 lignes\n",
            "\n",
            "Nombre de lignes où CIR_TOTAL_ECART = CIR_COLLECTION_ECART (±1): 33\n",
            "\n",
            "Quelques exemples :\n",
            "\n",
            "SIREN: 300347085\n",
            "CIR_TOTAL_ECART: 200000.00\n",
            "CIR_COLLECTION_ECART: 200000.00\n",
            "\n",
            "SIREN: 301857074\n",
            "CIR_TOTAL_ECART: 200000.00\n",
            "CIR_COLLECTION_ECART: 200000.00\n",
            "\n",
            "SIREN: 302306626\n",
            "CIR_TOTAL_ECART: 200000.00\n",
            "CIR_COLLECTION_ECART: 200000.00\n",
            "\n",
            "SIREN: 333401271\n",
            "CIR_TOTAL_ECART: -7289.81\n",
            "CIR_COLLECTION_ECART: -7290.00\n",
            "\n",
            "SIREN: 349760918\n",
            "CIR_TOTAL_ECART: 199999.22\n",
            "CIR_COLLECTION_ECART: 200000.00\n",
            "Somme CIR_TOTAL_DECLARE : 7,412,926.00 €\n",
            "Somme CIR_TOTAL_CALCULE : 10,939,737.25 €\n",
            "\n",
            "Résultats exportés dans: lignes_ecart_total_egal_collection.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Charger le fichier\n",
        "file_path = \"lignes_restantes_a_analyser.csv\"\n",
        "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
        "print(f\"Fichier chargé: {len(df)} lignes\")\n",
        "\n",
        "# Créer le masque pour identifier où CIR_TOTAL_ECART = CIR_COLLECTION_ECART (±1)\n",
        "mask = np.isclose(df['CIR_TOTAL_ECART'], df['CIR_COLLECTION_ECART'], atol=1.0)\n",
        "\n",
        "# Filtrer les lignes\n",
        "df_filtered = df[mask]\n",
        "\n",
        "print(f\"\\nNombre de lignes où CIR_TOTAL_ECART = CIR_COLLECTION_ECART (±1): {len(df_filtered)}\")\n",
        "\n",
        "# Afficher quelques statistiques sur ces lignes\n",
        "if len(df_filtered) > 0:\n",
        "    print(\"\\nQuelques exemples :\")\n",
        "    for _, row in df_filtered.head().iterrows():\n",
        "        print(f\"\\nSIREN: {row['SIREN_DECLARANT']}\")\n",
        "        print(f\"CIR_TOTAL_ECART: {row['CIR_TOTAL_ECART']:.2f}\")\n",
        "        print(f\"CIR_COLLECTION_ECART: {row['CIR_COLLECTION_ECART']:.2f}\")\n",
        "\n",
        "# Exporter les résultats\n",
        "output_file = \"lignes_ecart_total_egal_collection.csv\"\n",
        "df_filtered.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
        "# Calculer les sommes\n",
        "somme_declare = df_filtered['CIR_TOTAL_DECLARE'].sum()\n",
        "somme_calcule = df_filtered['CIR_TOTAL_CALCULE'].sum()\n",
        "\n",
        "print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
        "print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
        "print(f\"\\nRésultats exportés dans: {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\4065925440.py:5: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fichier principal chargé: 27957 lignes\n",
            "\n",
            "Nombre de lignes restantes à analyser: 367\n",
            "\n",
            "Nombre de lignes restantes à analyser: 367\n",
            "Résultats exportés dans: lignes_restantes_a_analyser.csv\n",
            "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Charger le fichier principal\n",
        "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR.csv\"\n",
        "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
        "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
        "\n",
        "# Charger les fichiers d'analyse précédents\n",
        "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')\n",
        "l7_egal_l8 = pd.read_csv(\"lignes_L7_egal_L8.csv\", sep=';', encoding='utf-8-sig')\n",
        "depenses_non0_cir0 = pd.read_csv(\"lignes_depenses_non0_cir_recherche_0.csv\", sep=';', encoding='utf-8-sig')\n",
        "analyse_l26a = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//analyse_L26A_vs_CIR_TOTAL.csv\", sep=';', encoding='utf-8-sig')\n",
        "ecart_relatif_50_innov0_rech1 = pd.read_csv(\"lignes_ecart_relatif_50_innovation0_recherche1.csv\", sep=';', encoding='utf-8-sig')\n",
        "ecart_total500 = pd.read_csv(\"lignes_ecart_total_entre_-500_et_500.csv\", sep=';', encoding='utf-8-sig')\n",
        "ecart_moins_100 = pd.read_csv(\"lignes_ecart_relatif_moins_100.csv\", sep=';', encoding='utf-8-sig')\n",
        "innovation_egal_total = pd.read_csv(\"lignes_ecart_total_egal_innovation.csv\", sep=';', encoding='utf-8-sig')\n",
        "collection_egal_total = pd.read_csv(\"lignes_ecart_total_egal_collection.csv\", sep=';', encoding='utf-8-sig')\n",
        "\n",
        "# Identifier les SIREN à exclure\n",
        "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT'])\n",
        "siren_l7_l8 = set(l7_egal_l8['SIREN_DECLARANT'])\n",
        "siren_depenses_non0_cir0 = set(depenses_non0_cir0['SIREN_DECLARANT'])\n",
        "siren_analyse_l26a = set(analyse_l26a['SIREN_DECLARANT'])\n",
        "siren_ecart_relatif_50_innov0_rech1 = set(ecart_relatif_50_innov0_rech1['SIREN_DECLARANT'])\n",
        "siren_ecart_total500 = set(ecart_total500['SIREN_DECLARANT'])\n",
        "siren_ecart_moins_100 = set(ecart_moins_100['SIREN_DECLARANT'])\n",
        "siren_innovation_egal_total = set(innovation_egal_total['SIREN_DECLARANT'])\n",
        "siren_collection_egal_total = set(collection_egal_total['SIREN_DECLARANT'])\n",
        "\n",
        "# Combiner tous les SIREN à exclure (ajout du cas collection_egal_total)\n",
        "siren_a_exclure = siren_jeunes_docteurs | siren_l7_l8 | siren_depenses_non0_cir0 | \\\n",
        "                  siren_analyse_l26a | siren_ecart_relatif_50_innov0_rech1 | \\\n",
        "                  siren_ecart_total500 | siren_ecart_moins_100 | \\\n",
        "                  siren_innovation_egal_total | siren_collection_egal_total\n",
        "\n",
        "# Filtrer le DataFrame principal\n",
        "df_restant = df[\n",
        "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) &\n",
        "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
        "]\n",
        "\n",
        "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
        "\n",
        "# Exporter les résultats\n",
        "output_file = \"lignes_restantes_a_analyser.csv\"\n",
        "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
        "print(f\"Résultats exportés dans: {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iVg58X05uK3"
      },
      "source": [
        "## Erreur Cir Déclarer vaut 0 alors que sa ne l'est pas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "w9yCLFKpS-F9",
        "outputId": "f20870a6-4cce-41be-a3c7-5512ee8623f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fichier chargé: 367 lignes\n",
            "Nombre de lignes où ECART_RELATIF_POURCENT = 100 et CIR_TOTAL_DECLARE = 0: 44\n",
            "Somme CIR_TOTAL_DECLARE : 0.00 €\n",
            "Somme CIR_TOTAL_CALCULE : 2,205,497.50 €\n",
            "Résultats exportés dans: lignes_ecart_100_cir_declare_0.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Charger le fichier des lignes restantes\n",
        "file_path = \"lignes_restantes_a_analyser.csv\"\n",
        "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
        "print(f\"Fichier chargé: {len(df)} lignes\")\n",
        "\n",
        "# Filtrer les lignes où ECART_RELATIF_POURCENT = 100 et CIR_TOTAL_DECLARE = 0\n",
        "df_filtered = df[(df['ECART_RELATIF_POURCENT'] == 100) & (df['CIR_TOTAL_DECLARE'] == 0)]\n",
        "\n",
        "print(f\"Nombre de lignes où ECART_RELATIF_POURCENT = 100 et CIR_TOTAL_DECLARE = 0: {len(df_filtered)}\")\n",
        "\n",
        "# Exporter les résultats\n",
        "output_file = \"lignes_ecart_100_cir_declare_0.csv\"\n",
        "df_filtered.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
        "# Calculer les sommes\n",
        "somme_declare = df_filtered['CIR_TOTAL_DECLARE'].sum()\n",
        "somme_calcule = df_filtered['CIR_TOTAL_CALCULE'].sum()\n",
        "\n",
        "print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
        "print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
        "print(f\"Résultats exportés dans: {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\1938235922.py:5: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fichier principal chargé: 27957 lignes\n",
            "\n",
            "Nombre de lignes restantes à analyser: 323\n",
            "\n",
            "Nombre de lignes restantes à analyser: 323\n",
            "Résultats exportés dans: lignes_restantes_a_analyser.csv\n",
            "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Charger le fichier principal\n",
        "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR.csv\"\n",
        "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
        "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
        "\n",
        "# Charger tous les fichiers d'analyse précédents\n",
        "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')\n",
        "l7_egal_l8 = pd.read_csv(\"lignes_L7_egal_L8.csv\", sep=';', encoding='utf-8-sig')\n",
        "depenses_non0_cir0 = pd.read_csv(\"lignes_depenses_non0_cir_recherche_0.csv\", sep=';', encoding='utf-8-sig')\n",
        "analyse_l26a = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//analyse_L26A_vs_CIR_TOTAL.csv\", sep=';', encoding='utf-8-sig')\n",
        "ecart_relatif_50_innov0_rech1 = pd.read_csv(\"lignes_ecart_relatif_50_innovation0_recherche1.csv\", sep=';', encoding='utf-8-sig')\n",
        "ecart_total500 = pd.read_csv(\"lignes_ecart_total_entre_-500_et_500.csv\", sep=';', encoding='utf-8-sig')\n",
        "ecart_moins_100 = pd.read_csv(\"lignes_ecart_relatif_moins_100.csv\", sep=';', encoding='utf-8-sig')\n",
        "innovation_egal_total = pd.read_csv(\"lignes_ecart_total_egal_innovation.csv\", sep=';', encoding='utf-8-sig')\n",
        "collection_egal_total = pd.read_csv(\"lignes_ecart_total_egal_collection.csv\", sep=';', encoding='utf-8-sig')\n",
        "ecart_100_cir_declare_0 = pd.read_csv(\"lignes_ecart_100_cir_declare_0.csv\", sep=';', encoding='utf-8-sig')\n",
        "\n",
        "# Identifier les SIREN à exclure\n",
        "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT'])\n",
        "siren_l7_l8 = set(l7_egal_l8['SIREN_DECLARANT'])\n",
        "siren_depenses_non0_cir0 = set(depenses_non0_cir0['SIREN_DECLARANT'])\n",
        "siren_analyse_l26a = set(analyse_l26a['SIREN_DECLARANT'])\n",
        "siren_ecart_relatif_50_innov0_rech1 = set(ecart_relatif_50_innov0_rech1['SIREN_DECLARANT'])\n",
        "siren_ecart_total500 = set(ecart_total500['SIREN_DECLARANT'])\n",
        "siren_ecart_moins_100 = set(ecart_moins_100['SIREN_DECLARANT'])\n",
        "siren_innovation_egal_total = set(innovation_egal_total['SIREN_DECLARANT'])\n",
        "siren_collection_egal_total = set(collection_egal_total['SIREN_DECLARANT'])\n",
        "siren_ecart_100_cir_declare_0 = set(ecart_100_cir_declare_0['SIREN_DECLARANT'])\n",
        "\n",
        "# Combiner tous les SIREN à exclure (ajout du cas ecart_100_cir_declare_0)\n",
        "siren_a_exclure = siren_jeunes_docteurs | siren_l7_l8 | siren_depenses_non0_cir0 | \\\n",
        "                  siren_analyse_l26a | siren_ecart_relatif_50_innov0_rech1 | \\\n",
        "                  siren_ecart_total500 | siren_ecart_moins_100 | \\\n",
        "                  siren_innovation_egal_total | siren_collection_egal_total | \\\n",
        "                  siren_ecart_100_cir_declare_0\n",
        "\n",
        "# Filtrer le DataFrame principal\n",
        "df_restant = df[\n",
        "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) &\n",
        "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
        "]\n",
        "\n",
        "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
        "\n",
        "# Exporter les résultats\n",
        "output_file = \"lignes_restantes_a_analyser.csv\"\n",
        "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
        "print(f\"Résultats exportés dans: {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HL5iyNQa5_0H"
      },
      "source": [
        "## Erreur liée à L6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "Pqc8rdEaS-GG",
        "outputId": "f3914f45-4432-4cc2-9dc0-1213142380a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fichier chargé: 323 lignes\n",
            "\n",
            "Nombre de lignes où CIR_TOTAL_ECART = CIR_RECHERCHE_ECART (±1) et L6_ECART hors [-1, 1]: 35\n",
            "Somme CIR_TOTAL_DECLARE : 8,632,110.00 €\n",
            "Somme CIR_TOTAL_CALCULE : 9,282,543.16 €\n",
            "\n",
            "Résultats exportés dans: lignes_ecart_total_egal_recherche_l6_ecart_hors_1.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Charger le fichier des lignes restantes\n",
        "file_path = \"lignes_restantes_a_analyser.csv\"\n",
        "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
        "print(f\"Fichier chargé: {len(df)} lignes\")\n",
        "\n",
        "# Filtrer les lignes où CIR_TOTAL_ECART = CIR_RECHERCHE_ECART (±1)\n",
        "mask_ecart = np.isclose(df['CIR_TOTAL_ECART'], df['CIR_RECHERCHE_ECART'], atol=1.0)\n",
        "\n",
        "# Filtrer les lignes où L6_ECART est strictement en dehors de [-1, 1]\n",
        "mask_l6 = (df['L6_ECART'] < -1) | (df['L6_ECART'] > 1)\n",
        "\n",
        "# Appliquer les deux filtres\n",
        "df_filtered = df[mask_ecart & mask_l6]\n",
        "\n",
        "print(f\"\\nNombre de lignes où CIR_TOTAL_ECART = CIR_RECHERCHE_ECART (±1) et L6_ECART hors [-1, 1]: {len(df_filtered)}\")\n",
        "# Exporter les résultats\n",
        "output_file = \"lignes_ecart_total_egal_recherche_l6_ecart_hors_1.csv\"\n",
        "df_filtered.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
        "# Calculer les sommes\n",
        "somme_declare = df_filtered['CIR_TOTAL_DECLARE'].sum()\n",
        "somme_calcule = df_filtered['CIR_TOTAL_CALCULE'].sum()\n",
        "\n",
        "print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
        "print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
        "print(f\"\\nRésultats exportés dans: {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\1009379534.py:5: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fichier principal chargé: 27957 lignes\n",
            "\n",
            "Nombre de lignes restantes à analyser: 288\n",
            "\n",
            "Nombre de lignes restantes à analyser: 288\n",
            "Résultats exportés dans: lignes_restantes_a_analyser.csv\n",
            "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Charger le fichier principal\n",
        "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR.csv\"\n",
        "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
        "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
        "\n",
        "# Charger tous les fichiers d'analyse précédents\n",
        "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')\n",
        "l7_egal_l8 = pd.read_csv(\"lignes_L7_egal_L8.csv\", sep=';', encoding='utf-8-sig')\n",
        "depenses_non0_cir0 = pd.read_csv(\"lignes_depenses_non0_cir_recherche_0.csv\", sep=';', encoding='utf-8-sig')\n",
        "analyse_l26a = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//analyse_L26A_vs_CIR_TOTAL.csv\", sep=';', encoding='utf-8-sig')\n",
        "ecart_relatif_50_innov0_rech1 = pd.read_csv(\"lignes_ecart_relatif_50_innovation0_recherche1.csv\", sep=';', encoding='utf-8-sig')\n",
        "ecart_total500 = pd.read_csv(\"lignes_ecart_total_entre_-500_et_500.csv\", sep=';', encoding='utf-8-sig')\n",
        "ecart_moins_100 = pd.read_csv(\"lignes_ecart_relatif_moins_100.csv\", sep=';', encoding='utf-8-sig')\n",
        "innovation_egal_total = pd.read_csv(\"lignes_ecart_total_egal_innovation.csv\", sep=';', encoding='utf-8-sig')\n",
        "collection_egal_total = pd.read_csv(\"lignes_ecart_total_egal_collection.csv\", sep=';', encoding='utf-8-sig')\n",
        "ecart_100_cir_declare_0 = pd.read_csv(\"lignes_ecart_100_cir_declare_0.csv\", sep=';', encoding='utf-8-sig')\n",
        "l6_ecart_hors_1 = pd.read_csv(\"lignes_ecart_total_egal_recherche_l6_ecart_hors_1.csv\", sep=';', encoding='utf-8-sig')\n",
        "\n",
        "# Identifier les SIREN à exclure\n",
        "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT'])\n",
        "siren_l7_l8 = set(l7_egal_l8['SIREN_DECLARANT'])\n",
        "siren_depenses_non0_cir0 = set(depenses_non0_cir0['SIREN_DECLARANT'])\n",
        "siren_analyse_l26a = set(analyse_l26a['SIREN_DECLARANT'])\n",
        "siren_ecart_relatif_50_innov0_rech1 = set(ecart_relatif_50_innov0_rech1['SIREN_DECLARANT'])\n",
        "siren_ecart_total500 = set(ecart_total500['SIREN_DECLARANT'])\n",
        "siren_ecart_moins_100 = set(ecart_moins_100['SIREN_DECLARANT'])\n",
        "siren_innovation_egal_total = set(innovation_egal_total['SIREN_DECLARANT'])\n",
        "siren_collection_egal_total = set(collection_egal_total['SIREN_DECLARANT'])\n",
        "siren_ecart_100_cir_declare_0 = set(ecart_100_cir_declare_0['SIREN_DECLARANT'])\n",
        "siren_l6_ecart_hors_1 = set(l6_ecart_hors_1['SIREN_DECLARANT'])\n",
        "\n",
        "# Combiner tous les SIREN à exclure (ajout du cas l6_ecart_hors_1)\n",
        "siren_a_exclure = siren_jeunes_docteurs | siren_l7_l8 | siren_depenses_non0_cir0 | \\\n",
        "                  siren_analyse_l26a | siren_ecart_relatif_50_innov0_rech1 | \\\n",
        "                  siren_ecart_total500 | siren_ecart_moins_100 | \\\n",
        "                  siren_innovation_egal_total | siren_collection_egal_total | \\\n",
        "                  siren_ecart_100_cir_declare_0 | siren_l6_ecart_hors_1\n",
        "\n",
        "# Filtrer le DataFrame principal\n",
        "df_restant = df[\n",
        "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) &\n",
        "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
        "]\n",
        "\n",
        "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
        "\n",
        "# Exporter les résultats\n",
        "output_file = \"lignes_restantes_a_analyser.csv\"\n",
        "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
        "print(f\"Résultats exportés dans: {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBO56qBf6WMB"
      },
      "source": [
        "## Erreur liée à L26"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "_rokKpCwS-GH",
        "outputId": "378a8f68-a48a-4be3-d58c-d3fdd194b811"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fichier chargé: 288 lignes\n",
            "Nombre de lignes correspondant au cas demandé : 28\n",
            "    SIREN_DECLARANT  L26A_ECART  L14_ECART  L20_ECART  L21_ECART\n",
            "7         327880001  -100000.04      -0.04        0.0        0.0\n",
            "11        335187696   400000.78       0.78        0.0        0.0\n",
            "16        343043790   200000.63       0.63        0.0        0.0\n",
            "31        389019274  -200000.45      -0.45        0.0        0.0\n",
            "51        425112612   -99999.89       0.11        0.0        0.0\n",
            "Somme CIR_TOTAL_DECLARE : 19,583,069.00 €\n",
            "Somme CIR_TOTAL_CALCULE : 20,493,169.63 €\n",
            "Résultats exportés dans: lignes_cas_L26A_ecart_hors_1_L14_L20_L21_dans_1.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Charger le fichier des lignes restantes\n",
        "file_path = \"lignes_restantes_a_analyser.csv\"\n",
        "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
        "print(f\"Fichier chargé: {len(df)} lignes\")\n",
        "\n",
        "# Appliquer les filtres demandés\n",
        "mask = (\n",
        "    ((df['L26A_ECART'] > 1) | (df['L26A_ECART'] < -1))\n",
        "    & ((df['L14_ECART'] > -1) & (df['L14_ECART'] < 1))\n",
        "    & ((df['L20_ECART'] > -1) & (df['L20_ECART'] < 1))\n",
        "    & ((df['L21_ECART'] > -1) & (df['L21_ECART'] < 1))\n",
        "    & ((df['L22_ECART'] > -1) & (df['L22_ECART'] < 1))\n",
        ")\n",
        "\n",
        "df_filtered = df[mask]\n",
        "print(f\"Nombre de lignes correspondant au cas demandé : {len(df_filtered)}\")\n",
        "\n",
        "# Afficher quelques exemples\n",
        "if len(df_filtered) > 0:\n",
        "    print(df_filtered[['SIREN_DECLARANT', 'L26A_ECART', 'L14_ECART', 'L20_ECART', 'L21_ECART']].head())\n",
        "\n",
        "# Exporter les résultats\n",
        "output_file = \"lignes_cas_L26A_ecart_hors_1_L14_L20_L21_dans_1.csv\"\n",
        "df_filtered.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
        "# Calculer les sommes\n",
        "somme_declare = df_filtered['CIR_TOTAL_DECLARE'].sum()\n",
        "somme_calcule = df_filtered['CIR_TOTAL_CALCULE'].sum()\n",
        "\n",
        "print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
        "print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
        "print(f\"Résultats exportés dans: {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\2783479905.py:5: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fichier principal chargé: 27957 lignes\n",
            "\n",
            "Nombre de lignes restantes à analyser: 260\n",
            "\n",
            "Nombre de lignes restantes à analyser: 260\n",
            "Résultats exportés dans: lignes_restantes_a_analyser.csv\n",
            "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Charger le fichier principal\n",
        "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR.csv\"\n",
        "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
        "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
        "\n",
        "# Charger tous les fichiers d'analyse précédents\n",
        "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')\n",
        "l7_egal_l8 = pd.read_csv(\"lignes_L7_egal_L8.csv\", sep=';', encoding='utf-8-sig')\n",
        "depenses_non0_cir0 = pd.read_csv(\"lignes_depenses_non0_cir_recherche_0.csv\", sep=';', encoding='utf-8-sig')\n",
        "analyse_l26a = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//analyse_L26A_vs_CIR_TOTAL.csv\", sep=';', encoding='utf-8-sig')\n",
        "ecart_relatif_50_innov0_rech1 = pd.read_csv(\"lignes_ecart_relatif_50_innovation0_recherche1.csv\", sep=';', encoding='utf-8-sig')\n",
        "ecart_total500 = pd.read_csv(\"lignes_ecart_total_entre_-500_et_500.csv\", sep=';', encoding='utf-8-sig')\n",
        "ecart_moins_100 = pd.read_csv(\"lignes_ecart_relatif_moins_100.csv\", sep=';', encoding='utf-8-sig')\n",
        "innovation_egal_total = pd.read_csv(\"lignes_ecart_total_egal_innovation.csv\", sep=';', encoding='utf-8-sig')\n",
        "collection_egal_total = pd.read_csv(\"lignes_ecart_total_egal_collection.csv\", sep=';', encoding='utf-8-sig')\n",
        "ecart_100_cir_declare_0 = pd.read_csv(\"lignes_ecart_100_cir_declare_0.csv\", sep=';', encoding='utf-8-sig')\n",
        "l6_ecart_hors_1 = pd.read_csv(\"lignes_ecart_total_egal_recherche_l6_ecart_hors_1.csv\", sep=';', encoding='utf-8-sig')\n",
        "cas_l26a = pd.read_csv(\"lignes_cas_L26A_ecart_hors_1_L14_L20_L21_dans_1.csv\", sep=';', encoding='utf-8-sig')\n",
        "\n",
        "# Identifier les SIREN à exclure\n",
        "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT'])\n",
        "siren_l7_l8 = set(l7_egal_l8['SIREN_DECLARANT'])\n",
        "siren_depenses_non0_cir0 = set(depenses_non0_cir0['SIREN_DECLARANT'])\n",
        "siren_analyse_l26a = set(analyse_l26a['SIREN_DECLARANT'])\n",
        "siren_ecart_relatif_50_innov0_rech1 = set(ecart_relatif_50_innov0_rech1['SIREN_DECLARANT'])\n",
        "siren_ecart_total500 = set(ecart_total500['SIREN_DECLARANT'])\n",
        "siren_ecart_moins_100 = set(ecart_moins_100['SIREN_DECLARANT'])\n",
        "siren_innovation_egal_total = set(innovation_egal_total['SIREN_DECLARANT'])\n",
        "siren_collection_egal_total = set(collection_egal_total['SIREN_DECLARANT'])\n",
        "siren_ecart_100_cir_declare_0 = set(ecart_100_cir_declare_0['SIREN_DECLARANT'])\n",
        "siren_l6_ecart_hors_1 = set(l6_ecart_hors_1['SIREN_DECLARANT'])\n",
        "siren_cas_l26a = set(cas_l26a['SIREN_DECLARANT'])\n",
        "\n",
        "# Combiner tous les SIREN à exclure (ajout du cas l6_ecart_hors_1)\n",
        "siren_a_exclure = siren_jeunes_docteurs | siren_l7_l8 | siren_depenses_non0_cir0 | \\\n",
        "                  siren_analyse_l26a | siren_ecart_relatif_50_innov0_rech1 | \\\n",
        "                  siren_ecart_total500 | siren_ecart_moins_100 | \\\n",
        "                  siren_innovation_egal_total | siren_collection_egal_total | \\\n",
        "                  siren_ecart_100_cir_declare_0 | siren_l6_ecart_hors_1 | siren_cas_l26a\n",
        "\n",
        "# Filtrer le DataFrame principal\n",
        "df_restant = df[\n",
        "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) &\n",
        "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
        "]\n",
        "\n",
        "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
        "\n",
        "# Exporter les résultats\n",
        "output_file = \"lignes_restantes_a_analyser.csv\"\n",
        "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
        "print(f\"Résultats exportés dans: {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBTuZXFF68Mp"
      },
      "source": [
        "## Erreur oublie CRC dans Cir Total Déclarer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "aHN4c7mrS-GH",
        "outputId": "21f459a6-5604-4eb8-bc1d-4a700af7c7f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fichier chargé: 260 lignes\n",
            "Nombre de lignes correspondant au cas demandé : 140\n",
            "    SIREN_DECLARANT  CIR_TOTAL_ECART  \\\n",
            "0         300163896         12824.45   \n",
            "1         300817954         41012.11   \n",
            "2         304189590         21231.03   \n",
            "3         314527557         86116.07   \n",
            "12        339918492          6405.25   \n",
            "\n",
            "    L91_MONTANT_TOTAL_CIR_RECHERCHE_COLLABORATIVE  \n",
            "0                                         12824.0  \n",
            "1                                         41012.5  \n",
            "2                                         21230.8  \n",
            "3                                         86116.0  \n",
            "12                                         6405.6  \n",
            "Somme CIR_TOTAL_DECLARE : 61,721,671.00 €\n",
            "Somme CIR_TOTAL_CALCULE : 67,394,882.63 €\n",
            "Résultats exportés dans: lignes_ecarts_cir_entre_-1_1_et_total_egal_L91.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Charger le fichier des lignes restantes\n",
        "file_path = \"lignes_restantes_a_analyser.csv\"\n",
        "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
        "print(f\"Fichier chargé: {len(df)} lignes\")\n",
        "\n",
        "# Filtrer les lignes où les écarts CIR (recherche, collection, innovation, collaboratif) sont tous entre -1 et 1\n",
        "mask_ecarts = (\n",
        "    df['CIR_RECHERCHE_ECART'].between(-1, 1) &\n",
        "    df['CIR_COLLECTION_ECART'].between(-1, 1) &\n",
        "    df['CIR_INNOVATION_ECART'].between(-1, 1) &\n",
        "    df['CIR_COLLABORATIF_ECART'].between(-1, 1)\n",
        ")\n",
        "\n",
        "# Filtrer les lignes où CIR_TOTAL_ECART = L91_MONTANT_TOTAL_CIR_RECHERCHE_COLLABORATIVE (à ±1 près)\n",
        "if 'L91_MONTANT_TOTAL_CIR_RECHERCHE_COLLABORATIVE' in df.columns:\n",
        "    mask_l91 = np.isclose(df['CIR_TOTAL_ECART'], df['L91_MONTANT_TOTAL_CIR_RECHERCHE_COLLABORATIVE'], atol=1.0)\n",
        "else:\n",
        "    mask_l91 = pd.Series([False]*len(df), index=df.index)\n",
        "    print(\"Colonne L91_MONTANT_TOTAL_CIR_RECHERCHE_COLLABORATIVE absente du fichier.\")\n",
        "\n",
        "# Appliquer les deux filtres\n",
        "df_filtered = df[mask_ecarts & mask_l91]\n",
        "\n",
        "print(f\"Nombre de lignes correspondant au cas demandé : {len(df_filtered)}\")\n",
        "\n",
        "# Afficher quelques exemples\n",
        "if len(df_filtered) > 0:\n",
        "    print(df_filtered[['SIREN_DECLARANT', 'CIR_TOTAL_ECART', 'L91_MONTANT_TOTAL_CIR_RECHERCHE_COLLABORATIVE']].head())\n",
        "\n",
        "# Exporter les résultats\n",
        "output_file = \"lignes_ecarts_cir_entre_-1_1_et_total_egal_L91.csv\"\n",
        "df_filtered.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
        "# Calculer les sommes\n",
        "somme_declare = df_filtered['CIR_TOTAL_DECLARE'].sum()\n",
        "somme_calcule = df_filtered['CIR_TOTAL_CALCULE'].sum()\n",
        "\n",
        "print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
        "print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
        "print(f\"Résultats exportés dans: {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgssJ6tB7N2C"
      },
      "source": [
        "### mise à jour fichier lignes restante"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "zlwiYsPqS-GH",
        "outputId": "6f4a63ae-d8fb-4a23-de4b-f4d12fb7b593"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_11968\\3789977644.py:5: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fichier principal chargé: 27957 lignes\n",
            "\n",
            "Nombre de lignes restantes à analyser: 120\n",
            "Résultats exportés dans: lignes_restantes_a_analyser.csv\n",
            "\n",
            "Nombre de lignes restantes à analyser: 120\n",
            "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Charger le fichier principal\n",
        "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR.csv\"\n",
        "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
        "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
        "\n",
        "# Charger tous les fichiers d'analyse précédents\n",
        "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')\n",
        "l7_egal_l8 = pd.read_csv(\"lignes_L7_egal_L8.csv\", sep=';', encoding='utf-8-sig')\n",
        "depenses_non0_cir0 = pd.read_csv(\"lignes_depenses_non0_cir_recherche_0.csv\", sep=';', encoding='utf-8-sig')\n",
        "analyse_l26a = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//analyse_L26A_vs_CIR_TOTAL.csv\", sep=';', encoding='utf-8-sig')\n",
        "ecart_relatif_50_innov0_rech1 = pd.read_csv(\"lignes_ecart_relatif_50_innovation0_recherche1.csv\", sep=';', encoding='utf-8-sig')\n",
        "ecart_total500 = pd.read_csv(\"lignes_ecart_total_entre_-500_et_500.csv\", sep=';', encoding='utf-8-sig')\n",
        "ecart_moins_100 = pd.read_csv(\"lignes_ecart_relatif_moins_100.csv\", sep=';', encoding='utf-8-sig')\n",
        "innovation_egal_total = pd.read_csv(\"lignes_ecart_total_egal_innovation.csv\", sep=';', encoding='utf-8-sig')\n",
        "collection_egal_total = pd.read_csv(\"lignes_ecart_total_egal_collection.csv\", sep=';', encoding='utf-8-sig')\n",
        "ecart_100_cir_declare_0 = pd.read_csv(\"lignes_ecart_100_cir_declare_0.csv\", sep=';', encoding='utf-8-sig')\n",
        "l6_ecart_hors_1 = pd.read_csv(\"lignes_ecart_total_egal_recherche_l6_ecart_hors_1.csv\", sep=';', encoding='utf-8-sig')\n",
        "cas_l26a = pd.read_csv(\"lignes_cas_L26A_ecart_hors_1_L14_L20_L21_dans_1.csv\", sep=';', encoding='utf-8-sig')\n",
        "ecarts_cir_l91 = pd.read_csv(\"lignes_ecarts_cir_entre_-1_1_et_total_egal_L91.csv\", sep=';', encoding='utf-8-sig')\n",
        "\n",
        "# Identifier les SIREN à exclure\n",
        "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT'])\n",
        "siren_l7_l8 = set(l7_egal_l8['SIREN_DECLARANT'])\n",
        "siren_depenses_non0_cir0 = set(depenses_non0_cir0['SIREN_DECLARANT'])\n",
        "siren_analyse_l26a = set(analyse_l26a['SIREN_DECLARANT'])\n",
        "siren_ecart_relatif_50_innov0_rech1 = set(ecart_relatif_50_innov0_rech1['SIREN_DECLARANT'])\n",
        "siren_ecart_total500 = set(ecart_total500['SIREN_DECLARANT'])\n",
        "siren_ecart_moins_100 = set(ecart_moins_100['SIREN_DECLARANT'])\n",
        "siren_innovation_egal_total = set(innovation_egal_total['SIREN_DECLARANT'])\n",
        "siren_collection_egal_total = set(collection_egal_total['SIREN_DECLARANT'])\n",
        "siren_ecart_100_cir_declare_0 = set(ecart_100_cir_declare_0['SIREN_DECLARANT'])\n",
        "siren_l6_ecart_hors_1 = set(l6_ecart_hors_1['SIREN_DECLARANT'])\n",
        "siren_cas_l26a = set(cas_l26a['SIREN_DECLARANT'])\n",
        "siren_ecarts_cir_l91 = set(ecarts_cir_l91['SIREN_DECLARANT'])\n",
        "\n",
        "# Combiner tous les SIREN à exclure (ajout du cas l6_ecart_hors_1)\n",
        "siren_a_exclure = siren_jeunes_docteurs | siren_l7_l8 | siren_depenses_non0_cir0 | \\\n",
        "                  siren_analyse_l26a | siren_ecart_relatif_50_innov0_rech1 | \\\n",
        "                  siren_ecart_total500 | siren_ecart_moins_100 | \\\n",
        "                  siren_innovation_egal_total | siren_collection_egal_total | \\\n",
        "                  siren_ecart_100_cir_declare_0 | siren_l6_ecart_hors_1 | siren_cas_l26a | siren_ecarts_cir_l91\n",
        "\n",
        "# Filtrer le DataFrame principal\n",
        "df_restant = df[\n",
        "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) &\n",
        "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
        "]\n",
        "\n",
        "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
        "\n",
        "# Exporter les résultats\n",
        "output_file = \"lignes_restantes_a_analyser.csv\"\n",
        "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
        "print(f\"Résultats exportés dans: {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-90DqN4FI94"
      },
      "source": [
        "# Correction Creance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*** DÉBUT DU SCRIPT DE CORRECTION CIR ***\n",
            "Date et heure: 2025-04-29 14:18:00\n",
            "Fichier d'entrée: M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR.csv\n",
            "Chargement et préparation des données depuis: M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR.csv...\n",
            "Fichier principal chargé: 27,957 lignes\n",
            "Formatage des SIRENs...\n",
            "Conversion des colonnes numériques...\n",
            "Initialisation de la colonne 'CIR_TOTAL_CORRIGE'...\n",
            "Préparation des données terminée.\n",
            "\n",
            "Sommes avant corrections spécifiques:\n",
            "  - CIR Déclaré Total: 8,875,111,740.00 €\n",
            "  - CIR Calculé Total: 7,586,181,390.35 €\n",
            "  - CIR Corrigé Initial Total: 7,586,181,390.35 €\n",
            "\n",
            "--- Début de l'application des corrections spécifiques ---\n",
            "\n",
            "1. CORRECTION ERREURS DÉPENSES PERSONNEL (JEUNES DOCTEURS)\n",
            "-> 16 lignes lues, 16 corrigées. Impact local: 575,806.51 €\n",
            "\n",
            "2. CORRECTION ERREUR L7 = L8 (FRAIS BREVETS)\n",
            "-> 1 lignes lues, 1 corrigées. Impact local: -0.64 €\n",
            "\n",
            "3. CORRECTION CIR RECHERCHE MANQUANT/INCOHÉRENT\n",
            "-> 23 lignes lues, 23 corrigées. Impact local: 6,787,631.33 €\n",
            "\n",
            "4. CORRECTION ERREURS DÉPENSES EXTERNALISÉES (L26A vs CIR)\n",
            "-> 365 lignes lues (EST_EGAL=True), 365 corrigées. Impact local: -47,798,433.07 €\n",
            "\n",
            "5. CORRECTION DOUBLEMENT SANS MOTIF (ÉCART ~50%)\n",
            "-> 181 lignes lues, 181 corrigées. Impact local: -30,489,210.37 €\n",
            "\n",
            "6. CORRECTION PETIT ÉCART (-500 à 500 EUR)\n",
            "-> 240 lignes lues, 240 corrigées. Impact local: 2,620.28 €\n",
            "\n",
            "7. CORRECTION PLAFOND PARTOUT (ÉCART -100%)\n",
            "-> 45 lignes lues, 45 corrigées. Impact local: -1,130,244,774.00 €\n",
            "\n",
            "8. CORRECTION CIR INNOVATION MANQUANT (ÉCART = INNOVATION)\n",
            "-> 245 lignes lues, 245 corrigées. Impact local: -2,455,574.77 €\n",
            "\n",
            "9. CORRECTION CIR COLLECTION MANQUANT (ÉCART = COLLECTION)\n",
            "-> 33 lignes lues, 33 corrigées. Impact local: 3,526,811.25 €\n",
            "\n",
            "10. CORRECTION CIR DÉCLARÉ = 0 (ÉCART +100%)\n",
            "-> 44 lignes lues, 44 corrigées. Impact local: 2,205,497.50 €\n",
            "\n",
            "11. CORRECTION ERREURS LIÉES À L6\n",
            "-> 35 lignes lues, 35 corrigées. Impact local: 650,433.16 €\n",
            "\n",
            "12. CORRECTION ERREURS LIÉES À L26\n",
            "-> 28 lignes lues, 28 corrigées. Impact local: 910,100.63 €\n",
            "\n",
            "13. CORRECTION OUBLI CRC (Cas spécifique Total=L91)\n",
            "-> 140 lignes lues, 140 corrigées. Impact local: 5,673,223.40 € (Label: err_oubli_crc)\n",
            "\n",
            "15. VALEUR CALCULÉE PRIVILÉGIÉE POUR LE RESTE IDENTIFIÉ\n",
            "-> 120 lignes lues, 120 corrigées. Impact local: -65,380,536.50 €\n",
            "\n",
            "--- Fin de l'application des corrections spécifiques ---\n",
            "Nombre total de modifications appliquées par les fonctions actives: 1,516\n",
            "Nombre de SIRENs uniques traités: 1,516\n",
            "\n",
            "--- Ajustement final : Mise à zéro des CIR corrigés négatifs ---\n",
            "25 lignes avec CIR_TOTAL_CORRIGE négatif ont été mises à 0 (Impact: 271,150.05 €).\n",
            "\n",
            "Confirmation pour les lignes restées 'Non traité' (26,441):\n",
            "  - Aucune valeur négative parmi les lignes 'Non traité'.\n",
            "\n",
            "Sauvegarde du fichier corrigé sous: Calcul_Creance_CIR_Corrige.csv\n",
            "Fichier sauvegardé avec succès.\n",
            "\n",
            "=====================================================\n",
            "                RÉSUMÉ FINAL\n",
            "=====================================================\n",
            "Montant total CIR déclaré (Original):       8,875,111,740.00 €\n",
            "Montant total CIR calculé (Original):       7,586,181,390.35 €\n",
            "Montant total CIR après corrections:        7,616,570,450.05 €\n",
            "\n",
            "Écart initial (calculé - déclaré):        -1,288,930,349.65 €\n",
            "Écart final (corrigé - déclaré):          -1,258,541,289.95 €\n",
            "Réduction de l'écart absolu:              30,389,059.70 €\n",
            "  Écart relatif initial:                  -14.52%\n",
            "  Écart relatif final:                    -14.18%\n",
            "  Réduction relative de l'écart:          2.36%\n",
            "\n",
            "--- Détails par Type de Traitement Appliqué ---\n",
            "\n",
            "Nombre d'entreprises par type de traitement final:\n",
            "  - Err_CIR_RECH                            :         23\n",
            "  - Err_Frais_BRV                           :          1\n",
            "  - Err_PLAF_EVW                            :         45\n",
            "  - Err_dbl_creance_totale                  :        181\n",
            "  - Err_dep_ext_plaf                        :        365\n",
            "  - Err_dep_personnel                       :         16\n",
            "  - Err_petite                              :        240\n",
            "  - Non traité                              :     26,441\n",
            "  - Valeur calculée privilégiée(Reste)      :        120\n",
            "  - collect_manquant                        :         33\n",
            "  - err_cir_total_declarer                  :         44\n",
            "  - err_l26                                 :         28\n",
            "  - err_l6                                  :         35\n",
            "  - err_oubli_crc                           :        140\n",
            "  - innov_manquant                          :        245\n",
            "\n",
            "Détails financiers par type de traitement final:\n",
            "\n",
            "Traitement: Err_CIR_RECH\n",
            "  Nombre d'entreprises:                 23        \n",
            "  CIR déclaré (groupe):                      95,803,865.00 €\n",
            "  CIR corrigé final (groupe):               102,763,760.56 €\n",
            "  Écart final (corrigé-déclaré groupe):       6,959,895.56 €\n",
            "  Impact relatif final (groupe):                     7.26%\n",
            "\n",
            "Traitement: Err_Frais_BRV\n",
            "  Nombre d'entreprises:                 1         \n",
            "  CIR déclaré (groupe):                       1,846,082.00 €\n",
            "  CIR corrigé final (groupe):                 1,846,081.36 €\n",
            "  Écart final (corrigé-déclaré groupe):              -0.64 €\n",
            "  Impact relatif final (groupe):                    -0.00%\n",
            "\n",
            "Traitement: Err_PLAF_EVW\n",
            "  Nombre d'entreprises:                 45        \n",
            "  CIR déclaré (groupe):                   1,130,244,774.00 €\n",
            "  CIR corrigé final (groupe):                         0.00 €\n",
            "  Écart final (corrigé-déclaré groupe):  -1,130,244,774.00 €\n",
            "  Impact relatif final (groupe):                  -100.00%\n",
            "\n",
            "Traitement: Err_dbl_creance_totale\n",
            "  Nombre d'entreprises:                 181       \n",
            "  CIR déclaré (groupe):                     121,956,843.00 €\n",
            "  CIR corrigé final (groupe):                91,467,632.63 €\n",
            "  Écart final (corrigé-déclaré groupe):     -30,489,210.37 €\n",
            "  Impact relatif final (groupe):                   -25.00%\n",
            "\n",
            "Traitement: Err_dep_ext_plaf\n",
            "  Nombre d'entreprises:                 365       \n",
            "  CIR déclaré (groupe):                     310,677,342.00 €\n",
            "  CIR corrigé final (groupe):               262,889,823.31 €\n",
            "  Écart final (corrigé-déclaré groupe):     -47,787,518.69 €\n",
            "  Impact relatif final (groupe):                   -15.38%\n",
            "\n",
            "Traitement: Err_dep_personnel\n",
            "  Nombre d'entreprises:                 16        \n",
            "  CIR déclaré (groupe):                       7,170,745.00 €\n",
            "  CIR corrigé final (groupe):                 7,746,551.51 €\n",
            "  Écart final (corrigé-déclaré groupe):         575,806.51 €\n",
            "  Impact relatif final (groupe):                     8.03%\n",
            "\n",
            "Traitement: Err_petite\n",
            "  Nombre d'entreprises:                 240       \n",
            "  CIR déclaré (groupe):                      53,889,844.00 €\n",
            "  CIR corrigé final (groupe):                53,892,464.28 €\n",
            "  Écart final (corrigé-déclaré groupe):           2,620.28 €\n",
            "  Impact relatif final (groupe):                     0.00%\n",
            "\n",
            "Traitement: Non traité\n",
            "  Nombre d'entreprises:                 26,441    \n",
            "  CIR déclaré (groupe):                   6,927,245,743.00 €\n",
            "  CIR corrigé final (groupe):             6,924,534,593.42 €\n",
            "  Écart final (corrigé-déclaré groupe):      -2,711,149.58 €\n",
            "  Impact relatif final (groupe):                    -0.04%\n",
            "\n",
            "Traitement: Valeur calculée privilégiée(Reste)\n",
            "  Nombre d'entreprises:                 120       \n",
            "  CIR déclaré (groupe):                     110,230,656.00 €\n",
            "  CIR corrigé final (groupe):                44,873,205.74 €\n",
            "  Écart final (corrigé-déclaré groupe):     -65,357,450.26 €\n",
            "  Impact relatif final (groupe):                   -59.29%\n",
            "\n",
            "Traitement: collect_manquant\n",
            "  Nombre d'entreprises:                 33        \n",
            "  CIR déclaré (groupe):                       7,412,926.00 €\n",
            "  CIR corrigé final (groupe):                10,939,737.25 €\n",
            "  Écart final (corrigé-déclaré groupe):       3,526,811.25 €\n",
            "  Impact relatif final (groupe):                    47.58%\n",
            "\n",
            "Traitement: err_cir_total_declarer\n",
            "  Nombre d'entreprises:                 44        \n",
            "  CIR déclaré (groupe):                               0.00 €\n",
            "  CIR corrigé final (groupe):                 2,205,497.50 €\n",
            "  Écart final (corrigé-déclaré groupe):       2,205,497.50 €\n",
            "\n",
            "Traitement: err_l26\n",
            "  Nombre d'entreprises:                 28        \n",
            "  CIR déclaré (groupe):                      19,583,069.00 €\n",
            "  CIR corrigé final (groupe):                20,493,169.63 €\n",
            "  Écart final (corrigé-déclaré groupe):         910,100.63 €\n",
            "  Impact relatif final (groupe):                     4.65%\n",
            "\n",
            "Traitement: err_l6\n",
            "  Nombre d'entreprises:                 35        \n",
            "  CIR déclaré (groupe):                       8,632,110.00 €\n",
            "  CIR corrigé final (groupe):                 9,282,543.16 €\n",
            "  Écart final (corrigé-déclaré groupe):         650,433.16 €\n",
            "  Impact relatif final (groupe):                     7.54%\n",
            "\n",
            "Traitement: err_oubli_crc\n",
            "  Nombre d'entreprises:                 140       \n",
            "  CIR déclaré (groupe):                      61,721,671.00 €\n",
            "  CIR corrigé final (groupe):                67,394,894.40 €\n",
            "  Écart final (corrigé-déclaré groupe):       5,673,223.40 €\n",
            "  Impact relatif final (groupe):                     9.19%\n",
            "\n",
            "Traitement: innov_manquant\n",
            "  Nombre d'entreprises:                 245       \n",
            "  CIR déclaré (groupe):                      18,696,070.00 €\n",
            "  CIR corrigé final (groupe):                16,240,495.30 €\n",
            "  Écart final (corrigé-déclaré groupe):      -2,455,574.70 €\n",
            "  Impact relatif final (groupe):                   -13.13%\n",
            "\n",
            "=====================================================\n",
            "Traitement terminé.\n",
            "=====================================================\n",
            "\n",
            "Script terminé avec succès.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# ===================================================================\n",
        "# FONCTIONS UTILITAIRES\n",
        "# ===================================================================\n",
        "\n",
        "def format_siren(siren):\n",
        "    \"\"\"Formate les SIREN pour avoir exactement 9 caractères\"\"\"\n",
        "    if pd.isna(siren):\n",
        "        return siren\n",
        "    siren_str = str(siren).strip()\n",
        "    # Gère les formats type '123456789.0'\n",
        "    if '.' in siren_str:\n",
        "        siren_str = siren_str.split('.')[0]\n",
        "    return siren_str.zfill(9)\n",
        "\n",
        "def convertir_en_nombre(valeur, defaut=0.0):\n",
        "    \"\"\"Convertit une valeur en nombre flottant de façon sécurisée\"\"\"\n",
        "    if pd.isna(valeur):\n",
        "        return defaut\n",
        "    valeur_str = str(valeur).strip()\n",
        "    if valeur_str == '':\n",
        "        return defaut\n",
        "    try:\n",
        "        # Remplace la virgule par un point pour la conversion décimale\n",
        "        return float(valeur_str.replace(',', '.'))\n",
        "    except ValueError:\n",
        "        # Retourne la valeur par défaut en cas d'erreur de conversion\n",
        "        return defaut\n",
        "    except Exception:\n",
        "         # Capture d'autres erreurs potentielles\n",
        "        return defaut\n",
        "\n",
        "# ===================================================================\n",
        "# CHARGEMENT ET PRÉPARATION DES DONNÉES\n",
        "# ===================================================================\n",
        "\n",
        "def charger_donnees(file_path=\"Calcul_Creance_CIR.csv\"):\n",
        "    \"\"\"Charge et prépare les données du fichier CIR\"\"\"\n",
        "    print(f\"Chargement et préparation des données depuis: {file_path}...\")\n",
        "    try:\n",
        "        df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig',\n",
        "                         converters={'SIREN_DECLARANT': str, 'SIREN_DEPOSANT': str},\n",
        "                         low_memory=False)\n",
        "        print(f\"Fichier principal chargé: {len(df):,} lignes\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"ERREUR: Fichier non trouvé: {file_path}.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"ERREUR lors du chargement du fichier principal: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "    print(\"Formatage des SIRENs...\")\n",
        "    if 'SIREN_DECLARANT' in df.columns:\n",
        "        df['SIREN_DECLARANT'] = df['SIREN_DECLARANT'].apply(format_siren)\n",
        "    else:\n",
        "        print(\"ERREUR CRITIQUE: Colonne 'SIREN_DECLARANT' non trouvée.\")\n",
        "        return None\n",
        "    if 'SIREN_DEPOSANT' in df.columns:\n",
        "        df['SIREN_DEPOSANT'] = df['SIREN_DEPOSANT'].apply(format_siren)\n",
        "\n",
        "    if 'TRAITEMENT_APPLIQUE' not in df.columns:\n",
        "        df['TRAITEMENT_APPLIQUE'] = \"Non traité\"\n",
        "    else:\n",
        "         # Assure que la colonne est de type string\n",
        "         df['TRAITEMENT_APPLIQUE'] = df['TRAITEMENT_APPLIQUE'].astype(str)\n",
        "\n",
        "    # Liste exhaustive des colonnes numériques à convertir\n",
        "    numeric_cols = [\n",
        "        'L1_DOTATION_AMORT_IMMO', 'L2_DOTATION_AMORT_SINISTR', 'L3_DEPENSES_PERSONNEL_CHERCHEURS',\n",
        "        'L4_REMUNERATION_INVENTEURS', 'L5_DEPENSES_JEUNES_DOCTEURS', 'L6_AUTRES_DEP_FONCT_CALCULE',\n",
        "        'L7_TOTAL_DEP_FONCT_DECLARE', 'L7_TOTAL_DEP_FONCT_CALCULE', 'L8_FRAIS_BREVETS_COV',\n",
        "        'L9_DEPENSES_DEFENSE_BREVETS', 'L10_DOTATION_AMORT_BREVETS', 'L11_DEPENSES_NORMALISATION_DECLARE',\n",
        "        'L12_PRIMES_COTISATIONS_BRUT', 'L12_PRIMES_COTISATIONS_PLAFONNEES', 'L13_VEILLE_TECHNO_BRUT',\n",
        "        'L13_VEILLE_TECHNO_PLAFONNEE', 'L14_TOTAL_DEPENSES_INTERNES_CALCULE', 'L21_TOTAL_DEP_EXT_PLAFONNEES_CALCULE',\n",
        "        'L22_TOTAL_DEPENSES_RECHERCHE_CALCULE', 'L23A_SUBVENTIONS', 'L23B_SOMMES_ENCAISSEES_TIERS',\n",
        "        'L24_DEPENSES_CONSEIL_CIR', 'L25_REMBOURSEMENTS_SUBVENTIONS', 'L26A_MONTANT_NET_DEPENSES_CALCULE',\n",
        "        'L26B_MONTANT_NET_DEPENSES_DOM_CALCULE', 'CIR_RECHERCHE_CALCULE', 'CIR_COLLECTION_CALCULE',\n",
        "        'CIR_INNOVATION_CALCULE', 'CIR_COLLABORATIF_CALCULE', 'CIR_TOTAL_DECLARE', 'CIR_TOTAL_CALCULE',\n",
        "        'CIR_TOTAL_ECART', 'ECART_RELATIF_POURCENT', 'CIR_RECHERCHE_ECART', 'CIR_INNOVATION_ECART',\n",
        "        'CIR_COLLECTION_ECART', 'CIR_COLLABORATIF_ECART', 'L6_ECART', 'L14_ECART', 'L17_ECART', 'L18_ECART',\n",
        "        'L19_ECART', 'L20_ECART', 'L21_ECART', 'L22_ECART', 'L26A_ECART', 'L26B_ECART',\n",
        "        'L91_MONTANT_TOTAL_CIR_RECHERCHE_COLLABORATIVE', 'CIR_TOTAL_CORRIGE' # Inclure si existe déjà\n",
        "    ]\n",
        "\n",
        "    print(\"Conversion des colonnes numériques...\")\n",
        "    for col in numeric_cols:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].apply(convertir_en_nombre)\n",
        "\n",
        "    # Initialisation de CIR_TOTAL_CORRIGE après les conversions\n",
        "    if 'CIR_TOTAL_CORRIGE' not in df.columns:\n",
        "        print(\"Initialisation de la colonne 'CIR_TOTAL_CORRIGE'...\")\n",
        "        if 'CIR_TOTAL_CALCULE' in df.columns:\n",
        "            df['CIR_TOTAL_CORRIGE'] = df['CIR_TOTAL_CALCULE'].copy()\n",
        "        else:\n",
        "            print(\"  Attention: 'CIR_TOTAL_CALCULE' non trouvé. 'CIR_TOTAL_CORRIGE' initialisé à 0.0.\")\n",
        "            df['CIR_TOTAL_CORRIGE'] = 0.0\n",
        "    else:\n",
        "        # Assurer qu'elle est bien numérique si elle existait\n",
        "        df['CIR_TOTAL_CORRIGE'] = df['CIR_TOTAL_CORRIGE'].apply(convertir_en_nombre)\n",
        "        print(\"La colonne 'CIR_TOTAL_CORRIGE' existait déjà et a été (re)convertie en numérique.\")\n",
        "\n",
        "    # Vérification finale des colonnes essentielles\n",
        "    essential_cols = ['SIREN_DECLARANT', 'CIR_TOTAL_DECLARE', 'CIR_TOTAL_CALCULE', 'CIR_TOTAL_CORRIGE']\n",
        "    for col in essential_cols:\n",
        "        if col not in df.columns:\n",
        "            print(f\"ERREUR CRITIQUE: Colonne essentielle '{col}' est manquante après chargement/préparation.\")\n",
        "            return None\n",
        "\n",
        "    print(\"Préparation des données terminée.\")\n",
        "    return df\n",
        "\n",
        "def charger_fichier_intermediaire(file_path, main_df_columns):\n",
        "    \"\"\"Charge un fichier intermédiaire, formate SIREN et convertit num.\"\"\"\n",
        "    try:\n",
        "        df_inter = pd.read_csv(file_path, sep=';', encoding='utf-8-sig',\n",
        "                               converters={'SIREN_DECLARANT': str, 'SIREN_DEPOSANT': str},\n",
        "                               low_memory=False)\n",
        "        if 'SIREN_DECLARANT' in df_inter.columns:\n",
        "            df_inter['SIREN_DECLARANT'] = df_inter['SIREN_DECLARANT'].apply(format_siren)\n",
        "        else:\n",
        "             print(f\"Attention: 'SIREN_DECLARANT' manquant dans '{file_path}'.\")\n",
        "             return pd.DataFrame(columns=main_df_columns)\n",
        "\n",
        "        numeric_cols_inter = [\n",
        "            'CIR_TOTAL_DECLARE', 'CIR_TOTAL_CALCULE', 'CIR_TOTAL_ECART',\n",
        "            'CIR_RECHERCHE_ECART', 'CIR_COLLECTION_ECART', 'CIR_INNOVATION_ECART', 'CIR_COLLABORATIF_CALCULE',\n",
        "             'L91_MONTANT_TOTAL_CIR_RECHERCHE_COLLABORATIVE'\n",
        "        ]\n",
        "        for col in numeric_cols_inter:\n",
        "            if col in df_inter.columns:\n",
        "                df_inter[col] = df_inter[col].apply(convertir_en_nombre)\n",
        "        if 'EST_EGAL' in df_inter.columns:\n",
        "             df_inter['EST_EGAL'] = df_inter['EST_EGAL'].apply(lambda x: str(x).strip().lower() == 'true')\n",
        "        return df_inter\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Info: Fichier intermédiaire '{file_path}' non trouvé.\")\n",
        "        return pd.DataFrame(columns=main_df_columns)\n",
        "    except Exception as e:\n",
        "        print(f\"Erreur chargement fichier intermédiaire '{file_path}': {str(e)}\")\n",
        "        return pd.DataFrame(columns=main_df_columns)\n",
        "\n",
        "# ===================================================================\n",
        "# FONCTIONS DE CORRECTION (1 à 12 Inchangées, 13 Modifiée, 14 Supprimée, 15 Inchangée)\n",
        "# ===================================================================\n",
        "\n",
        "# --- Fonctions 1 à 12 : Code simplifié pour la longueur, mais identique à la version précédente ---\n",
        "def correction_erreurs_personnel(df, processed_sirens, fichier_intermediaire=\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\"):\n",
        "    \"\"\"Corrige les erreurs de dépenses de personnel (jeunes docteurs).\"\"\"\n",
        "    print(\"\\n1. CORRECTION ERREURS DÉPENSES PERSONNEL (JEUNES DOCTEURS)\")\n",
        "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
        "    if df_error.empty: return 0\n",
        "    count = 0\n",
        "    before_sum = df_error['CIR_TOTAL_DECLARE'].sum() if 'CIR_TOTAL_DECLARE' in df_error.columns else 0.0\n",
        "    indices_traites_localement = []\n",
        "    for _, row in df_error.iterrows():\n",
        "        siren = row['SIREN_DECLARANT']\n",
        "        if siren in processed_sirens: continue\n",
        "        mask = df['SIREN_DECLARANT'] == siren\n",
        "        if not mask.any(): continue\n",
        "        idx = df.index[mask].tolist()[0]\n",
        "        l1_val=convertir_en_nombre(df.loc[idx,'L1_DOTATION_AMORT_IMMO']); l2_val=convertir_en_nombre(df.loc[idx,'L2_DOTATION_AMORT_SINISTR'])\n",
        "        l4_val=convertir_en_nombre(df.loc[idx,'L4_REMUNERATION_INVENTEURS']); l5_val=convertir_en_nombre(df.loc[idx,'L5_DEPENSES_JEUNES_DOCTEURS'])\n",
        "        l8_val=convertir_en_nombre(df.loc[idx,'L8_FRAIS_BREVETS_COV']); l9_val=convertir_en_nombre(df.loc[idx,'L9_DEPENSES_DEFENSE_BREVETS'])\n",
        "        l10_val=convertir_en_nombre(df.loc[idx,'L10_DOTATION_AMORT_BREVETS']); l11_val=convertir_en_nombre(df.loc[idx,'L11_DEPENSES_NORMALISATION_DECLARE'])\n",
        "        l12_brut_val=convertir_en_nombre(df.loc[idx,'L12_PRIMES_COTISATIONS_BRUT']); l13_brut_val=convertir_en_nombre(df.loc[idx,'L13_VEILLE_TECHNO_BRUT'])\n",
        "        l21_calcule_val=convertir_en_nombre(df.loc[idx,'L21_TOTAL_DEP_EXT_PLAFONNEES_CALCULE']); l23a_val=convertir_en_nombre(df.loc[idx,'L23A_SUBVENTIONS'])\n",
        "        l23b_val=convertir_en_nombre(df.loc[idx,'L23B_SOMMES_ENCAISSEES_TIERS']); l24_val=convertir_en_nombre(df.loc[idx,'L24_DEPENSES_CONSEIL_CIR'])\n",
        "        l25_val=convertir_en_nombre(df.loc[idx,'L25_REMBOURSEMENTS_SUBVENTIONS']); cir_coll_val=convertir_en_nombre(df.loc[idx,'CIR_COLLECTION_CALCULE'])\n",
        "        cir_inno_val=convertir_en_nombre(df.loc[idx,'CIR_INNOVATION_CALCULE']); cir_collab_val=convertir_en_nombre(df.loc[idx,'CIR_COLLABORATIF_CALCULE'])\n",
        "        l26b_val=convertir_en_nombre(df.loc[idx,'L26B_MONTANT_NET_DEPENSES_DOM_CALCULE'])\n",
        "        df.loc[idx,'L3_DEPENSES_PERSONNEL_CHERCHEURS']=l2_val; df.loc[idx,'L2_DOTATION_AMORT_SINISTR']=0.0\n",
        "        dep_cherch_tech_updated=df.loc[idx,'L3_DEPENSES_PERSONNEL_CHERCHEURS']; l2_updated=df.loc[idx,'L2_DOTATION_AMORT_SINISTR']\n",
        "        autres_dep_fonct=(l1_val*0.75)+((dep_cherch_tech_updated+l4_val)*0.43)+l5_val; df.loc[idx,'L6_AUTRES_DEP_FONCT_CALCULE']=autres_dep_fonct\n",
        "        total_dep_fonct=l1_val+l2_updated+dep_cherch_tech_updated+l4_val+l5_val+autres_dep_fonct; df.loc[idx,'L7_TOTAL_DEP_FONCT_CALCULE']=total_dep_fonct\n",
        "        prim_cotiz_plaf=min(l12_brut_val,60000); dep_veil_techno_plaf=min(l13_brut_val,60000)\n",
        "        total_dep_internes=total_dep_fonct+l8_val+l9_val+l10_val+l11_val+prim_cotiz_plaf+dep_veil_techno_plaf; df.loc[idx,'L14_TOTAL_DEPENSES_INTERNES_CALCULE']=total_dep_internes\n",
        "        total_dep_recherche=total_dep_internes+l21_calcule_val; df.loc[idx,'L22_TOTAL_DEPENSES_RECHERCHE_CALCULE']=total_dep_recherche\n",
        "        montant_net=total_dep_recherche-l23a_val-l23b_val-l24_val+l25_val; df.loc[idx,'L26A_MONTANT_NET_DEPENSES_CALCULE']=montant_net\n",
        "        taux_dom,taux_non_dom=0.50,0.30\n",
        "        if 'L26B_MONTANT_NET_DEPENSES_DOM_CALCULE' in df.columns and l26b_val > 0 :\n",
        "             montant_net_non_dom = max(0, montant_net - l26b_val); cir_recherche = (montant_net_non_dom * taux_non_dom) + (l26b_val * taux_dom)\n",
        "        else: cir_recherche = montant_net * taux_non_dom\n",
        "        cir_recherche=max(0, cir_recherche); df.loc[idx,'CIR_RECHERCHE_CALCULE']=cir_recherche\n",
        "        cir_total=cir_recherche+cir_coll_val+cir_inno_val+cir_collab_val; df.loc[idx,'CIR_TOTAL_CALCULE']=cir_total\n",
        "        df.loc[idx,'CIR_TOTAL_CORRIGE']=cir_total; df.loc[idx,'TRAITEMENT_APPLIQUE']=\"Err_dep_personnel\"\n",
        "        processed_sirens.add(siren); indices_traites_localement.append(idx); count+=1\n",
        "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
        "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
        "    return count\n",
        "\n",
        "def correction_erreurs_frais_brevets(df, processed_sirens, fichier_intermediaire=\"lignes_L7_egal_L8.csv\"):\n",
        "    \"\"\"Corrige les erreurs où L7 (déclaré) est égal à L8.\"\"\"\n",
        "    print(\"\\n2. CORRECTION ERREUR L7 = L8 (FRAIS BREVETS)\")\n",
        "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
        "    if df_error.empty: return 0\n",
        "    count = 0\n",
        "    before_sum = df_error['CIR_TOTAL_DECLARE'].sum() if 'CIR_TOTAL_DECLARE' in df_error.columns else 0.0\n",
        "    indices_traites_localement = []\n",
        "    for _, row in df_error.iterrows():\n",
        "        siren = row['SIREN_DECLARANT']\n",
        "        if siren in processed_sirens: continue\n",
        "        mask = df['SIREN_DECLARANT'] == siren\n",
        "        if not mask.any(): continue\n",
        "        idx = df.index[mask].tolist()[0]\n",
        "        l1_val=convertir_en_nombre(df.loc[idx,'L1_DOTATION_AMORT_IMMO']); l2_val=convertir_en_nombre(df.loc[idx,'L2_DOTATION_AMORT_SINISTR'])\n",
        "        l3_val=convertir_en_nombre(df.loc[idx,'L3_DEPENSES_PERSONNEL_CHERCHEURS']); l4_val=convertir_en_nombre(df.loc[idx,'L4_REMUNERATION_INVENTEURS'])\n",
        "        l5_val=convertir_en_nombre(df.loc[idx,'L5_DEPENSES_JEUNES_DOCTEURS']); l9_val=convertir_en_nombre(df.loc[idx,'L9_DEPENSES_DEFENSE_BREVETS'])\n",
        "        l10_val=convertir_en_nombre(df.loc[idx,'L10_DOTATION_AMORT_BREVETS']); l11_val=convertir_en_nombre(df.loc[idx,'L11_DEPENSES_NORMALISATION_DECLARE'])\n",
        "        l12_plaf_val=convertir_en_nombre(df.loc[idx,'L12_PRIMES_COTISATIONS_PLAFONNEES']); l13_plaf_val=convertir_en_nombre(df.loc[idx,'L13_VEILLE_TECHNO_PLAFONNEE'])\n",
        "        l21_calcule_val=convertir_en_nombre(df.loc[idx,'L21_TOTAL_DEP_EXT_PLAFONNEES_CALCULE']); l23a_val=convertir_en_nombre(df.loc[idx,'L23A_SUBVENTIONS'])\n",
        "        l23b_val=convertir_en_nombre(df.loc[idx,'L23B_SOMMES_ENCAISSEES_TIERS']); l24_val=convertir_en_nombre(df.loc[idx,'L24_DEPENSES_CONSEIL_CIR'])\n",
        "        l25_val=convertir_en_nombre(df.loc[idx,'L25_REMBOURSEMENTS_SUBVENTIONS']); cir_coll_val=convertir_en_nombre(df.loc[idx,'CIR_COLLECTION_CALCULE'])\n",
        "        cir_inno_val=convertir_en_nombre(df.loc[idx,'CIR_INNOVATION_CALCULE']); cir_collab_val=convertir_en_nombre(df.loc[idx,'CIR_COLLABORATIF_CALCULE'])\n",
        "        l26b_val=convertir_en_nombre(df.loc[idx,'L26B_MONTANT_NET_DEPENSES_DOM_CALCULE'])\n",
        "        df.loc[idx, 'L8_FRAIS_BREVETS_COV'] = 0.0; l8_corrected_val = 0.0\n",
        "        autres_dep_fonct = (l1_val*0.75) + ((l3_val + l4_val)*0.43) + l5_val; df.loc[idx, 'L6_AUTRES_DEP_FONCT_CALCULE'] = autres_dep_fonct\n",
        "        total_dep_fonct = l1_val+l2_val+l3_val+l4_val+l5_val+autres_dep_fonct; df.loc[idx, 'L7_TOTAL_DEP_FONCT_CALCULE'] = total_dep_fonct\n",
        "        total_dep_internes = total_dep_fonct + l8_corrected_val + l9_val + l10_val + l11_val + l12_plaf_val + l13_plaf_val\n",
        "        df.loc[idx, 'L14_TOTAL_DEPENSES_INTERNES_CALCULE'] = total_dep_internes\n",
        "        total_dep_recherche = total_dep_internes + l21_calcule_val; df.loc[idx, 'L22_TOTAL_DEPENSES_RECHERCHE_CALCULE'] = total_dep_recherche\n",
        "        montant_net = total_dep_recherche - l23a_val - l23b_val - l24_val + l25_val; df.loc[idx, 'L26A_MONTANT_NET_DEPENSES_CALCULE'] = montant_net\n",
        "        taux_dom, taux_non_dom = 0.50, 0.30\n",
        "        if 'L26B_MONTANT_NET_DEPENSES_DOM_CALCULE' in df.columns and l26b_val > 0 :\n",
        "             montant_net_non_dom = max(0, montant_net - l26b_val); cir_recherche = (montant_net_non_dom * taux_non_dom) + (l26b_val * taux_dom)\n",
        "        else: cir_recherche = montant_net * taux_non_dom\n",
        "        cir_recherche = max(0, cir_recherche); df.loc[idx, 'CIR_RECHERCHE_CALCULE'] = cir_recherche\n",
        "        cir_total = cir_recherche + cir_coll_val + cir_inno_val + cir_collab_val; df.loc[idx, 'CIR_TOTAL_CALCULE'] = cir_total\n",
        "        df.loc[idx, 'CIR_TOTAL_CORRIGE'] = cir_total; df.loc[idx, 'TRAITEMENT_APPLIQUE'] = \"Err_Frais_BRV\"\n",
        "        processed_sirens.add(siren); indices_traites_localement.append(idx); count += 1\n",
        "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
        "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
        "    return count\n",
        "\n",
        "def correction_cir_recherche_manquant(df, processed_sirens, fichier_intermediaire=\"lignes_depenses_non0_cir_recherche_0.csv\"):\n",
        "    \"\"\"Corrige les cas où le CIR recherche déclaré est manquant ou incohérent.\"\"\"\n",
        "    print(\"\\n3. CORRECTION CIR RECHERCHE MANQUANT/INCOHÉRENT\")\n",
        "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
        "    if df_error.empty: return 0\n",
        "    count = 0\n",
        "    before_sum = df_error['CIR_TOTAL_DECLARE'].sum() if 'CIR_TOTAL_DECLARE' in df_error.columns else 0.0\n",
        "    indices_traites_localement = []\n",
        "    for _, row in df_error.iterrows():\n",
        "        siren = row['SIREN_DECLARANT']\n",
        "        if siren in processed_sirens: continue\n",
        "        mask = df['SIREN_DECLARANT'] == siren\n",
        "        if not mask.any(): continue\n",
        "        idx = df.index[mask].tolist()[0]\n",
        "        calculated_value = df.loc[idx, 'CIR_TOTAL_CALCULE']\n",
        "        df.loc[idx, 'CIR_TOTAL_CORRIGE'] = calculated_value; df.loc[idx, 'TRAITEMENT_APPLIQUE'] = \"Err_CIR_RECH\"\n",
        "        processed_sirens.add(siren); indices_traites_localement.append(idx); count += 1\n",
        "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
        "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
        "    return count\n",
        "\n",
        "def correction_erreurs_depenses_externalisees(df, processed_sirens, fichier_intermediaire=\"analyse_L26A_vs_CIR_TOTAL.csv\"):\n",
        "    \"\"\"Corrige les erreurs liées aux dépenses externalisées (basé sur L26A vs CIR Total).\"\"\"\n",
        "    print(\"\\n4. CORRECTION ERREURS DÉPENSES EXTERNALISÉES (L26A vs CIR)\")\n",
        "    df_error_raw = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
        "    if df_error_raw.empty: return 0\n",
        "    df_error = df_error_raw\n",
        "    if 'EST_EGAL' in df_error.columns: df_error = df_error_raw[df_error_raw['EST_EGAL']].copy()\n",
        "    else: print(f\"Attention: Colonne 'EST_EGAL' non trouvée dans '{fichier_intermediaire}'.\")\n",
        "    if df_error.empty: print(f\"Aucune donnée pertinente (EST_EGAL=True) trouvée. Skipping.\"); return 0\n",
        "    count = 0\n",
        "    before_sum = df_error['CIR_TOTAL_DECLARE'].sum() if 'CIR_TOTAL_DECLARE' in df_error.columns else 0.0\n",
        "    indices_traites_localement = []\n",
        "    for _, row in df_error.iterrows():\n",
        "        siren = row['SIREN_DECLARANT']\n",
        "        if siren in processed_sirens: continue\n",
        "        mask = df['SIREN_DECLARANT'] == siren\n",
        "        if not mask.any(): continue\n",
        "        idx = df.index[mask].tolist()[0]\n",
        "        calculated_value = df.loc[idx, 'CIR_TOTAL_CALCULE']\n",
        "        df.loc[idx, 'CIR_TOTAL_CORRIGE'] = calculated_value; df.loc[idx, 'TRAITEMENT_APPLIQUE'] = \"Err_dep_ext_plaf\"\n",
        "        processed_sirens.add(siren); indices_traites_localement.append(idx); count += 1\n",
        "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
        "    print(f\"-> {len(df_error)} lignes lues (EST_EGAL=True), {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
        "    return count\n",
        "\n",
        "def correction_doublement_sans_motif(df, processed_sirens, fichier_intermediaire=\"lignes_ecart_relatif_50_innovation0_recherche1.csv\"):\n",
        "    \"\"\"Corrige les erreurs de doublement apparent (écart relatif ~50%). Prend la moyenne.\"\"\"\n",
        "    print(\"\\n5. CORRECTION DOUBLEMENT SANS MOTIF (ÉCART ~50%)\")\n",
        "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
        "    if df_error.empty: return 0\n",
        "    count = 0\n",
        "    before_sum = df_error['CIR_TOTAL_DECLARE'].sum() if 'CIR_TOTAL_DECLARE' in df_error.columns else 0.0\n",
        "    indices_traites_localement = []\n",
        "    for _, row in df_error.iterrows():\n",
        "        siren = row['SIREN_DECLARANT']\n",
        "        if siren in processed_sirens: continue\n",
        "        mask = df['SIREN_DECLARANT'] == siren\n",
        "        if not mask.any(): continue\n",
        "        idx = df.index[mask].tolist()[0]\n",
        "        declared = df.loc[idx, 'CIR_TOTAL_DECLARE']; calculated = df.loc[idx, 'CIR_TOTAL_CALCULE']\n",
        "        corrected = calculated if abs(declared) < 0.01 else (declared + calculated) / 2\n",
        "        df.loc[idx, 'CIR_TOTAL_CORRIGE'] = corrected; df.loc[idx, 'TRAITEMENT_APPLIQUE'] = \"Err_dbl_creance_totale\"\n",
        "        processed_sirens.add(siren); indices_traites_localement.append(idx); count += 1\n",
        "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
        "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
        "    return count\n",
        "\n",
        "def correction_ecart_petit(df, processed_sirens, fichier_intermediaire=\"lignes_ecart_total_entre_-500_et_500.csv\"):\n",
        "    \"\"\"Corrige les petits écarts (-500 à 500 EUR) en prenant la moyenne.\"\"\"\n",
        "    print(\"\\n6. CORRECTION PETIT ÉCART (-500 à 500 EUR)\")\n",
        "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
        "    if df_error.empty: return 0\n",
        "    count = 0\n",
        "    before_sum = df_error['CIR_TOTAL_DECLARE'].sum() if 'CIR_TOTAL_DECLARE' in df_error.columns else 0.0\n",
        "    indices_traites_localement = []\n",
        "    for _, row in df_error.iterrows():\n",
        "        siren = row['SIREN_DECLARANT']\n",
        "        if siren in processed_sirens: continue\n",
        "        mask = df['SIREN_DECLARANT'] == siren\n",
        "        if not mask.any(): continue\n",
        "        idx = df.index[mask].tolist()[0]\n",
        "        declared = df.loc[idx, 'CIR_TOTAL_DECLARE']; calculated = df.loc[idx, 'CIR_TOTAL_CALCULE']\n",
        "        corrected = (declared + calculated) / 2\n",
        "        df.loc[idx, 'CIR_TOTAL_CORRIGE'] = corrected; df.loc[idx, 'TRAITEMENT_APPLIQUE'] = \"Err_petite\"\n",
        "        processed_sirens.add(siren); indices_traites_localement.append(idx); count += 1\n",
        "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
        "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
        "    return count\n",
        "\n",
        "def correction_plafond_partout(df, processed_sirens, fichier_intermediaire=\"lignes_ecart_relatif_moins_100.csv\"):\n",
        "    \"\"\"Corrige les cas où l'écart est -100% (calculé=0), utilise la valeur calculée (0).\"\"\"\n",
        "    print(\"\\n7. CORRECTION PLAFOND PARTOUT (ÉCART -100%)\")\n",
        "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
        "    if df_error.empty: return 0\n",
        "    count = 0\n",
        "    before_sum = df_error['CIR_TOTAL_DECLARE'].sum() if 'CIR_TOTAL_DECLARE' in df_error.columns else 0.0\n",
        "    indices_traites_localement = []\n",
        "    for _, row in df_error.iterrows():\n",
        "        siren = row['SIREN_DECLARANT']\n",
        "        if siren in processed_sirens: continue\n",
        "        mask = df['SIREN_DECLARANT'] == siren\n",
        "        if not mask.any(): continue\n",
        "        idx = df.index[mask].tolist()[0]\n",
        "        calculated_value = df.loc[idx, 'CIR_TOTAL_CALCULE'] # Should be ~0\n",
        "        df.loc[idx, 'CIR_TOTAL_CORRIGE'] = calculated_value; df.loc[idx, 'TRAITEMENT_APPLIQUE'] = \"Err_PLAF_EVW\"\n",
        "        processed_sirens.add(siren); indices_traites_localement.append(idx); count += 1\n",
        "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
        "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
        "    return count\n",
        "\n",
        "def correction_cir_innovation(df, processed_sirens, fichier_intermediaire=\"lignes_ecart_total_egal_innovation.csv\"):\n",
        "    \"\"\"Corrige les cas où l'écart total correspond au CIR Innovation calculé.\"\"\"\n",
        "    print(\"\\n8. CORRECTION CIR INNOVATION MANQUANT (ÉCART = INNOVATION)\")\n",
        "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
        "    if df_error.empty: return 0\n",
        "    count = 0\n",
        "    before_sum = df_error['CIR_TOTAL_DECLARE'].sum() if 'CIR_TOTAL_DECLARE' in df_error.columns else 0.0\n",
        "    indices_traites_localement = []\n",
        "    for _, row in df_error.iterrows():\n",
        "        siren = row['SIREN_DECLARANT']\n",
        "        if siren in processed_sirens: continue\n",
        "        mask = df['SIREN_DECLARANT'] == siren\n",
        "        if not mask.any(): continue\n",
        "        idx = df.index[mask].tolist()[0]\n",
        "        calculated_value = df.loc[idx, 'CIR_TOTAL_CALCULE']\n",
        "        df.loc[idx, 'CIR_TOTAL_CORRIGE'] = calculated_value; df.loc[idx, 'TRAITEMENT_APPLIQUE'] = \"innov_manquant\"\n",
        "        processed_sirens.add(siren); indices_traites_localement.append(idx); count += 1\n",
        "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
        "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
        "    return count\n",
        "\n",
        "def correction_cir_collection(df, processed_sirens, fichier_intermediaire=\"lignes_ecart_total_egal_collection.csv\"):\n",
        "    \"\"\"Corrige les cas où l'écart total correspond au CIR Collection calculé.\"\"\"\n",
        "    print(\"\\n9. CORRECTION CIR COLLECTION MANQUANT (ÉCART = COLLECTION)\")\n",
        "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
        "    if df_error.empty: return 0\n",
        "    count = 0\n",
        "    before_sum = df_error['CIR_TOTAL_DECLARE'].sum() if 'CIR_TOTAL_DECLARE' in df_error.columns else 0.0\n",
        "    indices_traites_localement = []\n",
        "    for _, row in df_error.iterrows():\n",
        "        siren = row['SIREN_DECLARANT']\n",
        "        if siren in processed_sirens: continue\n",
        "        mask = df['SIREN_DECLARANT'] == siren\n",
        "        if not mask.any(): continue\n",
        "        idx = df.index[mask].tolist()[0]\n",
        "        calculated_value = df.loc[idx, 'CIR_TOTAL_CALCULE']\n",
        "        df.loc[idx, 'CIR_TOTAL_CORRIGE'] = calculated_value; df.loc[idx, 'TRAITEMENT_APPLIQUE'] = \"collect_manquant\"\n",
        "        processed_sirens.add(siren); indices_traites_localement.append(idx); count += 1\n",
        "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
        "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
        "    return count\n",
        "\n",
        "def correction_cir_declare_zero(df, processed_sirens, fichier_intermediaire=\"lignes_ecart_100_cir_declare_0.csv\"):\n",
        "    \"\"\"Corrige les cas où le CIR déclaré est 0 mais le calculé est positif.\"\"\"\n",
        "    print(\"\\n10. CORRECTION CIR DÉCLARÉ = 0 (ÉCART +100%)\")\n",
        "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
        "    if df_error.empty: return 0\n",
        "    count = 0\n",
        "    before_sum = 0.0 # Déclaré est 0\n",
        "    indices_traites_localement = []\n",
        "    for _, row in df_error.iterrows():\n",
        "        siren = row['SIREN_DECLARANT']\n",
        "        if siren in processed_sirens: continue\n",
        "        mask = df['SIREN_DECLARANT'] == siren\n",
        "        if not mask.any(): continue\n",
        "        idx = df.index[mask].tolist()[0]\n",
        "        calculated_value = df.loc[idx, 'CIR_TOTAL_CALCULE']\n",
        "        df.loc[idx, 'CIR_TOTAL_CORRIGE'] = calculated_value; df.loc[idx, 'TRAITEMENT_APPLIQUE'] = \"err_cir_total_declarer\"\n",
        "        processed_sirens.add(siren); indices_traites_localement.append(idx); count += 1\n",
        "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
        "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
        "    return count\n",
        "\n",
        "def correction_erreurs_l6(df, processed_sirens, fichier_intermediaire=\"lignes_ecart_total_egal_recherche_l6_ecart_hors_1.csv\"):\n",
        "    \"\"\"Corrige les erreurs liées à la ligne L6 (Autres dépenses de fonctionnement).\"\"\"\n",
        "    print(\"\\n11. CORRECTION ERREURS LIÉES À L6\")\n",
        "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
        "    if df_error.empty: return 0\n",
        "    count = 0\n",
        "    before_sum = df_error['CIR_TOTAL_DECLARE'].sum() if 'CIR_TOTAL_DECLARE' in df_error.columns else 0.0\n",
        "    indices_traites_localement = []\n",
        "    for _, row in df_error.iterrows():\n",
        "        siren = row['SIREN_DECLARANT']\n",
        "        if siren in processed_sirens: continue\n",
        "        mask = df['SIREN_DECLARANT'] == siren\n",
        "        if not mask.any(): continue\n",
        "        idx = df.index[mask].tolist()[0]\n",
        "        calculated_value = df.loc[idx, 'CIR_TOTAL_CALCULE']\n",
        "        df.loc[idx, 'CIR_TOTAL_CORRIGE'] = calculated_value; df.loc[idx, 'TRAITEMENT_APPLIQUE'] = \"err_l6\"\n",
        "        processed_sirens.add(siren); indices_traites_localement.append(idx); count += 1\n",
        "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
        "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
        "    return count\n",
        "\n",
        "def correction_erreurs_l26(df, processed_sirens, fichier_intermediaire=\"lignes_cas_L26A_ecart_hors_1_L14_L20_L21_dans_1.csv\"):\n",
        "    \"\"\"Corrige les erreurs liées à la ligne L26 (Montant net des dépenses).\"\"\"\n",
        "    print(\"\\n12. CORRECTION ERREURS LIÉES À L26\")\n",
        "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
        "    if df_error.empty: return 0\n",
        "    count = 0\n",
        "    before_sum = df_error['CIR_TOTAL_DECLARE'].sum() if 'CIR_TOTAL_DECLARE' in df_error.columns else 0.0\n",
        "    indices_traites_localement = []\n",
        "    for _, row in df_error.iterrows():\n",
        "        siren = row['SIREN_DECLARANT']\n",
        "        if siren in processed_sirens: continue\n",
        "        mask = df['SIREN_DECLARANT'] == siren\n",
        "        if not mask.any(): continue\n",
        "        idx = df.index[mask].tolist()[0]\n",
        "        calculated_value = df.loc[idx, 'CIR_TOTAL_CALCULE']\n",
        "        df.loc[idx, 'CIR_TOTAL_CORRIGE'] = calculated_value; df.loc[idx, 'TRAITEMENT_APPLIQUE'] = \"err_l26\"\n",
        "        processed_sirens.add(siren); indices_traites_localement.append(idx); count += 1\n",
        "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
        "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
        "    return count\n",
        "\n",
        "\n",
        "# --- Correction 13: CRC Manquant (Cas spécifique Total=L91) ---\n",
        "# *** LABEL MODIFIÉ ICI ***\n",
        "def correction_crc_manquant_cir_total(df, processed_sirens, fichier_intermediaire=\"lignes_ecarts_cir_entre_-1_1_et_total_egal_L91.csv\"):\n",
        "    \"\"\"Corrige les erreurs où CRC est manquant dans le CIR total (cas spécifique Total=L91). Label -> err_oubli_crc\"\"\"\n",
        "    print(\"\\n13. CORRECTION OUBLI CRC (Cas spécifique Total=L91)\") # Titre mis à jour\n",
        "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
        "    if df_error.empty: return 0\n",
        "    if 'L91_MONTANT_TOTAL_CIR_RECHERCHE_COLLABORATIVE' not in df.columns:\n",
        "        print(\"Colonne 'L91...' manquante. Skipping correction 13.\")\n",
        "        return 0\n",
        "    count = 0\n",
        "    before_sum = df_error['CIR_TOTAL_DECLARE'].sum() if 'CIR_TOTAL_DECLARE' in df_error.columns else 0.0\n",
        "    indices_traites_localement = []\n",
        "    for _, row in df_error.iterrows():\n",
        "        siren = row['SIREN_DECLARANT']\n",
        "        if siren in processed_sirens: continue\n",
        "        mask = df['SIREN_DECLARANT'] == siren\n",
        "        if not mask.any(): continue\n",
        "        idx = df.index[mask].tolist()[0]\n",
        "        declared = df.loc[idx, 'CIR_TOTAL_DECLARE']\n",
        "        crc = df.loc[idx, 'L91_MONTANT_TOTAL_CIR_RECHERCHE_COLLABORATIVE']\n",
        "        df.loc[idx, 'CIR_TOTAL_CORRIGE'] = declared + crc\n",
        "        # ---------- LABEL MODIFIÉ ----------\n",
        "        df.loc[idx, 'TRAITEMENT_APPLIQUE'] = \"err_oubli_crc\"\n",
        "        # ----------------------------------\n",
        "        processed_sirens.add(siren); indices_traites_localement.append(idx); count += 1\n",
        "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
        "    # Mettre à jour le label dans le message final\n",
        "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} € (Label: err_oubli_crc)\")\n",
        "    return count\n",
        "\n",
        "# --- Correction 14: SUPPRIMÉE ---\n",
        "# La fonction correction_crc_manquant_simple n'est plus définie.\n",
        "\n",
        "# --- Correction 15: Valeur Calculée pour le Reste (Inchangée) ---\n",
        "def correction_valeur_calculee_reste(df, processed_sirens, fichier_intermediaire=\"lignes_restantes_a_analyser.csv\"):\n",
        "    \"\"\"Applique la valeur calculée aux cas restants identifiés.\"\"\"\n",
        "    print(\"\\n15. VALEUR CALCULÉE PRIVILÉGIÉE POUR LE RESTE IDENTIFIÉ\")\n",
        "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
        "    if df_error.empty: return 0\n",
        "    count = 0\n",
        "    before_sum = df_error['CIR_TOTAL_DECLARE'].sum() if 'CIR_TOTAL_DECLARE' in df_error.columns else 0.0\n",
        "    indices_traites_localement = []\n",
        "    for _, row in df_error.iterrows():\n",
        "        siren = row['SIREN_DECLARANT']\n",
        "        if siren in processed_sirens: continue\n",
        "        mask = df['SIREN_DECLARANT'] == siren\n",
        "        if not mask.any(): continue\n",
        "        idx = df.index[mask].tolist()[0]\n",
        "        calculated_value = df.loc[idx, 'CIR_TOTAL_CALCULE']\n",
        "        df.loc[idx, 'CIR_TOTAL_CORRIGE'] = calculated_value\n",
        "        df.loc[idx, 'TRAITEMENT_APPLIQUE'] = \"Valeur calculée privilégiée(Reste)\"\n",
        "        processed_sirens.add(siren); indices_traites_localement.append(idx); count += 1\n",
        "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
        "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
        "    return count\n",
        "\n",
        "# ===================================================================\n",
        "# FONCTION PRINCIPALE (Orchestration - Appel à la fonction 14 supprimé)\n",
        "# ===================================================================\n",
        "\n",
        "def corriger_cir(file_path=\"Calcul_Creance_CIR.csv\"):\n",
        "    \"\"\"Fonction principale pour charger, corriger et sauvegarder le CIR.\"\"\"\n",
        "    df = charger_donnees(file_path)\n",
        "    if df is None:\n",
        "        print(\"\\nArrêt du traitement.\")\n",
        "        return None\n",
        "\n",
        "    original_declared = df['CIR_TOTAL_DECLARE'].sum()\n",
        "    original_calculated = df['CIR_TOTAL_CALCULE'].sum()\n",
        "    initial_corrected_sum = df['CIR_TOTAL_CORRIGE'].sum()\n",
        "    print(f\"\\nSommes avant corrections spécifiques:\")\n",
        "    print(f\"  - CIR Déclaré Total: {original_declared:,.2f} €\")\n",
        "    print(f\"  - CIR Calculé Total: {original_calculated:,.2f} €\")\n",
        "    print(f\"  - CIR Corrigé Initial Total: {initial_corrected_sum:,.2f} €\")\n",
        "\n",
        "    processed_sirens = set()\n",
        "    total_corrected_count = 0\n",
        "\n",
        "    print(\"\\n--- Début de l'application des corrections spécifiques ---\")\n",
        "    # Liste des fonctions de correction et de leurs fichiers associés\n",
        "    # La fonction 14 a été retirée de cette séquence\n",
        "    correction_definitions = [\n",
        "        (correction_erreurs_personnel, \"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\"), #1\n",
        "        (correction_erreurs_frais_brevets, \"lignes_L7_egal_L8.csv\"), #2\n",
        "        (correction_cir_recherche_manquant, \"lignes_depenses_non0_cir_recherche_0.csv\"), #3\n",
        "        (correction_erreurs_depenses_externalisees, \"analyse_L26A_vs_CIR_TOTAL.csv\"), #4\n",
        "        (correction_doublement_sans_motif, \"lignes_ecart_relatif_50_innovation0_recherche1.csv\"), #5\n",
        "        (correction_ecart_petit, \"lignes_ecart_total_entre_-500_et_500.csv\"), #6\n",
        "        (correction_plafond_partout, \"lignes_ecart_relatif_moins_100.csv\"), #7\n",
        "        (correction_cir_innovation, \"lignes_ecart_total_egal_innovation.csv\"), #8\n",
        "        (correction_cir_collection, \"lignes_ecart_total_egal_collection.csv\"), #9\n",
        "        (correction_cir_declare_zero, \"lignes_ecart_100_cir_declare_0.csv\"), #10\n",
        "        (correction_erreurs_l6, \"lignes_ecart_total_egal_recherche_l6_ecart_hors_1.csv\"), #11\n",
        "        (correction_erreurs_l26, \"lignes_cas_L26A_ecart_hors_1_L14_L20_L21_dans_1.csv\"), #12\n",
        "        (correction_crc_manquant_cir_total, \"lignes_ecarts_cir_entre_-1_1_et_total_egal_L91.csv\"), #13 (Label -> err_oubli_crc)\n",
        "        # Appel à la fonction 14 SUPPRIMÉ\n",
        "        (correction_valeur_calculee_reste, \"lignes_restantes_a_analyser.csv\") #15\n",
        "    ]\n",
        "\n",
        "    # Exécution séquentielle des corrections\n",
        "    for func, file in correction_definitions:\n",
        "         count = func(df, processed_sirens, file)\n",
        "         total_corrected_count += count\n",
        "\n",
        "    print(f\"\\n--- Fin de l'application des corrections spécifiques ---\")\n",
        "    print(f\"Nombre total de modifications appliquées par les fonctions actives: {total_corrected_count:,}\")\n",
        "    print(f\"Nombre de SIRENs uniques traités: {len(processed_sirens):,}\")\n",
        "\n",
        "    # --- Ajustement final : Mise à zéro des CIR corrigés négatifs ---\n",
        "    print(\"\\n--- Ajustement final : Mise à zéro des CIR corrigés négatifs ---\")\n",
        "    if 'CIR_TOTAL_CORRIGE' in df.columns:\n",
        "        # Assurer le type numérique avant la comparaison\n",
        "        if not pd.api.types.is_numeric_dtype(df['CIR_TOTAL_CORRIGE']):\n",
        "             df['CIR_TOTAL_CORRIGE'] = df['CIR_TOTAL_CORRIGE'].apply(convertir_en_nombre)\n",
        "\n",
        "        negative_mask = df['CIR_TOTAL_CORRIGE'] < 0\n",
        "        count_negative = negative_mask.sum()\n",
        "        if count_negative > 0:\n",
        "            sum_before_zeroing = df.loc[negative_mask, 'CIR_TOTAL_CORRIGE'].sum()\n",
        "            df.loc[negative_mask, 'CIR_TOTAL_CORRIGE'] = 0.0\n",
        "            print(f\"{count_negative:,} lignes avec CIR_TOTAL_CORRIGE négatif ont été mises à 0 (Impact: {-sum_before_zeroing:,.2f} €).\")\n",
        "        else: print(\"Aucune valeur négative trouvée dans CIR_TOTAL_CORRIGE après corrections.\")\n",
        "    else: print(\"Erreur: Colonne 'CIR_TOTAL_CORRIGE' non trouvée pour l'ajustement final.\")\n",
        "\n",
        "    # --- Finalisation des lignes 'Non traité' ---\n",
        "    mask_non_traite_final = df['TRAITEMENT_APPLIQUE'] == \"Non traité\"\n",
        "    count_non_traite = mask_non_traite_final.sum()\n",
        "    print(f\"\\nConfirmation pour les lignes restées 'Non traité' ({count_non_traite:,}):\")\n",
        "    if count_non_traite > 0:\n",
        "        # Assurer numérique et non-négatif\n",
        "        df.loc[mask_non_traite_final, 'CIR_TOTAL_CORRIGE'] = df.loc[mask_non_traite_final, 'CIR_TOTAL_CORRIGE'].apply(convertir_en_nombre)\n",
        "        neg_in_non_traite_mask = mask_non_traite_final & (df['CIR_TOTAL_CORRIGE'] < 0)\n",
        "        count_neg_in_non_traite = neg_in_non_traite_mask.sum()\n",
        "        if count_neg_in_non_traite > 0:\n",
        "             sum_neg_non_traite = df.loc[neg_in_non_traite_mask, 'CIR_TOTAL_CORRIGE'].sum()\n",
        "             df.loc[neg_in_non_traite_mask, 'CIR_TOTAL_CORRIGE'] = 0.0\n",
        "             print(f\"  - {count_neg_in_non_traite} de ces lignes étaient négatives et mises à 0 (impact: {-sum_neg_non_traite:,.2f} €).\")\n",
        "        else: print(\"  - Aucune valeur négative parmi les lignes 'Non traité'.\")\n",
        "    else: print(\"  - Aucune ligne marquée comme 'Non traité'.\")\n",
        "\n",
        "    # --- Calcul des totaux finaux ---\n",
        "    final_total_corrected = df['CIR_TOTAL_CORRIGE'].sum()\n",
        "\n",
        "    # --- Sauvegarde ---\n",
        "    output_file = \"Calcul_Creance_CIR_Corrige.csv\"\n",
        "    print(f\"\\nSauvegarde du fichier corrigé sous: {output_file}\")\n",
        "    try:\n",
        "        df.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False, decimal='.')\n",
        "        print(f\"Fichier sauvegardé avec succès.\")\n",
        "    except Exception as e: print(f\"ERREUR lors de la sauvegarde: {str(e)}\")\n",
        "\n",
        "    # --- Résumé Final ---\n",
        "    print(\"\\n=====================================================\")\n",
        "    print(\"                RÉSUMÉ FINAL\")\n",
        "    print(\"=====================================================\")\n",
        "    print(f\"Montant total CIR déclaré (Original):       {original_declared:,.2f} €\")\n",
        "    print(f\"Montant total CIR calculé (Original):       {original_calculated:,.2f} €\")\n",
        "    print(f\"Montant total CIR après corrections:        {final_total_corrected:,.2f} €\")\n",
        "    initial_ecart = original_calculated - original_declared\n",
        "    final_ecart = final_total_corrected - original_declared\n",
        "    improvement = abs(initial_ecart) - abs(final_ecart)\n",
        "    print(f\"\\nÉcart initial (calculé - déclaré):        {initial_ecart:,.2f} €\")\n",
        "    print(f\"Écart final (corrigé - déclaré):          {final_ecart:,.2f} €\")\n",
        "    print(f\"Réduction de l'écart absolu:              {improvement:,.2f} €\")\n",
        "    if abs(original_declared) > 0.01:\n",
        "        print(f\"  Écart relatif initial:                  {initial_ecart / original_declared * 100:.2f}%\")\n",
        "        print(f\"  Écart relatif final:                    {final_ecart / original_declared * 100:.2f}%\")\n",
        "        if abs(initial_ecart) > 0.01: print(f\"  Réduction relative de l'écart:          {improvement / abs(initial_ecart) * 100:.2f}%\")\n",
        "    else: print(\"\\nCalculs relatifs non pertinents (CIR déclaré total proche de zéro).\")\n",
        "\n",
        "    print(\"\\n--- Détails par Type de Traitement Appliqué ---\")\n",
        "    if 'TRAITEMENT_APPLIQUE' in df.columns:\n",
        "        treatment_counts = df['TRAITEMENT_APPLIQUE'].value_counts().sort_index()\n",
        "        print(\"\\nNombre d'entreprises par type de traitement final:\")\n",
        "        for treatment, count in treatment_counts.items(): print(f\"  - {treatment:<40}: {count:10,}\")\n",
        "        print(\"\\nDétails financiers par type de traitement final:\")\n",
        "        treatment_order = treatment_counts.index.tolist()\n",
        "        for treatment in treatment_order:\n",
        "            subset = df[df['TRAITEMENT_APPLIQUE'] == treatment]\n",
        "            if len(subset) == 0: continue\n",
        "            declared_subset = subset['CIR_TOTAL_DECLARE'].sum()\n",
        "            corrected_subset = subset['CIR_TOTAL_CORRIGE'].sum()\n",
        "            ecart_final_subset = corrected_subset - declared_subset\n",
        "            print(f\"\\nTraitement: {treatment}\")\n",
        "            print(f\"  Nombre d'entreprises:                 {len(subset):<10,}\")\n",
        "            print(f\"  CIR déclaré (groupe):                 {declared_subset:>18,.2f} €\")\n",
        "            print(f\"  CIR corrigé final (groupe):           {corrected_subset:>18,.2f} €\")\n",
        "            print(f\"  Écart final (corrigé-déclaré groupe): {ecart_final_subset:>18,.2f} €\")\n",
        "            if abs(declared_subset) > 0.01:\n",
        "                impact_relatif = ecart_final_subset / declared_subset * 100\n",
        "                print(f\"  Impact relatif final (groupe):        {impact_relatif:>17.2f}%\")\n",
        "    else: print(\"\\nColonne 'TRAITEMENT_APPLIQUE' non trouvée.\")\n",
        "\n",
        "    print(\"\\n=====================================================\")\n",
        "    print(\"Traitement terminé.\")\n",
        "    print(\"=====================================================\")\n",
        "    return df\n",
        "\n",
        "# ===================================================================\n",
        "# EXÉCUTION\n",
        "# ===================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    # Adapter le chemin si nécessaire\n",
        "    input_filename = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR.csv\"\n",
        "    print(f\"*** DÉBUT DU SCRIPT DE CORRECTION CIR ***\")\n",
        "    # Affichage de la date et heure actuelles - Utilisation de la date système\n",
        "    current_time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "    print(f\"Date et heure: {current_time_str}\")\n",
        "    print(f\"Fichier d'entrée: {input_filename}\")\n",
        "    df_corrige = corriger_cir(input_filename)\n",
        "    if df_corrige is not None: print(\"\\nScript terminé avec succès.\")\n",
        "    else: print(\"\\nLe script n'a pas pu se terminer correctement.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_init = pd.read_parquet(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//output//output_parquet//cir_millesime_2022_ss_dbls.parquet\")\n",
        "df_corrige = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_Corrige.csv\", \n",
        "                         sep=';', encoding='utf-8-sig', decimal='.',low_memory=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "vscode": {
          "languageId": "ruby"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nombre de lignes avec type_retenu non-null : 27957\n",
            "\n",
            "Exemples de résultats:\n",
            "       SIREN_DECLARANT TRAITEMENT_APPLIQUE type_retenu\n",
            "13709        533868873          Non traité         IND\n",
            "8841         477865562          Non traité       FILLE\n",
            "23114        842712010          Non traité         IND\n",
            "1271         327235818          Non traité        MERE\n",
            "10719        499732212    Err_dep_ext_plaf         IND\n"
          ]
        }
      ],
      "source": [
        "# 1. Charger le fichier corrigé existant\n",
        "df_corrige = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_Corrige.csv\", \n",
        "                         sep=';', encoding='utf-8-sig', low_memory=False)\n",
        "\n",
        "# 2. Standardiser les SIREN dans les deux DataFrames\n",
        "df_corrige['SIREN_STD'] = df_corrige['SIREN_DECLARANT'].astype(str).str.strip().str.zfill(9)\n",
        "df_init['siren_std'] = df_init['siren_declarant'].astype(str).str.strip().str.zfill(9)\n",
        "\n",
        "# 3. Créer un dictionnaire de correspondance SIREN → type_final\n",
        "siren_to_type = dict(zip(df_init['siren_std'], df_init['type_retenu']))\n",
        "\n",
        "# 4. Appliquer cette correspondance directement\n",
        "df_corrige['type_retenu'] = df_corrige['SIREN_STD'].map(siren_to_type)\n",
        "\n",
        "# 5. Supprimer la colonne temporaire SIREN_STD\n",
        "df_corrige = df_corrige.drop(columns=['SIREN_STD'])\n",
        "\n",
        "# 6. Sauvegarder le résultat\n",
        "df_corrige.to_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_Corrige2.csv\", \n",
        "                  sep=';', encoding='utf-8-sig', index=False, decimal='.')\n",
        "\n",
        "# 7. Vérifier le résultat\n",
        "non_null_count = df_corrige['type_retenu'].notna().sum()\n",
        "print(f\"Nombre de lignes avec type_retenu non-null : {non_null_count}\")\n",
        "\n",
        "# 8. Afficher quelques exemples\n",
        "print(\"\\nExemples de résultats:\")\n",
        "sample = df_corrige[['SIREN_DECLARANT', 'TRAITEMENT_APPLIQUE', 'type_retenu']].sample(5)\n",
        "print(sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nombre de SIREN qui sont déposants mais pas déclarants: 2444\n",
            "DataFrame original: 27957 lignes\n",
            "Nouvelles lignes ajoutées: 2444 lignes\n",
            "DataFrame final: 30401 lignes\n",
            "\n",
            "Fichier sauvegardé: M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_Corrige_avec_deposants.csv\n",
            "\n",
            "Exemple d'une nouvelle ligne ajoutée:\n",
            "SIREN_DECLARANT              908968548\n",
            "SIREN_DEPOSANT               908968548\n",
            "TRAITEMENT_APPLIQUE    Déposant ajouté\n",
            "type_retenu                       MERE\n",
            "CIR_TOTAL_DECLARE                    0\n",
            "CIR_TOTAL_CALCULE                    0\n",
            "CIR_TOTAL_CORRIGE                    0\n",
            "Name: 0, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# 1. Charger le fichier corrigé existant\n",
        "df_corrige = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_Corrige3.csv\", \n",
        "                         sep=';', encoding='utf-8-sig', low_memory=False)\n",
        "\n",
        "# 2. Standardiser et nettoyer les SIREN\n",
        "df_corrige['SIREN_DECLARANT_STD'] = df_corrige['SIREN_DECLARANT'].astype(str).str.replace(r'\\D', '', regex=True).str.strip().str.zfill(9)\n",
        "df_corrige['SIREN_DEPOSANT_STD'] = df_corrige['SIREN_DEPOSANT'].astype(str).str.replace(r'\\D', '', regex=True).str.strip().str.zfill(9)\n",
        "\n",
        "# 3. Créer les ensembles de SIREN déclarants et déposants\n",
        "set_declarants = set(df_corrige['SIREN_DECLARANT_STD'])\n",
        "set_deposants = set(df_corrige['SIREN_DEPOSANT_STD'])\n",
        "\n",
        "# 4. Identifier les SIREN qui sont déposants mais pas déclarants (en filtrant les SIREN non valides)\n",
        "#if siren and not (siren.strip('0') == '')\n",
        "deposants_non_declarants = {siren for siren in (set_deposants - set_declarants) }\n",
        "print(f\"Nombre de SIREN qui sont déposants mais pas déclarants: {len(deposants_non_declarants)}\")\n",
        "\n",
        "# 5. Créer les nouvelles lignes pour les déposants manquants\n",
        "new_rows = []\n",
        "\n",
        "for siren in deposants_non_declarants:\n",
        "    # Créer un dictionnaire pour la nouvelle ligne\n",
        "    new_row = {}\n",
        "    \n",
        "    # Copier la structure d'une ligne existante pour obtenir toutes les colonnes\n",
        "    for col in df_corrige.columns:\n",
        "        if col in ['SIREN_DECLARANT_STD', 'SIREN_DEPOSANT_STD']:\n",
        "            continue  # On n'inclut pas ces colonnes temporaires\n",
        "        \n",
        "        # Déterminer le type et la valeur appropriée\n",
        "        if col == 'SIREN_DECLARANT' or col == 'SIREN_DEPOSANT':\n",
        "            # Utiliser toujours le format chaîne pour éviter les problèmes\n",
        "            new_row[col] = siren\n",
        "        elif col == 'TRAITEMENT_APPLIQUE':\n",
        "            new_row[col] = 'Déposant ajouté'\n",
        "        elif col == 'type_retenu':  # Ajouter \"MERE\" dans la colonne type_retenu\n",
        "            new_row[col] = 'MERE'\n",
        "        elif col == 'DESIGNATION' or col == 'COMPLEMENT_DESIGNATION':\n",
        "            new_row[col] = '' # Champs texte vide\n",
        "        elif pd.api.types.is_numeric_dtype(df_corrige[col]):\n",
        "            # Pour les colonnes numériques, mettre 0\n",
        "            new_row[col] = 0\n",
        "        else:\n",
        "            # Pour les autres colonnes non numériques, mettre une valeur vide\n",
        "            new_row[col] = ''\n",
        "    \n",
        "    # Ajouter la ligne au tableau de nouvelles lignes\n",
        "    new_rows.append(new_row)\n",
        "\n",
        "# 6. Créer un DataFrame avec les nouvelles lignes\n",
        "if new_rows:\n",
        "    df_new_rows = pd.DataFrame(new_rows)\n",
        "    \n",
        "    # 7. Concaténer avec le DataFrame original\n",
        "    df_corrige_complet = pd.concat([df_corrige.drop(['SIREN_DECLARANT_STD', 'SIREN_DEPOSANT_STD'], axis=1),\n",
        "                                df_new_rows],\n",
        "                               ignore_index=True)\n",
        "    \n",
        "    # 8. Afficher des informations sur le résultat\n",
        "    print(f\"DataFrame original: {len(df_corrige)} lignes\")\n",
        "    print(f\"Nouvelles lignes ajoutées: {len(new_rows)} lignes\")\n",
        "    print(f\"DataFrame final: {len(df_corrige_complet)} lignes\")\n",
        "    \n",
        "    # 9. Sauvegarder le résultat\n",
        "    output_file = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_Corrige_avec_deposants.csv\"\n",
        "    df_corrige_complet.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
        "    print(f\"\\nFichier sauvegardé: {output_file}\")\n",
        "    \n",
        "    # 10. Afficher un exemple des nouvelles lignes\n",
        "    print(\"\\nExemple d'une nouvelle ligne ajoutée:\")\n",
        "    if not df_new_rows.empty:\n",
        "        cols_to_show = ['SIREN_DECLARANT', 'SIREN_DEPOSANT', 'TRAITEMENT_APPLIQUE', 'type_retenu', 'CIR_TOTAL_DECLARE', 'CIR_TOTAL_CALCULE', 'CIR_TOTAL_CORRIGE']\n",
        "        print(df_new_rows[cols_to_show].iloc[0])\n",
        "else:\n",
        "    print(\"Aucun déposant non déclarant trouvé, aucune ligne à ajouter.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Difference pour verifier si tous les deposants sont declarants."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nombre de SIREN présents soit comme déclarant, soit comme déposant (mais pas les deux) : 6533\n",
            "Exemples de SIREN présents dans un seul ensemble : ['775656325', '434039921', '385115142', '378888085', '318365228']\n",
            "\n",
            "Nombre de SIREN qui sont uniquement déclarants : 6533\n",
            "Exemples: ['775656325', '422505347', '434039921', '904479672', '385115142']\n",
            "Nombre de SIREN qui sont uniquement déposants : 0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Charger le fichier\n",
        "df = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_Corrige_avec_deposants.csv\", \n",
        "                 sep=';', encoding='utf-8-sig', low_memory=False)\n",
        "\n",
        "# Standardiser les SIREN (en string, 9 caractères, sans espaces)\n",
        "set_declarants = set(df['SIREN_DECLARANT'].astype(str).str.replace(r'\\D', '', regex=True).str.strip().str.zfill(9))\n",
        "set_deposants = set(df['SIREN_DEPOSANT'].astype(str).str.replace(r'\\D', '', regex=True).str.strip().str.zfill(9))\n",
        "\n",
        "# Différence symétrique (éléments dans l'un ou l'autre ensemble, mais pas les deux)\n",
        "difference_symetrique = set_declarants ^ set_deposants\n",
        "\n",
        "print(f\"Nombre de SIREN présents soit comme déclarant, soit comme déposant (mais pas les deux) : {len(difference_symetrique)}\")\n",
        "\n",
        "if len(difference_symetrique) == 0:\n",
        "    print(\"La différence symétrique est vide.\")\n",
        "else:\n",
        "    print(\"Exemples de SIREN présents dans un seul ensemble :\", list(difference_symetrique)[:5])\n",
        "    \n",
        "    # Si vous voulez aussi voir spécifiquement les SIREN qui sont uniquement déclarants\n",
        "    seulement_declarants = set_declarants - set_deposants\n",
        "    print(f\"\\nNombre de SIREN qui sont uniquement déclarants : {len(seulement_declarants)}\")\n",
        "    if len(seulement_declarants) > 0:\n",
        "        print(\"Exemples:\", list(seulement_declarants)[:5])\n",
        "    \n",
        "    # Et les SIREN qui sont uniquement déposants\n",
        "    seulement_deposants = set_deposants - set_declarants\n",
        "    print(f\"Nombre de SIREN qui sont uniquement déposants : {len(seulement_deposants)}\")\n",
        "    if len(seulement_deposants) > 0:\n",
        "        print(\"Exemples:\", list(seulement_deposants)[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chargement du fichier...\n",
            "Standardisation des SIREN...\n",
            "Calcul de la somme du CIR par déposant...\n",
            "Ajout de la nouvelle colonne au DataFrame...\n",
            "Attribution des valeurs selon le type...\n",
            "\n",
            "Nombre total d'entreprises: 30401\n",
            "Nombre de déposants uniques: 24259\n",
            "\n",
            "Distribution des valeurs cir_benef_total par type:\n",
            "               count          mean           std  min         25%         50%  \\\n",
            "type_retenu                                                                     \n",
            "FILLE         6485.0  0.000000e+00  0.000000e+00  0.0      0.0000       0.000   \n",
            "IND          19548.0  1.486049e+05  6.405565e+05  0.0  20689.2150   50638.775   \n",
            "MERE          4368.0  1.098945e+06  5.791363e+06  0.0  45006.6725  120684.815   \n",
            "\n",
            "                     75%           max  \n",
            "type_retenu                             \n",
            "FILLE             0.0000  0.000000e+00  \n",
            "IND          110767.6575  3.046598e+07  \n",
            "MERE         415645.3500  1.411021e+08  \n",
            "\n",
            "Top 5 des déposants (MERE) avec le plus grand total de CIR:\n",
            "      SIREN_DEPOSANT  cir_benef_total\n",
            "14438      562082909     1.411021e+08\n",
            "30299      441639465     1.282196e+08\n",
            "2104       341459386     9.985635e+07\n",
            "3509       383474814     9.968364e+07\n",
            "4351       395030844     9.853072e+07\n",
            "\n",
            "Fichier sauvegardé: M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_avec_benef_total.csv\n",
            "\n",
            "Somme totale de CIR_TOTAL_CORRIGE: 7,616,570,450.05 €\n",
            "Somme totale de cir_benef_total (pour les MERE et IND): 7,705,118,240.38 €\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. Charger le fichier\n",
        "print(\"Chargement du fichier...\")\n",
        "df = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_Corrige_avec_deposants.csv\", \n",
        "                 sep=';', encoding='utf-8-sig', low_memory=False)\n",
        "\n",
        "# 2. Standardiser les SIREN des déposants pour éviter les problèmes de format\n",
        "print(\"Standardisation des SIREN...\")\n",
        "df['SIREN_DEPOSANT_STD'] = df['SIREN_DEPOSANT'].astype(str).str.replace(r'\\D', '', regex=True).str.strip().str.zfill(9)\n",
        "\n",
        "# 3. Calculer la somme du CIR par déposant\n",
        "print(\"Calcul de la somme du CIR par déposant...\")\n",
        "# Utiliser CIR_TOTAL_CORRIGE qui est le montant final retenu après corrections\n",
        "cir_par_deposant = df.groupby('SIREN_DEPOSANT_STD')['CIR_TOTAL_CORRIGE'].sum().reset_index()\n",
        "cir_par_deposant.rename(columns={'CIR_TOTAL_CORRIGE': 'cir_benef_total_temp'}, inplace=True)\n",
        "\n",
        "# 4. Fusionner cette somme avec le DataFrame original\n",
        "print(\"Ajout de la nouvelle colonne au DataFrame...\")\n",
        "df = df.merge(cir_par_deposant, on='SIREN_DEPOSANT_STD', how='left')\n",
        "\n",
        "# 5. Mettre à zéro la colonne cir_benef_total pour toutes les lignes qui ne sont pas de type MERE\n",
        "print(\"Attribution des valeurs selon le type...\")\n",
        "# Créer la colonne finale 'cir_benef_total'\n",
        "df['cir_benef_total'] = 0.0  # Initialiser à zéro pour toutes les lignes\n",
        "\n",
        "# Mettre la somme calculée uniquement pour les lignes de type 'MERE' et 'IND'\n",
        "df.loc[df['type_retenu'] == 'MERE', 'cir_benef_total'] = df.loc[df['type_retenu'] == 'MERE', 'cir_benef_total_temp']\n",
        "df.loc[df['type_retenu'] == 'IND', 'cir_benef_total'] = df.loc[df['type_retenu'] == 'IND', 'cir_benef_total_temp']\n",
        "\n",
        "# Supprimer la colonne temporaire\n",
        "df.drop(['SIREN_DEPOSANT_STD', 'cir_benef_total_temp'], axis=1, inplace=True)\n",
        "\n",
        "# 6. Afficher quelques statistiques\n",
        "print(f\"\\nNombre total d'entreprises: {len(df)}\")\n",
        "print(f\"Nombre de déposants uniques: {df['SIREN_DEPOSANT'].nunique()}\")\n",
        "\n",
        "# Vérifier la distribution des valeurs cir_benef_total selon le type\n",
        "print(\"\\nDistribution des valeurs cir_benef_total par type:\")\n",
        "print(df.groupby('type_retenu')['cir_benef_total'].describe())\n",
        "\n",
        "# Trier par montant de cir_benef_total pour voir les déposants avec le plus grand total\n",
        "top_deposants = df[df['cir_benef_total'] > 0][['SIREN_DEPOSANT', 'cir_benef_total']].drop_duplicates().sort_values('cir_benef_total', ascending=False)\n",
        "print(\"\\nTop 5 des déposants (MERE) avec le plus grand total de CIR:\")\n",
        "print(top_deposants.head(5))\n",
        "\n",
        "# 7. Sauvegarder le résultat\n",
        "output_file = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_avec_benef_total.csv\"\n",
        "df.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
        "print(f\"\\nFichier sauvegardé: {output_file}\")\n",
        "\n",
        "# 8. Vérification - calcul de la somme totale de CIR\n",
        "total_cir_corrige = df['CIR_TOTAL_CORRIGE'].sum()\n",
        "total_cir_benef = df['cir_benef_total'].sum()\n",
        "print(f\"\\nSomme totale de CIR_TOTAL_CORRIGE: {total_cir_corrige:,.2f} €\")\n",
        "print(f\"Somme totale de cir_benef_total (pour les MERE et IND): {total_cir_benef:,.2f} €\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fichier sauvegardé: M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_avec_benef_total_final.csv\n",
            "\n",
            "Somme totale de CIR_TOTAL_CORRIGE: 7,616,570,450.05 €\n",
            "Somme totale de cir_benef_total (cas SIREN_DECLARANT == SIREN_DEPOSANT): 7,612,257,192.77 €\n",
            "difference entre les deux sommes: 4,313,257.28 €\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Charger le fichier\n",
        "df = pd.read_csv(output_file, sep=';', encoding='utf-8-sig', low_memory=False)\n",
        "\n",
        "# Standardiser les SIREN des déposants\n",
        "df['SIREN_DEPOSANT_STD'] = df['SIREN_DEPOSANT'].astype(str).str.replace(r'\\D', '', regex=True).str.strip().str.zfill(9)\n",
        "\n",
        "# Calculer la somme du CIR par déposant\n",
        "cir_par_deposant = df.groupby('SIREN_DEPOSANT_STD')['CIR_TOTAL_CORRIGE'].sum().reset_index()\n",
        "\"\"\"if cir_par_deposant == df['CIR_TOTAL_CORRIGE'].sum():\n",
        "    print(\"La somme des CIR par déposant est égale à la somme totale des CIR.\")\n",
        "else:   \n",
        "    print(\"La somme des CIR par déposant n'est pas égale à la somme totale des CIR. Vérifiez les données.\")\"\"\"\n",
        "\n",
        "cir_par_deposant.rename(columns={'CIR_TOTAL_CORRIGE': 'cir_benef_total_temp'}, inplace=True)\n",
        "\n",
        "# Fusionner cette somme avec le DataFrame original\n",
        "df = df.merge(cir_par_deposant, on='SIREN_DEPOSANT_STD', how='left')\n",
        "\n",
        "# Mettre à zéro la colonne cir_benef_total partout\n",
        "df['cir_benef_total'] = 0.0\n",
        "\n",
        "# Mettre la somme uniquement si SIREN_DECLARANT == SIREN_DEPOSANT\n",
        "mask = df['SIREN_DECLARANT'].astype(str).str.replace(r'\\D', '', regex=True).str.strip().str.zfill(9) == df['SIREN_DEPOSANT_STD']\n",
        "df.loc[mask, 'cir_benef_total'] = df.loc[mask, 'cir_benef_total_temp']\n",
        "\n",
        "# Supprimer la colonne temporaire\n",
        "df.drop(['SIREN_DEPOSANT_STD', 'cir_benef_total_temp'], axis=1, inplace=True)\n",
        "\n",
        "# Sauvegarder le résultat\n",
        "output_file_final = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_avec_benef_total_final.csv\"\n",
        "df.to_csv(output_file_final, sep=';', encoding='utf-8-sig', index=False)\n",
        "cir_par_deposant.to_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_avec_benef_total_par_deposant.csv\", sep=';', encoding='utf-8-sig', index=False)\n",
        "print(f\"Fichier sauvegardé: {output_file_final}\")\n",
        "\n",
        "# Vérification\n",
        "total_cir_corrige = df['CIR_TOTAL_CORRIGE'].sum()\n",
        "print(f\"\\nSomme totale de CIR_TOTAL_CORRIGE: {total_cir_corrige:,.2f} €\")\n",
        "print(f\"Somme totale de cir_benef_total (cas SIREN_DECLARANT == SIREN_DEPOSANT): {df['cir_benef_total'].sum():,.2f} €\")\n",
        "print(f\"difference entre les deux sommes: {total_cir_corrige - df['cir_benef_total'].sum():,.2f} €\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nombre d'entreprises contribuant à la différence: 6484\n",
            "type_retenu\n",
            "FILLE    6420\n",
            "MERE       63\n",
            "IND         1\n",
            "Name: count, dtype: int64\n",
            "Somme des CIR non attribués: 3,724,198,531.98 €\n"
          ]
        }
      ],
      "source": [
        "# Identifiez les lignes qui contribuent à la différence\n",
        "df_diff = df[(df['CIR_TOTAL_CORRIGE'] > 0) & (df['cir_benef_total'] == 0)]\n",
        "\n",
        "# Vérifiez leurs caractéristiques\n",
        "print(f\"Nombre d'entreprises contribuant à la différence: {len(df_diff)}\")\n",
        "print(df_diff['type_retenu'].value_counts())\n",
        "\n",
        "# Somme des CIR_TOTAL_CORRIGE pour ces lignes\n",
        "diff_sum = df_diff['CIR_TOTAL_CORRIGE'].sum()\n",
        "print(f\"Somme des CIR non attribués: {diff_sum:,.2f} €\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
