{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "178da2d1",
   "metadata": {},
   "source": [
    "# Recalcule Creance pour toute les entreprises Comparaison Calcule vs Non Calcule (2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5923c804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total d'entreprises: 27,923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n",
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_15208\\2350444244.py:996: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_comparaison[col_dest] = df_num[col_orig]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fichier de comparaison détaillée créé: M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB\\Calcul_Creance_CIR_2023.csv\n",
      "\n",
      "===== COMPARAISON CIR DÉCLARÉ VS RECALCULÉ =====\n",
      "\n",
      "Nombre total d'entreprises analysées: 27,923\n",
      "Nombre d'entreprises avec CIR déclaré: 27,178\n",
      "Nombre d'entreprises avec dépenses > 100M€: 21\n",
      "\n",
      "CIR TOTAL:\n",
      "CIR déclaré total: 7,986,816,564.00 €\n",
      "CIR recalculé total: 7,868,711,719.29 €\n",
      "Différence: -118,104,844.71 €\n",
      "Écart relatif: -1.48%\n",
      "\n",
      "ANALYSE DES ÉCARTS:\n",
      "Entreprises avec CIR conforme (écart ≤ 1€): 26,191 (93.80%)\n",
      "Entreprises avec CIR recalculé > CIR déclaré (écart > 1€): 733\n",
      "Montant total des écarts positifs: 31,893,319.83 €\n",
      "Entreprises avec CIR recalculé < CIR déclaré (écart < -1€): 999\n",
      "Montant total des écarts négatifs: -149,998,039.80 €\n",
      "\n",
      "DÉTAIL PAR COMPOSANTE DU CIR RECALCULÉ:\n",
      "CIR Recherche: 7,323,998,043.04 €\n",
      "CIR Collection: 27,543,075.80 €\n",
      "CIR Innovation: 500,767,614.75 €\n",
      "CIR Recherche Collaborative: 16,402,985.70 €\n",
      "\n",
      "Traitement terminé avec succès!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Charger les données\n",
    "df = pd.read_excel(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//output//output_parquet//new_millesime_CIR_2023_corrected_sans_doublon.xlsx\")\n",
    "#df = pd.read_parquet(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//output//output_parquet//new_millesime_CIR_2023.parquet\")\n",
    "\n",
    "def convertir_en_nombre(valeur, defaut=0):\n",
    "    \"\"\"Convertit une valeur en nombre de façon sécurisée\"\"\"\n",
    "    if pd.isna(valeur) or valeur == '' or valeur is None:\n",
    "        return defaut\n",
    "    try:\n",
    "        return float(valeur)\n",
    "    except:\n",
    "        return defaut\n",
    "\n",
    "def comparer_cir_declare_recalcule():\n",
    "    \"\"\"Compare le CIR déclaré et le CIR recalculé\"\"\"\n",
    "    print(f\"Nombre total d'entreprises: {len(df):,}\")\n",
    "\n",
    "    # Colonnes nécessaires pour recalculer le CIR\n",
    "    colonnes = [\n",
    "        'siren_declarant', 'siren_deposant', 'DESIGN', 'COMPLT_DESIGN',\n",
    "        'MT_NET_DEP_RD', 'MT_NET_DEP_RD_DOM', 'MT_TOT_CIR_CI_COLL_CII',\n",
    "        'MT_CIR_RECH_YC_QP_MOINS_DE100', 'MT_CI_COLL_APRS_MINIMI', 'MT_CII_YC_QP', 'MT_CRC',\n",
    "        'DOT_AMORT_IMMO', 'DOT_AMORT_IMMO_SINISTR', 'DEP_CHERCH_TECH', 'REM_SAL_INV',\n",
    "        'DEP_JD', 'OTR_DEP_FONCT', 'FRAIS_BREV_COV', 'DEP_MAINT_BREV_COV',\n",
    "        'DOT_AMORT_BREV', 'DEP_NORMALI', 'PRIM_COTIZ', 'DEP_VEIL_TECHNO',\n",
    "        'MT_DEP_FONCT_TOT', 'MT_TOT_RD_1',\n",
    "        'DEP_EXT_LIE_FR', 'DEP_EXT_LIE_ETR', 'DEP_EXT_NON_LIE_FR', 'DEP_EXT_NON_LIE_ETR',\n",
    "        'MT_TOT_DEP_EXT_ORG_AGREE', 'PLAF_OP_EXT', 'MT_TOT_OP_SOUS_TRAIT',\n",
    "        'PLAF_OP_EXT_ORG_AGRE_LIE', 'PLAF_OP_EXT_ORG_AGRE_NON_LIE', 'PLAF_GNRL_DEP_EXT', 'MT_DEP_EXT_PLAF',\n",
    "        'MT_TOT_RD_2',\n",
    "        'MT_AID_SUBV', 'MT_ENC_PRESTA', 'MT_DEP_CONSEILS_CIR', 'REMBST_SUBV',\n",
    "        'FRAIS_COLL', 'FRAIS_DEF_DESSIN', 'MT_TOT_DEP_COLL', 'MT_AID_SUBV_COLL',\n",
    "        'MT_DEP_CONSEILS_CIR_COLL', 'REMBST_SUBV_COLL', 'MT_NET_DEP_COLL', 'MT_NET_DEP_COLL_DOM',\n",
    "        'DOT_AMORT_IMMO_INO', 'DEP_PERSONEL_INO', 'FRAIS_BREV_COV_INO',\n",
    "        'FRAIS_DEF_BREV_INO', 'OP_INOV_EXT', 'MT_TOT_DEP_INO', 'MT_TOT_DEP_INO_PLAF',\n",
    "        'MT_AID_SUBV_INO', 'MT_ENC_PRESTA_INO', 'MT_DEP_CONSEILS_CII', 'REMBST_SUBV_INO',\n",
    "        'MT_NET_DEP_INO', 'MT_NET_DEP_INO_DOM', 'MT_NET_DEP_INO_MPE_CORSE', 'MT_NET_DEP_INO_ME_CORSE',\n",
    "        'DEP_CRC', 'DEP_CRC_FR', 'DEP_CRC_ETR', 'DEP_CRC_PLAF', 'AIDE_PUB_CRC',\n",
    "        'AIDE_PUB_REMB_CRC', 'MT_NET_DEP_CRC', 'MT_NET_DEP_CRC_PME', 'MT_CRC','MT_QP_COLL_RECU_MOINS_DE100',\n",
    "        'MT_QP_CIR_RECU_BIS','MT_QP_COLL_RECU_BIS','MT_AIDE_MINIMI_COLL','MT_QP_CII','QP_MT_CRC','MT_CII_CORSE',\n",
    "        'MT_CI_COLL_APRS_MINIMI_DOM', 'MT_CI_COLL_APRES_MINIMI_PLUS_DE100_DOM', 'MT_QP_CIR_RECU', 'MT_AIDE_MINIMI_MOINS_DE100'\n",
    "    ]\n",
    "\n",
    "    # Convertir en numérique et créer une copie défragmentée\n",
    "    df_tmp = df.copy()\n",
    "    for col in colonnes:\n",
    "        if col in df_tmp.columns:\n",
    "            if col not in ['siren_declarant', 'siren_deposant', 'DESIGN', 'COMPLT_DESIGN']:\n",
    "                df_tmp[col] = df_tmp[col].apply(convertir_en_nombre)\n",
    "        else:\n",
    "            if col not in ['siren_declarant', 'siren_deposant', 'DESIGN', 'COMPLT_DESIGN']:\n",
    "                df_tmp[col] = 0\n",
    "\n",
    "\n",
    "    # Créer un dictionnaire pour stocker toutes les colonnes calculées\n",
    "    # et les ajouter en une seule fois à la fin pour éviter la fragmentation\n",
    "    calc_columns = {}\n",
    "\n",
    "    ## I - DÉPENSES DE RECHERCHE OUVRANT DROIT AU CRÉDIT D'IMPÔT (CIR-RECHERCHE) \n",
    "    ## ANNÉE CIVILE 2023\n",
    "\n",
    "    # 1. Dépenses internes (Section I-A)\n",
    "\n",
    "    # Ligne 6: Autres dépenses de fonctionnement\n",
    "    calc_columns['LIGNE_6_CALC'] = (df_tmp['DOT_AMORT_IMMO'] * 0.75) + \\\n",
    "                               ((df_tmp['DEP_CHERCH_TECH'] + df_tmp['REM_SAL_INV']) * 0.43) + \\\n",
    "                               df_tmp['DEP_JD']\n",
    "\n",
    "    # Ligne 7: Total dépenses de fonctionnement\n",
    "    calc_columns['LIGNE_7_CALC'] = df_tmp['DOT_AMORT_IMMO'] + df_tmp['DOT_AMORT_IMMO_SINISTR'] + \\\n",
    "                               df_tmp['DEP_CHERCH_TECH'] + df_tmp['REM_SAL_INV'] + \\\n",
    "                               df_tmp['DEP_JD'] + calc_columns['LIGNE_6_CALC']\n",
    "\n",
    "\n",
    "    # Appliquer les plafonds pour les lignes concernées\n",
    "    # Ligne 11: Dépenses liées à la normalisation, utiliser directement la valeur renseignée\n",
    "    calc_columns['DEP_NORMALI_RECALC'] = df_tmp['DEP_NORMALI']  # Conserver la valeur telle quelle\n",
    "\n",
    "    # Ligne 12: Primes et cotisations (plafond 60 000 €)\n",
    "    calc_columns['PRIM_COTIZ_PLAFONNEES'] = np.minimum(df_tmp['PRIM_COTIZ'], 60000)\n",
    "\n",
    "    # Ligne 13: Dépenses de veille technologique (plafond 60 000 €)\n",
    "    calc_columns['DEP_VEIL_TECHNO_PLAFONNEES'] = np.minimum(df_tmp['DEP_VEIL_TECHNO'], 60000)\n",
    "\n",
    "\n",
    "    # Ligne 14: Total dépenses internes avec plafonds appliqués\n",
    "    calc_columns['LIGNE_14_CALC'] = calc_columns['LIGNE_7_CALC'] + df_tmp['FRAIS_BREV_COV'] + \\\n",
    "                                df_tmp['DEP_MAINT_BREV_COV'] + df_tmp['DOT_AMORT_BREV'] + \\\n",
    "                                calc_columns['DEP_NORMALI_RECALC'] + calc_columns['PRIM_COTIZ_PLAFONNEES'] + \\\n",
    "                                calc_columns['DEP_VEIL_TECHNO_PLAFONNEES']\n",
    "\n",
    "    # 2. Dépenses externalisées (Section I-B)\n",
    "\n",
    "    # Ligne 17: Total dépenses externalisées\n",
    "    calc_columns['LIGNE_17_CALC'] = df_tmp['DEP_EXT_LIE_FR'] + df_tmp['DEP_EXT_LIE_ETR'] + \\\n",
    "                                df_tmp['DEP_EXT_NON_LIE_FR'] + df_tmp['DEP_EXT_NON_LIE_ETR']\n",
    "\n",
    "    # Préparation pour les calculs complexes nécessitant des références à d'autres colonnes calculées\n",
    "    # Ajoutons temporairement les colonnes calculées au DataFrame\n",
    "    df_calc = pd.DataFrame(calc_columns)\n",
    "    df_calc_temp = pd.concat([df_tmp, df_calc], axis=1)\n",
    "\n",
    "    # Appliquer les plafonnements\n",
    "    # Ligne 18: Plafond global (3x dépenses internes)\n",
    "    calc_columns['LIGNE_18_CALC'] = np.minimum(df_calc_temp['LIGNE_17_CALC'], df_calc_temp['LIGNE_14_CALC'] * 3)\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_18_CALC'] = calc_columns['LIGNE_18_CALC']\n",
    "\n",
    "    # Pour les calculs complexes, utiliser des boucles au lieu de apply\n",
    "    # Ligne 19: Plafond pour organismes liés (2M€)\n",
    "    ligne_19_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        dep_liees = row['DEP_EXT_LIE_FR'] + row['DEP_EXT_LIE_ETR']\n",
    "        plafond = min(row['LIGNE_18_CALC'], 2000000)\n",
    "        ligne_19_values.append(min(dep_liees, plafond))\n",
    "    calc_columns['LIGNE_19_CALC'] = np.array(ligne_19_values)\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_19_CALC'] = calc_columns['LIGNE_19_CALC']\n",
    "\n",
    "    # Ligne 20: Plafond pour organismes non liés (10M€)\n",
    "    ligne_20_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        dep_non_liees = row['DEP_EXT_NON_LIE_FR'] + row['DEP_EXT_NON_LIE_ETR']\n",
    "        plafond_restant = min(row['LIGNE_18_CALC'] - row['LIGNE_19_CALC'], 10000000)\n",
    "        ligne_20_values.append(min(dep_non_liees, plafond_restant))\n",
    "    calc_columns['LIGNE_20_CALC'] = np.array(ligne_20_values)\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_20_CALC'] = calc_columns['LIGNE_20_CALC']\n",
    "\n",
    "    # Ligne 21: Total après plafonnements\n",
    "    ligne_21_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        ligne_21_values.append(min(row['LIGNE_19_CALC'] + row['LIGNE_20_CALC'], 10000000))\n",
    "    calc_columns['LIGNE_21_CALC'] = np.array(ligne_21_values)\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_21_CALC'] = calc_columns['LIGNE_21_CALC']\n",
    "\n",
    "    # 3. Montant total et net (Section I-C)\n",
    "\n",
    "    # Ligne 22: Total dépenses\n",
    "    calc_columns['LIGNE_22_CALC'] = df_calc_temp['LIGNE_14_CALC'] + df_calc_temp['LIGNE_21_CALC']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_22_CALC'] = calc_columns['LIGNE_22_CALC']\n",
    "\n",
    "    # Ligne 26a: Montant net\n",
    "    calc_columns['LIGNE_26A_CALC'] = df_calc_temp['LIGNE_22_CALC'] - df_tmp['MT_AID_SUBV'] - \\\n",
    "                                  df_tmp['MT_ENC_PRESTA'] - df_tmp['MT_DEP_CONSEILS_CIR'] + \\\n",
    "                                  df_tmp['REMBST_SUBV']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_26A_CALC'] = calc_columns['LIGNE_26A_CALC']\n",
    "\n",
    "    # Ligne 26b: Utiliser la valeur de MT_NET_DEP_RD_DOM directement\n",
    "    calc_columns['LIGNE_26B_CALC'] = df_tmp['MT_NET_DEP_RD_DOM']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_26B_CALC'] = calc_columns['LIGNE_26B_CALC']\n",
    "\n",
    "    ## II - DÉPENSES DE COLLECTION OUVRANT DROIT AU CRÉDIT D'IMPÔT (CIR-COLLECTION)\n",
    "    ## ANNÉE CIVILE 2023\n",
    "\n",
    "    # Ligne 28: Frais de défense des dessins et modèles (plafond 60 000 €)\n",
    "    calc_columns['FRAIS_DEF_DESSIN_PLAFONNES'] = np.minimum(df_tmp['FRAIS_DEF_DESSIN'], 60000)\n",
    "\n",
    "    # Ligne 29: Total des dépenses de collection\n",
    "    calc_columns['LIGNE_29_CALC'] = df_tmp['FRAIS_COLL'] + calc_columns['FRAIS_DEF_DESSIN_PLAFONNES']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_29_CALC'] = calc_columns['LIGNE_29_CALC']\n",
    "\n",
    "    # Ligne 33a: Montant net des dépenses de collection\n",
    "    calc_columns['LIGNE_33A_CALC'] = df_calc_temp['LIGNE_29_CALC'] - df_tmp['MT_AID_SUBV_COLL'] - \\\n",
    "                                  df_tmp['MT_DEP_CONSEILS_CIR_COLL'] + df_tmp['REMBST_SUBV_COLL']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_33A_CALC'] = calc_columns['LIGNE_33A_CALC']\n",
    "\n",
    "    # Ligne 33b: Utiliser la valeur de MT_NET_DEP_COLL_DOM directement\n",
    "    calc_columns['LIGNE_33B_CALC'] = df_tmp['MT_NET_DEP_COLL_DOM']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_33B_CALC'] = calc_columns['LIGNE_33B_CALC']\n",
    "\n",
    "    # Ligne 34a: Montant net total des dépenses de recherche et de collection\n",
    "    calc_columns['LIGNE_34A_CALC'] = df_calc_temp['LIGNE_26A_CALC'] + df_calc_temp['LIGNE_33A_CALC']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_34A_CALC'] = calc_columns['LIGNE_34A_CALC']\n",
    "\n",
    "    # Ligne 34b: Montant net total des dépenses de recherche et de collection DOM\n",
    "    calc_columns['LIGNE_34B_CALC'] = df_calc_temp['LIGNE_26B_CALC'] + df_calc_temp['LIGNE_33B_CALC']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_34B_CALC'] = calc_columns['LIGNE_34B_CALC']\n",
    "\n",
    "    ## V - DÉPENSES DE RECHERCHE COLLABORATIVE (CRC)\n",
    "    ## ANNÉE CIVILE 2023\n",
    "\n",
    "    # Vérifier si données disponibles pour la recherche collaborative\n",
    "    if all(col in df_tmp.columns for col in ['DEP_CRC', 'DEP_CRC_FR', 'DEP_CRC_ETR']):\n",
    "        # Dépenses éligibles\n",
    "        calc_columns['LIGNE_83_CALC'] = df_tmp['DEP_CRC_FR'] + df_tmp['DEP_CRC_ETR']\n",
    "\n",
    "        # Plafonnement à 6 000 000 €\n",
    "        calc_columns['LIGNE_84_CALC'] = np.minimum(calc_columns['LIGNE_83_CALC'], 6000000)\n",
    "\n",
    "        # Montant net des dépenses de recherche collaborative\n",
    "        calc_columns['MT_NET_DEP_CRC_CALC'] = calc_columns['LIGNE_84_CALC'] - df_tmp['AIDE_PUB_CRC'] + \\\n",
    "                                          df_tmp['AIDE_PUB_REMB_CRC']\n",
    "\n",
    "        # CRC selon les taux\n",
    "        calc_columns['LIGNE_89_CALC'] = ((calc_columns['MT_NET_DEP_CRC_CALC'] - df_tmp['MT_NET_DEP_CRC_PME']) * 0.4) + \\\n",
    "                                     (df_tmp['MT_NET_DEP_CRC_PME'] * 0.5)\n",
    "\n",
    "        calc_columns['CIR_COLLAB_RECALCULE'] = calc_columns['LIGNE_89_CALC']\n",
    "        calc_columns['LIGNE_86'] = calc_columns['MT_NET_DEP_CRC_CALC']  # Changé de LIGNE_87 à LIGNE_86 pour 2023\n",
    "    else:\n",
    "        # Si données non disponibles, mettre à 0\n",
    "        calc_columns['CIR_COLLAB_RECALCULE'] = np.zeros(len(df_tmp))\n",
    "        calc_columns['LIGNE_86'] = np.zeros(len(df_tmp))  # Changé de LIGNE_87 à LIGNE_86 pour 2023\n",
    "        calc_columns['LIGNE_89_CALC'] = np.zeros(len(df_tmp))\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    for col in ['CIR_COLLAB_RECALCULE', 'LIGNE_86', 'LIGNE_89_CALC']:  # Changé de LIGNE_87 à LIGNE_86 pour 2023\n",
    "        if col in calc_columns:\n",
    "            df_calc_temp[col] = calc_columns[col]\n",
    "\n",
    "    ## III - CALCUL DU CRÉDIT D'IMPÔT AU TITRE DES DÉPENSES DE RECHERCHE ET DE COLLECTION\n",
    "\n",
    "    # Identifier les entreprises <= 100M€ en utilisant la somme ligne 34a + ligne 86\n",
    "    calc_columns['DEPENSES_MOINS_100M'] = (df_calc_temp['LIGNE_34A_CALC'] + df_calc_temp['LIGNE_86']) <= 100000000  # Changé de LIGNE_87 à LIGNE_86 pour 2023\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['DEPENSES_MOINS_100M'] = calc_columns['DEPENSES_MOINS_100M']\n",
    "\n",
    "    # A. Dépenses <= 100 000 000 €\n",
    "\n",
    "    # CIR Recherche pour entreprises <= 100M€\n",
    "    ligne_36_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        if row['DEPENSES_MOINS_100M']:\n",
    "            ligne_36_values.append((row['LIGNE_26A_CALC'] - row['LIGNE_26B_CALC']) * 0.3 +\n",
    "                      row['LIGNE_26B_CALC'] * 0.5)\n",
    "        else:\n",
    "            ligne_36_values.append(0)\n",
    "    calc_columns['LIGNE_36_CALC'] = np.array(ligne_36_values)\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_36_CALC'] = calc_columns['LIGNE_36_CALC']\n",
    "\n",
    "    # Ligne 37: Quote-part de crédit d'impôt résultant de la participation sociétés de personnes\n",
    "    calc_columns['LIGNE_37'] = df_tmp['MT_QP_CIR_RECU']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_37'] = calc_columns['LIGNE_37']\n",
    "\n",
    "    # Calcul ligne 38a: Montant du crédit d'impôt pour dépenses de recherche\n",
    "    calc_columns['LIGNE_38A_CALC'] = df_calc_temp['LIGNE_36_CALC'] + 0 #df_calc_temp['LIGNE_37'] quote-part à 0 en 2023\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_38A_CALC'] = calc_columns['LIGNE_38A_CALC']\n",
    "\n",
    "    # Calcul ligne 38b: Montant du CIR pour dépenses de recherche DOM\n",
    "    calc_columns['LIGNE_38B_CALC'] = df_calc_temp['LIGNE_26B_CALC'] * 0.5  # Taux de 50% pour DOM\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_38B_CALC'] = calc_columns['LIGNE_38B_CALC']\n",
    "\n",
    "    # CIR Collection pour entreprises <= 100M€ (avant plafond de minimis)\n",
    "    ligne_40_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        if row['DEPENSES_MOINS_100M']:\n",
    "            ligne_40_values.append((row['LIGNE_33A_CALC'] - row['LIGNE_33B_CALC']) * 0.3 +\n",
    "                      row['LIGNE_33B_CALC'] * 0.5)\n",
    "        else:\n",
    "            ligne_40_values.append(0)\n",
    "    calc_columns['LIGNE_40_CALC'] = np.array(ligne_40_values)\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_40_CALC'] = calc_columns['LIGNE_40_CALC']\n",
    "\n",
    "    # Ligne 41: Quote-part de crédit d'impôt collection résultant de la participation sociétés de personnes\n",
    "    calc_columns['LIGNE_41'] = df_tmp['MT_QP_COLL_RECU_MOINS_DE100']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_41'] = calc_columns['LIGNE_41']\n",
    "\n",
    "    # Calcul ligne 42a: Montant total du crédit d'impôt pour dépenses de collection avant plafonnement\n",
    "    calc_columns['LIGNE_42A_CALC'] = df_calc_temp['LIGNE_40_CALC'] + 0 #df_calc_temp['LIGNE_41']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_42A_CALC'] = calc_columns['LIGNE_42A_CALC']\n",
    "\n",
    "    # Calcul ligne 42b: Montant du crédit collection DOM avant plafonnement\n",
    "    calc_columns['LIGNE_42B_CALC'] = df_calc_temp['LIGNE_33B_CALC'] * 0.5  # Taux de 50% pour DOM\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_42B_CALC'] = calc_columns['LIGNE_42B_CALC']\n",
    "\n",
    "    # Ligne 43: Montant des aides de minimis\n",
    "    calc_columns['LIGNE_43'] = df_tmp['MT_AIDE_MINIMI_MOINS_DE100']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_43'] = calc_columns['LIGNE_43']\n",
    "\n",
    "    # Calcul ligne 44: Montant cumulé du crédit d'impôt et des aides de minimis\n",
    "    calc_columns['LIGNE_44'] = df_calc_temp['LIGNE_42A_CALC'] + df_calc_temp['LIGNE_43']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_44'] = calc_columns['LIGNE_44']\n",
    "\n",
    "    # Calcul ligne 45a: Montant du crédit d'impôt pour dépenses de collection après plafonnement\n",
    "    ligne_45a_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        if row['LIGNE_43'] >= 200000:  # Si aides de minimis déjà à 200k€\n",
    "            ligne_45a_values.append(0)\n",
    "        elif row['LIGNE_44'] < 200000:  # Si cumul < 200k€\n",
    "            ligne_45a_values.append(row['LIGNE_42A_CALC'])\n",
    "        else:  # Si dépassement\n",
    "            ligne_45a_values.append(200000 - row['LIGNE_43'])\n",
    "    calc_columns['LIGNE_45A_CALC'] = np.array(ligne_45a_values)\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_45A_CALC'] = calc_columns['LIGNE_45A_CALC']\n",
    "\n",
    "    # ligne 45b: Montant du crédit collection DOM après plafonnement\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_45B_CALC'] = df_tmp['MT_CI_COLL_APRS_MINIMI_DOM']\n",
    "\n",
    "    # Calcul ligne 46a: Montant total du crédit d'impôt au titre des dépenses de recherche et de collection\n",
    "    calc_columns['LIGNE_46A_CALC'] = df_calc_temp['LIGNE_38A_CALC'] + df_calc_temp['LIGNE_45A_CALC']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_46A_CALC'] = calc_columns['LIGNE_46A_CALC']\n",
    "\n",
    "    # Calcul ligne 46b: Montant du crédit d'impôt recherche et collection exposées dans DOM\n",
    "    calc_columns['LIGNE_46B_CALC'] = df_calc_temp['LIGNE_38B_CALC'] + df_calc_temp['LIGNE_45B_CALC']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_46B_CALC'] = calc_columns['LIGNE_46B_CALC']\n",
    "\n",
    "    # B. Dépenses > 100 000 000 €\n",
    "\n",
    "    # Identifier les entreprises > 100M€\n",
    "    calc_columns['DEPENSES_PLUS_100M'] = ~df_calc_temp['DEPENSES_MOINS_100M']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['DEPENSES_PLUS_100M'] = calc_columns['DEPENSES_PLUS_100M']\n",
    "\n",
    "    # Limiter les dépenses à 100M€ - dépenses recherche collaborative\n",
    "    ligne_47a_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        if row['DEPENSES_PLUS_100M']:\n",
    "            ligne_47a_values.append(min(row['LIGNE_26A_CALC'], 100000000 - row['LIGNE_86']))  # Changé de LIGNE_87 à LIGNE_86 pour 2023\n",
    "        else:\n",
    "            ligne_47a_values.append(0)\n",
    "    calc_columns['LIGNE_47A_CALC'] = np.array(ligne_47a_values)\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_47A_CALC'] = calc_columns['LIGNE_47A_CALC']\n",
    "\n",
    "    # Proportion DOM dans la limite des 100M€ (ligne 47b)\n",
    "    ligne_47b_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        if row['DEPENSES_PLUS_100M']:\n",
    "            ligne_47b_values.append(min(row['LIGNE_26B_CALC'], 100000000 - row['LIGNE_86']))  # Changé de LIGNE_87 à LIGNE_86 pour 2023\n",
    "        else:\n",
    "            ligne_47b_values.append(0)\n",
    "    calc_columns['LIGNE_47B_CALC'] = np.array(ligne_47b_values)\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_47B_CALC'] = calc_columns['LIGNE_47B_CALC']\n",
    "\n",
    "    # Calcul CIR recherche première tranche (ligne 48)\n",
    "    ligne_48_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        if row['DEPENSES_PLUS_100M']:\n",
    "            ligne_48_values.append((row['LIGNE_47A_CALC'] - row['LIGNE_47B_CALC']) * 0.3 +\n",
    "                           row['LIGNE_47B_CALC'] * 0.5)\n",
    "        else:\n",
    "            ligne_48_values.append(0)\n",
    "    calc_columns['LIGNE_48_CALC'] = np.array(ligne_48_values)\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_48_CALC'] = calc_columns['LIGNE_48_CALC']\n",
    "\n",
    "    # Dépenses > 100M€ (ligne 49)\n",
    "    ligne_49_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        if row['DEPENSES_PLUS_100M']:\n",
    "            ligne_49_values.append(max(0, row['LIGNE_26A_CALC'] - (100000000 - row['LIGNE_86'])))  # Changé de LIGNE_87 à LIGNE_86 pour 2023\n",
    "        else:\n",
    "            ligne_49_values.append(0)\n",
    "    calc_columns['LIGNE_49_CALC'] = np.array(ligne_49_values)\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_49_CALC'] = calc_columns['LIGNE_49_CALC']\n",
    "\n",
    "    # CIR recherche deuxième tranche (au-delà de 100M€) (ligne 50)\n",
    "    calc_columns['LIGNE_50_CALC'] = df_calc_temp['LIGNE_49_CALC'] * 0.05\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_50_CALC'] = calc_columns['LIGNE_50_CALC']\n",
    "\n",
    "    # CIR recherche total pour entreprises > 100M€ (ligne 51)\n",
    "    calc_columns['LIGNE_51_CALC'] = df_calc_temp['LIGNE_48_CALC'] + df_calc_temp['LIGNE_50_CALC']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_51_CALC'] = calc_columns['LIGNE_51_CALC']\n",
    "\n",
    "    # Ligne 52: Quote-part de crédit d'impôt recherche résultant de la participation sociétés de personnes\n",
    "    calc_columns['LIGNE_52'] = df_tmp['MT_QP_CIR_RECU_BIS']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_52'] = calc_columns['LIGNE_52']\n",
    "\n",
    "    # Calcul ligne 53a: Montant du crédit d'impôt pour dépenses de recherche >100M€\n",
    "    calc_columns['LIGNE_53A_CALC'] = df_calc_temp['LIGNE_51_CALC'] + 0 #df_calc_temp['LIGNE_52'] quote-part à 0 en 2023\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_53A_CALC'] = calc_columns['LIGNE_53A_CALC']\n",
    "\n",
    "    # Calcul ligne 53b: Montant du crédit d'impôt pour dépenses de recherche DOM >100M€\n",
    "    # Comme pour 38b, c'est 50% des dépenses DOM dans la limite du plafond\n",
    "    calc_columns['LIGNE_53B_CALC'] = df_calc_temp['LIGNE_47B_CALC'] * 0.5\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_53B_CALC'] = calc_columns['LIGNE_53B_CALC']\n",
    "\n",
    "    # Calcul CIR collection pour entreprises > 100M€\n",
    "\n",
    "    # Ligne 54a: Montant net total des dépenses de collection\n",
    "    calc_columns['LIGNE_54A_CALC'] = df_calc_temp['LIGNE_33A_CALC']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_54A_CALC'] = calc_columns['LIGNE_54A_CALC']\n",
    "\n",
    "    # Ligne 54b: Montant net total des dépenses de collection DOM\n",
    "    calc_columns['LIGNE_54B_CALC'] = df_calc_temp['LIGNE_33B_CALC']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_54B_CALC'] = calc_columns['LIGNE_54B_CALC']\n",
    "\n",
    "    # Plafond disponible après dépenses recherche (ligne 55)\n",
    "    ligne_55_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        if row['DEPENSES_PLUS_100M']:\n",
    "            ligne_55_values.append(max(0, 100000000 - row['LIGNE_86'] - row['LIGNE_47A_CALC']))  # Changé de LIGNE_87 à LIGNE_86 pour 2023\n",
    "        else:\n",
    "            ligne_55_values.append(0)\n",
    "    calc_columns['LIGNE_55_CALC'] = np.array(ligne_55_values)\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_55_CALC'] = calc_columns['LIGNE_55_CALC']\n",
    "\n",
    "    # CIR collection première tranche (ligne 56)\n",
    "    ligne_56_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        if row['DEPENSES_PLUS_100M']:\n",
    "            dep_coll_plaf = min(row['LIGNE_54A_CALC'], row['LIGNE_55_CALC'])\n",
    "            dep_coll_dom_plaf = min(row['LIGNE_54B_CALC'], row['LIGNE_55_CALC'])\n",
    "            ligne_56_values.append((dep_coll_plaf - dep_coll_dom_plaf) * 0.3 + dep_coll_dom_plaf * 0.5)\n",
    "        else:\n",
    "            ligne_56_values.append(0)\n",
    "    calc_columns['LIGNE_56_CALC'] = np.array(ligne_56_values)\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_56_CALC'] = calc_columns['LIGNE_56_CALC']\n",
    "\n",
    "    # CIR collection deuxième tranche (ligne 57)\n",
    "    ligne_57_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        if row['DEPENSES_PLUS_100M']:\n",
    "            ligne_57_values.append(max(0, row['LIGNE_54A_CALC'] - row['LIGNE_55_CALC']) * 0.05)\n",
    "        else:\n",
    "            ligne_57_values.append(0)\n",
    "    calc_columns['LIGNE_57_CALC'] = np.array(ligne_57_values)\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_57_CALC'] = calc_columns['LIGNE_57_CALC']\n",
    "\n",
    "    # CIR collection avant plafonnement de minimis (ligne 58)\n",
    "    calc_columns['LIGNE_58_CALC'] = df_calc_temp['LIGNE_56_CALC'] + df_calc_temp['LIGNE_57_CALC']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_58_CALC'] = calc_columns['LIGNE_58_CALC']\n",
    "\n",
    "    # Ligne 59: Quote-part de crédit d'impôt collection résultant de la participation sociétés de personnes\n",
    "    calc_columns['LIGNE_59'] = df_tmp['MT_QP_COLL_RECU_BIS']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_59'] = calc_columns['LIGNE_59']\n",
    "\n",
    "    # Ligne 60: Montant du crédit d'impôt collection avant plafonnement de minimis\n",
    "    calc_columns['LIGNE_60'] = df_calc_temp['LIGNE_58_CALC'] + 0 #df_calc_temp['LIGNE_59'] quote-part à 0 en 2023\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_60'] = calc_columns['LIGNE_60']\n",
    "\n",
    "    # Ligne 61: Montant des aides de minimis\n",
    "    calc_columns['LIGNE_61'] = df_tmp['MT_AIDE_MINIMI_COLL']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_61'] = calc_columns['LIGNE_61']\n",
    "\n",
    "    # Ligne 62: Montant cumulé du crédit d'impôt et des aides de minimis\n",
    "    calc_columns['LIGNE_62'] = df_calc_temp['LIGNE_60'] + df_calc_temp['LIGNE_61']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_62'] = calc_columns['LIGNE_62']\n",
    "\n",
    "    # Ligne 63a: Montant du crédit d'impôt pour dépenses de collection après plafonnement\n",
    "    ligne_63a_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        if row['LIGNE_61'] >= 200000:  # Si aides de minimis déjà à 200k€\n",
    "            ligne_63a_values.append(0)\n",
    "        elif row['LIGNE_62'] < 200000:  # Si cumul < 200k€\n",
    "            ligne_63a_values.append(row['LIGNE_60'])\n",
    "        else:  # Si dépassement\n",
    "            ligne_63a_values.append(200000 - row['LIGNE_61'])\n",
    "    calc_columns['LIGNE_63A_CALC'] = np.array(ligne_63a_values)\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_63A_CALC'] = calc_columns['LIGNE_63A_CALC']\n",
    "\n",
    "    # Ligne 63b: Montant du crédit d'impôt pour dépenses de collection DOM après plafonnement\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_63B_CALC'] = df_tmp['MT_CI_COLL_APRES_MINIMI_PLUS_DE100_DOM']\n",
    "\n",
    "    # Ligne 64a: Montant total du crédit d'impôt au titre des dépenses de recherche et de collection\n",
    "    calc_columns['LIGNE_64A_CALC'] = df_calc_temp['LIGNE_53A_CALC'] + df_calc_temp['LIGNE_63A_CALC']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_64A_CALC'] = calc_columns['LIGNE_64A_CALC']\n",
    "\n",
    "    # Ligne 64b: Montant du crédit d'impôt recherche et collection exposées dans DOM\n",
    "    calc_columns['LIGNE_64B_CALC'] = df_calc_temp['LIGNE_53B_CALC'] + df_calc_temp['LIGNE_63B_CALC']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_64B_CALC'] = calc_columns['LIGNE_64B_CALC']\n",
    "\n",
    "    # Somme du CIR recherche selon le cas (<=100M€ ou >100M€)\n",
    "    cir_recherche_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        if row['DEPENSES_MOINS_100M']:\n",
    "            cir_recherche_values.append(row['LIGNE_38A_CALC'])\n",
    "        else:\n",
    "            cir_recherche_values.append(row['LIGNE_53A_CALC'])\n",
    "    calc_columns['CIR_RECHERCHE_RECALCULE'] = np.array(cir_recherche_values)\n",
    "\n",
    "    # Somme du CIR collection après plafonnement de minimis selon le cas\n",
    "    cir_collection_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        if row['DEPENSES_MOINS_100M']:\n",
    "            cir_collection_values.append(row['LIGNE_45A_CALC'])\n",
    "        else:\n",
    "            cir_collection_values.append(row['LIGNE_63A_CALC'])\n",
    "    calc_columns['CIR_COLLECTION_RECALCULE'] = np.array(cir_collection_values)\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    for col in ['CIR_RECHERCHE_RECALCULE', 'CIR_COLLECTION_RECALCULE']:\n",
    "        df_calc_temp[col] = calc_columns[col]\n",
    "\n",
    "    ## IV - DÉPENSES D'INNOVATION (CIR-INNOVATION)\n",
    "    ## ANNÉE CIVILE 2023\n",
    "    \n",
    "    # Vérifier si les données d'innovation sont disponibles\n",
    "    if all(col in df_tmp.columns for col in ['DOT_AMORT_IMMO_INO', 'DEP_PERSONEL_INO']):\n",
    "        # Total dépenses d'innovation\n",
    "        # Modification par rapport à 2022 : pas de calcul des autres dépenses de fonctionnement (ligne 67 en 2022)\n",
    "        # En 2023, les dépenses sont directement déclarées\n",
    "        calc_columns['LIGNE_71_CALC'] = df_tmp['DOT_AMORT_IMMO_INO'] + df_tmp['DEP_PERSONEL_INO'] + \\\n",
    "                                     df_tmp['FRAIS_BREV_COV_INO'] + df_tmp['FRAIS_DEF_BREV_INO'] + \\\n",
    "                                     df_tmp['OP_INOV_EXT']\n",
    "\n",
    "        # Plafonnement à 400 000 €\n",
    "        calc_columns['LIGNE_72_CALC'] = np.minimum(calc_columns['LIGNE_71_CALC'], 400000)\n",
    "\n",
    "        # Montant net des dépenses d'innovation\n",
    "        calc_columns['LIGNE_77A_CALC'] = calc_columns['LIGNE_72_CALC'] - df_tmp['MT_AID_SUBV_INO'] - \\\n",
    "                                       df_tmp['MT_ENC_PRESTA_INO'] - df_tmp['MT_DEP_CONSEILS_CII'] + \\\n",
    "                                       df_tmp['REMBST_SUBV_INO']\n",
    "\n",
    "        # Calcul des parts DOM et Corse\n",
    "        calc_columns['LIGNE_77B_CALC'] = df_tmp['MT_NET_DEP_INO_DOM']\n",
    "        calc_columns['LIGNE_77C_CALC'] = df_tmp['MT_NET_DEP_INO_MPE_CORSE']\n",
    "        calc_columns['LIGNE_77D_CALC'] = df_tmp['MT_NET_DEP_INO_ME_CORSE']\n",
    "\n",
    "        # Mise à jour du DataFrame temporaire\n",
    "        for col in ['LIGNE_71_CALC', 'LIGNE_72_CALC', 'LIGNE_77A_CALC',\n",
    "                    'LIGNE_77B_CALC', 'LIGNE_77C_CALC', 'LIGNE_77D_CALC']:\n",
    "            df_calc_temp[col] = calc_columns[col]\n",
    "\n",
    "        # CIR Innovation selon les taux - changement pour 2023 : taux passé de 20% à 30%\n",
    "        calc_columns['LIGNE_78_CALC'] = ((df_calc_temp['LIGNE_77A_CALC'] - df_calc_temp['LIGNE_77B_CALC'] -\n",
    "                                      df_calc_temp['LIGNE_77C_CALC'] - df_calc_temp['LIGNE_77D_CALC']) * 0.3) + \\\n",
    "                                     (df_calc_temp['LIGNE_77B_CALC'] * 0.6) + \\\n",
    "                                     (df_calc_temp['LIGNE_77C_CALC'] * 0.4) + \\\n",
    "                                     (df_calc_temp['LIGNE_77D_CALC'] * 0.35)\n",
    "\n",
    "        # Ligne 79: Quote-part de crédit d'impôt innovation résultant de la participation sociétés de personnes\n",
    "        calc_columns['LIGNE_79'] = df_tmp['MT_QP_CII']\n",
    "\n",
    "        # Ligne 80a: Montant total du crédit d'impôt au titre des dépenses d'innovation\n",
    "        calc_columns['LIGNE_80A_CALC'] = calc_columns['LIGNE_78_CALC'] + 0 #calc_columns['LIGNE_79'] on remplace quote part par 0 pour 2023\n",
    "\n",
    "        # Ligne 80b: Montant du crédit d'impôt pour dépenses d'innovation DOM\n",
    "        calc_columns['LIGNE_80B_CALC'] = df_tmp['MT_CII_YC_QP_DOM']\n",
    "\n",
    "        # Ligne 80c: Montant du crédit d'impôt pour dépenses d'innovation Corse\n",
    "        calc_columns['LIGNE_80C_CALC'] = df_tmp['MT_CII_CORSE']\n",
    "\n",
    "        calc_columns['CIR_INNOVATION_RECALCULE'] = calc_columns['LIGNE_80A_CALC']\n",
    "    else:\n",
    "        # Si données non disponibles, mettre à 0 (afin d'éviter des erreurs)\n",
    "        calc_columns['CIR_INNOVATION_RECALCULE'] = np.zeros(len(df_tmp))\n",
    "        calc_columns['LIGNE_78_CALC'] = np.zeros(len(df_tmp))\n",
    "        calc_columns['LIGNE_79'] = np.zeros(len(df_tmp))\n",
    "        calc_columns['LIGNE_80A_CALC'] = np.zeros(len(df_tmp))\n",
    "        calc_columns['LIGNE_80B_CALC'] = np.zeros(len(df_tmp))\n",
    "        calc_columns['LIGNE_80C_CALC'] = np.zeros(len(df_tmp))\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    for col in ['CIR_INNOVATION_RECALCULE', 'LIGNE_78_CALC', 'LIGNE_79', 'LIGNE_80A_CALC',\n",
    "               'LIGNE_80B_CALC', 'LIGNE_80C_CALC']:\n",
    "        if col in calc_columns:\n",
    "            df_calc_temp[col] = calc_columns[col]\n",
    "\n",
    "    # Ligne 81a: Montant total du crédit d'impôt au titre des dépenses de recherche, de collection et d'innovation\n",
    "    ligne_81a_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        if row['DEPENSES_MOINS_100M']:\n",
    "            ligne_81a_values.append(row['LIGNE_46A_CALC'] + row['LIGNE_80A_CALC'])\n",
    "        else:\n",
    "            ligne_81a_values.append(row['LIGNE_64A_CALC'] + row['LIGNE_80A_CALC'])\n",
    "    calc_columns['LIGNE_81A_CALC'] = np.array(ligne_81a_values)\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_81A_CALC'] = calc_columns['LIGNE_81A_CALC']\n",
    "\n",
    "    # Ligne 81b: Montant du crédit d'impôt recherche, collection et innovation DOM\n",
    "    ligne_81b_values = []\n",
    "    for _, row in df_calc_temp.iterrows():\n",
    "        if row['DEPENSES_MOINS_100M']:\n",
    "            ligne_81b_values.append(row['LIGNE_46B_CALC'] + row['LIGNE_80B_CALC'])\n",
    "        else:\n",
    "            ligne_81b_values.append(row['LIGNE_64B_CALC'] + row['LIGNE_80B_CALC'])\n",
    "    calc_columns['LIGNE_81B_CALC'] = np.array(ligne_81b_values)\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_81B_CALC'] = calc_columns['LIGNE_81B_CALC']\n",
    "\n",
    "    # Calcul ligne 90: Quote-part de crédit d'impôt résultant de la participation sociétés de personnes\n",
    "    calc_columns['LIGNE_90'] = df_tmp['QP_MT_CRC']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_90'] = 0 #calc_columns['LIGNE_90'] on remplace quote part par 0 pour 2023\n",
    "\n",
    "    # Calcul ligne 91: Montant total du crédit d'impôt au titre des dépenses de recherche collaborative\n",
    "    calc_columns['LIGNE_91_CALC'] = df_calc_temp['LIGNE_89_CALC'] + df_calc_temp['LIGNE_90']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['LIGNE_91_CALC'] = calc_columns['LIGNE_91_CALC']\n",
    "\n",
    "    ## TOTAL DU CRÉDIT D'IMPÔT FINAL (CIR + CII + CRC)\n",
    "\n",
    "    # Initialiser le total avec les composantes Recherche et Collection\n",
    "    calc_columns['CIR_TOTAL_RECALCULE'] = calc_columns['CIR_RECHERCHE_RECALCULE'] + \\\n",
    "                                          calc_columns['CIR_COLLECTION_RECALCULE']\n",
    "\n",
    "    # Ajouter la composante Innovation (CII) si elle a été calculée\n",
    "    if 'CIR_INNOVATION_RECALCULE' in calc_columns:\n",
    "        # S'assurer que la valeur n'est pas NaN avant d'ajouter\n",
    "        calc_columns['CIR_TOTAL_RECALCULE'] += np.nan_to_num(calc_columns['CIR_INNOVATION_RECALCULE'])\n",
    "\n",
    "    # Ajouter la composante Collaborative (CRC) TOTALE (Ligne 91)\n",
    "    if 'LIGNE_91_CALC' in calc_columns:\n",
    "        # S'assurer que la valeur n'est pas NaN avant d'ajouter\n",
    "        calc_columns['CIR_TOTAL_RECALCULE'] += np.nan_to_num(calc_columns['LIGNE_91_CALC'])\n",
    "\n",
    "    # Mettre à jour le DataFrame temporaire\n",
    "    if 'CIR_TOTAL_RECALCULE' not in df_calc_temp.columns:\n",
    "         df_calc_temp['CIR_TOTAL_RECALCULE'] = 0 \n",
    "    df_calc_temp['CIR_TOTAL_RECALCULE'] = calc_columns['CIR_TOTAL_RECALCULE']\n",
    "\n",
    "    # ANALYSE DES ÉCARTS\n",
    "\n",
    "    # Écarts sur toutes les lignes recalculées\n",
    "    # 1. Dépenses internes\n",
    "    calc_columns['ECART_LIGNE_6'] = calc_columns['LIGNE_6_CALC'] - df_tmp['OTR_DEP_FONCT']\n",
    "    calc_columns['ECART_LIGNE_7'] = calc_columns['LIGNE_7_CALC'] - df_tmp['MT_DEP_FONCT_TOT']\n",
    "    calc_columns['ECART_LIGNE_14'] = calc_columns['LIGNE_14_CALC'] - df_tmp['MT_TOT_RD_1']\n",
    "\n",
    "    # 2. Dépenses externalisées\n",
    "    calc_columns['ECART_LIGNE_17'] = calc_columns['LIGNE_17_CALC'] - df_tmp['MT_TOT_DEP_EXT_ORG_AGREE']\n",
    "    calc_columns['ECART_LIGNE_18'] = calc_columns['LIGNE_18_CALC'] - df_tmp['PLAF_OP_EXT']\n",
    "    calc_columns['ECART_LIGNE_19'] = calc_columns['LIGNE_19_CALC'] - df_tmp['PLAF_OP_EXT_ORG_AGRE_LIE']\n",
    "    calc_columns['ECART_LIGNE_20'] = calc_columns['LIGNE_20_CALC'] - df_tmp['PLAF_OP_EXT_ORG_AGRE_NON_LIE']\n",
    "    calc_columns['ECART_LIGNE_21'] = calc_columns['LIGNE_21_CALC'] - df_tmp['MT_DEP_EXT_PLAF']\n",
    "\n",
    "    # 3. Montant total et net\n",
    "    calc_columns['ECART_LIGNE_22'] = calc_columns['LIGNE_22_CALC'] - df_tmp['MT_TOT_RD_2']\n",
    "    calc_columns['ECART_LIGNE_26A'] = calc_columns['LIGNE_26A_CALC'] - df_tmp['MT_NET_DEP_RD']\n",
    "    calc_columns['ECART_LIGNE_26B'] = calc_columns['LIGNE_26B_CALC'] - df_tmp['MT_NET_DEP_RD_DOM']\n",
    "\n",
    "    # 4. Dépenses de collection\n",
    "    calc_columns['ECART_LIGNE_29'] = calc_columns['LIGNE_29_CALC'] - df_tmp['MT_TOT_DEP_COLL']\n",
    "    calc_columns['ECART_LIGNE_33A'] = calc_columns['LIGNE_33A_CALC'] - df_tmp['MT_NET_DEP_COLL']\n",
    "    calc_columns['ECART_LIGNE_33B'] = calc_columns['LIGNE_33B_CALC'] - df_tmp['MT_NET_DEP_COLL_DOM']\n",
    "\n",
    "    # 5. Innovation\n",
    "    if all(col in df_tmp.columns for col in ['MT_TOT_DEP_INO', 'MT_TOT_DEP_INO_PLAF', 'MT_NET_DEP_INO']):\n",
    "        calc_columns['ECART_LIGNE_71'] = calc_columns['LIGNE_71_CALC'] - df_tmp['MT_TOT_DEP_INO']\n",
    "        calc_columns['ECART_LIGNE_72'] = calc_columns['LIGNE_72_CALC'] - df_tmp['MT_TOT_DEP_INO_PLAF']\n",
    "        calc_columns['ECART_LIGNE_77A'] = calc_columns['LIGNE_77A_CALC'] - df_tmp['MT_NET_DEP_INO']\n",
    "\n",
    "    # 6. Collaboratif\n",
    "    if all(col in df_tmp.columns for col in ['DEP_CRC_PLAF', 'MT_NET_DEP_CRC']):\n",
    "        calc_columns['ECART_LIGNE_84'] = calc_columns['LIGNE_84_CALC'] - df_tmp['DEP_CRC_PLAF']\n",
    "        calc_columns['ECART_MT_NET_DEP_CRC'] = calc_columns['MT_NET_DEP_CRC_CALC'] - df_tmp['MT_NET_DEP_CRC']\n",
    "\n",
    "    # 7. Crédits d'impôt\n",
    "    calc_columns['ECART_CIR_RECHERCHE'] = calc_columns['CIR_RECHERCHE_RECALCULE'] - df_tmp['MT_CIR_RECH_YC_QP_MOINS_DE100']\n",
    "    calc_columns['ECART_CIR_COLLECTION'] = calc_columns['CIR_COLLECTION_RECALCULE'] - df_tmp['MT_CI_COLL_APRS_MINIMI']\n",
    "\n",
    "    if 'CIR_INNOVATION_RECALCULE' in df_calc_temp.columns:\n",
    "        calc_columns['ECART_CIR_INNOVATION'] = df_calc_temp['CIR_INNOVATION_RECALCULE'] - df_tmp['MT_CII_YC_QP']\n",
    "    else:\n",
    "        calc_columns['ECART_CIR_INNOVATION'] = -df_tmp['MT_CII_YC_QP']\n",
    "\n",
    "    \"\"\"if 'CIR_COLLAB_RECALCULE' in df_calc_temp.columns:\n",
    "        calc_columns['ECART_CIR_COLLAB'] = df_calc_temp['CIR_COLLAB_RECALCULE'] - df_tmp['MT_CRC']\n",
    "    else:\n",
    "        calc_columns['ECART_CIR_COLLAB'] = -df_tmp['MT_CRC']\"\"\"\n",
    "    \n",
    "    if 'LIGNE_91_CALC' in calc_columns and 'MT_CRC' in df_tmp.columns:\n",
    "        calc_columns['ECART_CIR_COLLAB'] = calc_columns['LIGNE_91_CALC'] - df_tmp['MT_CRC']\n",
    "    elif 'LIGNE_91_CALC' in calc_columns: # Si MT_CRC n'existe pas mais qu'on a recalculé\n",
    "        calc_columns['ECART_CIR_COLLAB'] = calc_columns['LIGNE_91_CALC']\n",
    "    elif 'MT_CRC' in df_tmp.columns: # Si on a déclaré mais pas recalculé (devrait pas arriver si CRC est calculé)\n",
    "        calc_columns['ECART_CIR_COLLAB'] = -df_tmp['MT_CRC']\n",
    "    else:\n",
    "        calc_columns['ECART_CIR_COLLAB'] = 0 # Ou une autre valeur par défaut\n",
    "\n",
    "    # Écart total CIR\n",
    "    calc_columns['ECART_CIR'] = df_calc_temp['CIR_TOTAL_RECALCULE'] - df_tmp['MT_TOT_CIR_CI_COLL_CII']\n",
    "\n",
    "    # Mise à jour du DataFrame temporaire\n",
    "    df_calc_temp['ECART_CIR'] = calc_columns['ECART_CIR']\n",
    "\n",
    "    # Indicateur de correspondance (avec seuil de tolérance de 1)\n",
    "    correspondance_values = []\n",
    "    for ecart in calc_columns['ECART_CIR']:\n",
    "        if abs(ecart) <= 1:\n",
    "            correspondance_values.append(\"Oui\")\n",
    "        else:\n",
    "            correspondance_values.append(\"Non\")\n",
    "    calc_columns['CORRESPONDANCE'] = np.array(correspondance_values)\n",
    "\n",
    "    # Écart relatif\n",
    "    ecart_relatif_values = []\n",
    "    for i, row in df_calc_temp.iterrows():\n",
    "        if row['MT_TOT_CIR_CI_COLL_CII'] > 0:\n",
    "            ecart_relatif_values.append((row['ECART_CIR'] / row['MT_TOT_CIR_CI_COLL_CII'] * 100))\n",
    "        else:\n",
    "            ecart_relatif_values.append(100 if row['ECART_CIR'] > 0 else 0)\n",
    "    calc_columns['ECART_RELATIF'] = np.array(ecart_relatif_values)\n",
    "\n",
    "    # Création du DataFrame final avec toutes les colonnes calculées\n",
    "    df_calc_final = pd.DataFrame(calc_columns)\n",
    "\n",
    "    # Création du DataFrame final pour l'analyse\n",
    "    df_num = pd.concat([df_tmp, df_calc_final], axis=1)\n",
    "\n",
    "    ## CRÉATION DU FICHIER DE COMPARAISON DÉTAILLÉ\n",
    "\n",
    "    # Préparation du dictionnaire de mapping pour la sortie\n",
    "    # Structure: 'colonne_originale': 'nom_colonne_sortie'\n",
    "    mapping_colonnes = {\n",
    "        # Colonnes d'identification\n",
    "        'siren_declarant': 'SIREN_DECLARANT',\n",
    "        'siren_deposant': 'SIREN_DEPOSANT',\n",
    "        'DESIGN': 'DESIGNATION',\n",
    "        'COMPLT_DESIGN': 'COMPLEMENT_DESIGNATION',\n",
    "\n",
    "        # I-A. Dépenses internes\n",
    "        'DOT_AMORT_IMMO': 'L1_DOTATION_AMORT_IMMO',\n",
    "        'DOT_AMORT_IMMO_SINISTR': 'L2_DOTATION_AMORT_SINISTR',\n",
    "        'DEP_CHERCH_TECH': 'L3_DEPENSES_PERSONNEL_CHERCHEURS',\n",
    "        'REM_SAL_INV': 'L4_REMUNERATION_INVENTEURS',\n",
    "        'DEP_JD': 'L5_DEPENSES_JEUNES_DOCTEURS',\n",
    "        'OTR_DEP_FONCT': 'L6_AUTRES_DEP_FONCT_DECLARE',\n",
    "        'LIGNE_6_CALC': 'L6_AUTRES_DEP_FONCT_CALCULE',\n",
    "        'ECART_LIGNE_6': 'L6_ECART',\n",
    "        'MT_DEP_FONCT_TOT': 'L7_TOTAL_DEP_FONCT_DECLARE',\n",
    "        'LIGNE_7_CALC': 'L7_TOTAL_DEP_FONCT_CALCULE',\n",
    "        'ECART_LIGNE_7': 'L7_ECART',\n",
    "        'FRAIS_BREV_COV': 'L8_FRAIS_BREVETS_COV',\n",
    "        'DEP_MAINT_BREV_COV': 'L9_DEPENSES_DEFENSE_BREVETS',\n",
    "        'DOT_AMORT_BREV': 'L10_DOTATION_AMORT_BREVETS',\n",
    "        'DEP_NORMALI': 'L11_DEPENSES_NORMALISATION_BRUT',\n",
    "        'DEP_NORMALI_RECALC': 'L11_DEPENSES_NORMALISATION_DECLARE',\n",
    "        'PRIM_COTIZ': 'L12_PRIMES_COTISATIONS_BRUT',\n",
    "        'PRIM_COTIZ_PLAFONNEES': 'L12_PRIMES_COTISATIONS_PLAFONNEES',\n",
    "        'DEP_VEIL_TECHNO': 'L13_VEILLE_TECHNO_BRUT',\n",
    "        'DEP_VEIL_TECHNO_PLAFONNEES': 'L13_VEILLE_TECHNO_PLAFONNEE',\n",
    "        'MT_TOT_RD_1': 'L14_TOTAL_DEPENSES_INTERNES_DECLARE',\n",
    "        'LIGNE_14_CALC': 'L14_TOTAL_DEPENSES_INTERNES_CALCULE',\n",
    "        'ECART_LIGNE_14': 'L14_ECART',\n",
    "\n",
    "        # I-B. Dépenses externalisées\n",
    "        'DEP_EXT_LIE_FR': 'L15A_DEPENSES_ORG_LIES_FR',\n",
    "        'DEP_EXT_LIE_ETR': 'L15B_DEPENSES_ORG_LIES_ETR',\n",
    "        'DEP_EXT_NON_LIE_FR': 'L16A_DEPENSES_ORG_NON_LIES_FR',\n",
    "        'DEP_EXT_NON_LIE_ETR': 'L16B_DEPENSES_ORG_NON_LIES_ETR',\n",
    "        'MT_TOT_DEP_EXT_ORG_AGREE': 'L17_TOTAL_DEP_EXTERNALISEES_DECLARE',\n",
    "        'LIGNE_17_CALC': 'L17_TOTAL_DEP_EXTERNALISEES_CALCULE',\n",
    "        'ECART_LIGNE_17': 'L17_ECART',\n",
    "        'PLAF_OP_EXT': 'L18_PLAFOND_GLOBAL_DECLARE',\n",
    "        'LIGNE_18_CALC': 'L18_PLAFOND_GLOBAL_CALCULE',\n",
    "        'ECART_LIGNE_18': 'L18_ECART',\n",
    "        'PLAF_OP_EXT_ORG_AGRE_LIE': 'L19_PLAFOND_ORG_LIES_DECLARE',\n",
    "        'LIGNE_19_CALC': 'L19_PLAFOND_ORG_LIES_CALCULE',\n",
    "        'ECART_LIGNE_19': 'L19_ECART',\n",
    "        'PLAF_OP_EXT_ORG_AGRE_NON_LIE': 'L20_PLAFOND_ORG_NON_LIES_DECLARE',\n",
    "        'LIGNE_20_CALC': 'L20_PLAFOND_ORG_NON_LIES_CALCULE',\n",
    "        'ECART_LIGNE_20': 'L20_ECART',\n",
    "        'MT_DEP_EXT_PLAF': 'L21_TOTAL_DEP_EXT_PLAFONNEES_DECLARE',\n",
    "        'LIGNE_21_CALC': 'L21_TOTAL_DEP_EXT_PLAFONNEES_CALCULE',\n",
    "        'ECART_LIGNE_21': 'L21_ECART',\n",
    "\n",
    "        # I-C. Montant total et net\n",
    "        'MT_TOT_RD_2': 'L22_TOTAL_DEPENSES_RECHERCHE_DECLARE',\n",
    "        'LIGNE_22_CALC': 'L22_TOTAL_DEPENSES_RECHERCHE_CALCULE',\n",
    "        'ECART_LIGNE_22': 'L22_ECART',\n",
    "        'MT_AID_SUBV': 'L23A_SUBVENTIONS',\n",
    "        'MT_ENC_PRESTA': 'L23B_SOMMES_ENCAISSEES_TIERS',\n",
    "        'MT_DEP_CONSEILS_CIR': 'L24_DEPENSES_CONSEIL_CIR',\n",
    "        'REMBST_SUBV': 'L25_REMBOURSEMENTS_SUBVENTIONS',\n",
    "        'MT_NET_DEP_RD': 'L26A_MONTANT_NET_DEPENSES_DECLARE',\n",
    "        'LIGNE_26A_CALC': 'L26A_MONTANT_NET_DEPENSES_CALCULE',\n",
    "        'ECART_LIGNE_26A': 'L26A_ECART',\n",
    "        'MT_NET_DEP_RD_DOM': 'L26B_MONTANT_NET_DEPENSES_DOM_DECLARE',\n",
    "        'LIGNE_26B_CALC': 'L26B_MONTANT_NET_DEPENSES_DOM_CALCULE',\n",
    "        'ECART_LIGNE_26B': 'L26B_ECART',\n",
    "\n",
    "        # II. Dépenses de collection\n",
    "        'FRAIS_COLL': 'L27_FRAIS_COLLECTION',\n",
    "        'FRAIS_DEF_DESSIN': 'L28_FRAIS_DEFENSE_DESSINS_BRUT',\n",
    "        'FRAIS_DEF_DESSIN_PLAFONNES': 'L28_FRAIS_DEFENSE_DESSINS_PLAFONNES',\n",
    "        'MT_TOT_DEP_COLL': 'L29_TOTAL_DEPENSES_COLLECTION_DECLARE',\n",
    "        'LIGNE_29_CALC': 'L29_TOTAL_DEPENSES_COLLECTION_CALCULE',\n",
    "        'ECART_LIGNE_29': 'L29_ECART',\n",
    "        'MT_AID_SUBV_COLL': 'L30_SUBVENTIONS_COLLECTION',\n",
    "        'MT_DEP_CONSEILS_CIR_COLL': 'L31_DEPENSES_CONSEIL_COLLECTION',\n",
    "        'REMBST_SUBV_COLL': 'L32_REMBOURSEMENTS_SUBVENTIONS_COLL',\n",
    "        'MT_NET_DEP_COLL': 'L33A_MONTANT_NET_COLLECTION_DECLARE',\n",
    "        'LIGNE_33A_CALC': 'L33A_MONTANT_NET_COLLECTION_CALCULE',\n",
    "        'ECART_LIGNE_33A': 'L33A_ECART',\n",
    "        'MT_NET_DEP_COLL_DOM': 'L33B_MONTANT_NET_COLLECTION_DOM_DECLARE',\n",
    "        'LIGNE_33B_CALC': 'L33B_MONTANT_NET_COLLECTION_DOM_CALCULE',\n",
    "        'ECART_LIGNE_33B': 'L33B_ECART',\n",
    "        'LIGNE_34A_CALC': 'L34A_MONTANT_NET_TOTAL_RD_COLL',\n",
    "        'LIGNE_34B_CALC': 'L34B_MONTANT_NET_TOTAL_RD_COLL_DOM',\n",
    "\n",
    "        # III. Calcul CIR Recherche et Collection\n",
    "        'LIGNE_36_CALC': 'L36_CREDIT_IMPOT_RECHERCHE_MOINS_100M',\n",
    "        'LIGNE_37': 'L37_QUOTE_PART_RECHERCHE_SOC_PERSONNES',\n",
    "        'LIGNE_38A_CALC': 'L38A_CREDIT_IMPOT_RECHERCHE_TOTAL',\n",
    "        'LIGNE_38B_CALC': 'L38B_CREDIT_IMPOT_RECHERCHE_DOM',\n",
    "        'LIGNE_40_CALC': 'L40_CREDIT_IMPOT_COLLECTION_MOINS_100M',\n",
    "        'LIGNE_41': 'L41_QUOTE_PART_COLLECTION_SOC_PERSONNES',\n",
    "        'LIGNE_42A_CALC': 'L42A_CREDIT_IMPOT_COLL_AVANT_PLAF',\n",
    "        'LIGNE_42B_CALC': 'L42B_CREDIT_IMPOT_COLL_DOM_AVANT_PLAF',\n",
    "        'LIGNE_43': 'L43_AIDES_MINIMIS',\n",
    "        'LIGNE_44': 'L44_CUMUL_CREDIT_IMPOT_ET_AIDES',\n",
    "        'LIGNE_45A_CALC': 'L45A_CREDIT_IMPOT_COLL_APRES_PLAF',\n",
    "        'LIGNE_45B_CALC': 'L45B_CREDIT_IMPOT_COLL_DOM_APRES_PLAF',\n",
    "        'LIGNE_46A_CALC': 'L46A_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION',\n",
    "        'LIGNE_46B_CALC': 'L46B_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION_DOM',\n",
    "        'LIGNE_47A_CALC': 'L47A_DEPENSES_RECHERCHE_LIMITE_100M',\n",
    "        'LIGNE_47B_CALC': 'L47B_DEPENSES_RECHERCHE_DOM_LIMITE',\n",
    "        'LIGNE_48_CALC': 'L48_CIR_RECHERCHE_PREMIERE_TRANCHE',\n",
    "        'LIGNE_49_CALC': 'L49_DEPENSES_RECHERCHE_SUP_100M',\n",
    "        'LIGNE_50_CALC': 'L50_CIR_RECHERCHE_DEUXIEME_TRANCHE',\n",
    "        'LIGNE_51_CALC': 'L51_CIR_RECHERCHE_PLUS_100M',\n",
    "        'LIGNE_52': 'L52_QUOTE_PART_RECHERCHE_SOC_PERSONNES_PLUS_100M',\n",
    "        'LIGNE_53A_CALC': 'L53A_CREDIT_IMPOT_RECHERCHE_TOTAL_PLUS_100M',\n",
    "        'LIGNE_53B_CALC': 'L53B_CREDIT_IMPOT_RECHERCHE_DOM_PLUS_100M',\n",
    "        'LIGNE_54A_CALC': 'L54A_MONTANT_NET_COLLECTION_PLUS_100M',\n",
    "        'LIGNE_54B_CALC': 'L54B_MONTANT_NET_COLLECTION_DOM_PLUS_100M',\n",
    "        'LIGNE_55_CALC': 'L55_PLAFOND_DISPO_COLLECTION',\n",
    "        'LIGNE_56_CALC': 'L56_CIR_COLLECTION_PREMIERE_TRANCHE',\n",
    "        'LIGNE_57_CALC': 'L57_CIR_COLLECTION_DEUXIEME_TRANCHE',\n",
    "        'LIGNE_58_CALC': 'L58_CIR_COLLECTION_PLUS_100M',\n",
    "        'LIGNE_59': 'L59_QUOTE_PART_COLLECTION_SOC_PERSONNES_PLUS_100M',\n",
    "        'LIGNE_60': 'L60_CREDIT_IMPOT_COLL_AVANT_PLAF_PLUS_100M',\n",
    "        'LIGNE_61': 'L61_AIDES_MINIMIS_PLUS_100M',\n",
    "        'LIGNE_62': 'L62_CUMUL_CREDIT_IMPOT_ET_AIDES_PLUS_100M',\n",
    "        'LIGNE_63A_CALC': 'L63A_CREDIT_IMPOT_COLL_APRES_PLAF_PLUS_100M',\n",
    "        'LIGNE_63B_CALC': 'L63B_CREDIT_IMPOT_COLL_DOM_APRES_PLAF_PLUS_100M',\n",
    "        'LIGNE_64A_CALC': 'L64A_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION_PLUS_100M',\n",
    "        'LIGNE_64B_CALC': 'L64B_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION_DOM_PLUS_100M',\n",
    "\n",
    "        # IV. Dépenses d'innovation\n",
    "        'DOT_AMORT_IMMO_INO': 'L65_DOTATION_AMORT_IMMO_INNOVATION',\n",
    "        'DEP_PERSONEL_INO': 'L66_DEPENSES_PERSONNEL_INNOVATION',\n",
    "        'FRAIS_BREV_COV_INO': 'L67_FRAIS_BREVETS_INNOVATION', # Changé pour 2023\n",
    "        'FRAIS_DEF_BREV_INO': 'L68_FRAIS_DEFENSE_BREVETS_INNOVATION',\n",
    "        'OP_INOV_EXT': 'L69_OPERATIONS_CONFIEES_INNOVATION',\n",
    "        'MT_TOT_DEP_INO': 'L70_TOTAL_DEPENSES_INNOVATION_DECLARE', # Changé pour 2023 (ligne 71->70)\n",
    "        'LIGNE_71_CALC': 'L70_TOTAL_DEPENSES_INNOVATION_CALCULE', # Changé pour 2023 (ligne 71->70)\n",
    "        'ECART_LIGNE_71': 'L70_ECART', # Changé pour 2023 (ligne 71->70)\n",
    "        'MT_TOT_DEP_INO_PLAF': 'L71_DEPENSES_INNOVATION_PLAFONNEES_DECLARE', # Changé pour 2023 (ligne 72->71)\n",
    "        'LIGNE_72_CALC': 'L71_DEPENSES_INNOVATION_PLAFONNEES_CALCULE', # Changé pour 2023 (ligne 72->71)\n",
    "        'ECART_LIGNE_72': 'L71_ECART', # Changé pour 2023 (ligne 72->71)\n",
    "        'MT_AID_SUBV_INO': 'L72_SUBVENTIONS_INNOVATION', # Changé pour 2023 (ligne 73->72)\n",
    "        'MT_ENC_PRESTA_INO': 'L73_PRESTATIONS_INNOVATION', # Changé pour 2023 (ligne 74->73)\n",
    "        'MT_DEP_CONSEILS_CII': 'L74_DEPENSES_CONSEIL_INNOVATION', # Changé pour 2023 (ligne 75->74)\n",
    "        'REMBST_SUBV_INO': 'L75_REMBOURSEMENTS_SUBVENTIONS_INNO', # Changé pour 2023 (ligne 76->75)\n",
    "        'MT_NET_DEP_INO': 'L76A_MONTANT_NET_INNOVATION_DECLARE', # Changé pour 2023 (ligne 77a->76a)\n",
    "        'LIGNE_77A_CALC': 'L76A_MONTANT_NET_INNOVATION_CALCULE', # Changé pour 2023 (ligne 77a->76a)\n",
    "        'ECART_LIGNE_77A': 'L76A_ECART', # Changé pour 2023 (ligne 77a->76a)\n",
    "        'MT_NET_DEP_INO_DOM': 'L76B_MONTANT_NET_INNOVATION_DOM', # Changé pour 2023 (ligne 77b->76b)\n",
    "        'MT_NET_DEP_INO_MPE_CORSE': 'L76C_MONTANT_NET_INNOVATION_CORSE_MPE', # Changé pour 2023 (ligne 77c->76c)\n",
    "        'MT_NET_DEP_INO_ME_CORSE': 'L76D_MONTANT_NET_INNOVATION_CORSE_ME', # Changé pour 2023 (ligne 77d->76d)\n",
    "        'LIGNE_78_CALC': 'L77_CREDIT_IMPOT_INNOVATION', # Changé pour 2023 (ligne 78->77)\n",
    "        'LIGNE_79': 'L78_QUOTE_PART_INNOVATION_SOC_PERSONNES', # Changé pour 2023 (ligne 79->78)\n",
    "        'LIGNE_80A_CALC': 'L79A_TOTAL_CREDIT_IMPOT_INNOVATION', # Changé pour 2023 (ligne 80a->79a)\n",
    "        'LIGNE_80B_CALC': 'L79B_CREDIT_IMPOT_INNOVATION_DOM', # Changé pour 2023 (ligne 80b->79b)\n",
    "        'LIGNE_80C_CALC': 'L79C_CREDIT_IMPOT_INNOVATION_CORSE', # Changé pour 2023 (ligne 80c->79c)\n",
    "        'LIGNE_81A_CALC': 'L80A_TOTAL_CIR_RECH_COLL_INNO', # Changé pour 2023 (ligne 81a->80a)\n",
    "        'LIGNE_81B_CALC': 'L80B_TOTAL_CIR_RECH_COLL_INNO_DOM', # Changé pour 2023 (ligne 81b->80b)\n",
    "\n",
    "        # V. Recherche collaborative\n",
    "        'DEP_CRC': 'L81_DEPENSES_RECHERCHE_COLLABORATIVE', # Changé pour 2023 (ligne 82->81)\n",
    "        'DEP_CRC_FR': 'L82A_DEPENSES_RC_FRANCE', # Changé pour 2023 (ligne 83a->82a)\n",
    "        'DEP_CRC_ETR': 'L82B_DEPENSES_RC_ETRANGER', # Changé pour 2023 (ligne 83b->82b)\n",
    "        'LIGNE_83_CALC': 'L82_TOTAL_DEPENSES_RC', # Changé pour 2023 (ligne 83->82)\n",
    "        'DEP_CRC_PLAF': 'L83_DEPENSES_RC_PLAFONNEES_DECLARE', # Changé pour 2023 (ligne 84->83)\n",
    "        'LIGNE_84_CALC': 'L83_DEPENSES_RC_PLAFONNEES_CALCULE', # Changé pour 2023 (ligne 84->83)\n",
    "        'ECART_LIGNE_84': 'L83_ECART', # Changé pour 2023 (ligne 84->83)\n",
    "        'AIDE_PUB_CRC': 'L84_AIDES_PUBLIQUES_RC', # Changé pour 2023 (ligne 85->84)\n",
    "        'AIDE_PUB_REMB_CRC': 'L85_REMBOURSEMENTS_AIDES_RC', # Changé pour 2023 (ligne 86->85)\n",
    "        'MT_NET_DEP_CRC': 'L86_MONTANT_NET_RC_DECLARE', # Changé pour 2023 (ligne 87->86)\n",
    "        'MT_NET_DEP_CRC_CALC': 'L86_MONTANT_NET_RC_CALCULE', # Changé pour 2023 (ligne 87->86)\n",
    "        'ECART_MT_NET_DEP_CRC': 'L86_ECART', # Changé pour 2023 (ligne 87->86)\n",
    "        'MT_NET_DEP_CRC_PME': 'L87_MONTANT_NET_RC_PME', # Changé pour 2023 (ligne 88->87)\n",
    "        'LIGNE_89_CALC': 'L88_CREDIT_IMPOT_RC', # Changé pour 2023 (ligne 89->88)\n",
    "        'LIGNE_90': 'L89_QUOTE_PART_RC_SOC_PERSONNES', # Changé pour 2023 (ligne 90->89)\n",
    "        'LIGNE_91_CALC': 'L90_MONTANT_TOTAL_CIR_RECHERCHE_COLLABORATIVE', # Changé pour 2023 (ligne 91->90)\n",
    "\n",
    "        # Crédits d'impôt par composante\n",
    "        'MT_CIR_RECH_YC_QP_MOINS_DE100': 'CIR_RECHERCHE_DECLARE',\n",
    "        'CIR_RECHERCHE_RECALCULE': 'CIR_RECHERCHE_CALCULE',\n",
    "        'ECART_CIR_RECHERCHE': 'CIR_RECHERCHE_ECART',\n",
    "\n",
    "        'MT_CI_COLL_APRS_MINIMI': 'CIR_COLLECTION_DECLARE',\n",
    "        'CIR_COLLECTION_RECALCULE': 'CIR_COLLECTION_CALCULE',\n",
    "        'ECART_CIR_COLLECTION': 'CIR_COLLECTION_ECART',\n",
    "\n",
    "        'MT_CII_YC_QP': 'CIR_INNOVATION_DECLARE',\n",
    "        'CIR_INNOVATION_RECALCULE': 'CIR_INNOVATION_CALCULE',\n",
    "        'ECART_CIR_INNOVATION': 'CIR_INNOVATION_ECART',\n",
    "\n",
    "        'MT_CRC': 'CIR_COLLABORATIF_DECLARE',\n",
    "        'CIR_COLLAB_RECALCULE': 'CIR_COLLABORATIF_CALCULE',\n",
    "        'ECART_CIR_COLLAB': 'CIR_COLLABORATIF_ECART',\n",
    "\n",
    "        # CIR Total\n",
    "        'MT_TOT_CIR_CI_COLL_CII': 'CIR_TOTAL_DECLARE',\n",
    "        'CIR_TOTAL_RECALCULE': 'CIR_TOTAL_CALCULE',\n",
    "        'ECART_CIR': 'CIR_TOTAL_ECART',\n",
    "\n",
    "        # Indicateurs\n",
    "        'CORRESPONDANCE': 'CORRESPONDANCE_CIR',\n",
    "        'ECART_RELATIF': 'ECART_RELATIF_POURCENT'\n",
    "    }\n",
    "\n",
    "    # Création du DataFrame de comparaison\n",
    "    df_comparaison = pd.DataFrame()\n",
    "\n",
    "    # Copier chaque colonne si elle existe\n",
    "    for col_orig, col_dest in mapping_colonnes.items():\n",
    "        if col_orig in df_num.columns:\n",
    "            df_comparaison[col_dest] = df_num[col_orig]\n",
    "        else:\n",
    "            # Ne pas ajouter les colonnes qui n'existent pas\n",
    "            pass\n",
    "\n",
    "    # Concaténation de la désignation et du complément si disponible\n",
    "    if 'COMPLEMENT_DESIGNATION' in df_comparaison.columns:\n",
    "        df_comparaison['DESIGNATION'] = df_comparaison.apply(\n",
    "            lambda x: f\"{x['DESIGNATION']} {x['COMPLEMENT_DESIGNATION']}\" if pd.notna(x['COMPLEMENT_DESIGNATION']) else x['DESIGNATION'],\n",
    "            axis=1\n",
    "        )\n",
    "        df_comparaison.drop('COMPLEMENT_DESIGNATION', axis=1, inplace=True)\n",
    "\n",
    "    # Formatage des montants\n",
    "    montant_cols = [col for col in df_comparaison.columns if col not in ['SIREN_DECLARANT', 'SIREN_DEPOSANT', 'DESIGNATION', 'CORRESPONDANCE_CIR']]\n",
    "    for col in montant_cols:\n",
    "        df_comparaison[col] = df_comparaison[col].round(2)\n",
    "\n",
    "    # Sauvegarde du fichier de sortie\n",
    "    output_filename = f\"Calcul_Creance_CIR_2023.csv\"\n",
    "    output_path = os.path.join(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB\", output_filename)\n",
    "\n",
    "    df_comparaison.to_csv(output_path, index=False, sep=';', encoding='utf-8-sig')\n",
    "\n",
    "    print(f\"\\nFichier de comparaison détaillée créé: {output_path}\")\n",
    "\n",
    "    # RÉSULTATS\n",
    "\n",
    "    # Somme des CIR déclarés\n",
    "    cir_declare_total = df_tmp['MT_TOT_CIR_CI_COLL_CII'].sum()\n",
    "\n",
    "    # Somme des CIR recalculés\n",
    "    cir_recalcule_total = df_calc_final['CIR_TOTAL_RECALCULE'].sum()\n",
    "\n",
    "    # Nombre d'entreprises\n",
    "    nb_entreprises_avec_cir = len(df_tmp[df_tmp['MT_TOT_CIR_CI_COLL_CII'] > 0])\n",
    "    nb_entreprises_plus_100m = df_calc_final['DEPENSES_PLUS_100M'].sum()\n",
    "\n",
    "    # Classement des écarts\n",
    "    ecarts_positifs = df_num[df_num['ECART_CIR'] > 1]  # Plus de 1 en plus\n",
    "    ecarts_negatifs = df_num[df_num['ECART_CIR'] < -1]  # Plus de 1 en moins\n",
    "    ecarts_conformes = df_num[abs(df_num['ECART_CIR']) <= 1]  # Différence de 1 ou moins\n",
    "\n",
    "    # AFFICHAGE DES RÉSULTATS\n",
    "    print(\"\\n===== COMPARAISON CIR DÉCLARÉ VS RECALCULÉ =====\")\n",
    "\n",
    "    print(f\"\\nNombre total d'entreprises analysées: {len(df_num):,}\")\n",
    "    print(f\"Nombre d'entreprises avec CIR déclaré: {nb_entreprises_avec_cir:,}\")\n",
    "    print(f\"Nombre d'entreprises avec dépenses > 100M€: {nb_entreprises_plus_100m:,}\")\n",
    "\n",
    "    print(f\"\\nCIR TOTAL:\")\n",
    "    print(f\"CIR déclaré total: {cir_declare_total:,.2f} €\")\n",
    "    print(f\"CIR recalculé total: {cir_recalcule_total:,.2f} €\")\n",
    "\n",
    "    difference = cir_recalcule_total - cir_declare_total\n",
    "    print(f\"Différence: {difference:,.2f} €\")\n",
    "    if cir_declare_total > 0:\n",
    "        print(f\"Écart relatif: {difference/cir_declare_total*100:.2f}%\")\n",
    "\n",
    "    print(f\"\\nANALYSE DES ÉCARTS:\")\n",
    "    print(f\"Entreprises avec CIR conforme (écart ≤ 1€): {len(ecarts_conformes):,} ({len(ecarts_conformes)/len(df_num)*100:.2f}%)\")\n",
    "\n",
    "    print(f\"Entreprises avec CIR recalculé > CIR déclaré (écart > 1€): {len(ecarts_positifs):,}\")\n",
    "    print(f\"Montant total des écarts positifs: {ecarts_positifs['ECART_CIR'].sum():,.2f} €\")\n",
    "\n",
    "    print(f\"Entreprises avec CIR recalculé < CIR déclaré (écart < -1€): {len(ecarts_negatifs):,}\")\n",
    "    print(f\"Montant total des écarts négatifs: {ecarts_negatifs['ECART_CIR'].sum():,.2f} €\")\n",
    "\n",
    "    # Détail par composante du CIR\n",
    "    print(f\"\\nDÉTAIL PAR COMPOSANTE DU CIR RECALCULÉ:\")\n",
    "    print(f\"CIR Recherche: {df_num['CIR_RECHERCHE_RECALCULE'].sum():,.2f} €\")\n",
    "    print(f\"CIR Collection: {df_num['CIR_COLLECTION_RECALCULE'].sum():,.2f} €\")\n",
    "\n",
    "    if 'CIR_INNOVATION_RECALCULE' in df_num.columns:\n",
    "        print(f\"CIR Innovation: {df_num['CIR_INNOVATION_RECALCULE'].sum():,.2f} €\")\n",
    "    else:\n",
    "        print(f\"CIR Innovation: 0.00 €\")\n",
    "\n",
    "    if 'CIR_COLLAB_RECALCULE' in df_num.columns:\n",
    "        print(f\"CIR Recherche Collaborative: {df_num['CIR_COLLAB_RECALCULE'].sum():,.2f} €\")\n",
    "    else:\n",
    "        print(f\"CIR Recherche Collaborative: 0.00 €\")\n",
    "\n",
    "    return df_comparaison\n",
    "\n",
    "# Exécuter le calcul\n",
    "try:\n",
    "    df_resultat = comparer_cir_declare_recalcule()\n",
    "    print(\"\\nTraitement terminé avec succès!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nErreur: {type(e).__name__}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537b968b",
   "metadata": {},
   "source": [
    "# Difference Creance Déclarer vs Calculé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ac7eff",
   "metadata": {},
   "source": [
    "## Crc manquant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c00b63a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total d'entreprises: 27923\n",
      "Nombre d'entreprises avec écarts (CORRESPONDANCE_CIR = 'Non'): 1732\n",
      "\n",
      "Exemples de SIREN_DECLARANT avant correction:\n",
      "  5520325.0 (type: <class 'str'>, longueur: 9)\n",
      "  5580436.0 (type: <class 'str'>, longueur: 9)\n",
      "  5680145.0 (type: <class 'str'>, longueur: 9)\n",
      "  6380042.0 (type: <class 'str'>, longueur: 9)\n",
      "  6580195.0 (type: <class 'str'>, longueur: 9)\n",
      "\n",
      "Nombre de SIREN n'ayant pas exactement 9 caractères: 27916\n",
      "\n",
      "Exemples de SIREN_DECLARANT après correction:\n",
      "  5520325.0 (type: <class 'str'>, longueur: 9)\n",
      "  5580436.0 (type: <class 'str'>, longueur: 9)\n",
      "  5680145.0 (type: <class 'str'>, longueur: 9)\n",
      "  6380042.0 (type: <class 'str'>, longueur: 9)\n",
      "  6580195.0 (type: <class 'str'>, longueur: 9)\n",
      "Nombre de SIREN n'ayant pas exactement 9 caractères après correction: 27915\n",
      "\n",
      "Nombre d'entreprises avec CRC apparemment manquant dans le montant déclaré: 11943\n",
      "\n",
      "Résultats après correction:\n",
      "Nombre d'entreprises avec écarts avant correction: 1732\n",
      "Nombre d'entreprises avec écarts après correction: 1729\n",
      "Nombre d'écarts résolus par l'ajout du CRC: 3 (0.17%)\n",
      "\n",
      "Exemples d'entreprises où l'écart a été résolu par l'ajout du CRC:\n",
      "\n",
      "Exemple 1: SAS (SIREN: 380505487.0)\n",
      "  CIR déclaré original: 63240.00\n",
      "  CIR déclaré corrigé: 63240.00\n",
      "  CIR calculé: 63239.00\n",
      "  Écart original: -1.00\n",
      "  Écart corrigé: -1.00\n",
      "  CRC calculé: 0.0\n",
      "\n",
      "Exemple 2: nan (SIREN: 439112905.0)\n",
      "  CIR déclaré original: 56676.00\n",
      "  CIR déclaré corrigé: 56676.00\n",
      "  CIR calculé: 56675.00\n",
      "  Écart original: -1.00\n",
      "  Écart corrigé: -1.00\n",
      "  CRC calculé: 0.0\n",
      "\n",
      "Exemple 3: nan (SIREN: 525365821.0)\n",
      "  CIR déclaré original: 203239.00\n",
      "  CIR déclaré corrigé: 203239.00\n",
      "  CIR calculé: 203238.00\n",
      "  Écart original: -1.00\n",
      "  Écart corrigé: -1.00\n",
      "  CRC calculé: 0.0\n",
      "\n",
      "Fichier original mis à jour: M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2023.csv\n",
      "- Format des SIREN corrigé\n",
      "- CRC manquant ajouté au montant déclaré\n",
      "\n",
      "Il reste 1729 entreprises avec des écarts à analyser.\n",
      "\n",
      "Principales sources d'écarts restants:\n",
      "1. CIR_RECHERCHE_ECART: 935 entreprises (54.08%)\n",
      "2. L26A_ECART: 353 entreprises (20.42%)\n",
      "3. L22_ECART: 351 entreprises (20.30%)\n",
      "4. CIR_INNOVATION_ECART: 322 entreprises (18.62%)\n",
      "5. L14_ECART: 234 entreprises (13.53%)\n",
      "\n",
      "Recherche d'autres patterns d'écarts similaires:\n",
      "  • Possible CIR Innovation manquant: 25 entreprises\n",
      "  • Possible CIR Collection manquant: 3 entreprises\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Fonction pour formater les SIREN correctement\n",
    "def format_siren(siren):\n",
    "    \"\"\"Formate les SIREN pour avoir exactement 9 caractères en ajoutant des zéros au début si nécessaire\"\"\"\n",
    "    if pd.isna(siren):\n",
    "        return siren\n",
    "\n",
    "    siren_str = str(siren).strip()\n",
    "\n",
    "    # Si le SIREN a moins de 9 caractères, ajouter des zéros au début\n",
    "    if len(siren_str) < 9:\n",
    "        siren_str = siren_str.zfill(9)  # zfill ajoute des zéros au début jusqu'à atteindre la longueur spécifiée\n",
    "\n",
    "    return siren_str\n",
    "\n",
    "# Charger le fichier CSV avec converters pour traiter SIREN comme du texte\n",
    "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2023.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig',\n",
    "                converters={'SIREN_DECLARANT': str, 'SIREN_DEPOSANT': str})\n",
    "\n",
    "print(f\"Nombre total d'entreprises: {len(df)}\")\n",
    "print(f\"Nombre d'entreprises avec écarts (CORRESPONDANCE_CIR = 'Non'): {len(df[df['CORRESPONDANCE_CIR'] == 'Non'])}\")\n",
    "\n",
    "# 1. Corriger le format des SIREN\n",
    "if 'SIREN_DECLARANT' in df.columns:\n",
    "    # Afficher quelques exemples de SIREN avant correction\n",
    "    print(\"\\nExemples de SIREN_DECLARANT avant correction:\")\n",
    "    for siren in df['SIREN_DECLARANT'].head(5):\n",
    "        print(f\"  {siren} (type: {type(siren)}, longueur: {len(str(siren))})\")\n",
    "\n",
    "    # Identifier les SIREN qui n'ont pas 9 caractères\n",
    "    siren_lengths = df['SIREN_DECLARANT'].apply(lambda x: len(str(x)) if pd.notna(x) else 0)\n",
    "    unusual_siren_count = (siren_lengths != 9).sum()\n",
    "    print(f\"\\nNombre de SIREN n'ayant pas exactement 9 caractères: {unusual_siren_count}\")\n",
    "\n",
    "    # Appliquer la correction aux SIREN\n",
    "    df['SIREN_DECLARANT'] = df['SIREN_DECLARANT'].apply(format_siren)\n",
    "\n",
    "    # Si la colonne SIREN_DEPOSANT existe également, la corriger\n",
    "    if 'SIREN_DEPOSANT' in df.columns:\n",
    "        df['SIREN_DEPOSANT'] = df['SIREN_DEPOSANT'].apply(format_siren)\n",
    "\n",
    "    # Vérifier les SIREN après correction\n",
    "    print(\"\\nExemples de SIREN_DECLARANT après correction:\")\n",
    "    for siren in df['SIREN_DECLARANT'].head(5):\n",
    "        print(f\"  {siren} (type: {type(siren)}, longueur: {len(str(siren))})\")\n",
    "\n",
    "    # Vérifier qu'il n'y a plus de SIREN avec une longueur incorrecte\n",
    "    siren_lengths_after = df['SIREN_DECLARANT'].apply(lambda x: len(str(x)) if pd.notna(x) else 0)\n",
    "    unusual_siren_count_after = (siren_lengths_after != 9).sum()\n",
    "    print(f\"Nombre de SIREN n'ayant pas exactement 9 caractères après correction: {unusual_siren_count_after}\")\n",
    "\n",
    "# 2. Identifier les cas où l'écart est dû au CRC manquant\n",
    "tolerance = 1.0  # 1€ de tolérance\n",
    "\n",
    "# Créer un masque pour identifier les cas où l'écart correspond au CRC calculé\n",
    "mask_crc_missing = (\n",
    "    # Cas où l'écart est positif (montant calculé > montant déclaré)\n",
    "    (df['CIR_TOTAL_ECART'] > 0) &\n",
    "    # L'écart est approximativement égal au CRC calculé\n",
    "    (abs(df['CIR_TOTAL_ECART'] - df['CIR_COLLABORATIF_CALCULE']) < tolerance) &\n",
    "    # Le CRC déclaré est nul ou très petit comparé au CRC calculé\n",
    "    ((df['CIR_COLLABORATIF_DECLARE'].isna()) |\n",
    "     (df['CIR_COLLABORATIF_DECLARE'] == 0) |\n",
    "     (df['CIR_COLLABORATIF_CALCULE'] > df['CIR_COLLABORATIF_DECLARE'] * 1.5))\n",
    ")\n",
    "\n",
    "# Compter les cas identifiés\n",
    "count_crc_missing = mask_crc_missing.sum()\n",
    "print(f\"\\nNombre d'entreprises avec CRC apparemment manquant dans le montant déclaré: {count_crc_missing}\")\n",
    "\n",
    "# 3. Sauvegarder les valeurs originales (pour information uniquement)\n",
    "df['CIR_TOTAL_DECLARE_ORIGINAL'] = df['CIR_TOTAL_DECLARE'].copy()\n",
    "df['CIR_TOTAL_ECART_ORIGINAL'] = df['CIR_TOTAL_ECART'].copy()\n",
    "df['CORRESPONDANCE_CIR_ORIGINAL'] = df['CORRESPONDANCE_CIR'].copy()\n",
    "\n",
    "# 4. Corriger directement le montant déclaré en ajoutant le CRC calculé\n",
    "df.loc[mask_crc_missing, 'CIR_TOTAL_DECLARE'] = df.loc[mask_crc_missing, 'CIR_TOTAL_DECLARE'] + df.loc[mask_crc_missing, 'CIR_COLLABORATIF_CALCULE']\n",
    "\n",
    "# 5. Recalculer l'écart\n",
    "df['CIR_TOTAL_ECART'] = df['CIR_TOTAL_CALCULE'] - df['CIR_TOTAL_DECLARE']\n",
    "\n",
    "# 6. Mettre à jour la correspondance\n",
    "df['CORRESPONDANCE_CIR'] = np.where(abs(df['CIR_TOTAL_ECART']) <= 1, \"Oui\", \"Non\")\n",
    "\n",
    "# 7. Analyser les résultats\n",
    "count_original_non = (df['CORRESPONDANCE_CIR_ORIGINAL'] == 'Non').sum()\n",
    "count_corrected_non = (df['CORRESPONDANCE_CIR'] == 'Non').sum()\n",
    "count_fixed = count_original_non - count_corrected_non\n",
    "\n",
    "print(f\"\\nRésultats après correction:\")\n",
    "print(f\"Nombre d'entreprises avec écarts avant correction: {count_original_non}\")\n",
    "print(f\"Nombre d'entreprises avec écarts après correction: {count_corrected_non}\")\n",
    "print(f\"Nombre d'écarts résolus par l'ajout du CRC: {count_fixed} ({count_fixed/count_original_non*100:.2f}%)\")\n",
    "\n",
    "# 8. Exemples d'entreprises corrigées (pour information uniquement)\n",
    "print(\"\\nExemples d'entreprises où l'écart a été résolu par l'ajout du CRC:\")\n",
    "df_resolved = df[(df['CORRESPONDANCE_CIR_ORIGINAL'] == 'Non') & (df['CORRESPONDANCE_CIR'] == 'Oui')].copy()\n",
    "if len(df_resolved) > 0:\n",
    "    sample_size = min(3, len(df_resolved))\n",
    "    for i, (_, row) in enumerate(df_resolved.head(sample_size).iterrows(), 1):\n",
    "        print(f\"\\nExemple {i}: {row.get('DESIGNATION', 'N/A')} (SIREN: {row.get('SIREN_DECLARANT', 'N/A')})\")\n",
    "        print(f\"  CIR déclaré original: {row['CIR_TOTAL_DECLARE_ORIGINAL']:.2f}\")\n",
    "        print(f\"  CIR déclaré corrigé: {row['CIR_TOTAL_DECLARE']:.2f}\")\n",
    "        print(f\"  CIR calculé: {row['CIR_TOTAL_CALCULE']:.2f}\")\n",
    "        print(f\"  Écart original: {row['CIR_TOTAL_ECART_ORIGINAL']:.2f}\")\n",
    "        print(f\"  Écart corrigé: {row['CIR_TOTAL_ECART']:.2f}\")\n",
    "        print(f\"  CRC calculé: {row.get('CIR_COLLABORATIF_CALCULE', 'N/A')}\")\n",
    "\n",
    "# 9. Supprimer les colonnes originales pour ne garder que les valeurs corrigées\n",
    "df = df.drop(['CIR_TOTAL_DECLARE_ORIGINAL', 'CIR_TOTAL_ECART_ORIGINAL', 'CORRESPONDANCE_CIR_ORIGINAL'], axis=1)\n",
    "\n",
    "# 10. Écraser le fichier original avec les données corrigées\n",
    "# S'assurer que les SIREN sont toujours formatés comme du texte lors de l'export\n",
    "df.to_csv(file_path, sep=';', encoding='utf-8-sig', index=False)\n",
    "\n",
    "print(f\"\\nFichier original mis à jour: {file_path}\")\n",
    "print(f\"- Format des SIREN corrigé\")\n",
    "print(f\"- CRC manquant ajouté au montant déclaré\")\n",
    "\n",
    "# 11. Résumé des écarts restants\n",
    "if count_corrected_non > 0:\n",
    "    print(f\"\\nIl reste {count_corrected_non} entreprises avec des écarts à analyser.\")\n",
    "\n",
    "    # Identifier les principales sources d'écarts restants\n",
    "    df_remaining_ecarts = df[df['CORRESPONDANCE_CIR'] == 'Non']\n",
    "\n",
    "    # Obtenir toutes les colonnes d'écart\n",
    "    ecart_cols = [col for col in df.columns if '_ECART' in col and col != 'CIR_TOTAL_ECART' and col != 'ECART_RELATIF_POURCENT']\n",
    "\n",
    "    # Compter les écarts significatifs par colonne\n",
    "    ecart_counts = {}\n",
    "    for col in ecart_cols:\n",
    "        if col in df_remaining_ecarts.columns:\n",
    "            non_zero = df_remaining_ecarts[abs(df_remaining_ecarts[col]) > 1]\n",
    "            if len(non_zero) > 0:\n",
    "                ecart_counts[col] = len(non_zero)\n",
    "\n",
    "    # Afficher les 5 principales sources d'écarts\n",
    "    sorted_ecarts = sorted(ecart_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    if sorted_ecarts:\n",
    "        print(\"\\nPrincipales sources d'écarts restants:\")\n",
    "        for i, (col, count) in enumerate(sorted_ecarts[:5], 1):\n",
    "            pct = count / count_corrected_non * 100\n",
    "            print(f\"{i}. {col}: {count} entreprises ({pct:.2f}%)\")\n",
    "\n",
    "    # Rechercher d'autres cas potentiels similaires au problème du CRC\n",
    "    print(\"\\nRecherche d'autres patterns d'écarts similaires:\")\n",
    "\n",
    "    # 1. Cas où l'écart correspond au CIR Innovation\n",
    "    if 'CIR_INNOVATION_CALCULE' in df_remaining_ecarts.columns:\n",
    "        innovation_missing = (\n",
    "            (df_remaining_ecarts['CIR_TOTAL_ECART'] > 0) &\n",
    "            (abs(df_remaining_ecarts['CIR_TOTAL_ECART'] - df_remaining_ecarts['CIR_INNOVATION_CALCULE']) < tolerance)\n",
    "        )\n",
    "        count_innovation = innovation_missing.sum()\n",
    "        if count_innovation > 0:\n",
    "            print(f\"  • Possible CIR Innovation manquant: {count_innovation} entreprises\")\n",
    "\n",
    "    # 2. Cas où l'écart correspond au CIR Collection\n",
    "    if 'CIR_COLLECTION_CALCULE' in df_remaining_ecarts.columns:\n",
    "        collection_missing = (\n",
    "            (df_remaining_ecarts['CIR_TOTAL_ECART'] > 0) &\n",
    "            (abs(df_remaining_ecarts['CIR_TOTAL_ECART'] - df_remaining_ecarts['CIR_COLLECTION_CALCULE']) < tolerance)\n",
    "        )\n",
    "        count_collection = collection_missing.sum()\n",
    "        if count_collection > 0:\n",
    "            print(f\"  • Possible CIR Collection manquant: {count_collection} entreprises\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3e5587",
   "metadata": {},
   "source": [
    "## Erreur depense personnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de785d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier chargé: 27923 lignes\n",
      "Nombre de lignes à corriger: 8\n",
      "\n",
      "Résultats de la correction:\n",
      "Somme CIR_TOTAL_DECLARE: 814,166.00 €\n",
      "Somme CIR_TOTAL_CALCULE avant correction: 741,658.50 €\n",
      "Somme CIR_TOTAL_CALCULE après correction: 1,015,295.11 €\n",
      "Écart avant correction: -72,507.50 €\n",
      "Écart après correction: 201,129.11 €\n",
      "\n",
      "Fichier corrigé sauvegardé: lignes_restantes_a_analyser_corrigees.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier original\n",
    "df = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2023.csv\", sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier chargé: {len(df)} lignes\")\n",
    "\n",
    "# Identifier les lignes concernées (ajout du critère correspondance)\n",
    "mask = (\n",
    "    (df['L3_DEPENSES_PERSONNEL_CHERCHEURS'] == 0.0) &\n",
    "    (df['L2_DOTATION_AMORT_SINISTR'] != 0.0) &\n",
    "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
    ")\n",
    "indices_to_update = df[mask].index\n",
    "print(f\"Nombre de lignes à corriger: {len(indices_to_update)}\")\n",
    "\n",
    "\n",
    "# Sauvegarder les valeurs originales pour analyse\n",
    "cir_calcule_avant = df.loc[indices_to_update, 'CIR_TOTAL_CALCULE'].copy()\n",
    "\n",
    "# Pour chaque ligne à corriger\n",
    "for idx in indices_to_update:\n",
    "    # 1. Transférer la valeur de dotation aux amortissements sinistrés vers dépenses de personnel\n",
    "    val_amort_sinistr = df.at[idx, 'L2_DOTATION_AMORT_SINISTR']\n",
    "    df.at[idx, 'L3_DEPENSES_PERSONNEL_CHERCHEURS'] = val_amort_sinistr\n",
    "    df.at[idx, 'L2_DOTATION_AMORT_SINISTR'] = 0.0\n",
    "\n",
    "    # 2. Recalculer la ligne 6 (autres dépenses de fonctionnement)\n",
    "    dot_amort_immo = df.at[idx, 'L1_DOTATION_AMORT_IMMO']\n",
    "    dep_cherch_tech = df.at[idx, 'L3_DEPENSES_PERSONNEL_CHERCHEURS']  # Nouvelle valeur\n",
    "    rem_sal_inv = df.at[idx, 'L4_REMUNERATION_INVENTEURS']\n",
    "    dep_jd = df.at[idx, 'L5_DEPENSES_JEUNES_DOCTEURS']\n",
    "\n",
    "    autres_dep_fonct = (dot_amort_immo * 0.75) + ((dep_cherch_tech + rem_sal_inv) * 0.43) + dep_jd\n",
    "    df.at[idx, 'L6_AUTRES_DEP_FONCT_CALCULE'] = autres_dep_fonct\n",
    "\n",
    "    # 3. Recalculer la ligne 7 (total dépenses de fonctionnement)\n",
    "    total_dep_fonct = dot_amort_immo + 0.0 + dep_cherch_tech + rem_sal_inv + dep_jd + autres_dep_fonct\n",
    "    df.at[idx, 'L7_TOTAL_DEP_FONCT_CALCULE'] = total_dep_fonct\n",
    "\n",
    "    # 4. Recalculer la ligne 14 (total dépenses internes)\n",
    "    frais_brev_cov = df.at[idx, 'L8_FRAIS_BREVETS_COV']\n",
    "    dep_maint_brev_cov = df.at[idx, 'L9_DEPENSES_DEFENSE_BREVETS']\n",
    "    dot_amort_brev = df.at[idx, 'L10_DOTATION_AMORT_BREVETS']\n",
    "    dep_normali = df.at[idx, 'L11_DEPENSES_NORMALISATION_DECLARE']\n",
    "    prim_cotiz = min(df.at[idx, 'L12_PRIMES_COTISATIONS_BRUT'], 60000)\n",
    "    dep_veil_techno = min(df.at[idx, 'L13_VEILLE_TECHNO_BRUT'], 60000)\n",
    "\n",
    "    total_dep_internes = total_dep_fonct + frais_brev_cov + dep_maint_brev_cov + dot_amort_brev + dep_normali + prim_cotiz + dep_veil_techno\n",
    "    df.at[idx, 'L14_TOTAL_DEPENSES_INTERNES_CALCULE'] = total_dep_internes\n",
    "\n",
    "    # 5. Recalculer la ligne 22 (total dépenses de recherche)\n",
    "    total_dep_ext = df.at[idx, 'L21_TOTAL_DEP_EXT_PLAFONNEES_CALCULE']\n",
    "    total_dep_recherche = total_dep_internes + total_dep_ext\n",
    "    df.at[idx, 'L22_TOTAL_DEPENSES_RECHERCHE_CALCULE'] = total_dep_recherche\n",
    "\n",
    "    # 6. Recalculer la ligne 26A (montant net des dépenses)\n",
    "    mt_aid_subv = df.at[idx, 'L23A_SUBVENTIONS']\n",
    "    mt_enc_presta = df.at[idx, 'L23B_SOMMES_ENCAISSEES_TIERS']\n",
    "    mt_dep_conseils_cir = df.at[idx, 'L24_DEPENSES_CONSEIL_CIR']\n",
    "    rembst_subv = df.at[idx, 'L25_REMBOURSEMENTS_SUBVENTIONS']\n",
    "\n",
    "    montant_net = total_dep_recherche - mt_aid_subv - mt_enc_presta - mt_dep_conseils_cir + rembst_subv\n",
    "    df.at[idx, 'L26A_MONTANT_NET_DEPENSES_CALCULE'] = montant_net\n",
    "\n",
    "    # 7. Recalculer le CIR recherche (30% du montant net)\n",
    "    cir_recherche = montant_net * 0.30\n",
    "    df.at[idx, 'CIR_RECHERCHE_CALCULE'] = cir_recherche\n",
    "\n",
    "    # 8. Recalculer le CIR total\n",
    "    cir_collection = df.at[idx, 'CIR_COLLECTION_CALCULE']\n",
    "    cir_innovation = df.at[idx, 'CIR_INNOVATION_CALCULE']\n",
    "    cir_collaboratif = df.at[idx, 'CIR_COLLABORATIF_CALCULE']\n",
    "\n",
    "    cir_total = cir_recherche + cir_collection + cir_innovation + cir_collaboratif\n",
    "    df.at[idx, 'CIR_TOTAL_CALCULE'] = cir_total\n",
    "\n",
    "    # 9. Recalculer l'écart et mettre à jour la correspondance\n",
    "    ecart_cir = cir_total - df.at[idx, 'CIR_TOTAL_DECLARE']\n",
    "    df.at[idx, 'CIR_TOTAL_ECART'] = ecart_cir\n",
    "    df.at[idx, 'CORRESPONDANCE_CIR'] = \"Oui\" if abs(ecart_cir) <= 1 else \"Non\"\n",
    "\n",
    "# Afficher les résultats\n",
    "somme_declare = df.loc[indices_to_update, 'CIR_TOTAL_DECLARE'].sum()\n",
    "somme_calcule_avant = cir_calcule_avant.sum()\n",
    "somme_calcule_apres = df.loc[indices_to_update, 'CIR_TOTAL_CALCULE'].sum()\n",
    "\n",
    "print(f\"\\nRésultats de la correction:\")\n",
    "print(f\"Somme CIR_TOTAL_DECLARE: {somme_declare:,.2f} €\")\n",
    "print(f\"Somme CIR_TOTAL_CALCULE avant correction: {somme_calcule_avant:,.2f} €\")\n",
    "print(f\"Somme CIR_TOTAL_CALCULE après correction: {somme_calcule_apres:,.2f} €\")\n",
    "print(f\"Écart avant correction: {somme_calcule_avant - somme_declare:,.2f} €\")\n",
    "print(f\"Écart après correction: {somme_calcule_apres - somme_declare:,.2f} €\")\n",
    "\n",
    "# Sauvegarder le fichier corrigé\n",
    "df.to_csv(\"lignes_restantes_a_analyser_corrigees.csv\", sep=';', encoding='utf-8-sig', index=False)\n",
    "print(f\"\\nFichier corrigé sauvegardé: lignes_restantes_a_analyser_corrigees.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e737770f",
   "metadata": {},
   "source": [
    "### mise à jour ligne restante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c503834b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier chargé: 27923 lignes\n",
      "Nombre de lignes après filtrage: 8\n",
      "Somme CIR_TOTAL_DECLARE : 814,166.00 €\n",
      "Somme CIR_TOTAL_CALCULE : 741,658.50 €\n",
      "Résultats exportés dans: lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\n",
      "\n",
      "Aperçu des données trouvées:\n",
      "Nombre d'entreprises: 8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier\n",
    "df = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2023.csv\", sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier chargé: {len(df)} lignes\")\n",
    "\n",
    "# Appliquer les filtres :\n",
    "# - L5_DEPENSES_JEUNES_DOCTEURS = 0.0\n",
    "# - L2_DOTATION_AMORT_SINISTR différent de 0.0\n",
    "df_filtered = df[\n",
    "    (df['L3_DEPENSES_PERSONNEL_CHERCHEURS'] == 0.0) &\n",
    "    (df['L2_DOTATION_AMORT_SINISTR'] != 0.0) &\n",
    "    (df['CORRESPONDANCE_CIR'] == \"Non\") \n",
    "]\n",
    "\n",
    "print(f\"Nombre de lignes après filtrage: {len(df_filtered)}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\"\n",
    "df_filtered.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "# Calculer les sommes\n",
    "somme_declare = df_filtered['CIR_TOTAL_DECLARE'].sum()\n",
    "somme_calcule = df_filtered['CIR_TOTAL_CALCULE'].sum()\n",
    "\n",
    "print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
    "print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
    "print(f\"Résultats exportés dans: {output_file}\")\n",
    "\n",
    "# Afficher quelques statistiques sur les lignes trouvées\n",
    "if len(df_filtered) > 0:\n",
    "    print(\"\\nAperçu des données trouvées:\")\n",
    "    print(f\"Nombre d'entreprises: {len(df_filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff554e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier principal chargé: 27923 lignes\n",
      "\n",
      "Nombre de lignes restantes à analyser: 1721\n",
      "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier principal\n",
    "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2023.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
    "\n",
    "# Charger les fichiers d'analyse précédents\n",
    "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')  # Nouveau fichier\n",
    "\n",
    "# Identifier les SIREN à exclure\n",
    "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT'])  # Nouveau set\n",
    "\n",
    "# Combiner tous les SIREN à exclure\n",
    "siren_a_exclure =  siren_jeunes_docteurs  # Ajout du nouveau set\n",
    "\n",
    "# Filtrer le DataFrame principal\n",
    "# - Exclure les SIREN déjà analysés\n",
    "# - Garder uniquement les lignes où CORRESPONDANCE_CIR est \"Non\"\n",
    "df_restant = df[\n",
    "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) & \n",
    "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
    "]\n",
    "\n",
    "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_restantes_a_analyser.csv\"\n",
    "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6347a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bd28258",
   "metadata": {},
   "source": [
    "## Erreur DEP Fonctionnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37d32f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier chargé: 1721 lignes\n",
      "Nombre de lignes à corriger: 0\n",
      "\n",
      "Résumé des corrections :\n",
      "Somme L7_TOTAL_DEP_FONCT_DECLARE avant correction: 0.00 €\n",
      "Somme L7_TOTAL_DEP_FONCT_CALCULE après correction: 0.00 €\n",
      "Différence sur L7: 0.00 €\n",
      "\n",
      "Impact sur le CIR :\n",
      "Somme CIR_TOTAL_DECLARE: 0.00 €\n",
      "Somme CIR_TOTAL_CALCULE avant correction: 0.00 €\n",
      "Somme CIR_TOTAL_CALCULE après correction: 0.00 €\n",
      "Écart avant correction: 0.00 €\n",
      "Écart après correction: 0.00 €\n",
      "Amélioration de l'écart: 0.00 €\n",
      "\n",
      "Nombre de lignes où la correspondance est passée de 'Non' à 'Oui': 0\n",
      "\n",
      "Fichier corrigé sauvegardé: lignes_restantes_a_analyser_corrigees_L7L8.csv\n",
      "\n",
      "Exemples de modifications significatives:\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier original\n",
    "file_path = \"lignes_restantes_a_analyser.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier chargé: {len(df)} lignes\")\n",
    "\n",
    "# Identifier les lignes à corriger\n",
    "mask = (df['L7_TOTAL_DEP_FONCT_DECLARE'] == df['L8_FRAIS_BREVETS_COV']) & (df['L7_TOTAL_DEP_FONCT_DECLARE'] != 0.0)\n",
    "indices_to_update = df[mask].index\n",
    "print(f\"Nombre de lignes à corriger: {len(indices_to_update)}\")\n",
    "\n",
    "# Sauvegarder les valeurs originales pour analyse\n",
    "cir_calcule_avant = df.loc[indices_to_update, 'CIR_TOTAL_CALCULE'].copy()\n",
    "l7_original = df.loc[indices_to_update, 'L7_TOTAL_DEP_FONCT_DECLARE'].copy()\n",
    "\n",
    "# Pour chaque ligne à corriger\n",
    "for idx in indices_to_update:\n",
    "    # 1. Calculer correctement le montant de la ligne 7 (total dépenses de fonctionnement)\n",
    "    dot_amort_immo = df.at[idx, 'L1_DOTATION_AMORT_IMMO']\n",
    "    dot_amort_sinistr = df.at[idx, 'L2_DOTATION_AMORT_SINISTR']\n",
    "    dep_cherch_tech = df.at[idx, 'L3_DEPENSES_PERSONNEL_CHERCHEURS']\n",
    "    rem_sal_inv = df.at[idx, 'L4_REMUNERATION_INVENTEURS']\n",
    "    dep_jd = df.at[idx, 'L5_DEPENSES_JEUNES_DOCTEURS']\n",
    "\n",
    "    # Calculer L6 si nécessaire\n",
    "    autres_dep_fonct = (dot_amort_immo * 0.75) + ((dep_cherch_tech + rem_sal_inv) * 0.43) + dep_jd\n",
    "\n",
    "    # Mettre à jour L6 calculé\n",
    "    df.at[idx, 'L6_AUTRES_DEP_FONCT_CALCULE'] = autres_dep_fonct\n",
    "\n",
    "    # Calculer le vrai montant de L7\n",
    "    total_dep_fonct = dot_amort_immo + dot_amort_sinistr + dep_cherch_tech + rem_sal_inv + dep_jd + autres_dep_fonct\n",
    "\n",
    "    # 2. Mettre à jour L7\n",
    "    df.at[idx, 'L7_TOTAL_DEP_FONCT_CALCULE'] = total_dep_fonct # laisser L7 tel quel (inchangé)\n",
    "\n",
    "    # Garder L8_FRAIS_BREVETS_COV tel quel (inchangé)\n",
    "    frais_brev_cov = df.at[idx, 'L8_FRAIS_BREVETS_COV'] # mettre à 0\n",
    "\n",
    "    # 3. Recalculer la ligne 14 (total dépenses internes)\n",
    "    dep_maint_brev_cov = df.at[idx, 'L9_DEPENSES_DEFENSE_BREVETS']\n",
    "    dot_amort_brev = df.at[idx, 'L10_DOTATION_AMORT_BREVETS']\n",
    "    dep_normali = df.at[idx, 'L11_DEPENSES_NORMALISATION_DECLARE']\n",
    "    prim_cotiz = df.at[idx, 'L12_PRIMES_COTISATIONS_PLAFONNEES']\n",
    "    dep_veil_techno = df.at[idx, 'L13_VEILLE_TECHNO_PLAFONNEE']\n",
    "\n",
    "    total_dep_internes = total_dep_fonct + frais_brev_cov + dep_maint_brev_cov + dot_amort_brev + dep_normali + prim_cotiz + dep_veil_techno\n",
    "    df.at[idx, 'L14_TOTAL_DEPENSES_INTERNES_CALCULE'] = total_dep_internes\n",
    "\n",
    "    # 4. Recalculer la ligne 22 (total dépenses de recherche)\n",
    "    total_dep_ext = df.at[idx, 'L21_TOTAL_DEP_EXT_PLAFONNEES_CALCULE']\n",
    "    total_dep_recherche = total_dep_internes + total_dep_ext\n",
    "    df.at[idx, 'L22_TOTAL_DEPENSES_RECHERCHE_CALCULE'] = total_dep_recherche\n",
    "\n",
    "    # 5. Recalculer la ligne 26A (montant net des dépenses)\n",
    "    mt_aid_subv = df.at[idx, 'L23A_SUBVENTIONS']\n",
    "    mt_enc_presta = df.at[idx, 'L23B_SOMMES_ENCAISSEES_TIERS']\n",
    "    mt_dep_conseils_cir = df.at[idx, 'L24_DEPENSES_CONSEIL_CIR']\n",
    "    rembst_subv = df.at[idx, 'L25_REMBOURSEMENTS_SUBVENTIONS']\n",
    "\n",
    "    montant_net = total_dep_recherche - mt_aid_subv - mt_enc_presta - mt_dep_conseils_cir + rembst_subv\n",
    "    df.at[idx, 'L26A_MONTANT_NET_DEPENSES_CALCULE'] = montant_net\n",
    "\n",
    "    # 6. Récupérer le montant DOM pour le calcul du CIR\n",
    "    montant_net_dom = df.at[idx, 'L26B_MONTANT_NET_DEPENSES_DOM_CALCULE']\n",
    "\n",
    "    # 7. Recalculer le CIR recherche (30% ou 50% selon localisation)\n",
    "    cir_recherche = ((montant_net - montant_net_dom) * 0.30) + (montant_net_dom * 0.50)\n",
    "    df.at[idx, 'CIR_RECHERCHE_CALCULE'] = cir_recherche\n",
    "\n",
    "    # 8. Recalculer le CIR total\n",
    "    cir_collection = df.at[idx, 'CIR_COLLECTION_CALCULE']\n",
    "    cir_innovation = df.at[idx, 'CIR_INNOVATION_CALCULE']\n",
    "    cir_collaboratif = df.at[idx, 'CIR_COLLABORATIF_CALCULE']\n",
    "\n",
    "    cir_total = cir_recherche + cir_collection + cir_innovation + cir_collaboratif\n",
    "    df.at[idx, 'CIR_TOTAL_CALCULE'] = cir_total\n",
    "\n",
    "    # 9. Recalculer l'écart et mettre à jour la correspondance\n",
    "    ecart_cir = cir_total - df.at[idx, 'CIR_TOTAL_DECLARE']\n",
    "    df.at[idx, 'CIR_TOTAL_ECART'] = ecart_cir\n",
    "    df.at[idx, 'CORRESPONDANCE_CIR'] = \"Oui\" if abs(ecart_cir) <= 1 else \"Non\"\n",
    "\n",
    "# Afficher le résumé des modifications\n",
    "l7_corrige = df.loc[indices_to_update, 'L7_TOTAL_DEP_FONCT_CALCULE']\n",
    "somme_declare = df.loc[indices_to_update, 'CIR_TOTAL_DECLARE'].sum()\n",
    "somme_calcule_avant = cir_calcule_avant.sum()\n",
    "somme_calcule_apres = df.loc[indices_to_update, 'CIR_TOTAL_CALCULE'].sum()\n",
    "\n",
    "print(f\"\\nRésumé des corrections :\")\n",
    "print(f\"Somme L7_TOTAL_DEP_FONCT_DECLARE avant correction: {l7_original.sum():,.2f} €\")\n",
    "print(f\"Somme L7_TOTAL_DEP_FONCT_CALCULE après correction: {l7_corrige.sum():,.2f} €\")\n",
    "print(f\"Différence sur L7: {l7_corrige.sum() - l7_original.sum():,.2f} €\")\n",
    "\n",
    "print(f\"\\nImpact sur le CIR :\")\n",
    "print(f\"Somme CIR_TOTAL_DECLARE: {somme_declare:,.2f} €\")\n",
    "print(f\"Somme CIR_TOTAL_CALCULE avant correction: {somme_calcule_avant:,.2f} €\")\n",
    "print(f\"Somme CIR_TOTAL_CALCULE après correction: {somme_calcule_apres:,.2f} €\")\n",
    "print(f\"Écart avant correction: {somme_calcule_avant - somme_declare:,.2f} €\")\n",
    "print(f\"Écart après correction: {somme_calcule_apres - somme_declare:,.2f} €\")\n",
    "print(f\"Amélioration de l'écart: {abs(somme_calcule_avant - somme_declare) - abs(somme_calcule_apres - somme_declare):,.2f} €\")\n",
    "\n",
    "# Compter les lignes où la correspondance s'est améliorée\n",
    "count_improved = 0\n",
    "for idx in indices_to_update:\n",
    "    if df.at[idx, 'CORRESPONDANCE_CIR'] == \"Oui\" and abs(cir_calcule_avant[idx] - df.at[idx, 'CIR_TOTAL_DECLARE']) > 1:\n",
    "        count_improved += 1\n",
    "\n",
    "print(f\"\\nNombre de lignes où la correspondance est passée de 'Non' à 'Oui': {count_improved}\")\n",
    "\n",
    "# Sauvegarder le fichier corrigé\n",
    "df.to_csv(\"lignes_restantes_a_analyser_corrigees_L7L8.csv\", sep=';', encoding='utf-8-sig', index=False)\n",
    "print(f\"\\nFichier corrigé sauvegardé: lignes_restantes_a_analyser_corrigees_L7L8.csv\")\n",
    "\n",
    "# Afficher des exemples de modifications\n",
    "print(\"\\nExemples de modifications significatives:\")\n",
    "# Calculer l'impact en pourcentage sur le CIR\n",
    "df_impact = pd.DataFrame({\n",
    "    'SIREN': df.loc[indices_to_update, 'SIREN_DECLARANT'],\n",
    "    'Désignation': df.loc[indices_to_update, 'DESIGNATION'],\n",
    "    'L7 avant': l7_original,\n",
    "    'L7 après': l7_corrige,\n",
    "    'CIR avant': cir_calcule_avant,\n",
    "    'CIR après': df.loc[indices_to_update, 'CIR_TOTAL_CALCULE'],\n",
    "    'Impact': abs(df.loc[indices_to_update, 'CIR_TOTAL_CALCULE'] - cir_calcule_avant)\n",
    "})\n",
    "\n",
    "# Afficher les 5 cas avec le plus grand impact en valeur absolue\n",
    "for _, row in df_impact.sort_values('Impact', ascending=False).head(5).iterrows():\n",
    "    print(f\"SIREN: {row['SIREN']}\")\n",
    "    print(f\"  Désignation: {row['Désignation']}\")\n",
    "    print(f\"  L7 avant: {row['L7 avant']:,.2f} €\")\n",
    "    print(f\"  L7 après: {row['L7 après']:,.2f} €\")\n",
    "    print(f\"  CIR avant: {row['CIR avant']:,.2f} €\")\n",
    "    print(f\"  CIR après: {row['CIR après']:,.2f} €\")\n",
    "    print(f\"  Impact: {row['Impact']:,.2f} € ({row['Impact']/row['CIR avant']*100 if row['CIR avant'] != 0 else 0:.2f}%)\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4584c853",
   "metadata": {},
   "source": [
    "### ligne liée au erreur dep fonctionnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d703418a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier chargé: 1721 lignes\n",
      "Nombre de lignes où L7_TOTAL_DEP_FONCT_DECLARE = L8_FRAIS_BREVETS_COV: 0\n",
      "Somme CIR_TOTAL_DECLARE : 0.00 €\n",
      "Somme CIR_TOTAL_CALCULE : 0.00 €\n",
      "Résultats exportés dans: lignes_L7_egal_L8.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier des lignes restantes\n",
    "file_path = \"lignes_restantes_a_analyser.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier chargé: {len(df)} lignes\")\n",
    "\n",
    "# Filtrer les lignes où L7_TOTAL_DEP_FONCT_DECLARE = L8_FRAIS_BREVETS_COV\n",
    "df_filtered = df[(df['L7_TOTAL_DEP_FONCT_DECLARE'] == df['L8_FRAIS_BREVETS_COV']) & (df['L7_TOTAL_DEP_FONCT_DECLARE'] != 0.0)]\n",
    "\n",
    "print(f\"Nombre de lignes où L7_TOTAL_DEP_FONCT_DECLARE = L8_FRAIS_BREVETS_COV: {len(df_filtered)}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_L7_egal_L8.csv\"\n",
    "df_filtered.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "# Calculer les sommes\n",
    "somme_declare = df_filtered['CIR_TOTAL_DECLARE'].sum()\n",
    "somme_calcule = df_filtered['CIR_TOTAL_CALCULE'].sum()\n",
    "\n",
    "print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
    "print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6644ad06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier principal chargé: 27923 lignes\n",
      "\n",
      "Nombre de lignes restantes à analyser: 1721\n",
      "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier principal\n",
    "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2023.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
    "\n",
    "# Charger les fichiers d'analyse précédents\n",
    "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')  # Nouveau fichier\n",
    "l7_egal_l8 = pd.read_csv(\"lignes_L7_egal_L8.csv\", sep=';', encoding='utf-8-sig')\n",
    "\n",
    "# Identifier les SIREN à exclure\n",
    "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT']) \n",
    "siren_l7_l8 = set(l7_egal_l8['SIREN_DECLARANT'])\n",
    "\n",
    "# Combiner tous les SIREN à exclure\n",
    "siren_a_exclure =  siren_jeunes_docteurs | siren_l7_l8 \n",
    "\n",
    "# Filtrer le DataFrame principal\n",
    "# - Exclure les SIREN déjà analysés\n",
    "# - Garder uniquement les lignes où CORRESPONDANCE_CIR est \"Non\"\n",
    "df_restant = df[\n",
    "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) & \n",
    "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
    "]\n",
    "\n",
    "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_restantes_a_analyser.csv\"\n",
    "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ef32bb",
   "metadata": {},
   "source": [
    "## Erreur Cir Recherche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7fda12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier chargé: 1721 lignes\n",
      "Nombre de lignes après filtrage: 18\n",
      "Somme CIR_TOTAL_DECLARE : 65,519,439.00 €\n",
      "Somme CIR_TOTAL_CALCULE : 66,542,918.10 €\n",
      "Résultats exportés dans: lignes_depenses_non0_cir_recherche_0.csv\n",
      "\n",
      "Aperçu des données trouvées:\n",
      "Nombre d'entreprises: 18\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier\n",
    "df = pd.read_csv(\"lignes_restantes_a_analyser.csv\", sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier chargé: {len(df)} lignes\")\n",
    "\n",
    "# Appliquer les filtres :\n",
    "# - L22_TOTAL_DEPENSES_RECHERCHE_DECLARE différent de 0.0\n",
    "# - CIR_RECHERCHE_DECLARE = 0.0\n",
    "df_filtered = df[\n",
    "    (df['L22_TOTAL_DEPENSES_RECHERCHE_DECLARE'] != 0.0) &\n",
    "    (df['CIR_RECHERCHE_DECLARE'] == 0.0)\n",
    "]\n",
    "\n",
    "print(f\"Nombre de lignes après filtrage: {len(df_filtered)}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_depenses_non0_cir_recherche_0.csv\"\n",
    "df_filtered.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "# Calculer les sommes\n",
    "somme_declare = df_filtered['CIR_TOTAL_DECLARE'].sum()\n",
    "somme_calcule = df_filtered['CIR_TOTAL_CALCULE'].sum()\n",
    "\n",
    "print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
    "print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
    "print(f\"Résultats exportés dans: {output_file}\")\n",
    "\n",
    "# Afficher quelques statistiques sur les lignes trouvées\n",
    "if len(df_filtered) > 0:\n",
    "    print(\"\\nAperçu des données trouvées:\")\n",
    "    print(f\"Nombre d'entreprises: {len(df_filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e1583fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier principal chargé: 27923 lignes\n",
      "\n",
      "Nombre de lignes restantes à analyser: 1703\n",
      "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier principal\n",
    "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2023.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
    "\n",
    "# Charger les fichiers d'analyse précédents\n",
    "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')\n",
    "l7_egal_l8 = pd.read_csv(\"lignes_L7_egal_L8.csv\", sep=';', encoding='utf-8-sig')\n",
    "depenses_non0_cir0 = pd.read_csv(\"lignes_depenses_non0_cir_recherche_0.csv\", sep=';', encoding='utf-8-sig')\n",
    "\n",
    "# Identifier les SIREN à exclure\n",
    "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT'])\n",
    "siren_l7_l8 = set(l7_egal_l8['SIREN_DECLARANT'])\n",
    "siren_depenses_non0_cir0 = set(depenses_non0_cir0['SIREN_DECLARANT'])\n",
    "\n",
    "# Combiner tous les SIREN à exclure (ajout du nouveau cas)\n",
    "siren_a_exclure = siren_jeunes_docteurs | siren_l7_l8  | siren_depenses_non0_cir0\n",
    "\n",
    "# Filtrer le DataFrame principal\n",
    "df_restant = df[\n",
    "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) &\n",
    "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
    "]\n",
    "\n",
    "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_restantes_a_analyser.csv\"\n",
    "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cdc7cc",
   "metadata": {},
   "source": [
    "## Erreur depense Externalisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ef2340e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier chargé: 1703 lignes\n",
      "Nombre de lignes extraites: 144\n",
      "Lignes exportées dans: lignes_ecart_cir_recherche_externalise.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Chemin du fichier\n",
    "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//lignes_restantes_a_analyser.csv\"\n",
    "\n",
    "# Charger le fichier\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier chargé: {len(df)} lignes\")\n",
    "\n",
    "# Colonnes d'écart pour les dépenses externalisées\n",
    "colonnes_ext = ['L17_ECART', 'L18_ECART', 'L19_ECART', 'L20_ECART', 'L21_ECART']\n",
    "\n",
    "# Extraire les lignes qui répondent à tous les critères\n",
    "mask_correspondance = df['CORRESPONDANCE_CIR'] == \"Non\"\n",
    "mask_cir = df['CIR_RECHERCHE_ECART'] != 0\n",
    "mask_ext = df[colonnes_ext].abs().sum(axis=1) > 0\n",
    "\n",
    "# Combiner tous les filtres\n",
    "df_resultat = df[mask_correspondance & mask_cir & mask_ext]\n",
    "\n",
    "print(f\"Nombre de lignes extraites: {len(df_resultat)}\")\n",
    "\n",
    "# Exporter vers un fichier CSV\n",
    "output_file = \"lignes_ecart_cir_recherche_externalise.csv\"\n",
    "df_resultat.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "print(f\"Lignes exportées dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d741a72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier chargé: 144 lignes\n",
      "\n",
      "Résultats de l'analyse:\n",
      "- Nombre de lignes où L26A_ECART = CIR_TOTAL_ECART / 3: 127 sur 144\n",
      "- Pourcentage: 88.19%\n",
      "\n",
      "Exemples où L26A_ECART = CIR_TOTAL_ECART / 3:\n",
      "SIREN: 60502291.0, L26A_ECART: -436289.0, CIR_TOTAL_ECART/3: -43629.0\n",
      "Nombre de lignes où L26A_ECART = CIR_TOTAL_ECART / 3: 127\n",
      "Somme CIR_TOTAL_DECLARE : 64,076,281.00 €\n",
      "Somme CIR_TOTAL_CALCULE : 61,614,223.96 €\n",
      "Résultats exportés dans: lignes_L26A_egal_CIR_TOTAL_div_3.csv\n",
      "SIREN: 300702305.0, L26A_ECART: -1999999.63, CIR_TOTAL_ECART/3: -199999.96333333338\n",
      "Nombre de lignes où L26A_ECART = CIR_TOTAL_ECART / 3: 127\n",
      "Somme CIR_TOTAL_DECLARE : 64,076,281.00 €\n",
      "Somme CIR_TOTAL_CALCULE : 61,614,223.96 €\n",
      "Résultats exportés dans: lignes_L26A_egal_CIR_TOTAL_div_3.csv\n",
      "SIREN: 301165841.0, L26A_ECART: -560734.74, CIR_TOTAL_ECART/3: -56073.23999999999\n",
      "Nombre de lignes où L26A_ECART = CIR_TOTAL_ECART / 3: 127\n",
      "Somme CIR_TOTAL_DECLARE : 64,076,281.00 €\n",
      "Somme CIR_TOTAL_CALCULE : 61,614,223.96 €\n",
      "Résultats exportés dans: lignes_L26A_egal_CIR_TOTAL_div_3.csv\n",
      "SIREN: 304398563.0, L26A_ECART: -4.24, CIR_TOTAL_ECART/3: -0.4233333333322662\n",
      "Nombre de lignes où L26A_ECART = CIR_TOTAL_ECART / 3: 127\n",
      "Somme CIR_TOTAL_DECLARE : 64,076,281.00 €\n",
      "Somme CIR_TOTAL_CALCULE : 61,614,223.96 €\n",
      "Résultats exportés dans: lignes_L26A_egal_CIR_TOTAL_div_3.csv\n",
      "SIREN: 305061186.0, L26A_ECART: -1688543.43, CIR_TOTAL_ECART/3: -168854.4766666667\n",
      "Nombre de lignes où L26A_ECART = CIR_TOTAL_ECART / 3: 127\n",
      "Somme CIR_TOTAL_DECLARE : 64,076,281.00 €\n",
      "Somme CIR_TOTAL_CALCULE : 61,614,223.96 €\n",
      "Résultats exportés dans: lignes_L26A_egal_CIR_TOTAL_div_3.csv\n",
      "\n",
      "Exemples où L26A_ECART ≠ CIR_TOTAL_ECART / 3:\n",
      "SIREN: 331565929.0, L26A_ECART: -0.29, CIR_TOTAL_ECART/3: 3520.036666666662, Ratio: -0.0000\n",
      "SIREN: 501096838.0, L26A_ECART: -3.07, CIR_TOTAL_ECART/3: 4918.1599999999935, Ratio: -0.0001\n",
      "SIREN: 540019643.0, L26A_ECART: -0.19, CIR_TOTAL_ECART/3: 3791.6800000000003, Ratio: -0.0000\n",
      "SIREN: 813744364.0, L26A_ECART: -1.4, CIR_TOTAL_ECART/3: 1861.9600000000016, Ratio: -0.0001\n",
      "SIREN: 815307764.0, L26A_ECART: -0.1, CIR_TOTAL_ECART/3: 2686.656666666667, Ratio: -0.0000\n",
      "\n",
      "Résultats détaillés exportés dans: analyse_L26A_vs_CIR_TOTAL.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier CSV généré précédemment\n",
    "fichier = \"lignes_ecart_cir_recherche_externalise.csv\"\n",
    "df = pd.read_csv(fichier, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier chargé: {len(df)} lignes\")\n",
    "\n",
    "# Convertir les colonnes en numérique pour s'assurer que les calculs seront corrects\n",
    "df['L26A_ECART'] = pd.to_numeric(df['L26A_ECART'], errors='coerce')\n",
    "df['CIR_TOTAL_ECART'] = pd.to_numeric(df['CIR_TOTAL_ECART'], errors='coerce')\n",
    "\n",
    "# Créer une colonne pour vérifier si L26A_ECART = CIR_TOTAL_ECART / 0.3\n",
    "# Permettre une petite marge d'erreur pour les arrondis (0.1%)\n",
    "df['RATIO'] = df['L26A_ECART'] / (df['CIR_TOTAL_ECART'] / 0.3)\n",
    "df['EST_EGAL'] = np.isclose(df['RATIO'], 1, rtol=1)  # Tolérance relative de 0.1%\n",
    "\n",
    "# Compter combien de lignes respectent cette relation\n",
    "nb_egal = df['EST_EGAL'].sum()\n",
    "pourcentage = (nb_egal / len(df)) * 100\n",
    "\n",
    "print(f\"\\nRésultats de l'analyse:\")\n",
    "print(f\"- Nombre de lignes où L26A_ECART = CIR_TOTAL_ECART / 3: {nb_egal} sur {len(df)}\")\n",
    "print(f\"- Pourcentage: {pourcentage:.2f}%\")\n",
    "\n",
    "# Afficher quelques exemples où la relation est respectée\n",
    "print(\"\\nExemples où L26A_ECART = CIR_TOTAL_ECART / 3:\")\n",
    "exemples_egal = df[df['EST_EGAL']].head(5)\n",
    "for _, row in exemples_egal.iterrows():\n",
    "    print(f\"SIREN: {row['SIREN_DECLARANT']}, L26A_ECART: {row['L26A_ECART']}, CIR_TOTAL_ECART/3: {row['CIR_TOTAL_ECART']/3}\")\n",
    "    # Filtrer uniquement les lignes où L26A_ECART = CIR_TOTAL_ECART / 3 est vrai\n",
    "    df_resultat = df[df['EST_EGAL']]\n",
    "\n",
    "    # Afficher le nombre de lignes correspondantes\n",
    "    print(f\"Nombre de lignes où L26A_ECART = CIR_TOTAL_ECART / 3: {len(df_resultat)}\")\n",
    "\n",
    "    # Exporter les résultats filtrés dans un fichier CSV\n",
    "    df_resultat.to_csv(\"lignes_L26A_egal_CIR_TOTAL_div_3.csv\", sep=';', encoding='utf-8-sig', index=False)\n",
    "    # Calculer les sommes\n",
    "    somme_declare = df_resultat['CIR_TOTAL_DECLARE'].sum()\n",
    "    somme_calcule = df_resultat['CIR_TOTAL_CALCULE'].sum()\n",
    "\n",
    "    print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
    "    print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
    "    print(f\"Résultats exportés dans: lignes_L26A_egal_CIR_TOTAL_div_3.csv\")\n",
    "# Afficher quelques exemples où la relation n'est pas respectée\n",
    "print(\"\\nExemples où L26A_ECART ≠ CIR_TOTAL_ECART / 3:\")\n",
    "exemples_different = df[~df['EST_EGAL']].head(5)\n",
    "for _, row in exemples_different.iterrows():\n",
    "    print(f\"SIREN: {row['SIREN_DECLARANT']}, L26A_ECART: {row['L26A_ECART']}, CIR_TOTAL_ECART/3: {row['CIR_TOTAL_ECART']/3}, Ratio: {row['RATIO']:.4f}\")\n",
    "\n",
    "# Exporter les résultats avec la colonne d'analyse supplémentaire\n",
    "df.to_csv(\"analyse_L26A_vs_CIR_TOTAL.csv\", sep=';', encoding='utf-8-sig', index=False)\n",
    "print(f\"\\nRésultats détaillés exportés dans: analyse_L26A_vs_CIR_TOTAL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8c16175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier principal chargé: 27923 lignes\n",
      "\n",
      "Nombre de lignes restantes à analyser: 1559\n",
      "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier principal\n",
    "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2023.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
    "\n",
    "# Charger les fichiers d'analyse précédents\n",
    "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')\n",
    "l7_egal_l8 = pd.read_csv(\"lignes_L7_egal_L8.csv\", sep=';', encoding='utf-8-sig')\n",
    "depenses_non0_cir0 = pd.read_csv(\"lignes_depenses_non0_cir_recherche_0.csv\", sep=';', encoding='utf-8-sig')\n",
    "analyse_l26a = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//analyse_L26A_vs_CIR_TOTAL.csv\", sep=';', encoding='utf-8-sig')\n",
    "\n",
    "# Identifier les SIREN à exclure\n",
    "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT'])\n",
    "siren_l7_l8 = set(l7_egal_l8['SIREN_DECLARANT'])\n",
    "siren_depenses_non0_cir0 = set(depenses_non0_cir0['SIREN_DECLARANT'])\n",
    "siren_analyse_l26a = set(analyse_l26a['SIREN_DECLARANT'])\n",
    "\n",
    "# Combiner tous les SIREN à exclure (ajout du cas analyse_L26A_vs_CIR_TOTAL.csv)\n",
    "siren_a_exclure = siren_jeunes_docteurs | siren_l7_l8 | siren_depenses_non0_cir0 | siren_analyse_l26a\n",
    "\n",
    "# Filtrer le DataFrame principal\n",
    "df_restant = df[\n",
    "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) &\n",
    "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
    "]\n",
    "\n",
    "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_restantes_a_analyser.csv\"\n",
    "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729db27f",
   "metadata": {},
   "source": [
    "## Erreur doublement sans motif de la créance total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da658fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier chargé: 1559 lignes\n",
      "Lignes extraites: 7\n",
      "Somme CIR_TOTAL_DECLARE : 1,847,283.00 €\n",
      "Somme CIR_TOTAL_CALCULE : 923,641.52 €\n",
      "Résultats exportés dans: lignes_ecart_relatif_50_innovation0_recherche1.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier des lignes restantes\n",
    "file_path = \"lignes_restantes_a_analyser.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier chargé: {len(df)} lignes\")\n",
    "\n",
    "# Filtrer selon les critères :\n",
    "# - ECART_RELATIF_POURCENT == -50 ou 50\n",
    "# - CIR_INNOVATION_ECART == 0\n",
    "# - CIR_RECHERCHE_ECART entre -1 et 1 inclus\n",
    "mask = (\n",
    "    df['ECART_RELATIF_POURCENT'].isin([-50.0, 50.0]) &\n",
    "    (df['CIR_INNOVATION_ECART'] == 0.0) &\n",
    "    (df['CIR_RECHERCHE_ECART'].between(-1, 1))\n",
    ")\n",
    "\n",
    "df_filtered = df[mask]\n",
    "print(f\"Lignes extraites: {len(df_filtered)}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_ecart_relatif_50_innovation0_recherche1.csv\"\n",
    "df_filtered.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "# Calculer les sommes\n",
    "somme_declare = df_filtered['CIR_TOTAL_DECLARE'].sum()\n",
    "somme_calcule = df_filtered['CIR_TOTAL_CALCULE'].sum()\n",
    "\n",
    "print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
    "print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba4bea65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier principal chargé: 27923 lignes\n",
      "\n",
      "Nombre de lignes restantes à analyser: 1552\n",
      "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier principal\n",
    "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2023.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
    "\n",
    "# Charger les fichiers d'analyse précédents\n",
    "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')\n",
    "l7_egal_l8 = pd.read_csv(\"lignes_L7_egal_L8.csv\", sep=';', encoding='utf-8-sig')\n",
    "depenses_non0_cir0 = pd.read_csv(\"lignes_depenses_non0_cir_recherche_0.csv\", sep=';', encoding='utf-8-sig')\n",
    "analyse_l26a = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//analyse_L26A_vs_CIR_TOTAL.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_relatif_50_innov0_rech1 = pd.read_csv(\"lignes_ecart_relatif_50_innovation0_recherche1.csv\", sep=';', encoding='utf-8-sig')\n",
    "\n",
    "# Identifier les SIREN à exclure\n",
    "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT'])\n",
    "siren_l7_l8 = set(l7_egal_l8['SIREN_DECLARANT'])\n",
    "siren_depenses_non0_cir0 = set(depenses_non0_cir0['SIREN_DECLARANT'])\n",
    "siren_analyse_l26a = set(analyse_l26a['SIREN_DECLARANT'])\n",
    "siren_ecart_relatif_50_innov0_rech1 = set(ecart_relatif_50_innov0_rech1['SIREN_DECLARANT'])\n",
    "\n",
    "# Combiner tous les SIREN à exclure (ajout du cas analyse_L26A_vs_CIR_TOTAL.csv)\n",
    "siren_a_exclure = siren_jeunes_docteurs | siren_l7_l8 | siren_depenses_non0_cir0 | siren_analyse_l26a | siren_ecart_relatif_50_innov0_rech1\n",
    "\n",
    "# Filtrer le DataFrame principal\n",
    "df_restant = df[\n",
    "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) &\n",
    "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
    "]\n",
    "\n",
    "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_restantes_a_analyser.csv\"\n",
    "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c99aef",
   "metadata": {},
   "source": [
    "## erreur diff Cir total compris entre -500 et 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f211df5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier chargé: 1552 lignes\n",
      "Nombre de lignes extraites: 289\n",
      "Somme CIR_TOTAL_DECLARE : 65,700,751.00 €\n",
      "Somme CIR_TOTAL_CALCULE : 65,702,853.69 €\n",
      "Résultats exportés dans: lignes_ecart_total_entre_-500_et_500.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier des lignes restantes à analyser\n",
    "file_path = \"lignes_restantes_a_analyser.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier chargé: {len(df)} lignes\")\n",
    "\n",
    "# Filtrer les lignes où CIR_TOTAL_ECART est entre -500 et 500 et CORRESPONDANCE_CIR == \"Non\"\n",
    "mask_ecart = df['CIR_TOTAL_ECART'].between(-500, 500) & df['CORRESPONDANCE_CIR'].eq(\"Non\")\n",
    "df_resultat = df[mask_ecart]\n",
    "\n",
    "print(f\"Nombre de lignes extraites: {len(df_resultat)}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_ecart_total_entre_-500_et_500.csv\"\n",
    "df_resultat.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "# Calculer les sommes\n",
    "somme_declare = df_resultat['CIR_TOTAL_DECLARE'].sum()\n",
    "somme_calcule = df_resultat['CIR_TOTAL_CALCULE'].sum()\n",
    "\n",
    "print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
    "print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f09d4bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier principal chargé: 27923 lignes\n",
      "\n",
      "Nombre de lignes restantes à analyser: 1263\n",
      "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier principal\n",
    "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2023.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
    "\n",
    "# Charger les fichiers d'analyse précédents\n",
    "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')\n",
    "l7_egal_l8 = pd.read_csv(\"lignes_L7_egal_L8.csv\", sep=';', encoding='utf-8-sig')\n",
    "depenses_non0_cir0 = pd.read_csv(\"lignes_depenses_non0_cir_recherche_0.csv\", sep=';', encoding='utf-8-sig')\n",
    "analyse_l26a = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//analyse_L26A_vs_CIR_TOTAL.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_relatif_50_innov0_rech1 = pd.read_csv(\"lignes_ecart_relatif_50_innovation0_recherche1.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_total500 = pd.read_csv(\"lignes_ecart_total_entre_-500_et_500.csv\", sep=';', encoding='utf-8-sig')\n",
    "\n",
    "# Identifier les SIREN à exclure\n",
    "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT'])\n",
    "siren_l7_l8 = set(l7_egal_l8['SIREN_DECLARANT'])\n",
    "siren_depenses_non0_cir0 = set(depenses_non0_cir0['SIREN_DECLARANT'])\n",
    "siren_analyse_l26a = set(analyse_l26a['SIREN_DECLARANT'])\n",
    "siren_ecart_relatif_50_innov0_rech1 = set(ecart_relatif_50_innov0_rech1['SIREN_DECLARANT'])\n",
    "siren_ecart_total500 = set(ecart_total500['SIREN_DECLARANT'])\n",
    "\n",
    "# Combiner tous les SIREN à exclure (ajout du cas lignes_ecart_total_entre_-500_et_500.csv)\n",
    "siren_a_exclure = siren_jeunes_docteurs | siren_l7_l8 | siren_depenses_non0_cir0 | siren_analyse_l26a | siren_ecart_relatif_50_innov0_rech1 | siren_ecart_total500\n",
    "\n",
    "# Filtrer le DataFrame principal\n",
    "df_restant = df[\n",
    "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) &\n",
    "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
    "]\n",
    "\n",
    "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_restantes_a_analyser.csv\"\n",
    "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96a15ee",
   "metadata": {},
   "source": [
    "## Plafond Partout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6a8e85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier chargé: 1263 lignes\n",
      "Nombre de lignes avec ECART_RELATIF_POURCENT = -100: 318\n",
      "Somme CIR_TOTAL_DECLARE : 56,716,432.00 €\n",
      "Somme CIR_TOTAL_CALCULE : 0.00 €\n",
      "Résultats exportés dans: lignes_ecart_relatif_moins_100.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier avec les 703 lignes restantes\n",
    "file_path = \"lignes_restantes_a_analyser.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier chargé: {len(df)} lignes\")\n",
    "\n",
    "# Filtrer les lignes où ECART_RELATIF_POURCENT est égal à -100\n",
    "df_ecart_negatif = df[df['ECART_RELATIF_POURCENT'] == -100]\n",
    "print(f\"Nombre de lignes avec ECART_RELATIF_POURCENT = -100: {len(df_ecart_negatif)}\")\n",
    "\n",
    "# Exporter les résultats dans un fichier CSV\n",
    "output_file = \"lignes_ecart_relatif_moins_100.csv\"\n",
    "df_ecart_negatif.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "# Calculer les sommes\n",
    "somme_declare = df_ecart_negatif['CIR_TOTAL_DECLARE'].sum()\n",
    "somme_calcule = df_ecart_negatif['CIR_TOTAL_CALCULE'].sum()\n",
    "\n",
    "print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
    "print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bbe0435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier principal chargé: 27923 lignes\n",
      "\n",
      "Nombre de lignes restantes à analyser: 945\n",
      "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier principal\n",
    "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2023.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
    "\n",
    "# Charger les fichiers d'analyse précédents\n",
    "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')\n",
    "l7_egal_l8 = pd.read_csv(\"lignes_L7_egal_L8.csv\", sep=';', encoding='utf-8-sig')\n",
    "depenses_non0_cir0 = pd.read_csv(\"lignes_depenses_non0_cir_recherche_0.csv\", sep=';', encoding='utf-8-sig')\n",
    "analyse_l26a = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//analyse_L26A_vs_CIR_TOTAL.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_relatif_50_innov0_rech1 = pd.read_csv(\"lignes_ecart_relatif_50_innovation0_recherche1.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_total500 = pd.read_csv(\"lignes_ecart_total_entre_-500_et_500.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_moins_100 = pd.read_csv(\"lignes_ecart_relatif_moins_100.csv\", sep=';', encoding='utf-8-sig')\n",
    "\n",
    "# Identifier les SIREN à exclure\n",
    "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT'])\n",
    "siren_l7_l8 = set(l7_egal_l8['SIREN_DECLARANT'])\n",
    "siren_depenses_non0_cir0 = set(depenses_non0_cir0['SIREN_DECLARANT'])\n",
    "siren_analyse_l26a = set(analyse_l26a['SIREN_DECLARANT'])\n",
    "siren_ecart_relatif_50_innov0_rech1 = set(ecart_relatif_50_innov0_rech1['SIREN_DECLARANT'])\n",
    "siren_ecart_total500 = set(ecart_total500['SIREN_DECLARANT'])\n",
    "siren_ecart_moins_100 = set(ecart_moins_100['SIREN_DECLARANT'])\n",
    "\n",
    "# Combiner tous les SIREN à exclure (ajout du cas lignes_ecart_relatif_moins_100.csv)\n",
    "siren_a_exclure = siren_jeunes_docteurs | siren_l7_l8 | siren_depenses_non0_cir0 | \\\n",
    "                  siren_analyse_l26a | siren_ecart_relatif_50_innov0_rech1 | \\\n",
    "                  siren_ecart_total500 | siren_ecart_moins_100\n",
    "\n",
    "# Filtrer le DataFrame principal\n",
    "df_restant = df[\n",
    "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) &\n",
    "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
    "]\n",
    "\n",
    "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_restantes_a_analyser.csv\"\n",
    "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcabae6",
   "metadata": {},
   "source": [
    "## Erreur Cir innovation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2549a12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier chargé: 945 lignes\n",
      "\n",
      "Nombre de lignes où CIR_TOTAL_ECART = CIR_INNOVATION_ECART (±1): 204\n",
      "\n",
      "Exemples :\n",
      "SIREN: 301468211.0\n",
      "CIR_TOTAL_ECART: 33729.64\n",
      "CIR_INNOVATION_ECART: 33730.00\n",
      "SIREN: 310863774.0\n",
      "CIR_TOTAL_ECART: -46134.00\n",
      "CIR_INNOVATION_ECART: -46134.00\n",
      "SIREN: 311243067.0\n",
      "CIR_TOTAL_ECART: 5465.40\n",
      "CIR_INNOVATION_ECART: 5465.70\n",
      "SIREN: 312940224.0\n",
      "CIR_TOTAL_ECART: 40000.00\n",
      "CIR_INNOVATION_ECART: 40000.00\n",
      "SIREN: 316742980.0\n",
      "CIR_TOTAL_ECART: 3981.88\n",
      "CIR_INNOVATION_ECART: 3981.90\n",
      "Somme CIR_TOTAL_DECLARE : 14,528,954.00 €\n",
      "Somme CIR_TOTAL_CALCULE : 16,166,757.67 €\n",
      "\n",
      "Résultats exportés dans: lignes_ecart_total_egal_innovation.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier des lignes restantes\n",
    "file_path = \"lignes_restantes_a_analyser.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier chargé: {len(df)} lignes\")\n",
    "\n",
    "# Filtrer les lignes où CIR_TOTAL_ECART = CIR_INNOVATION_ECART (±1)\n",
    "mask = np.isclose(df['CIR_TOTAL_ECART'], df['CIR_INNOVATION_ECART'], atol=1.0)\n",
    "df_filtered = df[mask]\n",
    "\n",
    "print(f\"\\nNombre de lignes où CIR_TOTAL_ECART = CIR_INNOVATION_ECART (±1): {len(df_filtered)}\")\n",
    "\n",
    "# Afficher quelques exemples\n",
    "if len(df_filtered) > 0:\n",
    "    print(\"\\nExemples :\")\n",
    "    for _, row in df_filtered.head().iterrows():\n",
    "        print(f\"SIREN: {row['SIREN_DECLARANT']}\")\n",
    "        print(f\"CIR_TOTAL_ECART: {row['CIR_TOTAL_ECART']:.2f}\")\n",
    "        print(f\"CIR_INNOVATION_ECART: {row['CIR_INNOVATION_ECART']:.2f}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_ecart_total_egal_innovation.csv\"\n",
    "df_filtered.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "# Calculer les sommes\n",
    "somme_declare = df_filtered['CIR_TOTAL_DECLARE'].sum()\n",
    "somme_calcule = df_filtered['CIR_TOTAL_CALCULE'].sum()\n",
    "\n",
    "print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
    "print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
    "print(f\"\\nRésultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b096c57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier principal chargé: 27923 lignes\n",
      "\n",
      "Nombre de lignes restantes à analyser: 740\n",
      "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier principal\n",
    "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2023.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
    "\n",
    "# Charger les fichiers d'analyse précédents\n",
    "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')\n",
    "l7_egal_l8 = pd.read_csv(\"lignes_L7_egal_L8.csv\", sep=';', encoding='utf-8-sig')\n",
    "depenses_non0_cir0 = pd.read_csv(\"lignes_depenses_non0_cir_recherche_0.csv\", sep=';', encoding='utf-8-sig')\n",
    "analyse_l26a = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//analyse_L26A_vs_CIR_TOTAL.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_relatif_50_innov0_rech1 = pd.read_csv(\"lignes_ecart_relatif_50_innovation0_recherche1.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_total500 = pd.read_csv(\"lignes_ecart_total_entre_-500_et_500.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_moins_100 = pd.read_csv(\"lignes_ecart_relatif_moins_100.csv\", sep=';', encoding='utf-8-sig')\n",
    "innovation_egal_total = pd.read_csv(\"lignes_ecart_total_egal_innovation.csv\", sep=';', encoding='utf-8-sig')\n",
    "\n",
    "# Identifier les SIREN à exclure\n",
    "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT'])\n",
    "siren_l7_l8 = set(l7_egal_l8['SIREN_DECLARANT'])\n",
    "siren_depenses_non0_cir0 = set(depenses_non0_cir0['SIREN_DECLARANT'])\n",
    "siren_analyse_l26a = set(analyse_l26a['SIREN_DECLARANT'])\n",
    "siren_ecart_relatif_50_innov0_rech1 = set(ecart_relatif_50_innov0_rech1['SIREN_DECLARANT'])\n",
    "siren_ecart_total500 = set(ecart_total500['SIREN_DECLARANT'])\n",
    "siren_ecart_moins_100 = set(ecart_moins_100['SIREN_DECLARANT'])\n",
    "siren_innovation_egal_total = set(innovation_egal_total['SIREN_DECLARANT'])\n",
    "\n",
    "# Combiner tous les SIREN à exclure (ajout du cas innovation_egal_total)\n",
    "siren_a_exclure = siren_jeunes_docteurs | siren_l7_l8 | siren_depenses_non0_cir0 | \\\n",
    "                  siren_analyse_l26a | siren_ecart_relatif_50_innov0_rech1 | \\\n",
    "                  siren_ecart_total500 | siren_ecart_moins_100 | \\\n",
    "                  siren_innovation_egal_total\n",
    "\n",
    "# Filtrer le DataFrame principal\n",
    "df_restant = df[\n",
    "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) &\n",
    "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
    "]\n",
    "\n",
    "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_restantes_a_analyser.csv\"\n",
    "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c135580",
   "metadata": {},
   "source": [
    "## Erreur Cir Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "658dc078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier chargé: 740 lignes\n",
      "\n",
      "Nombre de lignes où CIR_TOTAL_ECART = CIR_COLLECTION_ECART (±1): 12\n",
      "\n",
      "Quelques exemples :\n",
      "\n",
      "SIREN: 302306626.0\n",
      "CIR_TOTAL_ECART: -94531.00\n",
      "CIR_COLLECTION_ECART: -94531.00\n",
      "\n",
      "SIREN: 322106873.0\n",
      "CIR_TOTAL_ECART: -5567.10\n",
      "CIR_COLLECTION_ECART: -5567.00\n",
      "\n",
      "SIREN: 342973484.0\n",
      "CIR_TOTAL_ECART: -40544.18\n",
      "CIR_COLLECTION_ECART: -40544.00\n",
      "\n",
      "SIREN: 344894985.0\n",
      "CIR_TOTAL_ECART: 158947.00\n",
      "CIR_COLLECTION_ECART: 158947.50\n",
      "\n",
      "SIREN: 382456051.0\n",
      "CIR_TOTAL_ECART: -16856.00\n",
      "CIR_COLLECTION_ECART: -16856.00\n",
      "Somme CIR_TOTAL_DECLARE : 1,428,913.00 €\n",
      "Somme CIR_TOTAL_CALCULE : 1,556,337.42 €\n",
      "\n",
      "Résultats exportés dans: lignes_ecart_total_egal_collection.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier\n",
    "file_path = \"lignes_restantes_a_analyser.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier chargé: {len(df)} lignes\")\n",
    "\n",
    "# Créer le masque pour identifier où CIR_TOTAL_ECART = CIR_COLLECTION_ECART (±1)\n",
    "mask = np.isclose(df['CIR_TOTAL_ECART'], df['CIR_COLLECTION_ECART'], atol=1.0)\n",
    "\n",
    "# Filtrer les lignes\n",
    "df_filtered = df[mask]\n",
    "\n",
    "print(f\"\\nNombre de lignes où CIR_TOTAL_ECART = CIR_COLLECTION_ECART (±1): {len(df_filtered)}\")\n",
    "\n",
    "# Afficher quelques statistiques sur ces lignes\n",
    "if len(df_filtered) > 0:\n",
    "    print(\"\\nQuelques exemples :\")\n",
    "    for _, row in df_filtered.head().iterrows():\n",
    "        print(f\"\\nSIREN: {row['SIREN_DECLARANT']}\")\n",
    "        print(f\"CIR_TOTAL_ECART: {row['CIR_TOTAL_ECART']:.2f}\")\n",
    "        print(f\"CIR_COLLECTION_ECART: {row['CIR_COLLECTION_ECART']:.2f}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_ecart_total_egal_collection.csv\"\n",
    "df_filtered.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "# Calculer les sommes\n",
    "somme_declare = df_filtered['CIR_TOTAL_DECLARE'].sum()\n",
    "somme_calcule = df_filtered['CIR_TOTAL_CALCULE'].sum()\n",
    "\n",
    "print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
    "print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
    "print(f\"\\nRésultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f020acbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier principal chargé: 27923 lignes\n",
      "\n",
      "Nombre de lignes restantes à analyser: 728\n",
      "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier principal\n",
    "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2023.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
    "\n",
    "# Charger les fichiers d'analyse précédents\n",
    "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')\n",
    "l7_egal_l8 = pd.read_csv(\"lignes_L7_egal_L8.csv\", sep=';', encoding='utf-8-sig')\n",
    "depenses_non0_cir0 = pd.read_csv(\"lignes_depenses_non0_cir_recherche_0.csv\", sep=';', encoding='utf-8-sig')\n",
    "analyse_l26a = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//analyse_L26A_vs_CIR_TOTAL.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_relatif_50_innov0_rech1 = pd.read_csv(\"lignes_ecart_relatif_50_innovation0_recherche1.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_total500 = pd.read_csv(\"lignes_ecart_total_entre_-500_et_500.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_moins_100 = pd.read_csv(\"lignes_ecart_relatif_moins_100.csv\", sep=';', encoding='utf-8-sig')\n",
    "innovation_egal_total = pd.read_csv(\"lignes_ecart_total_egal_innovation.csv\", sep=';', encoding='utf-8-sig')\n",
    "collection_egal_total = pd.read_csv(\"lignes_ecart_total_egal_collection.csv\", sep=';', encoding='utf-8-sig')\n",
    "\n",
    "# Identifier les SIREN à exclure\n",
    "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT'])\n",
    "siren_l7_l8 = set(l7_egal_l8['SIREN_DECLARANT'])\n",
    "siren_depenses_non0_cir0 = set(depenses_non0_cir0['SIREN_DECLARANT'])\n",
    "siren_analyse_l26a = set(analyse_l26a['SIREN_DECLARANT'])\n",
    "siren_ecart_relatif_50_innov0_rech1 = set(ecart_relatif_50_innov0_rech1['SIREN_DECLARANT'])\n",
    "siren_ecart_total500 = set(ecart_total500['SIREN_DECLARANT'])\n",
    "siren_ecart_moins_100 = set(ecart_moins_100['SIREN_DECLARANT'])\n",
    "siren_innovation_egal_total = set(innovation_egal_total['SIREN_DECLARANT'])\n",
    "siren_collection_egal_total = set(collection_egal_total['SIREN_DECLARANT'])\n",
    "\n",
    "# Combiner tous les SIREN à exclure (ajout du cas collection_egal_total)\n",
    "siren_a_exclure = siren_jeunes_docteurs | siren_l7_l8 | siren_depenses_non0_cir0 | \\\n",
    "                  siren_analyse_l26a | siren_ecart_relatif_50_innov0_rech1 | \\\n",
    "                  siren_ecart_total500 | siren_ecart_moins_100 | \\\n",
    "                  siren_innovation_egal_total | siren_collection_egal_total\n",
    "\n",
    "# Filtrer le DataFrame principal\n",
    "df_restant = df[\n",
    "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) &\n",
    "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
    "]\n",
    "\n",
    "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_restantes_a_analyser.csv\"\n",
    "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9588a29",
   "metadata": {},
   "source": [
    "## Erreur Cir Déclarer vaut 0 alors que sa ne l'est pas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54ddf72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier chargé: 728 lignes\n",
      "Nombre de lignes où ECART_RELATIF_POURCENT = 100 et CIR_TOTAL_DECLARE = 0: 103\n",
      "Somme CIR_TOTAL_DECLARE : 0.00 €\n",
      "Somme CIR_TOTAL_CALCULE : 10,879,886.21 €\n",
      "Résultats exportés dans: lignes_ecart_100_cir_declare_0.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier des lignes restantes\n",
    "file_path = \"lignes_restantes_a_analyser.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier chargé: {len(df)} lignes\")\n",
    "\n",
    "# Filtrer les lignes où ECART_RELATIF_POURCENT = 100 et CIR_TOTAL_DECLARE = 0\n",
    "df_filtered = df[(df['ECART_RELATIF_POURCENT'] == 100) & (df['CIR_TOTAL_DECLARE'] == 0)]\n",
    "\n",
    "print(f\"Nombre de lignes où ECART_RELATIF_POURCENT = 100 et CIR_TOTAL_DECLARE = 0: {len(df_filtered)}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_ecart_100_cir_declare_0.csv\"\n",
    "df_filtered.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "# Calculer les sommes\n",
    "somme_declare = df_filtered['CIR_TOTAL_DECLARE'].sum()\n",
    "somme_calcule = df_filtered['CIR_TOTAL_CALCULE'].sum()\n",
    "\n",
    "print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
    "print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a9bc6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier principal chargé: 27923 lignes\n",
      "\n",
      "Nombre de lignes restantes à analyser: 624\n",
      "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier principal\n",
    "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2023.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
    "\n",
    "# Charger tous les fichiers d'analyse précédents\n",
    "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')\n",
    "l7_egal_l8 = pd.read_csv(\"lignes_L7_egal_L8.csv\", sep=';', encoding='utf-8-sig')\n",
    "depenses_non0_cir0 = pd.read_csv(\"lignes_depenses_non0_cir_recherche_0.csv\", sep=';', encoding='utf-8-sig')\n",
    "analyse_l26a = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//analyse_L26A_vs_CIR_TOTAL.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_relatif_50_innov0_rech1 = pd.read_csv(\"lignes_ecart_relatif_50_innovation0_recherche1.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_total500 = pd.read_csv(\"lignes_ecart_total_entre_-500_et_500.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_moins_100 = pd.read_csv(\"lignes_ecart_relatif_moins_100.csv\", sep=';', encoding='utf-8-sig')\n",
    "innovation_egal_total = pd.read_csv(\"lignes_ecart_total_egal_innovation.csv\", sep=';', encoding='utf-8-sig')\n",
    "collection_egal_total = pd.read_csv(\"lignes_ecart_total_egal_collection.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_100_cir_declare_0 = pd.read_csv(\"lignes_ecart_100_cir_declare_0.csv\", sep=';', encoding='utf-8-sig')\n",
    "\n",
    "# Identifier les SIREN à exclure\n",
    "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT'])\n",
    "siren_l7_l8 = set(l7_egal_l8['SIREN_DECLARANT'])\n",
    "siren_depenses_non0_cir0 = set(depenses_non0_cir0['SIREN_DECLARANT'])\n",
    "siren_analyse_l26a = set(analyse_l26a['SIREN_DECLARANT'])\n",
    "siren_ecart_relatif_50_innov0_rech1 = set(ecart_relatif_50_innov0_rech1['SIREN_DECLARANT'])\n",
    "siren_ecart_total500 = set(ecart_total500['SIREN_DECLARANT'])\n",
    "siren_ecart_moins_100 = set(ecart_moins_100['SIREN_DECLARANT'])\n",
    "siren_innovation_egal_total = set(innovation_egal_total['SIREN_DECLARANT'])\n",
    "siren_collection_egal_total = set(collection_egal_total['SIREN_DECLARANT'])\n",
    "siren_ecart_100_cir_declare_0 = set(ecart_100_cir_declare_0['SIREN_DECLARANT'])\n",
    "\n",
    "# Combiner tous les SIREN à exclure (ajout du cas ecart_100_cir_declare_0)\n",
    "siren_a_exclure = siren_jeunes_docteurs | siren_l7_l8 | siren_depenses_non0_cir0 | \\\n",
    "                  siren_analyse_l26a | siren_ecart_relatif_50_innov0_rech1 | \\\n",
    "                  siren_ecart_total500 | siren_ecart_moins_100 | \\\n",
    "                  siren_innovation_egal_total | siren_collection_egal_total | \\\n",
    "                  siren_ecart_100_cir_declare_0\n",
    "\n",
    "# Filtrer le DataFrame principal\n",
    "df_restant = df[\n",
    "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) &\n",
    "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
    "]\n",
    "\n",
    "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_restantes_a_analyser.csv\"\n",
    "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259fda6d",
   "metadata": {},
   "source": [
    "## Erreur liée à L6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9fe6e833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier chargé: 624 lignes\n",
      "\n",
      "Nombre de lignes où CIR_TOTAL_ECART = CIR_RECHERCHE_ECART (±1) et L6_ECART hors [-1, 1]: 44\n",
      "Somme CIR_TOTAL_DECLARE : 4,535,248.00 €\n",
      "Somme CIR_TOTAL_CALCULE : 4,872,529.08 €\n",
      "\n",
      "Résultats exportés dans: lignes_ecart_total_egal_recherche_l6_ecart_hors_1.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier des lignes restantes\n",
    "file_path = \"lignes_restantes_a_analyser.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier chargé: {len(df)} lignes\")\n",
    "\n",
    "# Filtrer les lignes où CIR_TOTAL_ECART = CIR_RECHERCHE_ECART (±1)\n",
    "mask_ecart = np.isclose(df['CIR_TOTAL_ECART'], df['CIR_RECHERCHE_ECART'], atol=1.0)\n",
    "\n",
    "# Filtrer les lignes où L6_ECART est strictement en dehors de [-1, 1]\n",
    "mask_l6 = (df['L6_ECART'] < -1) | (df['L6_ECART'] > 1)\n",
    "\n",
    "# Appliquer les deux filtres\n",
    "df_filtered = df[mask_ecart & mask_l6]\n",
    "\n",
    "print(f\"\\nNombre de lignes où CIR_TOTAL_ECART = CIR_RECHERCHE_ECART (±1) et L6_ECART hors [-1, 1]: {len(df_filtered)}\")\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_ecart_total_egal_recherche_l6_ecart_hors_1.csv\"\n",
    "df_filtered.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "# Calculer les sommes\n",
    "somme_declare = df_filtered['CIR_TOTAL_DECLARE'].sum()\n",
    "somme_calcule = df_filtered['CIR_TOTAL_CALCULE'].sum()\n",
    "\n",
    "print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
    "print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
    "print(f\"\\nRésultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a7e16ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier principal chargé: 27923 lignes\n",
      "\n",
      "Nombre de lignes restantes à analyser: 580\n",
      "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier principal\n",
    "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2023.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
    "\n",
    "# Charger tous les fichiers d'analyse précédents\n",
    "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')\n",
    "l7_egal_l8 = pd.read_csv(\"lignes_L7_egal_L8.csv\", sep=';', encoding='utf-8-sig')\n",
    "depenses_non0_cir0 = pd.read_csv(\"lignes_depenses_non0_cir_recherche_0.csv\", sep=';', encoding='utf-8-sig')\n",
    "analyse_l26a = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//analyse_L26A_vs_CIR_TOTAL.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_relatif_50_innov0_rech1 = pd.read_csv(\"lignes_ecart_relatif_50_innovation0_recherche1.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_total500 = pd.read_csv(\"lignes_ecart_total_entre_-500_et_500.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_moins_100 = pd.read_csv(\"lignes_ecart_relatif_moins_100.csv\", sep=';', encoding='utf-8-sig')\n",
    "innovation_egal_total = pd.read_csv(\"lignes_ecart_total_egal_innovation.csv\", sep=';', encoding='utf-8-sig')\n",
    "collection_egal_total = pd.read_csv(\"lignes_ecart_total_egal_collection.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_100_cir_declare_0 = pd.read_csv(\"lignes_ecart_100_cir_declare_0.csv\", sep=';', encoding='utf-8-sig')\n",
    "l6_ecart_hors_1 = pd.read_csv(\"lignes_ecart_total_egal_recherche_l6_ecart_hors_1.csv\", sep=';', encoding='utf-8-sig')\n",
    "\n",
    "# Identifier les SIREN à exclure\n",
    "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT'])\n",
    "siren_l7_l8 = set(l7_egal_l8['SIREN_DECLARANT'])\n",
    "siren_depenses_non0_cir0 = set(depenses_non0_cir0['SIREN_DECLARANT'])\n",
    "siren_analyse_l26a = set(analyse_l26a['SIREN_DECLARANT'])\n",
    "siren_ecart_relatif_50_innov0_rech1 = set(ecart_relatif_50_innov0_rech1['SIREN_DECLARANT'])\n",
    "siren_ecart_total500 = set(ecart_total500['SIREN_DECLARANT'])\n",
    "siren_ecart_moins_100 = set(ecart_moins_100['SIREN_DECLARANT'])\n",
    "siren_innovation_egal_total = set(innovation_egal_total['SIREN_DECLARANT'])\n",
    "siren_collection_egal_total = set(collection_egal_total['SIREN_DECLARANT'])\n",
    "siren_ecart_100_cir_declare_0 = set(ecart_100_cir_declare_0['SIREN_DECLARANT'])\n",
    "siren_l6_ecart_hors_1 = set(l6_ecart_hors_1['SIREN_DECLARANT'])\n",
    "\n",
    "# Combiner tous les SIREN à exclure (ajout du cas l6_ecart_hors_1)\n",
    "siren_a_exclure = siren_jeunes_docteurs | siren_l7_l8 | siren_depenses_non0_cir0 | \\\n",
    "                  siren_analyse_l26a | siren_ecart_relatif_50_innov0_rech1 | \\\n",
    "                  siren_ecart_total500 | siren_ecart_moins_100 | \\\n",
    "                  siren_innovation_egal_total | siren_collection_egal_total | \\\n",
    "                  siren_ecart_100_cir_declare_0 | siren_l6_ecart_hors_1\n",
    "\n",
    "# Filtrer le DataFrame principal\n",
    "df_restant = df[\n",
    "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) &\n",
    "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
    "]\n",
    "\n",
    "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_restantes_a_analyser.csv\"\n",
    "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b14840",
   "metadata": {},
   "source": [
    "## Erreur liée à L26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d5608b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier chargé: 580 lignes\n",
      "Nombre de lignes correspondant au cas demandé : 3\n",
      "     SIREN_DECLARANT  L26A_ECART  L14_ECART  L20_ECART  L21_ECART\n",
      "437      830552808.0   122840.19       0.19        0.0        0.0\n",
      "465      844724021.0   -53680.00       0.00        0.0        0.0\n",
      "532      898441894.0   138123.45       0.45        0.0        0.0\n",
      "Somme CIR_TOTAL_DECLARE : 167,892.00 €\n",
      "Somme CIR_TOTAL_CALCULE : 215,086.50 €\n",
      "Résultats exportés dans: lignes_cas_L26A_ecart_hors_1_L14_L20_L21_dans_1.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier des lignes restantes\n",
    "file_path = \"lignes_restantes_a_analyser.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier chargé: {len(df)} lignes\")\n",
    "\n",
    "# Appliquer les filtres demandés\n",
    "mask = (\n",
    "    ((df['L26A_ECART'] > 1) | (df['L26A_ECART'] < -1))\n",
    "    & ((df['L14_ECART'] > -1) & (df['L14_ECART'] < 1))\n",
    "    & ((df['L20_ECART'] > -1) & (df['L20_ECART'] < 1))\n",
    "    & ((df['L21_ECART'] > -1) & (df['L21_ECART'] < 1))\n",
    "    & ((df['L22_ECART'] > -1) & (df['L22_ECART'] < 1))\n",
    ")\n",
    "\n",
    "df_filtered = df[mask]\n",
    "print(f\"Nombre de lignes correspondant au cas demandé : {len(df_filtered)}\")\n",
    "\n",
    "# Afficher quelques exemples\n",
    "if len(df_filtered) > 0:\n",
    "    print(df_filtered[['SIREN_DECLARANT', 'L26A_ECART', 'L14_ECART', 'L20_ECART', 'L21_ECART']].head())\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_cas_L26A_ecart_hors_1_L14_L20_L21_dans_1.csv\"\n",
    "df_filtered.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "# Calculer les sommes\n",
    "somme_declare = df_filtered['CIR_TOTAL_DECLARE'].sum()\n",
    "somme_calcule = df_filtered['CIR_TOTAL_CALCULE'].sum()\n",
    "\n",
    "print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
    "print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "061ecb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier principal chargé: 27923 lignes\n",
      "\n",
      "Nombre de lignes restantes à analyser: 577\n",
      "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier principal\n",
    "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2023.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
    "\n",
    "# Charger tous les fichiers d'analyse précédents\n",
    "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')\n",
    "l7_egal_l8 = pd.read_csv(\"lignes_L7_egal_L8.csv\", sep=';', encoding='utf-8-sig')\n",
    "depenses_non0_cir0 = pd.read_csv(\"lignes_depenses_non0_cir_recherche_0.csv\", sep=';', encoding='utf-8-sig')\n",
    "analyse_l26a = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//analyse_L26A_vs_CIR_TOTAL.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_relatif_50_innov0_rech1 = pd.read_csv(\"lignes_ecart_relatif_50_innovation0_recherche1.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_total500 = pd.read_csv(\"lignes_ecart_total_entre_-500_et_500.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_moins_100 = pd.read_csv(\"lignes_ecart_relatif_moins_100.csv\", sep=';', encoding='utf-8-sig')\n",
    "innovation_egal_total = pd.read_csv(\"lignes_ecart_total_egal_innovation.csv\", sep=';', encoding='utf-8-sig')\n",
    "collection_egal_total = pd.read_csv(\"lignes_ecart_total_egal_collection.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_100_cir_declare_0 = pd.read_csv(\"lignes_ecart_100_cir_declare_0.csv\", sep=';', encoding='utf-8-sig')\n",
    "l6_ecart_hors_1 = pd.read_csv(\"lignes_ecart_total_egal_recherche_l6_ecart_hors_1.csv\", sep=';', encoding='utf-8-sig')\n",
    "cas_l26a = pd.read_csv(\"lignes_cas_L26A_ecart_hors_1_L14_L20_L21_dans_1.csv\", sep=';', encoding='utf-8-sig')\n",
    "\n",
    "# Identifier les SIREN à exclure\n",
    "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT'])\n",
    "siren_l7_l8 = set(l7_egal_l8['SIREN_DECLARANT'])\n",
    "siren_depenses_non0_cir0 = set(depenses_non0_cir0['SIREN_DECLARANT'])\n",
    "siren_analyse_l26a = set(analyse_l26a['SIREN_DECLARANT'])\n",
    "siren_ecart_relatif_50_innov0_rech1 = set(ecart_relatif_50_innov0_rech1['SIREN_DECLARANT'])\n",
    "siren_ecart_total500 = set(ecart_total500['SIREN_DECLARANT'])\n",
    "siren_ecart_moins_100 = set(ecart_moins_100['SIREN_DECLARANT'])\n",
    "siren_innovation_egal_total = set(innovation_egal_total['SIREN_DECLARANT'])\n",
    "siren_collection_egal_total = set(collection_egal_total['SIREN_DECLARANT'])\n",
    "siren_ecart_100_cir_declare_0 = set(ecart_100_cir_declare_0['SIREN_DECLARANT'])\n",
    "siren_l6_ecart_hors_1 = set(l6_ecart_hors_1['SIREN_DECLARANT'])\n",
    "siren_cas_l26a = set(cas_l26a['SIREN_DECLARANT'])\n",
    "\n",
    "# Combiner tous les SIREN à exclure (ajout du cas l6_ecart_hors_1)\n",
    "siren_a_exclure = siren_jeunes_docteurs | siren_l7_l8 | siren_depenses_non0_cir0 | \\\n",
    "                  siren_analyse_l26a | siren_ecart_relatif_50_innov0_rech1 | \\\n",
    "                  siren_ecart_total500 | siren_ecart_moins_100 | \\\n",
    "                  siren_innovation_egal_total | siren_collection_egal_total | \\\n",
    "                  siren_ecart_100_cir_declare_0 | siren_l6_ecart_hors_1 | siren_cas_l26a\n",
    "\n",
    "# Filtrer le DataFrame principal\n",
    "df_restant = df[\n",
    "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) &\n",
    "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
    "]\n",
    "\n",
    "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_restantes_a_analyser.csv\"\n",
    "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6374493e",
   "metadata": {},
   "source": [
    "## Erreur oublie CRC dans Cir Total Déclarer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "508eef7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier chargé: 577 lignes\n",
      "Colonne L91_MONTANT_TOTAL_CIR_RECHERCHE_COLLABORATIVE absente du fichier.\n",
      "Nombre de lignes correspondant au cas demandé : 0\n",
      "Somme CIR_TOTAL_DECLARE : 0.00 €\n",
      "Somme CIR_TOTAL_CALCULE : 0.00 €\n",
      "Résultats exportés dans: lignes_ecarts_cir_entre_-1_1_et_total_egal_L91.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier des lignes restantes\n",
    "file_path = \"lignes_restantes_a_analyser.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier chargé: {len(df)} lignes\")\n",
    "\n",
    "# Filtrer les lignes où les écarts CIR (recherche, collection, innovation, collaboratif) sont tous entre -1 et 1\n",
    "mask_ecarts = (\n",
    "    df['CIR_RECHERCHE_ECART'].between(-1, 1) &\n",
    "    df['CIR_COLLECTION_ECART'].between(-1, 1) &\n",
    "    df['CIR_INNOVATION_ECART'].between(-1, 1) &\n",
    "    df['CIR_COLLABORATIF_ECART'].between(-1, 1)\n",
    ")\n",
    "\n",
    "# Filtrer les lignes où CIR_TOTAL_ECART = L91_MONTANT_TOTAL_CIR_RECHERCHE_COLLABORATIVE (à ±1 près)\n",
    "if 'L91_MONTANT_TOTAL_CIR_RECHERCHE_COLLABORATIVE' in df.columns:\n",
    "    mask_l91 = np.isclose(df['CIR_TOTAL_ECART'], df['L91_MONTANT_TOTAL_CIR_RECHERCHE_COLLABORATIVE'], atol=1.0)\n",
    "else:\n",
    "    mask_l91 = pd.Series([False]*len(df), index=df.index)\n",
    "    print(\"Colonne L91_MONTANT_TOTAL_CIR_RECHERCHE_COLLABORATIVE absente du fichier.\")\n",
    "\n",
    "# Appliquer les deux filtres\n",
    "df_filtered = df[mask_ecarts & mask_l91]\n",
    "\n",
    "print(f\"Nombre de lignes correspondant au cas demandé : {len(df_filtered)}\")\n",
    "\n",
    "# Afficher quelques exemples\n",
    "if len(df_filtered) > 0:\n",
    "    print(df_filtered[['SIREN_DECLARANT', 'CIR_TOTAL_ECART', 'L91_MONTANT_TOTAL_CIR_RECHERCHE_COLLABORATIVE']].head())\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_ecarts_cir_entre_-1_1_et_total_egal_L91.csv\"\n",
    "df_filtered.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "# Calculer les sommes\n",
    "somme_declare = df_filtered['CIR_TOTAL_DECLARE'].sum()\n",
    "somme_calcule = df_filtered['CIR_TOTAL_CALCULE'].sum()\n",
    "\n",
    "print(f\"Somme CIR_TOTAL_DECLARE : {somme_declare:,.2f} €\")\n",
    "print(f\"Somme CIR_TOTAL_CALCULE : {somme_calcule:,.2f} €\")\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6670176",
   "metadata": {},
   "source": [
    "### mise à jour fichier lignes restante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db2fb265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier principal chargé: 27923 lignes\n",
      "\n",
      "Nombre de lignes restantes à analyser: 577\n",
      "Résultats exportés dans: lignes_restantes_a_analyser.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier principal\n",
    "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2023.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "print(f\"Fichier principal chargé: {len(df)} lignes\")\n",
    "\n",
    "# Charger tous les fichiers d'analyse précédents\n",
    "jeunes_docteurs = pd.read_csv(\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\", sep=';', encoding='utf-8-sig')\n",
    "l7_egal_l8 = pd.read_csv(\"lignes_L7_egal_L8.csv\", sep=';', encoding='utf-8-sig')\n",
    "depenses_non0_cir0 = pd.read_csv(\"lignes_depenses_non0_cir_recherche_0.csv\", sep=';', encoding='utf-8-sig')\n",
    "analyse_l26a = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//analyse_L26A_vs_CIR_TOTAL.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_relatif_50_innov0_rech1 = pd.read_csv(\"lignes_ecart_relatif_50_innovation0_recherche1.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_total500 = pd.read_csv(\"lignes_ecart_total_entre_-500_et_500.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_moins_100 = pd.read_csv(\"lignes_ecart_relatif_moins_100.csv\", sep=';', encoding='utf-8-sig')\n",
    "innovation_egal_total = pd.read_csv(\"lignes_ecart_total_egal_innovation.csv\", sep=';', encoding='utf-8-sig')\n",
    "collection_egal_total = pd.read_csv(\"lignes_ecart_total_egal_collection.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecart_100_cir_declare_0 = pd.read_csv(\"lignes_ecart_100_cir_declare_0.csv\", sep=';', encoding='utf-8-sig')\n",
    "l6_ecart_hors_1 = pd.read_csv(\"lignes_ecart_total_egal_recherche_l6_ecart_hors_1.csv\", sep=';', encoding='utf-8-sig')\n",
    "cas_l26a = pd.read_csv(\"lignes_cas_L26A_ecart_hors_1_L14_L20_L21_dans_1.csv\", sep=';', encoding='utf-8-sig')\n",
    "ecarts_cir_l91 = pd.read_csv(\"lignes_ecarts_cir_entre_-1_1_et_total_egal_L91.csv\", sep=';', encoding='utf-8-sig')\n",
    "\n",
    "# Identifier les SIREN à exclure\n",
    "siren_jeunes_docteurs = set(jeunes_docteurs['SIREN_DECLARANT'])\n",
    "siren_l7_l8 = set(l7_egal_l8['SIREN_DECLARANT'])\n",
    "siren_depenses_non0_cir0 = set(depenses_non0_cir0['SIREN_DECLARANT'])\n",
    "siren_analyse_l26a = set(analyse_l26a['SIREN_DECLARANT'])\n",
    "siren_ecart_relatif_50_innov0_rech1 = set(ecart_relatif_50_innov0_rech1['SIREN_DECLARANT'])\n",
    "siren_ecart_total500 = set(ecart_total500['SIREN_DECLARANT'])\n",
    "siren_ecart_moins_100 = set(ecart_moins_100['SIREN_DECLARANT'])\n",
    "siren_innovation_egal_total = set(innovation_egal_total['SIREN_DECLARANT'])\n",
    "siren_collection_egal_total = set(collection_egal_total['SIREN_DECLARANT'])\n",
    "siren_ecart_100_cir_declare_0 = set(ecart_100_cir_declare_0['SIREN_DECLARANT'])\n",
    "siren_l6_ecart_hors_1 = set(l6_ecart_hors_1['SIREN_DECLARANT'])\n",
    "siren_cas_l26a = set(cas_l26a['SIREN_DECLARANT'])\n",
    "siren_ecarts_cir_l91 = set(ecarts_cir_l91['SIREN_DECLARANT'])\n",
    "\n",
    "# Combiner tous les SIREN à exclure (ajout du cas l6_ecart_hors_1)\n",
    "siren_a_exclure = siren_jeunes_docteurs | siren_l7_l8 | siren_depenses_non0_cir0 | \\\n",
    "                  siren_analyse_l26a | siren_ecart_relatif_50_innov0_rech1 | \\\n",
    "                  siren_ecart_total500 | siren_ecart_moins_100 | \\\n",
    "                  siren_innovation_egal_total | siren_collection_egal_total | \\\n",
    "                  siren_ecart_100_cir_declare_0 | siren_l6_ecart_hors_1 | siren_cas_l26a | siren_ecarts_cir_l91\n",
    "\n",
    "# Filtrer le DataFrame principal\n",
    "df_restant = df[\n",
    "    (~df['SIREN_DECLARANT'].isin(siren_a_exclure)) &\n",
    "    (df['CORRESPONDANCE_CIR'] == \"Non\")\n",
    "]\n",
    "\n",
    "print(f\"\\nNombre de lignes restantes à analyser: {len(df_restant)}\")\n",
    "\n",
    "# Exporter les résultats\n",
    "output_file = \"lignes_restantes_a_analyser.csv\"\n",
    "df_restant.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "print(f\"Résultats exportés dans: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff8a0923",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'entreprises ayant un CIR calculé identique à au moins une autre: 2115\n",
      "Exemples d'entreprises avec CIR calculé identique :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SIREN_DECLARANT</th>\n",
       "      <th>DESIGNATION</th>\n",
       "      <th>CIR_TOTAL_CALCULE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27306</th>\n",
       "      <td>919557447.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23765</th>\n",
       "      <td>881023683.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14122</th>\n",
       "      <td>662053388.0</td>\n",
       "      <td>AU LIEGEUR</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14107</th>\n",
       "      <td>662006170.0</td>\n",
       "      <td>PIERRE FABRE SA</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14097</th>\n",
       "      <td>655780088.0</td>\n",
       "      <td>CONTINENTAL HOLDING FRANCE SAS</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6938</th>\n",
       "      <td>438277030.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2927653.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>56501711.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5071017.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12335</th>\n",
       "      <td>525009809.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5071017.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13478</th>\n",
       "      <td>542005376.0</td>\n",
       "      <td>FAURECIA SIEGES D'AUTOMOBILE</td>\n",
       "      <td>16270413.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4048</th>\n",
       "      <td>393162433.0</td>\n",
       "      <td>FAURECIA SIEGES D'AUTOMOBILE</td>\n",
       "      <td>16270413.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2115 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SIREN_DECLARANT                     DESIGNATION  CIR_TOTAL_CALCULE\n",
       "27306      919557447.0                             NaN              -0.07\n",
       "23765      881023683.0                             NaN              -0.07\n",
       "14122      662053388.0                      AU LIEGEUR               0.00\n",
       "14107      662006170.0                 PIERRE FABRE SA               0.00\n",
       "14097      655780088.0  CONTINENTAL HOLDING FRANCE SAS               0.00\n",
       "...                ...                             ...                ...\n",
       "6938       438277030.0                             NaN         2927653.15\n",
       "43          56501711.0                             NaN         5071017.29\n",
       "12335      525009809.0                             NaN         5071017.29\n",
       "13478      542005376.0    FAURECIA SIEGES D'AUTOMOBILE        16270413.37\n",
       "4048       393162433.0    FAURECIA SIEGES D'AUTOMOBILE        16270413.37\n",
       "\n",
       "[2115 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# On suppose que df_resultat (issu de comparer_cir_declare_recalcule) contient la colonne 'CIR_TOTAL_CALCULE'\n",
    "# et que le fichier traité dans la cellule 3 est \"C://Users//msamb//Documents//new_millesime_CIR_2023_avec_deposants_ajoutes.xlsx\"\n",
    "\n",
    "# Charger le fichier de comparaison détaillée si besoin\n",
    "df_resultat = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2023.csv\", sep=';', encoding='utf-8-sig')\n",
    "\n",
    "# Recherche des entreprises ayant un CIR calculé identique\n",
    "cir_counts = df_resultat['CIR_TOTAL_CALCULE'].value_counts()\n",
    "cir_duplicated = cir_counts[cir_counts > 1].index\n",
    "\n",
    "# Filtrer les entreprises concernées\n",
    "df_cir_identique = df_resultat[df_resultat['CIR_TOTAL_CALCULE'].isin(cir_duplicated)]\n",
    "df_cir_identique.to_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//output-specifique(2023)//entreprises_cir_identique.csv\", sep=';', encoding='utf-8-sig', index=False)\n",
    "\n",
    "print(f\"Nombre d'entreprises ayant un CIR calculé identique à au moins une autre: {len(df_cir_identique)}\")\n",
    "print(\"Exemples d'entreprises avec CIR calculé identique :\")\n",
    "display(df_cir_identique[['SIREN_DECLARANT', 'DESIGNATION', 'CIR_TOTAL_CALCULE']].sort_values('CIR_TOTAL_CALCULE'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26094efe",
   "metadata": {},
   "source": [
    "# Correction Creance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e130f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** DÉBUT DU SCRIPT DE CORRECTION CIR ***\n",
      "Date et heure: 2025-06-04 14:23:53\n",
      "Fichier d'entrée: M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2023.csv\n",
      "Chargement et préparation des données depuis: M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2023.csv...\n",
      "Fichier principal chargé: 27,923 lignes\n",
      "Formatage des SIRENs...\n",
      "Conversion des colonnes numériques...\n",
      "Initialisation de la colonne 'CIR_TOTAL_CORRIGE'...\n",
      "Préparation des données terminée.\n",
      "\n",
      "Sommes avant corrections spécifiques:\n",
      "  - CIR Déclaré Total: 7,986,816,564.00 €\n",
      "  - CIR Calculé Total: 7,868,711,717.18 €\n",
      "  - CIR Corrigé Initial Total: 7,868,711,717.18 €\n",
      "\n",
      "--- Début de l'application des corrections spécifiques ---\n",
      "\n",
      "1. CORRECTION ERREURS DÉPENSES PERSONNEL (JEUNES DOCTEURS)\n",
      "-> 8 lignes lues, 8 corrigées. Impact local: 201,129.11 €\n",
      "\n",
      "2. CORRECTION ERREUR L7 = L8 (FRAIS BREVETS)\n",
      "\n",
      "3. CORRECTION CIR RECHERCHE MANQUANT/INCOHÉRENT\n",
      "-> 18 lignes lues, 18 corrigées. Impact local: 1,023,479.10 €\n",
      "\n",
      "4. CORRECTION ERREURS DÉPENSES EXTERNALISÉES (L26A vs CIR)\n",
      "-> 127 lignes lues (EST_EGAL=True), 127 corrigées. Impact local: -2,462,057.04 €\n",
      "\n",
      "5. CORRECTION DOUBLEMENT SANS MOTIF (ÉCART ~50%)\n",
      "-> 7 lignes lues, 7 corrigées. Impact local: -461,820.74 €\n",
      "\n",
      "6. CORRECTION PETIT ÉCART (-500 à 500 EUR)\n",
      "-> 289 lignes lues, 289 corrigées. Impact local: 90,975.37 €\n",
      "\n",
      "7. CORRECTION PLAFOND PARTOUT (ÉCART -100%)\n",
      "-> 318 lignes lues, 314 corrigées. Impact local: -56,716,432.00 €\n",
      "\n",
      "8. CORRECTION CIR INNOVATION MANQUANT (ÉCART = INNOVATION)\n",
      "-> 204 lignes lues, 202 corrigées. Impact local: 1,593,340.44 €\n",
      "\n",
      "9. CORRECTION CIR COLLECTION MANQUANT (ÉCART = COLLECTION)\n",
      "-> 12 lignes lues, 12 corrigées. Impact local: 127,424.42 €\n",
      "\n",
      "10. CORRECTION CIR DÉCLARÉ = 0 (ÉCART +100%)\n",
      "-> 103 lignes lues, 103 corrigées. Impact local: 10,848,824.51 €\n",
      "\n",
      "11. CORRECTION ERREURS LIÉES À L6\n",
      "-> 44 lignes lues, 44 corrigées. Impact local: 672,097.46 €\n",
      "\n",
      "12. CORRECTION ERREURS LIÉES À L26\n",
      "-> 3 lignes lues, 3 corrigées. Impact local: 47,194.50 €\n",
      "\n",
      "13. CORRECTION OUBLI CRC (Cas spécifique Total=L91)\n",
      "\n",
      "15. VALEUR CALCULÉE PRIVILÉGIÉE POUR LE RESTE IDENTIFIÉ\n",
      "-> 577 lignes lues, 574 corrigées. Impact local: -73,605,216.67 €\n",
      "\n",
      "--- Fin de l'application des corrections spécifiques ---\n",
      "Nombre total de modifications appliquées par les fonctions actives: 1,701\n",
      "Nombre de SIRENs uniques traités: 1,701\n",
      "\n",
      "--- Ajustement final : Mise à zéro des CIR corrigés négatifs ---\n",
      "28 lignes avec CIR_TOTAL_CORRIGE négatif ont été mises à 0 (Impact: 381,120.08 €).\n",
      "\n",
      "Confirmation pour les lignes restées 'Non traité' (26,222):\n",
      "  - Aucune valeur négative parmi les lignes 'Non traité'.\n",
      "\n",
      "Sauvegarde du fichier corrigé sous: C:/Users/msamb/Documents/Calcul_Creance_CIR_Corrige_2023.csv\n",
      "Fichier sauvegardé avec succès.\n",
      "\n",
      "=====================================================\n",
      "                RÉSUMÉ FINAL\n",
      "=====================================================\n",
      "Montant total CIR déclaré (Original):       7,986,816,564.00 €\n",
      "Montant total CIR calculé (Original):       7,868,711,717.18 €\n",
      "Montant total CIR après corrections:        7,869,827,573.24 €\n",
      "\n",
      "Écart initial (calculé - déclaré):        -118,104,846.82 €\n",
      "Écart final (corrigé - déclaré):          -116,988,990.76 €\n",
      "Réduction de l'écart absolu:              1,115,856.06 €\n",
      "  Écart relatif initial:                  -1.48%\n",
      "  Écart relatif final:                    -1.46%\n",
      "  Réduction relative de l'écart:          0.94%\n",
      "\n",
      "--- Détails par Type de Traitement Appliqué ---\n",
      "\n",
      "Nombre d'entreprises par type de traitement final:\n",
      "  - Err_CIR_RECH                            :         18\n",
      "  - Err_PLAF_EVW                            :        314\n",
      "  - Err_dbl_creance_totale                  :          7\n",
      "  - Err_dep_ext_plaf                        :        127\n",
      "  - Err_dep_personnel                       :          8\n",
      "  - Err_petite                              :        289\n",
      "  - Non traité                              :     26,222\n",
      "  - Valeur calculée privilégiée(Reste)      :        574\n",
      "  - collect_manquant                        :         12\n",
      "  - err_cir_total_declarer                  :        103\n",
      "  - err_l26                                 :          3\n",
      "  - err_l6                                  :         44\n",
      "  - innov_manquant                          :        202\n",
      "\n",
      "Détails financiers par type de traitement final:\n",
      "\n",
      "Traitement: Err_CIR_RECH\n",
      "  Nombre d'entreprises:                 18        \n",
      "  CIR déclaré (groupe):                      65,535,830.00 €\n",
      "  CIR corrigé final (groupe):                66,543,083.50 €\n",
      "  Écart final (corrigé-déclaré groupe):       1,007,253.50 €\n",
      "  Impact relatif final (groupe):                     1.54%\n",
      "\n",
      "Traitement: Err_PLAF_EVW\n",
      "  Nombre d'entreprises:                 314       \n",
      "  CIR déclaré (groupe):                      56,465,934.00 €\n",
      "  CIR corrigé final (groupe):                         0.00 €\n",
      "  Écart final (corrigé-déclaré groupe):     -56,465,934.00 €\n",
      "  Impact relatif final (groupe):                  -100.00%\n",
      "\n",
      "Traitement: Err_dbl_creance_totale\n",
      "  Nombre d'entreprises:                 7         \n",
      "  CIR déclaré (groupe):                       1,847,283.00 €\n",
      "  CIR corrigé final (groupe):                 1,385,462.26 €\n",
      "  Écart final (corrigé-déclaré groupe):        -461,820.74 €\n",
      "  Impact relatif final (groupe):                   -25.00%\n",
      "\n",
      "Traitement: Err_dep_ext_plaf\n",
      "  Nombre d'entreprises:                 127       \n",
      "  CIR déclaré (groupe):                      64,076,281.00 €\n",
      "  CIR corrigé final (groupe):                61,623,223.96 €\n",
      "  Écart final (corrigé-déclaré groupe):      -2,453,057.04 €\n",
      "  Impact relatif final (groupe):                    -3.83%\n",
      "\n",
      "Traitement: Err_dep_personnel\n",
      "  Nombre d'entreprises:                 8         \n",
      "  CIR déclaré (groupe):                         814,166.00 €\n",
      "  CIR corrigé final (groupe):                 1,015,295.11 €\n",
      "  Écart final (corrigé-déclaré groupe):         201,129.11 €\n",
      "  Impact relatif final (groupe):                    24.70%\n",
      "\n",
      "Traitement: Err_petite\n",
      "  Nombre d'entreprises:                 289       \n",
      "  CIR déclaré (groupe):                      65,791,005.00 €\n",
      "  CIR corrigé final (groupe):                65,791,727.37 €\n",
      "  Écart final (corrigé-déclaré groupe):             722.37 €\n",
      "  Impact relatif final (groupe):                     0.00%\n",
      "\n",
      "Traitement: Non traité\n",
      "  Nombre d'entreprises:                 26,222    \n",
      "  CIR déclaré (groupe):                   7,322,439,807.00 €\n",
      "  CIR corrigé final (groupe):             7,323,700,332.27 €\n",
      "  Écart final (corrigé-déclaré groupe):       1,260,525.27 €\n",
      "  Impact relatif final (groupe):                     0.02%\n",
      "\n",
      "Traitement: Valeur calculée privilégiée(Reste)\n",
      "  Nombre d'entreprises:                 574       \n",
      "  CIR déclaré (groupe):                     388,834,199.00 €\n",
      "  CIR corrigé final (groupe):               315,796,245.54 €\n",
      "  Écart final (corrigé-déclaré groupe):     -73,037,953.46 €\n",
      "  Impact relatif final (groupe):                   -18.78%\n",
      "\n",
      "Traitement: collect_manquant\n",
      "  Nombre d'entreprises:                 12        \n",
      "  CIR déclaré (groupe):                       1,428,913.00 €\n",
      "  CIR corrigé final (groupe):                 1,556,337.42 €\n",
      "  Écart final (corrigé-déclaré groupe):         127,424.42 €\n",
      "  Impact relatif final (groupe):                     8.92%\n",
      "\n",
      "Traitement: err_cir_total_declarer\n",
      "  Nombre d'entreprises:                 103       \n",
      "  CIR déclaré (groupe):                          25,628.00 €\n",
      "  CIR corrigé final (groupe):                10,848,824.51 €\n",
      "  Écart final (corrigé-déclaré groupe):      10,823,196.51 €\n",
      "  Impact relatif final (groupe):                 42231.92%\n",
      "\n",
      "Traitement: err_l26\n",
      "  Nombre d'entreprises:                 3         \n",
      "  CIR déclaré (groupe):                         167,892.00 €\n",
      "  CIR corrigé final (groupe):                   215,086.50 €\n",
      "  Écart final (corrigé-déclaré groupe):          47,194.50 €\n",
      "  Impact relatif final (groupe):                    28.11%\n",
      "\n",
      "Traitement: err_l6\n",
      "  Nombre d'entreprises:                 44        \n",
      "  CIR déclaré (groupe):                       4,870,698.00 €\n",
      "  CIR corrigé final (groupe):                 5,207,345.46 €\n",
      "  Écart final (corrigé-déclaré groupe):         336,647.46 €\n",
      "  Impact relatif final (groupe):                     6.91%\n",
      "\n",
      "Traitement: innov_manquant\n",
      "  Nombre d'entreprises:                 202       \n",
      "  CIR déclaré (groupe):                      14,518,928.00 €\n",
      "  CIR corrigé final (groupe):                16,144,609.34 €\n",
      "  Écart final (corrigé-déclaré groupe):       1,625,681.34 €\n",
      "  Impact relatif final (groupe):                    11.20%\n",
      "\n",
      "=====================================================\n",
      "Traitement terminé.\n",
      "=====================================================\n",
      "\n",
      "Script terminé avec succès.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# ===================================================================\n",
    "# FONCTIONS UTILITAIRES\n",
    "# ===================================================================\n",
    "\n",
    "def format_siren(siren):\n",
    "    \"\"\"Formate les SIREN pour avoir exactement 9 caractères\"\"\"\n",
    "    if pd.isna(siren):\n",
    "        return siren\n",
    "    siren_str = str(siren).strip()\n",
    "    # Gère les formats type '123456789.0'\n",
    "    if '.' in siren_str:\n",
    "        siren_str = siren_str.split('.')[0]\n",
    "    return siren_str.zfill(9)\n",
    "\n",
    "def convertir_en_nombre(valeur, defaut=0.0):\n",
    "    \"\"\"Convertit une valeur en nombre flottant de façon sécurisée\"\"\"\n",
    "    if pd.isna(valeur):\n",
    "        return defaut\n",
    "    valeur_str = str(valeur).strip()\n",
    "    if valeur_str == '':\n",
    "        return defaut\n",
    "    try:\n",
    "        # Remplace la virgule par un point pour la conversion décimale\n",
    "        return float(valeur_str.replace(',', '.'))\n",
    "    except ValueError:\n",
    "        # Retourne la valeur par défaut en cas d'erreur de conversion\n",
    "        return defaut\n",
    "    except Exception:\n",
    "         # Capture d'autres erreurs potentielles\n",
    "        return defaut\n",
    "\n",
    "# ===================================================================\n",
    "# CHARGEMENT ET PRÉPARATION DES DONNÉES\n",
    "# ===================================================================\n",
    "\n",
    "def charger_donnees(file_path=\"Calcul_Creance_CIR_2023.csv\"):\n",
    "    \"\"\"Charge et prépare les données du fichier CIR\"\"\"\n",
    "    print(f\"Chargement et préparation des données depuis: {file_path}...\")\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig',\n",
    "                         converters={'SIREN_DECLARANT': str, 'SIREN_DEPOSANT': str},\n",
    "                         low_memory=False)\n",
    "        print(f\"Fichier principal chargé: {len(df):,} lignes\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERREUR: Fichier non trouvé: {file_path}.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"ERREUR lors du chargement du fichier principal: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "    print(\"Formatage des SIRENs...\")\n",
    "    if 'SIREN_DECLARANT' in df.columns:\n",
    "        df['SIREN_DECLARANT'] = df['SIREN_DECLARANT'].apply(format_siren)\n",
    "    else:\n",
    "        print(\"ERREUR CRITIQUE: Colonne 'SIREN_DECLARANT' non trouvée.\")\n",
    "        return None\n",
    "    if 'SIREN_DEPOSANT' in df.columns:\n",
    "        df['SIREN_DEPOSANT'] = df['SIREN_DEPOSANT'].apply(format_siren)\n",
    "\n",
    "    if 'TRAITEMENT_APPLIQUE' not in df.columns:\n",
    "        df['TRAITEMENT_APPLIQUE'] = \"Non traité\"\n",
    "    else:\n",
    "         # Assure que la colonne est de type string\n",
    "         df['TRAITEMENT_APPLIQUE'] = df['TRAITEMENT_APPLIQUE'].astype(str)\n",
    "\n",
    "    # Liste exhaustive des colonnes numériques à convertir\n",
    "    numeric_cols = [\n",
    "        'L1_DOTATION_AMORT_IMMO', 'L2_DOTATION_AMORT_SINISTR', 'L3_DEPENSES_PERSONNEL_CHERCHEURS',\n",
    "        'L4_REMUNERATION_INVENTEURS', 'L5_DEPENSES_JEUNES_DOCTEURS', 'L6_AUTRES_DEP_FONCT_CALCULE',\n",
    "        'L7_TOTAL_DEP_FONCT_DECLARE', 'L7_TOTAL_DEP_FONCT_CALCULE', 'L8_FRAIS_BREVETS_COV',\n",
    "        'L9_DEPENSES_DEFENSE_BREVETS', 'L10_DOTATION_AMORT_BREVETS', 'L11_DEPENSES_NORMALISATION_DECLARE',\n",
    "        'L12_PRIMES_COTISATIONS_BRUT', 'L12_PRIMES_COTISATIONS_PLAFONNEES', 'L13_VEILLE_TECHNO_BRUT',\n",
    "        'L13_VEILLE_TECHNO_PLAFONNEE', 'L14_TOTAL_DEPENSES_INTERNES_CALCULE', 'L21_TOTAL_DEP_EXT_PLAFONNEES_CALCULE',\n",
    "        'L22_TOTAL_DEPENSES_RECHERCHE_CALCULE', 'L23A_SUBVENTIONS', 'L23B_SOMMES_ENCAISSEES_TIERS',\n",
    "        'L24_DEPENSES_CONSEIL_CIR', 'L25_REMBOURSEMENTS_SUBVENTIONS', 'L26A_MONTANT_NET_DEPENSES_CALCULE',\n",
    "        'L26B_MONTANT_NET_DEPENSES_DOM_CALCULE', 'CIR_RECHERCHE_CALCULE', 'CIR_COLLECTION_CALCULE',\n",
    "        'CIR_INNOVATION_CALCULE', 'CIR_COLLABORATIF_CALCULE', 'CIR_TOTAL_DECLARE', 'CIR_TOTAL_CALCULE',\n",
    "        'CIR_TOTAL_ECART', 'ECART_RELATIF_POURCENT', 'CIR_RECHERCHE_ECART', 'CIR_INNOVATION_ECART',\n",
    "        'CIR_COLLECTION_ECART', 'CIR_COLLABORATIF_ECART', 'L6_ECART', 'L14_ECART', 'L17_ECART', 'L18_ECART',\n",
    "        'L19_ECART', 'L20_ECART', 'L21_ECART', 'L22_ECART', 'L26A_ECART', 'L26B_ECART',\n",
    "        'L91_MONTANT_TOTAL_CIR_RECHERCHE_COLLABORATIVE', 'CIR_TOTAL_CORRIGE' # Inclure si existe déjà\n",
    "    ]\n",
    "\n",
    "    print(\"Conversion des colonnes numériques...\")\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].apply(convertir_en_nombre)\n",
    "\n",
    "    # Initialisation de CIR_TOTAL_CORRIGE après les conversions\n",
    "    if 'CIR_TOTAL_CORRIGE' not in df.columns:\n",
    "        print(\"Initialisation de la colonne 'CIR_TOTAL_CORRIGE'...\")\n",
    "        if 'CIR_TOTAL_CALCULE' in df.columns:\n",
    "            df['CIR_TOTAL_CORRIGE'] = df['CIR_TOTAL_CALCULE'].copy()\n",
    "        else:\n",
    "            print(\"  Attention: 'CIR_TOTAL_CALCULE' non trouvé. 'CIR_TOTAL_CORRIGE' initialisé à 0.0.\")\n",
    "            df['CIR_TOTAL_CORRIGE'] = 0.0\n",
    "    else:\n",
    "        # Assurer qu'elle est bien numérique si elle existait\n",
    "        df['CIR_TOTAL_CORRIGE'] = df['CIR_TOTAL_CORRIGE'].apply(convertir_en_nombre)\n",
    "        print(\"La colonne 'CIR_TOTAL_CORRIGE' existait déjà et a été (re)convertie en numérique.\")\n",
    "\n",
    "    # Vérification finale des colonnes essentielles\n",
    "    essential_cols = ['SIREN_DECLARANT', 'CIR_TOTAL_DECLARE', 'CIR_TOTAL_CALCULE', 'CIR_TOTAL_CORRIGE']\n",
    "    for col in essential_cols:\n",
    "        if col not in df.columns:\n",
    "            print(f\"ERREUR CRITIQUE: Colonne essentielle '{col}' est manquante après chargement/préparation.\")\n",
    "            return None\n",
    "\n",
    "    print(\"Préparation des données terminée.\")\n",
    "    return df\n",
    "\n",
    "def charger_fichier_intermediaire(file_path, main_df_columns):\n",
    "    \"\"\"Charge un fichier intermédiaire, formate SIREN et convertit num.\"\"\"\n",
    "    try:\n",
    "        df_inter = pd.read_csv(file_path, sep=';', encoding='utf-8-sig',\n",
    "                               converters={'SIREN_DECLARANT': str, 'SIREN_DEPOSANT': str},\n",
    "                               low_memory=False)\n",
    "        if 'SIREN_DECLARANT' in df_inter.columns:\n",
    "            df_inter['SIREN_DECLARANT'] = df_inter['SIREN_DECLARANT'].apply(format_siren)\n",
    "        else:\n",
    "             print(f\"Attention: 'SIREN_DECLARANT' manquant dans '{file_path}'.\")\n",
    "             return pd.DataFrame(columns=main_df_columns)\n",
    "\n",
    "        numeric_cols_inter = [\n",
    "            'CIR_TOTAL_DECLARE', 'CIR_TOTAL_CALCULE', 'CIR_TOTAL_ECART',\n",
    "            'CIR_RECHERCHE_ECART', 'CIR_COLLECTION_ECART', 'CIR_INNOVATION_ECART', 'CIR_COLLABORATIF_CALCULE',\n",
    "             'L91_MONTANT_TOTAL_CIR_RECHERCHE_COLLABORATIVE'\n",
    "        ]\n",
    "        for col in numeric_cols_inter:\n",
    "            if col in df_inter.columns:\n",
    "                df_inter[col] = df_inter[col].apply(convertir_en_nombre)\n",
    "        if 'EST_EGAL' in df_inter.columns:\n",
    "             df_inter['EST_EGAL'] = df_inter['EST_EGAL'].apply(lambda x: str(x).strip().lower() == 'true')\n",
    "        return df_inter\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Info: Fichier intermédiaire '{file_path}' non trouvé.\")\n",
    "        return pd.DataFrame(columns=main_df_columns)\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur chargement fichier intermédiaire '{file_path}': {str(e)}\")\n",
    "        return pd.DataFrame(columns=main_df_columns)\n",
    "\n",
    "# ===================================================================\n",
    "# FONCTIONS DE CORRECTION (1 à 12 Inchangées, 13 Modifiée, 14 Supprimée, 15 Inchangée)\n",
    "# ===================================================================\n",
    "\n",
    "# --- Fonctions 1 à 12 : Code simplifié pour la longueur, mais identique à la version précédente ---\n",
    "def correction_erreurs_personnel(df, processed_sirens, fichier_intermediaire=\"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\"):\n",
    "    \"\"\"Corrige les erreurs de dépenses de personnel (jeunes docteurs).\"\"\"\n",
    "    print(\"\\n1. CORRECTION ERREURS DÉPENSES PERSONNEL (JEUNES DOCTEURS)\")\n",
    "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
    "    if df_error.empty: return 0\n",
    "    count = 0\n",
    "    before_sum = df_error['CIR_TOTAL_DECLARE'].sum() if 'CIR_TOTAL_DECLARE' in df_error.columns else 0.0\n",
    "    indices_traites_localement = []\n",
    "    for _, row in df_error.iterrows():\n",
    "        siren = row['SIREN_DECLARANT']\n",
    "        if siren in processed_sirens: continue\n",
    "        mask = df['SIREN_DECLARANT'] == siren\n",
    "        if not mask.any(): continue\n",
    "        idx = df.index[mask].tolist()[0]\n",
    "        l1_val=convertir_en_nombre(df.loc[idx,'L1_DOTATION_AMORT_IMMO']); l2_val=convertir_en_nombre(df.loc[idx,'L2_DOTATION_AMORT_SINISTR'])\n",
    "        l4_val=convertir_en_nombre(df.loc[idx,'L4_REMUNERATION_INVENTEURS']); l5_val=convertir_en_nombre(df.loc[idx,'L5_DEPENSES_JEUNES_DOCTEURS'])\n",
    "        l8_val=convertir_en_nombre(df.loc[idx,'L8_FRAIS_BREVETS_COV']); l9_val=convertir_en_nombre(df.loc[idx,'L9_DEPENSES_DEFENSE_BREVETS'])\n",
    "        l10_val=convertir_en_nombre(df.loc[idx,'L10_DOTATION_AMORT_BREVETS']); l11_val=convertir_en_nombre(df.loc[idx,'L11_DEPENSES_NORMALISATION_DECLARE'])\n",
    "        l12_brut_val=convertir_en_nombre(df.loc[idx,'L12_PRIMES_COTISATIONS_BRUT']); l13_brut_val=convertir_en_nombre(df.loc[idx,'L13_VEILLE_TECHNO_BRUT'])\n",
    "        l21_calcule_val=convertir_en_nombre(df.loc[idx,'L21_TOTAL_DEP_EXT_PLAFONNEES_CALCULE']); l23a_val=convertir_en_nombre(df.loc[idx,'L23A_SUBVENTIONS'])\n",
    "        l23b_val=convertir_en_nombre(df.loc[idx,'L23B_SOMMES_ENCAISSEES_TIERS']); l24_val=convertir_en_nombre(df.loc[idx,'L24_DEPENSES_CONSEIL_CIR'])\n",
    "        l25_val=convertir_en_nombre(df.loc[idx,'L25_REMBOURSEMENTS_SUBVENTIONS']); cir_coll_val=convertir_en_nombre(df.loc[idx,'CIR_COLLECTION_CALCULE'])\n",
    "        cir_inno_val=convertir_en_nombre(df.loc[idx,'CIR_INNOVATION_CALCULE']); cir_collab_val=convertir_en_nombre(df.loc[idx,'CIR_COLLABORATIF_CALCULE'])\n",
    "        l26b_val=convertir_en_nombre(df.loc[idx,'L26B_MONTANT_NET_DEPENSES_DOM_CALCULE'])\n",
    "        df.loc[idx,'L3_DEPENSES_PERSONNEL_CHERCHEURS']=l2_val; df.loc[idx,'L2_DOTATION_AMORT_SINISTR']=0.0\n",
    "        dep_cherch_tech_updated=df.loc[idx,'L3_DEPENSES_PERSONNEL_CHERCHEURS']; l2_updated=df.loc[idx,'L2_DOTATION_AMORT_SINISTR']\n",
    "        autres_dep_fonct=(l1_val*0.75)+((dep_cherch_tech_updated+l4_val)*0.43)+l5_val; df.loc[idx,'L6_AUTRES_DEP_FONCT_CALCULE']=autres_dep_fonct\n",
    "        total_dep_fonct=l1_val+l2_updated+dep_cherch_tech_updated+l4_val+l5_val+autres_dep_fonct; df.loc[idx,'L7_TOTAL_DEP_FONCT_CALCULE']=total_dep_fonct\n",
    "        prim_cotiz_plaf=min(l12_brut_val,60000); dep_veil_techno_plaf=min(l13_brut_val,60000)\n",
    "        total_dep_internes=total_dep_fonct+l8_val+l9_val+l10_val+l11_val+prim_cotiz_plaf+dep_veil_techno_plaf; df.loc[idx,'L14_TOTAL_DEPENSES_INTERNES_CALCULE']=total_dep_internes\n",
    "        total_dep_recherche=total_dep_internes+l21_calcule_val; df.loc[idx,'L22_TOTAL_DEPENSES_RECHERCHE_CALCULE']=total_dep_recherche\n",
    "        montant_net=total_dep_recherche-l23a_val-l23b_val-l24_val+l25_val; df.loc[idx,'L26A_MONTANT_NET_DEPENSES_CALCULE']=montant_net\n",
    "        taux_dom,taux_non_dom=0.50,0.30\n",
    "        if 'L26B_MONTANT_NET_DEPENSES_DOM_CALCULE' in df.columns and l26b_val > 0 :\n",
    "             montant_net_non_dom = max(0, montant_net - l26b_val); cir_recherche = (montant_net_non_dom * taux_non_dom) + (l26b_val * taux_dom)\n",
    "        else: cir_recherche = montant_net * taux_non_dom\n",
    "        cir_recherche=max(0, cir_recherche); df.loc[idx,'CIR_RECHERCHE_CALCULE']=cir_recherche\n",
    "        cir_total=cir_recherche+cir_coll_val+cir_inno_val+cir_collab_val; df.loc[idx,'CIR_TOTAL_CALCULE']=cir_total\n",
    "        df.loc[idx,'CIR_TOTAL_CORRIGE']=cir_total; df.loc[idx,'TRAITEMENT_APPLIQUE']=\"Err_dep_personnel\"\n",
    "        processed_sirens.add(siren); indices_traites_localement.append(idx); count+=1\n",
    "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
    "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
    "    return count\n",
    "\n",
    "def correction_erreurs_frais_brevets(df, processed_sirens, fichier_intermediaire=\"lignes_L7_egal_L8.csv\"):\n",
    "    \"\"\"Corrige les erreurs où L7 (déclaré) est égal à L8.\"\"\"\n",
    "    print(\"\\n2. CORRECTION ERREUR L7 = L8 (FRAIS BREVETS)\")\n",
    "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
    "    if df_error.empty: return 0\n",
    "    count = 0\n",
    "    before_sum = df_error['CIR_TOTAL_DECLARE'].sum() if 'CIR_TOTAL_DECLARE' in df_error.columns else 0.0\n",
    "    indices_traites_localement = []\n",
    "    for _, row in df_error.iterrows():\n",
    "        siren = row['SIREN_DECLARANT']\n",
    "        if siren in processed_sirens: continue\n",
    "        mask = df['SIREN_DECLARANT'] == siren\n",
    "        if not mask.any(): continue\n",
    "        idx = df.index[mask].tolist()[0]\n",
    "        l1_val=convertir_en_nombre(df.loc[idx,'L1_DOTATION_AMORT_IMMO']); l2_val=convertir_en_nombre(df.loc[idx,'L2_DOTATION_AMORT_SINISTR'])\n",
    "        l3_val=convertir_en_nombre(df.loc[idx,'L3_DEPENSES_PERSONNEL_CHERCHEURS']); l4_val=convertir_en_nombre(df.loc[idx,'L4_REMUNERATION_INVENTEURS'])\n",
    "        l5_val=convertir_en_nombre(df.loc[idx,'L5_DEPENSES_JEUNES_DOCTEURS']); l9_val=convertir_en_nombre(df.loc[idx,'L9_DEPENSES_DEFENSE_BREVETS'])\n",
    "        l10_val=convertir_en_nombre(df.loc[idx,'L10_DOTATION_AMORT_BREVETS']); l11_val=convertir_en_nombre(df.loc[idx,'L11_DEPENSES_NORMALISATION_DECLARE'])\n",
    "        l12_plaf_val=convertir_en_nombre(df.loc[idx,'L12_PRIMES_COTISATIONS_PLAFONNEES']); l13_plaf_val=convertir_en_nombre(df.loc[idx,'L13_VEILLE_TECHNO_PLAFONNEE'])\n",
    "        l21_calcule_val=convertir_en_nombre(df.loc[idx,'L21_TOTAL_DEP_EXT_PLAFONNEES_CALCULE']); l23a_val=convertir_en_nombre(df.loc[idx,'L23A_SUBVENTIONS'])\n",
    "        l23b_val=convertir_en_nombre(df.loc[idx,'L23B_SOMMES_ENCAISSEES_TIERS']); l24_val=convertir_en_nombre(df.loc[idx,'L24_DEPENSES_CONSEIL_CIR'])\n",
    "        l25_val=convertir_en_nombre(df.loc[idx,'L25_REMBOURSEMENTS_SUBVENTIONS']); cir_coll_val=convertir_en_nombre(df.loc[idx,'CIR_COLLECTION_CALCULE'])\n",
    "        cir_inno_val=convertir_en_nombre(df.loc[idx,'CIR_INNOVATION_CALCULE']); cir_collab_val=convertir_en_nombre(df.loc[idx,'CIR_COLLABORATIF_CALCULE'])\n",
    "        l26b_val=convertir_en_nombre(df.loc[idx,'L26B_MONTANT_NET_DEPENSES_DOM_CALCULE'])\n",
    "        df.loc[idx, 'L8_FRAIS_BREVETS_COV'] = 0.0; l8_corrected_val = 0.0\n",
    "        autres_dep_fonct = (l1_val*0.75) + ((l3_val + l4_val)*0.43) + l5_val; df.loc[idx, 'L6_AUTRES_DEP_FONCT_CALCULE'] = autres_dep_fonct\n",
    "        total_dep_fonct = l1_val+l2_val+l3_val+l4_val+l5_val+autres_dep_fonct; df.loc[idx, 'L7_TOTAL_DEP_FONCT_CALCULE'] = total_dep_fonct\n",
    "        total_dep_internes = total_dep_fonct + l8_corrected_val + l9_val + l10_val + l11_val + l12_plaf_val + l13_plaf_val\n",
    "        df.loc[idx, 'L14_TOTAL_DEPENSES_INTERNES_CALCULE'] = total_dep_internes\n",
    "        total_dep_recherche = total_dep_internes + l21_calcule_val; df.loc[idx, 'L22_TOTAL_DEPENSES_RECHERCHE_CALCULE'] = total_dep_recherche\n",
    "        montant_net = total_dep_recherche - l23a_val - l23b_val - l24_val + l25_val; df.loc[idx, 'L26A_MONTANT_NET_DEPENSES_CALCULE'] = montant_net\n",
    "        taux_dom, taux_non_dom = 0.50, 0.30\n",
    "        if 'L26B_MONTANT_NET_DEPENSES_DOM_CALCULE' in df.columns and l26b_val > 0 :\n",
    "             montant_net_non_dom = max(0, montant_net - l26b_val); cir_recherche = (montant_net_non_dom * taux_non_dom) + (l26b_val * taux_dom)\n",
    "        else: cir_recherche = montant_net * taux_non_dom\n",
    "        cir_recherche = max(0, cir_recherche); df.loc[idx, 'CIR_RECHERCHE_CALCULE'] = cir_recherche\n",
    "        cir_total = cir_recherche + cir_coll_val + cir_inno_val + cir_collab_val; df.loc[idx, 'CIR_TOTAL_CALCULE'] = cir_total\n",
    "        df.loc[idx, 'CIR_TOTAL_CORRIGE'] = cir_total; df.loc[idx, 'TRAITEMENT_APPLIQUE'] = \"Err_Frais_BRV\"\n",
    "        processed_sirens.add(siren); indices_traites_localement.append(idx); count += 1\n",
    "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
    "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
    "    return count\n",
    "\n",
    "def correction_cir_recherche_manquant(df, processed_sirens, fichier_intermediaire=\"lignes_depenses_non0_cir_recherche_0.csv\"):\n",
    "    \"\"\"Corrige les cas où le CIR recherche déclaré est manquant ou incohérent.\"\"\"\n",
    "    print(\"\\n3. CORRECTION CIR RECHERCHE MANQUANT/INCOHÉRENT\")\n",
    "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
    "    if df_error.empty: return 0\n",
    "    count = 0\n",
    "    before_sum = df_error['CIR_TOTAL_DECLARE'].sum() if 'CIR_TOTAL_DECLARE' in df_error.columns else 0.0\n",
    "    indices_traites_localement = []\n",
    "    for _, row in df_error.iterrows():\n",
    "        siren = row['SIREN_DECLARANT']\n",
    "        if siren in processed_sirens: continue\n",
    "        mask = df['SIREN_DECLARANT'] == siren\n",
    "        if not mask.any(): continue\n",
    "        idx = df.index[mask].tolist()[0]\n",
    "        calculated_value = df.loc[idx, 'CIR_TOTAL_CALCULE']\n",
    "        df.loc[idx, 'CIR_TOTAL_CORRIGE'] = calculated_value; df.loc[idx, 'TRAITEMENT_APPLIQUE'] = \"Err_CIR_RECH\"\n",
    "        processed_sirens.add(siren); indices_traites_localement.append(idx); count += 1\n",
    "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
    "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
    "    return count\n",
    "\n",
    "def correction_erreurs_depenses_externalisees(df, processed_sirens, fichier_intermediaire=\"analyse_L26A_vs_CIR_TOTAL.csv\"):\n",
    "    \"\"\"Corrige les erreurs liées aux dépenses externalisées (basé sur L26A vs CIR Total).\"\"\"\n",
    "    print(\"\\n4. CORRECTION ERREURS DÉPENSES EXTERNALISÉES (L26A vs CIR)\")\n",
    "    df_error_raw = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
    "    if df_error_raw.empty: return 0\n",
    "    df_error = df_error_raw\n",
    "    if 'EST_EGAL' in df_error.columns: df_error = df_error_raw[df_error_raw['EST_EGAL']].copy()\n",
    "    else: print(f\"Attention: Colonne 'EST_EGAL' non trouvée dans '{fichier_intermediaire}'.\")\n",
    "    if df_error.empty: print(f\"Aucune donnée pertinente (EST_EGAL=True) trouvée. Skipping.\"); return 0\n",
    "    count = 0\n",
    "    before_sum = df_error['CIR_TOTAL_DECLARE'].sum() if 'CIR_TOTAL_DECLARE' in df_error.columns else 0.0\n",
    "    indices_traites_localement = []\n",
    "    for _, row in df_error.iterrows():\n",
    "        siren = row['SIREN_DECLARANT']\n",
    "        if siren in processed_sirens: continue\n",
    "        mask = df['SIREN_DECLARANT'] == siren\n",
    "        if not mask.any(): continue\n",
    "        idx = df.index[mask].tolist()[0]\n",
    "        calculated_value = df.loc[idx, 'CIR_TOTAL_CALCULE']\n",
    "        df.loc[idx, 'CIR_TOTAL_CORRIGE'] = calculated_value; df.loc[idx, 'TRAITEMENT_APPLIQUE'] = \"Err_dep_ext_plaf\"\n",
    "        processed_sirens.add(siren); indices_traites_localement.append(idx); count += 1\n",
    "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
    "    print(f\"-> {len(df_error)} lignes lues (EST_EGAL=True), {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
    "    return count\n",
    "\n",
    "def correction_doublement_sans_motif(df, processed_sirens, fichier_intermediaire=\"lignes_ecart_relatif_50_innovation0_recherche1.csv\"):\n",
    "    \"\"\"Corrige les erreurs de doublement apparent (écart relatif ~50%). Prend la moyenne.\"\"\"\n",
    "    print(\"\\n5. CORRECTION DOUBLEMENT SANS MOTIF (ÉCART ~50%)\")\n",
    "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
    "    if df_error.empty: return 0\n",
    "    count = 0\n",
    "    before_sum = df_error['CIR_TOTAL_DECLARE'].sum() if 'CIR_TOTAL_DECLARE' in df_error.columns else 0.0\n",
    "    indices_traites_localement = []\n",
    "    for _, row in df_error.iterrows():\n",
    "        siren = row['SIREN_DECLARANT']\n",
    "        if siren in processed_sirens: continue\n",
    "        mask = df['SIREN_DECLARANT'] == siren\n",
    "        if not mask.any(): continue\n",
    "        idx = df.index[mask].tolist()[0]\n",
    "        declared = df.loc[idx, 'CIR_TOTAL_DECLARE']; calculated = df.loc[idx, 'CIR_TOTAL_CALCULE']\n",
    "        corrected = calculated if abs(declared) < 0.01 else (declared + calculated) / 2\n",
    "        df.loc[idx, 'CIR_TOTAL_CORRIGE'] = corrected; df.loc[idx, 'TRAITEMENT_APPLIQUE'] = \"Err_dbl_creance_totale\"\n",
    "        processed_sirens.add(siren); indices_traites_localement.append(idx); count += 1\n",
    "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
    "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
    "    return count\n",
    "\n",
    "def correction_ecart_petit(df, processed_sirens, fichier_intermediaire=\"lignes_ecart_total_entre_-500_et_500.csv\"):\n",
    "    \"\"\"Corrige les petits écarts (-500 à 500 EUR) en prenant la moyenne.\"\"\"\n",
    "    print(\"\\n6. CORRECTION PETIT ÉCART (-500 à 500 EUR)\")\n",
    "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
    "    if df_error.empty: return 0\n",
    "    count = 0\n",
    "    before_sum = df_error['CIR_TOTAL_DECLARE'].sum() if 'CIR_TOTAL_DECLARE' in df_error.columns else 0.0\n",
    "    indices_traites_localement = []\n",
    "    for _, row in df_error.iterrows():\n",
    "        siren = row['SIREN_DECLARANT']\n",
    "        if siren in processed_sirens: continue\n",
    "        mask = df['SIREN_DECLARANT'] == siren\n",
    "        if not mask.any(): continue\n",
    "        idx = df.index[mask].tolist()[0]\n",
    "        declared = df.loc[idx, 'CIR_TOTAL_DECLARE']; calculated = df.loc[idx, 'CIR_TOTAL_CALCULE']\n",
    "        corrected = (declared + calculated) / 2\n",
    "        df.loc[idx, 'CIR_TOTAL_CORRIGE'] = corrected; df.loc[idx, 'TRAITEMENT_APPLIQUE'] = \"Err_petite\"\n",
    "        processed_sirens.add(siren); indices_traites_localement.append(idx); count += 1\n",
    "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
    "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
    "    return count\n",
    "\n",
    "def correction_plafond_partout(df, processed_sirens, fichier_intermediaire=\"lignes_ecart_relatif_moins_100.csv\"):\n",
    "    \"\"\"Corrige les cas où l'écart est -100% (calculé=0), utilise la valeur calculée (0).\"\"\"\n",
    "    print(\"\\n7. CORRECTION PLAFOND PARTOUT (ÉCART -100%)\")\n",
    "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
    "    if df_error.empty: return 0\n",
    "    count = 0\n",
    "    before_sum = df_error['CIR_TOTAL_DECLARE'].sum() if 'CIR_TOTAL_DECLARE' in df_error.columns else 0.0\n",
    "    indices_traites_localement = []\n",
    "    for _, row in df_error.iterrows():\n",
    "        siren = row['SIREN_DECLARANT']\n",
    "        if siren in processed_sirens: continue\n",
    "        mask = df['SIREN_DECLARANT'] == siren\n",
    "        if not mask.any(): continue\n",
    "        idx = df.index[mask].tolist()[0]\n",
    "        calculated_value = df.loc[idx, 'CIR_TOTAL_CALCULE'] # Should be ~0\n",
    "        df.loc[idx, 'CIR_TOTAL_CORRIGE'] = calculated_value; df.loc[idx, 'TRAITEMENT_APPLIQUE'] = \"Err_PLAF_EVW\"\n",
    "        processed_sirens.add(siren); indices_traites_localement.append(idx); count += 1\n",
    "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
    "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
    "    return count\n",
    "\n",
    "def correction_cir_innovation(df, processed_sirens, fichier_intermediaire=\"lignes_ecart_total_egal_innovation.csv\"):\n",
    "    \"\"\"Corrige les cas où l'écart total correspond au CIR Innovation calculé.\"\"\"\n",
    "    print(\"\\n8. CORRECTION CIR INNOVATION MANQUANT (ÉCART = INNOVATION)\")\n",
    "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
    "    if df_error.empty: return 0\n",
    "    count = 0\n",
    "    before_sum = df_error['CIR_TOTAL_DECLARE'].sum() if 'CIR_TOTAL_DECLARE' in df_error.columns else 0.0\n",
    "    indices_traites_localement = []\n",
    "    for _, row in df_error.iterrows():\n",
    "        siren = row['SIREN_DECLARANT']\n",
    "        if siren in processed_sirens: continue\n",
    "        mask = df['SIREN_DECLARANT'] == siren\n",
    "        if not mask.any(): continue\n",
    "        idx = df.index[mask].tolist()[0]\n",
    "        calculated_value = df.loc[idx, 'CIR_TOTAL_CALCULE']\n",
    "        df.loc[idx, 'CIR_TOTAL_CORRIGE'] = calculated_value; df.loc[idx, 'TRAITEMENT_APPLIQUE'] = \"innov_manquant\"\n",
    "        processed_sirens.add(siren); indices_traites_localement.append(idx); count += 1\n",
    "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
    "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
    "    return count\n",
    "\n",
    "def correction_cir_collection(df, processed_sirens, fichier_intermediaire=\"lignes_ecart_total_egal_collection.csv\"):\n",
    "    \"\"\"Corrige les cas où l'écart total correspond au CIR Collection calculé.\"\"\"\n",
    "    print(\"\\n9. CORRECTION CIR COLLECTION MANQUANT (ÉCART = COLLECTION)\")\n",
    "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
    "    if df_error.empty: return 0\n",
    "    count = 0\n",
    "    before_sum = df_error['CIR_TOTAL_DECLARE'].sum() if 'CIR_TOTAL_DECLARE' in df_error.columns else 0.0\n",
    "    indices_traites_localement = []\n",
    "    for _, row in df_error.iterrows():\n",
    "        siren = row['SIREN_DECLARANT']\n",
    "        if siren in processed_sirens: continue\n",
    "        mask = df['SIREN_DECLARANT'] == siren\n",
    "        if not mask.any(): continue\n",
    "        idx = df.index[mask].tolist()[0]\n",
    "        calculated_value = df.loc[idx, 'CIR_TOTAL_CALCULE']\n",
    "        df.loc[idx, 'CIR_TOTAL_CORRIGE'] = calculated_value; df.loc[idx, 'TRAITEMENT_APPLIQUE'] = \"collect_manquant\"\n",
    "        processed_sirens.add(siren); indices_traites_localement.append(idx); count += 1\n",
    "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
    "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
    "    return count\n",
    "\n",
    "def correction_cir_declare_zero(df, processed_sirens, fichier_intermediaire=\"lignes_ecart_100_cir_declare_0.csv\"):\n",
    "    \"\"\"Corrige les cas où le CIR déclaré est 0 mais le calculé est positif.\"\"\"\n",
    "    print(\"\\n10. CORRECTION CIR DÉCLARÉ = 0 (ÉCART +100%)\")\n",
    "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
    "    if df_error.empty: return 0\n",
    "    count = 0\n",
    "    before_sum = 0.0 # Déclaré est 0\n",
    "    indices_traites_localement = []\n",
    "    for _, row in df_error.iterrows():\n",
    "        siren = row['SIREN_DECLARANT']\n",
    "        if siren in processed_sirens: continue\n",
    "        mask = df['SIREN_DECLARANT'] == siren\n",
    "        if not mask.any(): continue\n",
    "        idx = df.index[mask].tolist()[0]\n",
    "        calculated_value = df.loc[idx, 'CIR_TOTAL_CALCULE']\n",
    "        df.loc[idx, 'CIR_TOTAL_CORRIGE'] = calculated_value; df.loc[idx, 'TRAITEMENT_APPLIQUE'] = \"err_cir_total_declarer\"\n",
    "        processed_sirens.add(siren); indices_traites_localement.append(idx); count += 1\n",
    "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
    "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
    "    return count\n",
    "\n",
    "def correction_erreurs_l6(df, processed_sirens, fichier_intermediaire=\"lignes_ecart_total_egal_recherche_l6_ecart_hors_1.csv\"):\n",
    "    \"\"\"Corrige les erreurs liées à la ligne L6 (Autres dépenses de fonctionnement).\"\"\"\n",
    "    print(\"\\n11. CORRECTION ERREURS LIÉES À L6\")\n",
    "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
    "    if df_error.empty: return 0\n",
    "    count = 0\n",
    "    before_sum = df_error['CIR_TOTAL_DECLARE'].sum() if 'CIR_TOTAL_DECLARE' in df_error.columns else 0.0\n",
    "    indices_traites_localement = []\n",
    "    for _, row in df_error.iterrows():\n",
    "        siren = row['SIREN_DECLARANT']\n",
    "        if siren in processed_sirens: continue\n",
    "        mask = df['SIREN_DECLARANT'] == siren\n",
    "        if not mask.any(): continue\n",
    "        idx = df.index[mask].tolist()[0]\n",
    "        calculated_value = df.loc[idx, 'CIR_TOTAL_CALCULE']\n",
    "        df.loc[idx, 'CIR_TOTAL_CORRIGE'] = calculated_value; df.loc[idx, 'TRAITEMENT_APPLIQUE'] = \"err_l6\"\n",
    "        processed_sirens.add(siren); indices_traites_localement.append(idx); count += 1\n",
    "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
    "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
    "    return count\n",
    "\n",
    "def correction_erreurs_l26(df, processed_sirens, fichier_intermediaire=\"lignes_cas_L26A_ecart_hors_1_L14_L20_L21_dans_1.csv\"):\n",
    "    \"\"\"Corrige les erreurs liées à la ligne L26 (Montant net des dépenses).\"\"\"\n",
    "    print(\"\\n12. CORRECTION ERREURS LIÉES À L26\")\n",
    "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
    "    if df_error.empty: return 0\n",
    "    count = 0\n",
    "    before_sum = df_error['CIR_TOTAL_DECLARE'].sum() if 'CIR_TOTAL_DECLARE' in df_error.columns else 0.0\n",
    "    indices_traites_localement = []\n",
    "    for _, row in df_error.iterrows():\n",
    "        siren = row['SIREN_DECLARANT']\n",
    "        if siren in processed_sirens: continue\n",
    "        mask = df['SIREN_DECLARANT'] == siren\n",
    "        if not mask.any(): continue\n",
    "        idx = df.index[mask].tolist()[0]\n",
    "        calculated_value = df.loc[idx, 'CIR_TOTAL_CALCULE']\n",
    "        df.loc[idx, 'CIR_TOTAL_CORRIGE'] = calculated_value; df.loc[idx, 'TRAITEMENT_APPLIQUE'] = \"err_l26\"\n",
    "        processed_sirens.add(siren); indices_traites_localement.append(idx); count += 1\n",
    "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
    "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
    "    return count\n",
    "\n",
    "def correction_crc_manquant_cir_total(df, processed_sirens, fichier_intermediaire=\"lignes_ecarts_cir_entre_-1_1_et_total_egal_L91.csv\"):\n",
    "    \"\"\"Corrige les erreurs où CRC est manquant dans le CIR total (cas spécifique Total=L91).\"\"\"\n",
    "    print(\"\\n13. CORRECTION OUBLI CRC (Cas spécifique Total=L91)\")\n",
    "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
    "    if df_error.empty: return 0\n",
    "    if 'L91_MONTANT_TOTAL_CIR_RECHERCHE_COLLABORATIVE' not in df.columns:\n",
    "        print(\"Colonne 'L91...' manquante. Skipping correction 13.\")\n",
    "        return 0\n",
    "    count = 0\n",
    "    before_sum = df_error['CIR_TOTAL_DECLARE'].sum() if 'CIR_TOTAL_DECLARE' in df_error.columns else 0.0\n",
    "    indices_traites_localement = []\n",
    "    for _, row in df_error.iterrows():\n",
    "        siren = row['SIREN_DECLARANT']\n",
    "        if siren in processed_sirens: continue\n",
    "        mask = df['SIREN_DECLARANT'] == siren\n",
    "        if not mask.any(): continue\n",
    "        idx = df.index[mask].tolist()[0]\n",
    "        declared = df.loc[idx, 'CIR_TOTAL_DECLARE']\n",
    "        crc = df.loc[idx, 'L91_MONTANT_TOTAL_CIR_RECHERCHE_COLLABORATIVE']\n",
    "        df.loc[idx, 'CIR_TOTAL_CORRIGE'] = declared + crc\n",
    "        df.loc[idx, 'TRAITEMENT_APPLIQUE'] = \"err_oubli_crc\"\n",
    "        processed_sirens.add(siren); indices_traites_localement.append(idx); count += 1\n",
    "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
    "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
    "    return count\n",
    "\n",
    "def correction_valeur_calculee_reste(df, processed_sirens, fichier_intermediaire=\"lignes_restantes_a_analyser.csv\"):\n",
    "    \"\"\"Applique la valeur calculée aux cas restants identifiés.\"\"\"\n",
    "    print(\"\\n15. VALEUR CALCULÉE PRIVILÉGIÉE POUR LE RESTE IDENTIFIÉ\")\n",
    "    df_error = charger_fichier_intermediaire(fichier_intermediaire, df.columns)\n",
    "    if df_error.empty: return 0\n",
    "    count = 0\n",
    "    before_sum = df_error['CIR_TOTAL_DECLARE'].sum() if 'CIR_TOTAL_DECLARE' in df_error.columns else 0.0\n",
    "    indices_traites_localement = []\n",
    "    for _, row in df_error.iterrows():\n",
    "        siren = row['SIREN_DECLARANT']\n",
    "        if siren in processed_sirens: continue\n",
    "        mask = df['SIREN_DECLARANT'] == siren\n",
    "        if not mask.any(): continue\n",
    "        idx = df.index[mask].tolist()[0]\n",
    "        calculated_value = df.loc[idx, 'CIR_TOTAL_CALCULE']\n",
    "        df.loc[idx, 'CIR_TOTAL_CORRIGE'] = calculated_value\n",
    "        df.loc[idx, 'TRAITEMENT_APPLIQUE'] = \"Valeur calculée privilégiée(Reste)\"\n",
    "        processed_sirens.add(siren); indices_traites_localement.append(idx); count += 1\n",
    "    after_sum = df.loc[indices_traites_localement, 'CIR_TOTAL_CORRIGE'].sum() if indices_traites_localement else 0.0\n",
    "    print(f\"-> {len(df_error)} lignes lues, {count} corrigées. Impact local: {after_sum - before_sum:,.2f} €\")\n",
    "    return count\n",
    "\n",
    "# ===================================================================\n",
    "# FONCTION PRINCIPALE (Orchestration - Modifiée)\n",
    "# ===================================================================\n",
    "\n",
    "def corriger_cir(file_path=\"Calcul_Creance_CIR_2023.csv\"):\n",
    "    \"\"\"Fonction principale pour charger, corriger et sauvegarder le CIR.\"\"\"\n",
    "    df = charger_donnees(file_path)\n",
    "    if df is None:\n",
    "        print(\"\\nArrêt du traitement.\")\n",
    "        return None\n",
    "\n",
    "    original_declared = df['CIR_TOTAL_DECLARE'].sum()\n",
    "    original_calculated = df['CIR_TOTAL_CALCULE'].sum()\n",
    "    initial_corrected_sum = df['CIR_TOTAL_CORRIGE'].sum()\n",
    "    print(f\"\\nSommes avant corrections spécifiques:\")\n",
    "    print(f\"  - CIR Déclaré Total: {original_declared:,.2f} €\")\n",
    "    print(f\"  - CIR Calculé Total: {original_calculated:,.2f} €\")\n",
    "    print(f\"  - CIR Corrigé Initial Total: {initial_corrected_sum:,.2f} €\")\n",
    "\n",
    "    processed_sirens = set()\n",
    "    total_corrected_count = 0\n",
    "\n",
    "    print(\"\\n--- Début de l'application des corrections spécifiques ---\")\n",
    "    # Liste des fonctions de correction et de leurs fichiers associés\n",
    "    correction_definitions = [\n",
    "        (correction_erreurs_personnel, \"lignes_jeunes_docteurs_0_amort_sinistr_non0.csv\"), #1\n",
    "        (correction_erreurs_frais_brevets, \"lignes_L7_egal_L8.csv\"), #2\n",
    "        (correction_cir_recherche_manquant, \"lignes_depenses_non0_cir_recherche_0.csv\"), #3\n",
    "        (correction_erreurs_depenses_externalisees, \"analyse_L26A_vs_CIR_TOTAL.csv\"), #4\n",
    "        (correction_doublement_sans_motif, \"lignes_ecart_relatif_50_innovation0_recherche1.csv\"), #5\n",
    "        (correction_ecart_petit, \"lignes_ecart_total_entre_-500_et_500.csv\"), #6\n",
    "        (correction_plafond_partout, \"lignes_ecart_relatif_moins_100.csv\"), #7\n",
    "        (correction_cir_innovation, \"lignes_ecart_total_egal_innovation.csv\"), #8\n",
    "        (correction_cir_collection, \"lignes_ecart_total_egal_collection.csv\"), #9\n",
    "        (correction_cir_declare_zero, \"lignes_ecart_100_cir_declare_0.csv\"), #10\n",
    "        (correction_erreurs_l6, \"lignes_ecart_total_egal_recherche_l6_ecart_hors_1.csv\"), #11\n",
    "        (correction_erreurs_l26, \"lignes_cas_L26A_ecart_hors_1_L14_L20_L21_dans_1.csv\"), #12\n",
    "        (correction_crc_manquant_cir_total, \"lignes_ecarts_cir_entre_-1_1_et_total_egal_L91.csv\"), #13\n",
    "        (correction_valeur_calculee_reste, \"lignes_restantes_a_analyser.csv\") #15\n",
    "    ]\n",
    "\n",
    "    # Exécution séquentielle des corrections\n",
    "    for func, file in correction_definitions:\n",
    "        count = func(df, processed_sirens, file)\n",
    "        total_corrected_count += count\n",
    "\n",
    "    print(f\"\\n--- Fin de l'application des corrections spécifiques ---\")\n",
    "    print(f\"Nombre total de modifications appliquées par les fonctions actives: {total_corrected_count:,}\")\n",
    "    print(f\"Nombre de SIRENs uniques traités: {len(processed_sirens):,}\")\n",
    "\n",
    "    # --- Ajustement final : Mise à zéro des CIR corrigés négatifs ---\n",
    "    print(\"\\n--- Ajustement final : Mise à zéro des CIR corrigés négatifs ---\")\n",
    "    if 'CIR_TOTAL_CORRIGE' in df.columns:\n",
    "        # Assurer le type numérique avant la comparaison\n",
    "        if not pd.api.types.is_numeric_dtype(df['CIR_TOTAL_CORRIGE']):\n",
    "             df['CIR_TOTAL_CORRIGE'] = df['CIR_TOTAL_CORRIGE'].apply(convertir_en_nombre)\n",
    "\n",
    "        negative_mask = df['CIR_TOTAL_CORRIGE'] < 0\n",
    "        count_negative = negative_mask.sum()\n",
    "        if count_negative > 0:\n",
    "            sum_before_zeroing = df.loc[negative_mask, 'CIR_TOTAL_CORRIGE'].sum()\n",
    "            df.loc[negative_mask, 'CIR_TOTAL_CORRIGE'] = 0.0\n",
    "            print(f\"{count_negative:,} lignes avec CIR_TOTAL_CORRIGE négatif ont été mises à 0 (Impact: {-sum_before_zeroing:,.2f} €).\")\n",
    "        else: print(\"Aucune valeur négative trouvée dans CIR_TOTAL_CORRIGE après corrections.\")\n",
    "    else: print(\"Erreur: Colonne 'CIR_TOTAL_CORRIGE' non trouvée pour l'ajustement final.\")\n",
    "\n",
    "    # --- Finalisation des lignes 'Non traité' ---\n",
    "    mask_non_traite_final = df['TRAITEMENT_APPLIQUE'] == \"Non traité\"\n",
    "    count_non_traite = mask_non_traite_final.sum()\n",
    "    print(f\"\\nConfirmation pour les lignes restées 'Non traité' ({count_non_traite:,}):\")\n",
    "    if count_non_traite > 0:\n",
    "        # Assurer numérique et non-négatif\n",
    "        df.loc[mask_non_traite_final, 'CIR_TOTAL_CORRIGE'] = df.loc[mask_non_traite_final, 'CIR_TOTAL_CORRIGE'].apply(convertir_en_nombre)\n",
    "        neg_in_non_traite_mask = mask_non_traite_final & (df['CIR_TOTAL_CORRIGE'] < 0)\n",
    "        count_neg_in_non_traite = neg_in_non_traite_mask.sum()\n",
    "        if count_neg_in_non_traite > 0:\n",
    "             sum_neg_non_traite = df.loc[neg_in_non_traite_mask, 'CIR_TOTAL_CORRIGE'].sum()\n",
    "             df.loc[neg_in_non_traite_mask, 'CIR_TOTAL_CORRIGE'] = 0.0\n",
    "             print(f\"  - {count_neg_in_non_traite} de ces lignes étaient négatives et mises à 0 (impact: {-sum_neg_non_traite:,.2f} €).\")\n",
    "        else: print(\"  - Aucune valeur négative parmi les lignes 'Non traité'.\")\n",
    "    else: print(\"  - Aucune ligne marquée comme 'Non traité'.\")\n",
    "\n",
    "    # --- Calcul des totaux finaux ---\n",
    "    final_total_corrected = df['CIR_TOTAL_CORRIGE'].sum()\n",
    "\n",
    "    # --- Sauvegarde avec nouveau chemin local ---\n",
    "    output_file = \"C:/Users/msamb/Documents/Calcul_Creance_CIR_Corrige_2023.csv\"\n",
    "    print(f\"\\nSauvegarde du fichier corrigé sous: {output_file}\")\n",
    "    try:\n",
    "        df.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False, decimal='.')\n",
    "        print(f\"Fichier sauvegardé avec succès.\")\n",
    "    except Exception as e: \n",
    "        print(f\"ERREUR lors de la sauvegarde: {str(e)}\")\n",
    "\n",
    "    # --- Résumé Final ---\n",
    "    print(\"\\n=====================================================\")\n",
    "    print(\"                RÉSUMÉ FINAL\")\n",
    "    print(\"=====================================================\")\n",
    "    print(f\"Montant total CIR déclaré (Original):       {original_declared:,.2f} €\")\n",
    "    print(f\"Montant total CIR calculé (Original):       {original_calculated:,.2f} €\")\n",
    "    print(f\"Montant total CIR après corrections:        {final_total_corrected:,.2f} €\")\n",
    "    initial_ecart = original_calculated - original_declared\n",
    "    final_ecart = final_total_corrected - original_declared\n",
    "    improvement = abs(initial_ecart) - abs(final_ecart)\n",
    "    print(f\"\\nÉcart initial (calculé - déclaré):        {initial_ecart:,.2f} €\")\n",
    "    print(f\"Écart final (corrigé - déclaré):          {final_ecart:,.2f} €\")\n",
    "    print(f\"Réduction de l'écart absolu:              {improvement:,.2f} €\")\n",
    "    if abs(original_declared) > 0.01:\n",
    "        print(f\"  Écart relatif initial:                  {initial_ecart / original_declared * 100:.2f}%\")\n",
    "        print(f\"  Écart relatif final:                    {final_ecart / original_declared * 100:.2f}%\")\n",
    "        if abs(initial_ecart) > 0.01: print(f\"  Réduction relative de l'écart:          {improvement / abs(initial_ecart) * 100:.2f}%\")\n",
    "    else: print(\"\\nCalculs relatifs non pertinents (CIR déclaré total proche de zéro).\")\n",
    "\n",
    "    print(\"\\n--- Détails par Type de Traitement Appliqué ---\")\n",
    "    if 'TRAITEMENT_APPLIQUE' in df.columns:\n",
    "        treatment_counts = df['TRAITEMENT_APPLIQUE'].value_counts().sort_index()\n",
    "        print(\"\\nNombre d'entreprises par type de traitement final:\")\n",
    "        for treatment, count in treatment_counts.items(): print(f\"  - {treatment:<40}: {count:10,}\")\n",
    "        print(\"\\nDétails financiers par type de traitement final:\")\n",
    "        treatment_order = treatment_counts.index.tolist()\n",
    "        for treatment in treatment_order:\n",
    "            subset = df[df['TRAITEMENT_APPLIQUE'] == treatment]\n",
    "            if len(subset) == 0: continue\n",
    "            declared_subset = subset['CIR_TOTAL_DECLARE'].sum()\n",
    "            corrected_subset = subset['CIR_TOTAL_CORRIGE'].sum()\n",
    "            ecart_final_subset = corrected_subset - declared_subset\n",
    "            print(f\"\\nTraitement: {treatment}\")\n",
    "            print(f\"  Nombre d'entreprises:                 {len(subset):<10,}\")\n",
    "            print(f\"  CIR déclaré (groupe):                 {declared_subset:>18,.2f} €\")\n",
    "            print(f\"  CIR corrigé final (groupe):           {corrected_subset:>18,.2f} €\")\n",
    "            print(f\"  Écart final (corrigé-déclaré groupe): {ecart_final_subset:>18,.2f} €\")\n",
    "            if abs(declared_subset) > 0.01:\n",
    "                impact_relatif = ecart_final_subset / declared_subset * 100\n",
    "                print(f\"  Impact relatif final (groupe):        {impact_relatif:>17.2f}%\")\n",
    "    else: print(\"\\nColonne 'TRAITEMENT_APPLIQUE' non trouvée.\")\n",
    "\n",
    "    print(\"\\n=====================================================\")\n",
    "    print(\"Traitement terminé.\")\n",
    "    print(\"=====================================================\")\n",
    "    return df\n",
    "\n",
    "# ===================================================================\n",
    "# EXÉCUTION\n",
    "# ===================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Chemin adapté\n",
    "    input_filename = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//Calcul_Creance_CIR_2023.csv\"\n",
    "    print(f\"*** DÉBUT DU SCRIPT DE CORRECTION CIR ***\")\n",
    "    # Affichage de la date et heure actuelles\n",
    "    current_time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"Date et heure: {current_time_str}\")\n",
    "    print(f\"Fichier d'entrée: {input_filename}\")\n",
    "    df_corrige = corriger_cir(input_filename)\n",
    "    if df_corrige is not None: print(\"\\nScript terminé avec succès.\")\n",
    "    else: print(\"\\nLe script n'a pas pu se terminer correctement.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e1610c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_init = pd.read_excel(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//output//output_parquet//new_millesime_CIR_2023_corrected_sans_doublon.xlsx\") \n",
    "df_corrige = pd.read_csv(\"C://Users//msamb//Documents//Calcul_Creance_CIR_Corrige_2023.csv\", \n",
    "                         sep=';', encoding='utf-8-sig', decimal='.', low_memory=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f88bfe",
   "metadata": {},
   "source": [
    "# Fusion des 2 fichiers pour avoir toute les variables dont nous avons besoin pour l'etude "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bfb8ee19",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de SIREN communs: 26734\n",
      "Nombre de SIREN uniques dans df_corrige: 26734\n",
      "Nombre de SIREN uniques dans df_init: 26734\n",
      "Nombre de lignes avec type_final non-null: 27923 sur 27923\n",
      "Nombre de lignes avec mere_final non-null: 7240 sur 27923\n",
      "Fichier sauvegardé avec succès avec les deux colonnes ajoutées.\n",
      "\n",
      "Exemples de résultats avec les deux colonnes ajoutées:\n",
      "       SIREN_DECLARANT  SIREN_DEPOSANT                 TRAITEMENT_APPLIQUE  \\\n",
      "2203         343564639       343564639                          Non traité   \n",
      "13607        552049447       552049447  Valeur calculée privilégiée(Reste)   \n",
      "17844        813140357       813140357                          Non traité   \n",
      "16307        800683468       800683468                          Non traité   \n",
      "8137         451518021       451518021                          Non traité   \n",
      "\n",
      "      type_final   mere_final  \n",
      "2203         IND          NaN  \n",
      "13607      FILLE  552049447.0  \n",
      "17844        IND          NaN  \n",
      "16307       MERE  800683468.0  \n",
      "8137         IND          NaN  \n",
      "\n",
      "Distribution des valeurs dans type_final:\n",
      "type_final\n",
      "IND      20683\n",
      "FILLE     6044\n",
      "MERE      1196\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution des valeurs dans mere_final:\n",
      "mere_final\n",
      "880511118.0    145\n",
      "383699048.0    131\n",
      "552037806.0    116\n",
      "903199800.0     40\n",
      "403210032.0     35\n",
      "350807947.0     35\n",
      "702027376.0     28\n",
      "572015246.0     27\n",
      "709802094.0     26\n",
      "343115135.0     26\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Charger les fichiers originaux\n",
    "df_init = pd.read_excel(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//output//output_parquet//new_millesime_CIR_2023_corrected_sans_doublon.xlsx\")\n",
    "df_corrige = pd.read_csv(\"C://Users//msamb//Documents//Calcul_Creance_CIR_Corrige_2023.csv\", \n",
    "                         sep=';', encoding='utf-8-sig', decimal='.', low_memory=False)\n",
    "\n",
    "# 2. Standardiser les SIREN déposants puisque c'est la meilleure correspondance\n",
    "def standardize_siren(siren):\n",
    "    \"\"\"Standardise le SIREN en supprimant tous les caractères non numériques et en complétant avec des zéros.\"\"\"\n",
    "    if pd.isna(siren):\n",
    "        return None\n",
    "    siren_str = str(siren).replace(' ', '').replace('-', '').replace('.', '')\n",
    "    # Supprimer tous les caractères non numériques\n",
    "    siren_str = ''.join(c for c in siren_str if c.isdigit())\n",
    "    # Garder seulement les 9 derniers chiffres pour les SIREN longs\n",
    "    if len(siren_str) > 9:\n",
    "        siren_str = siren_str[-9:]\n",
    "    # Compléter avec des zéros au début si nécessaire\n",
    "    return siren_str.zfill(9)\n",
    "\n",
    "# 3. Appliquer la standardisation\n",
    "df_init['siren_deposant_std'] = df_init['siren_deposant'].apply(standardize_siren)\n",
    "df_corrige['SIREN_DEPOSANT_STD'] = df_corrige['SIREN_DEPOSANT'].apply(standardize_siren)\n",
    "\n",
    "# 4. Vérifier la correspondance\n",
    "common_sirens = set(df_corrige['SIREN_DEPOSANT_STD']) & set(df_init['siren_deposant_std'])\n",
    "print(f\"Nombre de SIREN communs: {len(common_sirens)}\")\n",
    "print(f\"Nombre de SIREN uniques dans df_corrige: {df_corrige['SIREN_DEPOSANT_STD'].nunique()}\")\n",
    "print(f\"Nombre de SIREN uniques dans df_init: {df_init['siren_deposant_std'].nunique()}\")\n",
    "\n",
    "# 5. Créer les dictionnaires de correspondance pour les deux colonnes\n",
    "siren_to_type = dict(zip(df_init['siren_deposant_std'], df_init['type_final']))\n",
    "siren_to_mere = dict(zip(df_init['siren_deposant_std'], df_init['mere_final']))\n",
    "\n",
    "# 6. Appliquer les deux correspondances en même temps\n",
    "df_corrige['type_final'] = df_corrige['SIREN_DEPOSANT_STD'].map(siren_to_type)\n",
    "df_corrige['mere_final'] = df_corrige['SIREN_DEPOSANT_STD'].map(siren_to_mere)\n",
    "\n",
    "# 7. Vérifier les résultats\n",
    "type_non_null = df_corrige['type_final'].notna().sum()\n",
    "mere_non_null = df_corrige['mere_final'].notna().sum()\n",
    "print(f\"Nombre de lignes avec type_final non-null: {type_non_null} sur {len(df_corrige)}\")\n",
    "print(f\"Nombre de lignes avec mere_final non-null: {mere_non_null} sur {len(df_corrige)}\")\n",
    "\n",
    "# 8. Supprimer la colonne temporaire\n",
    "df_corrige = df_corrige.drop(columns=['SIREN_DEPOSANT_STD'])\n",
    "\n",
    "# 9. Sauvegarder le résultat\n",
    "df_corrige.to_csv(\"C://Users//msamb//Documents//Calcul_Creance_CIR_Corrige_Final_2023.csv\", \n",
    "                  sep=';', encoding='utf-8-sig', index=False)\n",
    "\n",
    "print(\"Fichier sauvegardé avec succès avec les deux colonnes ajoutées.\")\n",
    "\n",
    "# 10. Afficher des exemples des résultats\n",
    "print(\"\\nExemples de résultats avec les deux colonnes ajoutées:\")\n",
    "sample = df_corrige[['SIREN_DECLARANT', 'SIREN_DEPOSANT', 'TRAITEMENT_APPLIQUE', 'type_final', 'mere_final']].sample(5)\n",
    "print(sample)\n",
    "\n",
    "# 11. Afficher les distributions des valeurs\n",
    "print(\"\\nDistribution des valeurs dans type_final:\")\n",
    "print(df_corrige['type_final'].value_counts().head(10))\n",
    "\n",
    "print(\"\\nDistribution des valeurs dans mere_final:\")\n",
    "print(df_corrige['mere_final'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c3d4eafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de SIREN qui sont déposants mais pas déclarants: 386\n",
      "DataFrame original: 27923 lignes\n",
      "Nouvelles lignes ajoutées: 386 lignes\n",
      "DataFrame final: 28309 lignes\n",
      "\n",
      "Fichier sauvegardé: C://Users//msamb//Documents//Calcul_Creance_CIR_Corrige_avec_deposants.csv\n",
      "\n",
      "Exemple d'une nouvelle ligne ajoutée:\n",
      "SIREN_DECLARANT              348939513\n",
      "SIREN_DEPOSANT               348939513\n",
      "TRAITEMENT_APPLIQUE    Déposant ajouté\n",
      "type_final                        MERE\n",
      "CIR_TOTAL_DECLARE                    0\n",
      "CIR_TOTAL_CALCULE                    0\n",
      "CIR_TOTAL_CORRIGE                    0\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 1. Charger le fichier corrigé existant\n",
    "df_corrige = pd.read_csv(\"C://Users//msamb//Documents//Calcul_Creance_CIR_Corrige_Final_2023.csv\", \n",
    "                         sep=';', encoding='utf-8-sig', low_memory=False)\n",
    "\n",
    "# 2. Standardiser et nettoyer les SIREN\n",
    "df_corrige['SIREN_DECLARANT_STD'] = df_corrige['SIREN_DECLARANT'].astype(str).str.replace(r'\\D', '', regex=True).str.strip().str.zfill(9)\n",
    "df_corrige['SIREN_DEPOSANT_STD'] = df_corrige['SIREN_DEPOSANT'].astype(str).str.replace(r'\\D', '', regex=True).str.strip().str.zfill(9)\n",
    "\n",
    "# 3. Créer les ensembles de SIREN déclarants et déposants\n",
    "set_declarants = set(df_corrige['SIREN_DECLARANT_STD'])\n",
    "set_deposants = set(df_corrige['SIREN_DEPOSANT_STD'])\n",
    "\n",
    "# 4. Identifier les SIREN qui sont déposants mais pas déclarants (en filtrant les SIREN non valides)\n",
    "#if siren and not (siren.strip('0') == '')\n",
    "deposants_non_declarants = {siren for siren in (set_deposants - set_declarants) }\n",
    "print(f\"Nombre de SIREN qui sont déposants mais pas déclarants: {len(deposants_non_declarants)}\")\n",
    "\n",
    "# 5. Créer les nouvelles lignes pour les déposants manquants\n",
    "new_rows = []\n",
    "\n",
    "for siren in deposants_non_declarants:\n",
    "    # Créer un dictionnaire pour la nouvelle ligne\n",
    "    new_row = {}\n",
    "    \n",
    "    # Copier la structure d'une ligne existante pour obtenir toutes les colonnes\n",
    "    for col in df_corrige.columns:\n",
    "        if col in ['SIREN_DECLARANT_STD', 'SIREN_DEPOSANT_STD']:\n",
    "            continue  # On n'inclut pas ces colonnes temporaires\n",
    "        \n",
    "        # Déterminer le type et la valeur appropriée\n",
    "        if col == 'SIREN_DECLARANT' or col == 'SIREN_DEPOSANT':\n",
    "            # Utiliser toujours le format chaîne pour éviter les problèmes\n",
    "            new_row[col] = siren\n",
    "        elif col == 'TRAITEMENT_APPLIQUE':\n",
    "            new_row[col] = 'Déposant ajouté'\n",
    "        elif col == 'type_final':  # Ajouter \"MERE\" dans la colonne type_retenu\n",
    "            new_row[col] = 'MERE'\n",
    "        elif col == 'DESIGNATION' or col == 'COMPLEMENT_DESIGNATION':\n",
    "            new_row[col] = '' # Champs texte vide\n",
    "        elif pd.api.types.is_numeric_dtype(df_corrige[col]):\n",
    "            # Pour les colonnes numériques, mettre 0\n",
    "            new_row[col] = 0\n",
    "        else:\n",
    "            # Pour les autres colonnes non numériques, mettre une valeur vide\n",
    "            new_row[col] = ''\n",
    "    \n",
    "    # Ajouter la ligne au tableau de nouvelles lignes\n",
    "    new_rows.append(new_row)\n",
    "\n",
    "# 6. Créer un DataFrame avec les nouvelles lignes\n",
    "if new_rows:\n",
    "    df_new_rows = pd.DataFrame(new_rows)\n",
    "    \n",
    "    # 7. Concaténer avec le DataFrame original\n",
    "    df_corrige_complet = pd.concat([df_corrige.drop(['SIREN_DECLARANT_STD', 'SIREN_DEPOSANT_STD'], axis=1),\n",
    "                                df_new_rows],\n",
    "                               ignore_index=True)\n",
    "    \n",
    "    # 8. Afficher des informations sur le résultat\n",
    "    print(f\"DataFrame original: {len(df_corrige)} lignes\")\n",
    "    print(f\"Nouvelles lignes ajoutées: {len(new_rows)} lignes\")\n",
    "    print(f\"DataFrame final: {len(df_corrige_complet)} lignes\")\n",
    "    \n",
    "    # 9. Sauvegarder le résultat\n",
    "    output_file = \"C://Users//msamb//Documents//Calcul_Creance_CIR_Corrige_avec_deposants.csv\"\n",
    "    df_corrige_complet.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "    print(f\"\\nFichier sauvegardé: {output_file}\")\n",
    "    \n",
    "    # 10. Afficher un exemple des nouvelles lignes\n",
    "    print(\"\\nExemple d'une nouvelle ligne ajoutée:\")\n",
    "    if not df_new_rows.empty:\n",
    "        cols_to_show = ['SIREN_DECLARANT', 'SIREN_DEPOSANT', 'TRAITEMENT_APPLIQUE', 'type_final', 'CIR_TOTAL_DECLARE', 'CIR_TOTAL_CALCULE', 'CIR_TOTAL_CORRIGE']\n",
    "        print(df_new_rows[cols_to_show].iloc[0])\n",
    "else:\n",
    "    print(\"Aucun déposant non déclarant trouvé, aucune ligne à ajouter.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97247f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de SIREN qui sont déposants mais pas déclarants: 0\n",
      "Aucun déposant non déclarant trouvé, aucune ligne à ajouter.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 1. Charger le fichier corrigé existant\n",
    "df_corrige = pd.read_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//output-specifique(2023)//Calcul_Creance_CIR_2023-format_complet.csv\", \n",
    "                         sep=';', encoding='utf-8-sig', low_memory=False)\n",
    "\n",
    "# 2. Standardiser et nettoyer les SIREN\n",
    "df_corrige['SIREN_DECLARANT_STD'] = df_corrige['SIREN_DECLARANT'].astype(str).str.replace(r'\\D', '', regex=True).str.strip().str.zfill(9)\n",
    "df_corrige['SIREN_DEPOSANT_STD'] = df_corrige['SIREN_DEPOSANT'].astype(str).str.replace(r'\\D', '', regex=True).str.strip().str.zfill(9)\n",
    "\n",
    "# 3. Créer les ensembles de SIREN déclarants et déposants\n",
    "set_declarants = set(df_corrige['SIREN_DECLARANT_STD'])\n",
    "set_deposants = set(df_corrige['SIREN_DEPOSANT_STD'])\n",
    "\n",
    "# 4. Identifier les SIREN qui sont déposants mais pas déclarants (en filtrant les SIREN non valides)\n",
    "#if siren and not (siren.strip('0') == '')\n",
    "deposants_non_declarants = {siren for siren in (set_deposants - set_declarants) }\n",
    "print(f\"Nombre de SIREN qui sont déposants mais pas déclarants: {len(deposants_non_declarants)}\")\n",
    "\n",
    "# 5. Créer les nouvelles lignes pour les déposants manquants\n",
    "new_rows = []\n",
    "\n",
    "for siren in deposants_non_declarants:\n",
    "    # Créer un dictionnaire pour la nouvelle ligne\n",
    "    new_row = {}\n",
    "    \n",
    "    # Copier la structure d'une ligne existante pour obtenir toutes les colonnes\n",
    "    for col in df_corrige.columns:\n",
    "        if col in ['SIREN_DECLARANT_STD', 'SIREN_DEPOSANT_STD']:\n",
    "            continue  # On n'inclut pas ces colonnes temporaires\n",
    "        \n",
    "        # Déterminer le type et la valeur appropriée\n",
    "        if col == 'SIREN_DECLARANT' or col == 'SIREN_DEPOSANT':\n",
    "            # Utiliser toujours le format chaîne pour éviter les problèmes\n",
    "            new_row[col] = siren\n",
    "        elif col == 'TRAITEMENT_APPLIQUE':\n",
    "            new_row[col] = 'Déposant ajouté'\n",
    "        elif col == 'type_final':  # Ajouter \"MERE\" dans la colonne type_retenu\n",
    "            new_row[col] = 'MERE'\n",
    "        elif col == 'DESIGNATION' or col == 'COMPLEMENT_DESIGNATION':\n",
    "            new_row[col] = '' # Champs texte vide\n",
    "        elif pd.api.types.is_numeric_dtype(df_corrige[col]):\n",
    "            # Pour les colonnes numériques, mettre 0\n",
    "            new_row[col] = 0\n",
    "        else:\n",
    "            # Pour les autres colonnes non numériques, mettre une valeur vide\n",
    "            new_row[col] = ''\n",
    "    \n",
    "    # Ajouter la ligne au tableau de nouvelles lignes\n",
    "    new_rows.append(new_row)\n",
    "\n",
    "# 6. Créer un DataFrame avec les nouvelles lignes\n",
    "if new_rows:\n",
    "    df_new_rows = pd.DataFrame(new_rows)\n",
    "    \n",
    "    # 7. Concaténer avec le DataFrame original\n",
    "    df_corrige_complet = pd.concat([df_corrige.drop(['SIREN_DECLARANT_STD', 'SIREN_DEPOSANT_STD'], axis=1),\n",
    "                                df_new_rows],\n",
    "                               ignore_index=True)\n",
    "    \n",
    "    # 8. Afficher des informations sur le résultat\n",
    "    print(f\"DataFrame original: {len(df_corrige)} lignes\")\n",
    "    print(f\"Nouvelles lignes ajoutées: {len(new_rows)} lignes\")\n",
    "    print(f\"DataFrame final: {len(df_corrige_complet)} lignes\")\n",
    "    \n",
    "    # 9. Sauvegarder le résultat\n",
    "    output_file = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//output-specifique(2023)//Calcul_Creance_CIR_2023-format_completavec_deposants.csv\"\n",
    "    df_corrige_complet.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "    print(f\"\\nFichier sauvegardé: {output_file}\")\n",
    "    \n",
    "    # 10. Afficher un exemple des nouvelles lignes\n",
    "    print(\"\\nExemple d'une nouvelle ligne ajoutée:\")\n",
    "    if not df_new_rows.empty:\n",
    "        cols_to_show = ['SIREN_DECLARANT', 'SIREN_DEPOSANT', 'TRAITEMENT_APPLIQUE', 'type_final', 'CIR_TOTAL_DECLARE', 'CIR_TOTAL_CALCULE', 'CIR_TOTAL_CORRIGE']\n",
    "        print(df_new_rows[cols_to_show].iloc[0])\n",
    "else:\n",
    "    print(\"Aucun déposant non déclarant trouvé, aucune ligne à ajouter.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd86524",
   "metadata": {},
   "source": [
    "## Difference pour verifier si tous les deposants sont declarants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7fd20f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de SIREN présents soit comme déclarant, soit comme déposant (mais pas les deux) : 1477\n",
      "Exemples de SIREN présents dans un seul ensemble : ['423538644', '972500508', '448252254', '327250031', '718206964']\n",
      "\n",
      "Nombre de SIREN qui sont uniquement déclarants : 1477\n",
      "Exemples: ['945752137', '513947630', '352876197', '822026621', '898192075']\n",
      "Nombre de SIREN qui sont uniquement déposants : 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier\n",
    "df = pd.read_csv(\"C://Users//msamb//Documents//Calcul_Creance_CIR_Corrige_avec_deposants.csv\", \n",
    "                 sep=';', encoding='utf-8-sig', low_memory=False)\n",
    "\n",
    "# Standardiser les SIREN (en string, 9 caractères, sans espaces)\n",
    "set_declarants = set(df['SIREN_DECLARANT'].astype(str).str.replace(r'\\D', '', regex=True).str.strip().str.zfill(9))\n",
    "set_deposants = set(df['SIREN_DEPOSANT'].astype(str).str.replace(r'\\D', '', regex=True).str.strip().str.zfill(9))\n",
    "\n",
    "# Différence symétrique (éléments dans l'un ou l'autre ensemble, mais pas les deux)\n",
    "difference_symetrique = set_declarants ^ set_deposants\n",
    "\n",
    "print(f\"Nombre de SIREN présents soit comme déclarant, soit comme déposant (mais pas les deux) : {len(difference_symetrique)}\")\n",
    "\n",
    "if len(difference_symetrique) == 0:\n",
    "    print(\"La différence symétrique est vide.\")\n",
    "else:\n",
    "    print(\"Exemples de SIREN présents dans un seul ensemble :\", list(difference_symetrique)[:5])\n",
    "    \n",
    "    # Si vous voulez aussi voir spécifiquement les SIREN qui sont uniquement déclarants\n",
    "    seulement_declarants = set_declarants - set_deposants\n",
    "    print(f\"\\nNombre de SIREN qui sont uniquement déclarants : {len(seulement_declarants)}\")\n",
    "    if len(seulement_declarants) > 0:\n",
    "        print(\"Exemples:\", list(seulement_declarants)[:5])\n",
    "    \n",
    "    # Et les SIREN qui sont uniquement déposants\n",
    "    seulement_deposants = set_deposants - set_declarants\n",
    "    print(f\"Nombre de SIREN qui sont uniquement déposants : {len(seulement_deposants)}\")\n",
    "    if len(seulement_deposants) > 0:\n",
    "        print(\"Exemples:\", list(seulement_deposants)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "110b71b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du fichier...\n",
      "Standardisation des SIREN...\n",
      "Calcul de la somme du CIR par déposant...\n",
      "Ajout de la nouvelle colonne au DataFrame...\n",
      "Attribution des valeurs selon le type...\n",
      "\n",
      "Nombre total d'entreprises: 28309\n",
      "Nombre de déposants uniques: 26734\n",
      "\n",
      "Distribution des valeurs cir_benef_total par type:\n",
      "              count           mean           std  min         25%       50%  \\\n",
      "type_final                                                                    \n",
      "FILLE        6044.0       0.000000  0.000000e+00  0.0      0.0000      0.00   \n",
      "IND         20683.0  173715.311999  8.006087e+05  0.0  22250.5700  54363.89   \n",
      "MERE         1582.0  732067.927342  3.900243e+06  0.0  19464.1275  84860.08   \n",
      "\n",
      "                    75%          max  \n",
      "type_final                            \n",
      "FILLE            0.0000         0.00  \n",
      "IND         121256.6050  31196803.29  \n",
      "MERE        339894.9925  90632009.12  \n",
      "\n",
      "Top 5 des déposants (MERE) avec le plus grand total de CIR:\n",
      "       SIREN_DEPOSANT  cir_benef_total\n",
      "28212       441639465      90632009.12\n",
      "27968       330703844      72350605.22\n",
      "28063       542039532      56097798.22\n",
      "13999       632012100      33885883.64\n",
      "14306       712042456      33013516.32\n",
      "\n",
      "Fichier sauvegardé: C://Users//msamb//Documents//Calcul_Creance_CIR_avec_benef_total.csv\n",
      "\n",
      "Somme totale de CIR_TOTAL_CORRIGE: 7,869,827,573.24 €\n",
      "Somme totale de cir_benef_total (pour les MERE et IND): 4,751,085,259.13 €\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Charger le fichier\n",
    "print(\"Chargement du fichier...\")\n",
    "df = pd.read_csv(\"C://Users//msamb//Documents//Calcul_Creance_CIR_Corrige_avec_deposants.csv\", \n",
    "                 sep=';', encoding='utf-8-sig', low_memory=False)\n",
    "\n",
    "# 2. Standardiser les SIREN des déposants pour éviter les problèmes de format\n",
    "print(\"Standardisation des SIREN...\")\n",
    "df['SIREN_DEPOSANT_STD'] = df['SIREN_DEPOSANT'].astype(str).str.replace(r'\\D', '', regex=True).str.strip().str.zfill(9)\n",
    "\n",
    "# 3. Calculer la somme du CIR par déposant\n",
    "print(\"Calcul de la somme du CIR par déposant...\")\n",
    "# Utiliser CIR_TOTAL_CORRIGE qui est le montant final retenu après corrections\n",
    "cir_par_deposant = df.groupby('SIREN_DEPOSANT_STD')['CIR_TOTAL_CORRIGE'].sum().reset_index()\n",
    "cir_par_deposant.rename(columns={'CIR_TOTAL_CORRIGE': 'cir_benef_total_temp'}, inplace=True)\n",
    "\n",
    "# 4. Fusionner cette somme avec le DataFrame original\n",
    "print(\"Ajout de la nouvelle colonne au DataFrame...\")\n",
    "df = df.merge(cir_par_deposant, on='SIREN_DEPOSANT_STD', how='left')\n",
    "\n",
    "# 5. Mettre à zéro la colonne cir_benef_total pour toutes les lignes qui ne sont pas de type MERE\n",
    "print(\"Attribution des valeurs selon le type...\")\n",
    "# Créer la colonne finale 'cir_benef_total'\n",
    "df['cir_benef_total'] = 0.0  # Initialiser à zéro pour toutes les lignes\n",
    "\n",
    "# Mettre la somme calculée uniquement pour les lignes de type 'MERE' et 'IND'\n",
    "df.loc[df['type_final'] == 'MERE', 'cir_benef_total'] = df.loc[df['type_final'] == 'MERE', 'cir_benef_total_temp']\n",
    "df.loc[df['type_final'] == 'IND', 'cir_benef_total'] = df.loc[df['type_final'] == 'IND', 'cir_benef_total_temp']\n",
    "\n",
    "# Supprimer la colonne temporaire\n",
    "df.drop(['SIREN_DEPOSANT_STD', 'cir_benef_total_temp'], axis=1, inplace=True)\n",
    "\n",
    "# 6. Afficher quelques statistiques\n",
    "print(f\"\\nNombre total d'entreprises: {len(df)}\")\n",
    "print(f\"Nombre de déposants uniques: {df['SIREN_DEPOSANT'].nunique()}\")\n",
    "\n",
    "# Vérifier la distribution des valeurs cir_benef_total selon le type\n",
    "print(\"\\nDistribution des valeurs cir_benef_total par type:\")\n",
    "print(df.groupby('type_final')['cir_benef_total'].describe())\n",
    "\n",
    "# Trier par montant de cir_benef_total pour voir les déposants avec le plus grand total\n",
    "top_deposants = df[df['cir_benef_total'] > 0][['SIREN_DEPOSANT', 'cir_benef_total']].drop_duplicates().sort_values('cir_benef_total', ascending=False)\n",
    "print(\"\\nTop 5 des déposants (MERE) avec le plus grand total de CIR:\")\n",
    "print(top_deposants.head(5))\n",
    "\n",
    "# 7. Sauvegarder le résultat\n",
    "output_file = \"C://Users//msamb//Documents//Calcul_Creance_CIR_avec_benef_total.csv\"\n",
    "df.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "print(f\"\\nFichier sauvegardé: {output_file}\")\n",
    "\n",
    "# 8. Vérification - calcul de la somme totale de CIR\n",
    "total_cir_corrige = df['CIR_TOTAL_CORRIGE'].sum()\n",
    "total_cir_benef = df['cir_benef_total'].sum()\n",
    "print(f\"\\nSomme totale de CIR_TOTAL_CORRIGE: {total_cir_corrige:,.2f} €\")\n",
    "print(f\"Somme totale de cir_benef_total (pour les MERE et IND): {total_cir_benef:,.2f} €\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "95275d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier sauvegardé: M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_avec_benef_total_final.csv\n",
      "\n",
      "Somme totale de CIR_TOTAL_CORRIGE: 7,869,827,573.24 €\n",
      "Somme totale de cir_benef_total: 7,869,827,573.24 €\n",
      "Différence entre les deux sommes: 0.00 €\n",
      "\n",
      "Nombre de SIREN déposants sans correspondance: 6\n",
      "Montant CIR pour ces SIREN: 6,266,675.16 € (0.08% du total)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier\n",
    "df = pd.read_csv(output_file, sep=';', encoding='utf-8-sig', low_memory=False)\n",
    "\n",
    "# Standardiser les SIREN des déposants et des déclarants\n",
    "df['SIREN_DEPOSANT_STD'] = df['SIREN_DEPOSANT'].astype(str).str.replace(r'\\D', '', regex=True).str.strip().str.zfill(9)\n",
    "df['SIREN_DECLARANT_STD'] = df['SIREN_DECLARANT'].astype(str).str.replace(r'\\D', '', regex=True).str.strip().str.zfill(9)\n",
    "\n",
    "# Créer une colonne pour la correspondance\n",
    "df['IS_MATCH'] = df['SIREN_DEPOSANT_STD'] == df['SIREN_DECLARANT_STD']\n",
    "\n",
    "# Calculer la somme du CIR par déposant\n",
    "cir_total_par_deposant = df.groupby('SIREN_DEPOSANT_STD')['CIR_TOTAL_CORRIGE'].sum().reset_index()\n",
    "cir_total_par_deposant.rename(columns={'CIR_TOTAL_CORRIGE': 'TOTAL_CIR'}, inplace=True)\n",
    "\n",
    "# Initialiser la nouvelle colonne\n",
    "df['cir_benef_total'] = 0.0\n",
    "\n",
    "# Méthode simplifiée: traiter chaque SIREN déposant séparément\n",
    "for siren in cir_total_par_deposant['SIREN_DEPOSANT_STD'].unique():\n",
    "    montant_total = cir_total_par_deposant.loc[cir_total_par_deposant['SIREN_DEPOSANT_STD'] == siren, 'TOTAL_CIR'].values[0]\n",
    "    \n",
    "    # Sélectionner toutes les lignes avec ce SIREN déposant\n",
    "    lignes_siren = df[df['SIREN_DEPOSANT_STD'] == siren]\n",
    "    \n",
    "    # Vérifier s'il y a des lignes correspondantes (SIREN_DEPOSANT = SIREN_DECLARANT)\n",
    "    lignes_match = lignes_siren[lignes_siren['IS_MATCH']]\n",
    "    \n",
    "    if len(lignes_match) > 0:\n",
    "        # S'il y a des correspondances, distribuer le montant également entre ces lignes\n",
    "        montant_par_ligne = montant_total / len(lignes_match)\n",
    "        df.loc[lignes_match.index, 'cir_benef_total'] = montant_par_ligne\n",
    "    else:\n",
    "        # S'il n'y a pas de correspondance, mettre le montant total sur la première ligne\n",
    "        df.loc[lignes_siren.index[0], 'cir_benef_total'] = montant_total\n",
    "\n",
    "# Vérification\n",
    "total_cir_corrige = df['CIR_TOTAL_CORRIGE'].sum()\n",
    "total_cir_benef = df['cir_benef_total'].sum()\n",
    "\n",
    "# Créer un fichier de vérification avec les totaux par SIREN déposant\n",
    "verification = df.groupby('SIREN_DEPOSANT_STD')[['CIR_TOTAL_CORRIGE', 'cir_benef_total']].sum()\n",
    "verification['difference'] = verification['CIR_TOTAL_CORRIGE'] - verification['cir_benef_total']\n",
    "verification.to_csv(\"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//verification_totaux_par_siren.csv\", sep=';')\n",
    "\n",
    "# Comptage des SIREN sans correspondance\n",
    "siren_avec_match = df[df['IS_MATCH']]['SIREN_DEPOSANT_STD'].unique()\n",
    "siren_tous = df['SIREN_DEPOSANT_STD'].unique()\n",
    "siren_sans_match = set(siren_tous) - set(siren_avec_match)\n",
    "\n",
    "# Supprimer les colonnes temporaires avant de sauvegarder\n",
    "df = df.drop(['SIREN_DEPOSANT_STD', 'SIREN_DECLARANT_STD', 'IS_MATCH'], axis=1)\n",
    "\n",
    "# Sauvegarder le résultat\n",
    "output_file_final = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_avec_benef_total_final.csv\"\n",
    "df.to_csv(output_file_final, sep=';', encoding='utf-8-sig', index=False)\n",
    "\n",
    "print(f\"Fichier sauvegardé: {output_file_final}\")\n",
    "print(f\"\\nSomme totale de CIR_TOTAL_CORRIGE: {total_cir_corrige:,.2f} €\")\n",
    "print(f\"Somme totale de cir_benef_total: {total_cir_benef:,.2f} €\")\n",
    "print(f\"Différence entre les deux sommes: {total_cir_corrige - total_cir_benef:,.2f} €\")\n",
    "print(f\"\\nNombre de SIREN déposants sans correspondance: {len(siren_sans_match)}\")\n",
    "\n",
    "# Montant CIR pour les SIREN sans correspondance\n",
    "cir_sans_match = sum(verification.loc[[s for s in siren_sans_match if s in verification.index], 'CIR_TOTAL_CORRIGE'])\n",
    "print(f\"Montant CIR pour ces SIREN: {cir_sans_match:,.2f} € ({cir_sans_match/total_cir_corrige*100:.2f}% du total)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0331c88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier sauvegardé avec succès: M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_avec_benef_total_final_renamed.csv\n",
      "Colonnes renommées: ['CIR_RECHERCHE_DECLARE', 'CIR_RECHERCHE_CALCULE', 'CIR_RECHERCHE_ECART', 'CIR_COLLECTION_DECLARE', 'CIR_COLLECTION_CALCULE', 'CIR_COLLECTION_ECART', 'CIR_INNOVATION_DECLARE', 'CIR_INNOVATION_CALCULE', 'CIR_INNOVATION_ECART', 'CIR_COLLABORATIF_DECLARE', 'CIR_COLLABORATIF_CALCULE', 'CIR_COLLABORATIF_ECART', 'CIR_TOTAL_DECLARE', 'CIR_TOTAL_CALCULE', 'CIR_TOTAL_ECART', 'CIR_TOTAL_CORRIGE']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier CSV\n",
    "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_avec_benef_total_final.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "\n",
    "# Dictionnaire de renommage des colonnes\n",
    "renommage = {\n",
    "    # Renommage des colonnes CIR recherche\n",
    "    'CIR_RECHERCHE_DECLARE': 'crerd_gen_declare',\n",
    "    'CIR_RECHERCHE_CALCULE': 'crerd_gen_calcule',\n",
    "    'CIR_RECHERCHE_ECART': 'crerd_gen_ecart',\n",
    "    \n",
    "    # Renommage des colonnes CIR collection\n",
    "    'CIR_COLLECTION_DECLARE': 'crecoll_gen_declare',\n",
    "    'CIR_COLLECTION_CALCULE': 'crecoll_gen_calcule',\n",
    "    'CIR_COLLECTION_ECART': 'crecoll_gen_ecart',\n",
    "    \n",
    "    # Renommage des colonnes CIR innovation\n",
    "    'CIR_INNOVATION_DECLARE': 'creinno_gen_declare',\n",
    "    'CIR_INNOVATION_CALCULE': 'creinno_gen_calcule',\n",
    "    'CIR_INNOVATION_ECART': 'creinno_gen_ecart',\n",
    "    \n",
    "    # Renommage des colonnes CIR collaboratif\n",
    "    'CIR_COLLABORATIF_DECLARE': 'crecrc_declare',\n",
    "    'CIR_COLLABORATIF_CALCULE': 'crecrc_calcule',\n",
    "    'CIR_COLLABORATIF_ECART': 'crecrc_ecart',\n",
    "    \n",
    "    # Renommage des colonnes CIR total\n",
    "    'CIR_TOTAL_DECLARE': 'cretot_gen_declare',\n",
    "    'CIR_TOTAL_CALCULE': 'cretot_gen_calcule',\n",
    "    'CIR_TOTAL_ECART': 'cretot_gen_ecart',\n",
    "    'CIR_TOTAL_CORRIGE': 'cretot_gen_corrige'\n",
    "}\n",
    "\n",
    "# Appliquer le renommage (uniquement pour les colonnes qui existent)\n",
    "colonnes_existantes = {col: nouveau_nom for col, nouveau_nom in renommage.items() if col in df.columns}\n",
    "df = df.rename(columns=colonnes_existantes)\n",
    "\n",
    "# Sauvegarder le fichier avec les nouvelles colonnes\n",
    "output_file = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_avec_benef_total_final_renamed.csv\"\n",
    "df.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "\n",
    "print(f\"Fichier sauvegardé avec succès: {output_file}\")\n",
    "print(f\"Colonnes renommées: {list(colonnes_existantes.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f539b6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de lignes: 28309\n",
      "Colonnes renommées: 16\n",
      "Calcul des montants bénéficiaires...\n",
      "  Calcul de cirrech_benef...\n",
      "  Calcul de cic_benef...\n",
      "  Calcul de cii_benef...\n",
      "  Calcul de crecrc_benef...\n",
      "  Calcul de cirtot_benef...\n",
      "Vérification de la cohérence des montants...\n",
      "Écart entre cirtot_benef et cir_benef_total: 0.00\n",
      "Écart entre somme des composantes et total bénéficiaire: 853099.92\n",
      "\n",
      "Vérification des totaux générés vs bénéficiaires:\n",
      "Type de crédit Généré         Bénéficiaire   Écart          Écart %   \n",
      "-----------------------------------------------------------------\n",
      "crerd_gen      7324271677.45  7324271677.45  0.00           0.00      %\n",
      "crecoll_gen    27543075.80    27543075.80    0.00           0.00      %\n",
      "creinno_gen    500767614.75   500767614.75   0.00           0.00      %\n",
      "crecrc         16402985.70    16402985.70    0.00           0.00      %\n",
      "cretot_gen     7869827573.24  7869827573.24  0.00           0.00      %\n",
      "Sauvegarde du fichier: M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_format_2021.csv\n",
      "Traitement terminé avec succès!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier avec les types de données spécifiés pour améliorer les performances\n",
    "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_avec_benef_total_final.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Nombre total de lignes: {len(df)}\")\n",
    "\n",
    "# 1. RENOMMER TOUTES LES COLONNES (opération rapide)\n",
    "renommage_complet = {\n",
    "    'CIR_RECHERCHE_DECLARE': 'crerd_gen_declare',\n",
    "    'CIR_RECHERCHE_CALCULE': 'crerd_gen',\n",
    "    'CIR_RECHERCHE_ECART': 'crerd_gen_ecart',\n",
    "    'CIR_COLLECTION_DECLARE': 'crecoll_gen_declare',\n",
    "    'CIR_COLLECTION_CALCULE': 'crecoll_gen',\n",
    "    'CIR_COLLECTION_ECART': 'crecoll_gen_ecart',\n",
    "    'CIR_INNOVATION_DECLARE': 'creinno_gen_declare',\n",
    "    'CIR_INNOVATION_CALCULE': 'creinno_gen',\n",
    "    'CIR_INNOVATION_ECART': 'creinno_gen_ecart',\n",
    "    'CIR_COLLABORATIF_DECLARE': 'crecrc_declare',\n",
    "    'CIR_COLLABORATIF_CALCULE': 'crecrc',\n",
    "    'CIR_COLLABORATIF_ECART': 'crecrc_ecart',\n",
    "    'CIR_TOTAL_DECLARE': 'cretot_gen_declare',\n",
    "    'CIR_TOTAL_CALCULE': 'cretot_gen_calcule',\n",
    "    'CIR_TOTAL_ECART': 'cretot_gen_ecart',\n",
    "    'CIR_TOTAL_CORRIGE': 'cretot_gen'\n",
    "}\n",
    "\n",
    "# Renommer uniquement les colonnes qui existent\n",
    "colonnes_existantes = {col: nouveau_nom for col, nouveau_nom in renommage_complet.items() if col in df.columns}\n",
    "df = df.rename(columns=colonnes_existantes)\n",
    "\n",
    "print(f\"Colonnes renommées: {len(colonnes_existantes)}\")\n",
    "\n",
    "# 2. CALCULER LES CRÉDITS BÉNÉFICIAIRES DE MANIÈRE OPTIMISÉE\n",
    "# Standardiser les SIREN une seule fois\n",
    "df['SIREN_DEPOSANT_STD'] = df['SIREN_DEPOSANT'].astype(str).str.replace(r'\\D', '', regex=True).str.zfill(9)\n",
    "df['SIREN_DECLARANT_STD'] = df['SIREN_DECLARANT'].astype(str).str.replace(r'\\D', '', regex=True).str.zfill(9)\n",
    "df['IS_MATCH'] = df['SIREN_DEPOSANT_STD'] == df['SIREN_DECLARANT_STD']\n",
    "\n",
    "# Version vectorisée et optimisée pour calculer les valeurs bénéficiaires\n",
    "def calculer_benef_optimise(df, colonne_source):\n",
    "    # Créer un DataFrame avec les informations essentielles\n",
    "    df_temp = df[['SIREN_DEPOSANT_STD', 'IS_MATCH', colonne_source]].copy()\n",
    "    \n",
    "    # Calculer la somme totale par déposant\n",
    "    sommes = df_temp.groupby('SIREN_DEPOSANT_STD')[colonne_source].sum().to_dict()\n",
    "    \n",
    "    # Créer une série pour stocker les résultats\n",
    "    resultats = pd.Series(index=df.index, dtype='float64')\n",
    "    \n",
    "    # Pour chaque SIREN déposant unique\n",
    "    for siren, montant in sommes.items():\n",
    "        # Lignes correspondant à ce SIREN\n",
    "        mask_siren = df['SIREN_DEPOSANT_STD'] == siren\n",
    "        \n",
    "        # Lignes où il y a correspondance\n",
    "        mask_match = mask_siren & df['IS_MATCH']\n",
    "        count_match = mask_match.sum()\n",
    "        \n",
    "        if count_match > 0:\n",
    "            # Distribuer le montant également entre les lignes correspondantes\n",
    "            resultats[mask_match] = montant / count_match\n",
    "        else:\n",
    "            # Première ligne du SIREN\n",
    "            if mask_siren.any():\n",
    "                idx = df[mask_siren].index[0]\n",
    "                resultats[idx] = montant\n",
    "    \n",
    "    return resultats\n",
    "\n",
    "# Calculer tous les bénéficiaires d'un coup pour gagner du temps\n",
    "print(\"Calcul des montants bénéficiaires...\")\n",
    "colonnes_source = ['crerd_gen', 'crecoll_gen', 'creinno_gen', 'crecrc', 'cretot_gen']\n",
    "colonnes_benef = ['cirrech_benef', 'cic_benef', 'cii_benef', 'crecrc_benef', 'cirtot_benef']\n",
    "\n",
    "for col_source, col_benef in zip(colonnes_source, colonnes_benef):\n",
    "    if col_source in df.columns:\n",
    "        print(f\"  Calcul de {col_benef}...\")\n",
    "        df[col_benef] = calculer_benef_optimise(df, col_source)\n",
    "    else:\n",
    "        print(f\"  Colonne {col_source} non trouvée, {col_benef} initialisé à 0\")\n",
    "        df[col_benef] = 0\n",
    "\n",
    "# 3. VÉRIFIER LA COHÉRENCE DES MONTANTS\n",
    "print(\"Vérification de la cohérence des montants...\")\n",
    "\n",
    "# Vérifier que cir_benef_total correspond à cirtot_benef (si présent)\n",
    "if 'cir_benef_total' in df.columns:\n",
    "    ecart_total = (df['cirtot_benef'] - df['cir_benef_total']).abs().sum()\n",
    "    print(f\"Écart entre cirtot_benef et cir_benef_total: {ecart_total:.2f}\")\n",
    "\n",
    "# Vérifier que la somme des composantes bénéficiaires égale le total bénéficiaire (vectorisé)\n",
    "df['somme_composantes_benef'] = df[['cirrech_benef', 'cic_benef', 'cii_benef', 'crecrc_benef']].fillna(0).sum(axis=1)\n",
    "ecart_composantes = (df['somme_composantes_benef'] - df['cirtot_benef']).abs().sum()\n",
    "print(f\"Écart entre somme des composantes et total bénéficiaire: {ecart_composantes:.2f}\")\n",
    "\n",
    "# Comparer les totaux (vectorisé)\n",
    "print(\"\\nVérification des totaux générés vs bénéficiaires:\")\n",
    "print(f\"{'Type de crédit':<15}{'Généré':<15}{'Bénéficiaire':<15}{'Écart':<15}{'Écart %':<10}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for col_gen, col_benef in zip(colonnes_source, colonnes_benef):\n",
    "    if col_gen in df.columns and col_benef in df.columns:\n",
    "        total_gen = df[col_gen].sum()\n",
    "        total_benef = df[col_benef].sum()\n",
    "        ecart = total_gen - total_benef\n",
    "        ecart_pct = 0 if total_gen == 0 else ecart / total_gen * 100\n",
    "        print(f\"{col_gen:<15}{total_gen:<15.2f}{total_benef:<15.2f}{ecart:<15.2f}{ecart_pct:<10.2f}%\")\n",
    "\n",
    "# Ajouter les variables pour les DOM-TOM en une seule opération vectorisée\n",
    "for col in ['crerd_genom', 'crecoll_genom', 'creinno_genom', 'cretot_genom']:\n",
    "    df[col] = 0\n",
    "\n",
    "# Supprimer les colonnes temporaires en une seule opération\n",
    "df = df.drop(['SIREN_DEPOSANT_STD', 'SIREN_DECLARANT_STD', 'IS_MATCH', 'somme_composantes_benef'], axis=1)\n",
    "\n",
    "# Sauvegarder le fichier\n",
    "output_file = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_format_2021.csv\"\n",
    "print(f\"Sauvegarde du fichier: {output_file}\")\n",
    "df.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "\n",
    "print(\"Traitement terminé avec succès!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7b8a96f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de lignes: 28309\n",
      "Colonnes disponibles: 185\n",
      "\n",
      "=== CALCUL DES CRÉDITS DOM-TOM ===\n",
      "Colonnes DOM R&D trouvées: ['L26B_MONTANT_NET_DEPENSES_DOM_DECLARE', 'L26B_MONTANT_NET_DEPENSES_DOM_CALCULE', 'L38B_CREDIT_IMPOT_RECHERCHE_DOM', 'L46B_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION_DOM', 'L47B_DEPENSES_RECHERCHE_DOM_LIMITE', 'L53B_CREDIT_IMPOT_RECHERCHE_DOM_PLUS_100M', 'L64B_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION_DOM_PLUS_100M']\n",
      "Colonnes DOM Collection trouvées: ['L33B_MONTANT_NET_COLLECTION_DOM_DECLARE', 'L33B_MONTANT_NET_COLLECTION_DOM_CALCULE', 'L46B_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION_DOM', 'L54B_MONTANT_NET_COLLECTION_DOM_PLUS_100M', 'L64B_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION_DOM_PLUS_100M']\n",
      "Colonnes DOM Innovation trouvées: ['L76B_MONTANT_NET_INNOVATION_DOM', 'L79B_CREDIT_IMPOT_INNOVATION_DOM']\n",
      "CIR Recherche DOM calculé: 14,015,514.50 €\n",
      "CIR Collection DOM calculé: 199,838.00 €\n",
      "CIR Innovation DOM+Corse calculé: 5,224,736.25 €\n",
      "CIR Total DOM calculé: 19,440,088.75 €\n",
      "\n",
      "=== CALCUL DES MONTANTS NETS BÉNÉFICIAIRES ===\n",
      "Colonne dépenses R&D trouvée: L26A_MONTANT_NET_DEPENSES_CALCULE\n",
      "Colonne dépenses Collection trouvée: L33A_MONTANT_NET_COLLECTION_CALCULE\n",
      "Colonne dépenses Innovation trouvée: L76A_MONTANT_NET_INNOVATION_CALCULE\n",
      "Calcul des montants nets des dépenses bénéficiaires:\n",
      "  Dépenses R&D: Calcul en cours...\n",
      "    Total généré: 25,173,407,509.81 € | Total bénéficiaire: 25,173,407,509.81 € | Écart: 0.00 €\n",
      "    Répartition: 18399 avec correspondance, 5 sans correspondance\n",
      "  Dépenses Collection: Calcul en cours...\n",
      "    Total généré: 151,402,446.00 € | Total bénéficiaire: 151,402,446.00 € | Écart: 0.00 €\n",
      "    Répartition: 854 avec correspondance, 0 sans correspondance\n",
      "  Dépenses Innovation: Calcul en cours...\n",
      "    Total généré: 1,661,365,577.00 € | Total bénéficiaire: 1,661,365,577.00 € | Écart: 0.00 €\n",
      "    Répartition: 11026 avec correspondance, 1 sans correspondance\n",
      "Montant total des dépenses bénéficiaires: 26,986,175,532.81 €\n",
      "\n",
      "=== CRÉATION DES INDICATRICES ===\n",
      "Indicatrices créées avec succès\n",
      "\n",
      "============================================================\n",
      "RAPPORT DÉTAILLÉ DE VÉRIFICATION DES DONNÉES\n",
      "============================================================\n",
      "\n",
      "1. MONTANTS NETS DES DÉPENSES BÉNÉFICIAIRES:\n",
      "   • Dépenses R&D bénéficiaires: 25,173,407,509.81 €\n",
      "   • Dépenses Collection bénéficiaires: 151,402,446.00 €\n",
      "   • Dépenses Innovation bénéficiaires: 1,661,365,577.00 €\n",
      "   • TOTAL dépenses bénéficiaires: 26,986,175,532.81 €\n",
      "\n",
      "2. CRÉDITS D'IMPÔT DOM-TOM:\n",
      "   • CIR Recherche DOM: 14,015,514.50 €\n",
      "   • CIR Collection DOM: 199,838.00 €\n",
      "   • CIR Innovation DOM: 5,224,736.25 €\n",
      "   • TOTAL CIR DOM: 19,440,088.75 €\n",
      "\n",
      "3. RÉPARTITION DES INDICATRICES:\n",
      "   • i_dep_rd    : 19,153 Oui ( 67.7%) |  9,156 Non ( 32.3%)\n",
      "   • i_dep_inno  : 11,063 Oui ( 39.1%) | 17,246 Non ( 60.9%)\n",
      "   • i_dep_coll  :    750 Oui (  2.6%) | 27,559 Non ( 97.4%)\n",
      "   • i_bef       : 26,097 Oui ( 92.2%) |  2,212 Non (  7.8%)\n",
      "   • i_bef_rech  : 18,378 Oui ( 64.9%) |  9,931 Non ( 35.1%)\n",
      "   • i_bef_inno  : 11,016 Oui ( 38.9%) | 17,293 Non ( 61.1%)\n",
      "   • i_bef_crc   :    319 Oui (  1.1%) | 27,990 Non ( 98.9%)\n",
      "   • i_bef_coll  :    744 Oui (  2.6%) | 27,565 Non ( 97.4%)\n",
      "\n",
      "4. VÉRIFICATIONS DE COHÉRENCE:\n",
      "   • Bénéficiaires totaux: 26,097\n",
      "   • Détail: Recherche 18,378 | Collection 744 | Innovation 11,016 | CRC 319\n",
      "   • Entreprises avec dépenses R&D mais sans bénéfice recherche: 1,252\n",
      "   • Entreprises avec dépenses Collection mais sans bénéfice collection: 33\n",
      "   • Entreprises avec dépenses Innovation mais sans bénéfice innovation: 187\n",
      "\n",
      "============================================================\n",
      "TRAITEMENT TERMINÉ AVEC SUCCÈS\n",
      "============================================================\n",
      "Fichier sauvegardé: M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_format_2021_complet.csv\n",
      "Nombre total de lignes: 28,309\n",
      "Nombre total de colonnes: 198\n",
      "Taille du fichier final: 5,605,182 cellules\n",
      "\n",
      "NOUVELLES COLONNES CRÉÉES (17):\n",
      "   1. crerd_genom\n",
      "   2. crecoll_genom\n",
      "   3. creinno_genom\n",
      "   4. cretot_genom\n",
      "   5. deprd_benef\n",
      "   6. depcoll_benef\n",
      "   7. depinno_benef\n",
      "   8. deptot_benef\n",
      "   9. i_dep_rd\n",
      "  10. i_dep_inno\n",
      "  11. i_dep_coll\n",
      "  12. i_bef\n",
      "  13. i_bef_rech\n",
      "  14. i_bef_inno\n",
      "  15. i_bef_crc\n",
      "  16. i_bef_coll\n",
      "  17. date_traitement\n",
      "\n",
      "Fichier prêt \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier obtenu précédemment\n",
    "file_path = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_format_2021.csv\"\n",
    "df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Nombre total de lignes: {len(df)}\")\n",
    "print(f\"Colonnes disponibles: {len(df.columns)}\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n=== CALCUL DES CRÉDITS DOM-TOM ===\")\n",
    "\n",
    "# Rechercher les colonnes DOM spécifiques\n",
    "colonnes_dom_rd = [col for col in df.columns if 'DOM' in col and ('RECHERCHE' in col or 'DEPENSES' in col)]\n",
    "colonnes_dom_coll = [col for col in df.columns if 'DOM' in col and 'COLLECTION' in col]\n",
    "colonnes_dom_inno = [col for col in df.columns if 'DOM' in col and 'INNOVATION' in col]\n",
    "\n",
    "print(f\"Colonnes DOM R&D trouvées: {colonnes_dom_rd}\")\n",
    "print(f\"Colonnes DOM Collection trouvées: {colonnes_dom_coll}\")\n",
    "print(f\"Colonnes DOM Innovation trouvées: {colonnes_dom_inno}\")\n",
    "\n",
    "# Calculer les crédits DOM-TOM avec les taux spécifiques\n",
    "# CIR Recherche DOM : 50%\n",
    "if 'L26B_MONTANT_NET_DEPENSES_DOM_CALCULE' in df.columns:\n",
    "    df['crerd_genom'] = df['L26B_MONTANT_NET_DEPENSES_DOM_CALCULE'].fillna(0) * 0.50\n",
    "    print(f\"CIR Recherche DOM calculé: {df['crerd_genom'].sum():,.2f} €\")\n",
    "else:\n",
    "    df['crerd_genom'] = 0\n",
    "    print(\"Pas de données DOM pour la recherche trouvées\")\n",
    "\n",
    "# CIR Collection DOM : 50%\n",
    "col_coll_dom = next((col for col in df.columns if 'L33B' in col and 'DOM' in col), None)\n",
    "if col_coll_dom:\n",
    "    df['crecoll_genom'] = df[col_coll_dom].fillna(0) * 0.50\n",
    "    print(f\"CIR Collection DOM calculé: {df['crecoll_genom'].sum():,.2f} €\")\n",
    "else:\n",
    "    df['crecoll_genom'] = 0\n",
    "    print(\"Pas de données DOM pour la collection trouvées\")\n",
    "\n",
    "# CIR Innovation DOM : 60% + Corse\n",
    "col_inno_dom = next((col for col in df.columns if 'L76B' in col and 'DOM' in col), None)\n",
    "col_inno_corse_mpe = next((col for col in df.columns if 'L76C' in col and 'CORSE' in col), None)\n",
    "col_inno_corse_me = next((col for col in df.columns if 'L76D' in col and 'CORSE' in col), None)\n",
    "\n",
    "if col_inno_dom:\n",
    "    cii_dom = df[col_inno_dom].fillna(0) * 0.60\n",
    "else:\n",
    "    cii_dom = 0\n",
    "\n",
    "if col_inno_corse_mpe:\n",
    "    cii_corse_mpe = df[col_inno_corse_mpe].fillna(0) * 0.40\n",
    "else:\n",
    "    cii_corse_mpe = 0\n",
    "\n",
    "if col_inno_corse_me:\n",
    "    cii_corse_me = df[col_inno_corse_me].fillna(0) * 0.35\n",
    "else:\n",
    "    cii_corse_me = 0\n",
    "\n",
    "df['creinno_genom'] = cii_dom + cii_corse_mpe + cii_corse_me\n",
    "print(f\"CIR Innovation DOM+Corse calculé: {df['creinno_genom'].sum():,.2f} €\")\n",
    "\n",
    "# CIR Total DOM\n",
    "df['cretot_genom'] = df['crerd_genom'] + df['crecoll_genom'] + df['creinno_genom']\n",
    "print(f\"CIR Total DOM calculé: {df['cretot_genom'].sum():,.2f} €\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n=== CALCUL DES MONTANTS NETS BÉNÉFICIAIRES ===\")\n",
    "\n",
    "# Standardiser les SIREN pour assurer la cohérence\n",
    "df['SIREN_DEPOSANT_STD'] = df['SIREN_DEPOSANT'].astype(str).str.replace(r'\\D', '', regex=True).str.zfill(9)\n",
    "df['SIREN_DECLARANT_STD'] = df['SIREN_DECLARANT'].astype(str).str.replace(r'\\D', '', regex=True).str.zfill(9)\n",
    "df['IS_MATCH'] = df['SIREN_DEPOSANT_STD'] == df['SIREN_DECLARANT_STD']\n",
    "\n",
    "# Recherche automatique des colonnes de dépenses\n",
    "def trouver_colonne_depenses(patterns, description):\n",
    "    \"\"\"Trouve la meilleure colonne correspondant aux patterns donnés\"\"\"\n",
    "    for pattern in patterns:\n",
    "        colonnes_trouvees = [col for col in df.columns if pattern in col]\n",
    "        if colonnes_trouvees:\n",
    "            print(f\"Colonne {description} trouvée: {colonnes_trouvees[0]}\")\n",
    "            return colonnes_trouvees[0]\n",
    "    print(f\"Aucune colonne {description} trouvée\")\n",
    "    return None\n",
    "\n",
    "# Rechercher les colonnes de dépenses\n",
    "colonne_depenses_rd = trouver_colonne_depenses([\n",
    "    'L26A_MONTANT_NET_DEPENSES_CALCULE',\n",
    "    'L26A_MONTANT_NET_DEPENSES_DECLARE',\n",
    "    'MONTANT_NET_DEPENSES'\n",
    "], \"dépenses R&D\")\n",
    "\n",
    "col_dep_coll = trouver_colonne_depenses([\n",
    "    'L33A_MONTANT_NET_COLLECTION_CALCULE',\n",
    "    'L33A_MONTANT_NET_COLLECTION_DECLARE',\n",
    "    'MONTANT_NET_COLLECTION'\n",
    "], \"dépenses Collection\")\n",
    "\n",
    "col_dep_inno = trouver_colonne_depenses([\n",
    "    'L76A_MONTANT_NET_INNOVATION_CALCULE',\n",
    "    'L76A_MONTANT_NET_INNOVATION_DECLARE',\n",
    "    'MONTANT_NET_INNOVATION'\n",
    "], \"dépenses Innovation\")\n",
    "\n",
    "# Fonction optimisée pour calculer les montants nets bénéficiaires\n",
    "def calculer_benef_optimise(df, colonne_source, nom_calcul=\"\"):\n",
    "    \"\"\"Calcule les montants bénéficiaires de manière optimisée\"\"\"\n",
    "    if colonne_source is None or colonne_source not in df.columns:\n",
    "        print(f\"  {nom_calcul}: Colonne non trouvée, initialisation à 0\")\n",
    "        return pd.Series(0, index=df.index, dtype='float64')\n",
    "    \n",
    "    print(f\"  {nom_calcul}: Calcul en cours...\")\n",
    "    \n",
    "    # Créer un DataFrame temporaire avec les données essentielles\n",
    "    df_temp = df[['SIREN_DEPOSANT_STD', 'IS_MATCH', colonne_source]].copy()\n",
    "    df_temp[colonne_source] = df_temp[colonne_source].fillna(0)\n",
    "    \n",
    "    # Calculer la somme totale par déposant\n",
    "    sommes = df_temp.groupby('SIREN_DEPOSANT_STD')[colonne_source].sum().to_dict()\n",
    "    \n",
    "    # Créer une série pour stocker les résultats\n",
    "    resultats = pd.Series(0, index=df.index, dtype='float64')\n",
    "    \n",
    "    # Compteurs pour le rapport\n",
    "    count_match = 0\n",
    "    count_no_match = 0\n",
    "    \n",
    "    # Pour chaque SIREN déposant unique\n",
    "    for siren, montant in sommes.items():\n",
    "        if montant == 0:\n",
    "            continue\n",
    "            \n",
    "        # Identifier les lignes correspondant à ce SIREN\n",
    "        mask_siren = df['SIREN_DEPOSANT_STD'] == siren\n",
    "        \n",
    "        # Identifier les lignes où il y a correspondance (déclarant = déposant)\n",
    "        mask_match_siren = mask_siren & df['IS_MATCH']\n",
    "        nb_match = mask_match_siren.sum()\n",
    "        \n",
    "        if nb_match > 0:\n",
    "            # Distribuer le montant également entre les lignes correspondantes\n",
    "            resultats[mask_match_siren] = montant / nb_match\n",
    "            count_match += nb_match\n",
    "        else:\n",
    "            # Attribuer à la première ligne du SIREN s'il n'y a pas de correspondance\n",
    "            if mask_siren.any():\n",
    "                idx = df[mask_siren].index[0]\n",
    "                resultats[idx] = montant\n",
    "                count_no_match += 1\n",
    "    \n",
    "    total_benef = resultats.sum()\n",
    "    total_gen = df_temp[colonne_source].sum()\n",
    "    print(f\"    Total généré: {total_gen:,.2f} € | Total bénéficiaire: {total_benef:,.2f} € | Écart: {total_gen-total_benef:,.2f} €\")\n",
    "    print(f\"    Répartition: {count_match} avec correspondance, {count_no_match} sans correspondance\")\n",
    "    \n",
    "    return resultats\n",
    "\n",
    "# Calculer les montants nets des dépenses bénéficiaires\n",
    "print(\"Calcul des montants nets des dépenses bénéficiaires:\")\n",
    "df['deprd_benef'] = calculer_benef_optimise(df, colonne_depenses_rd, \"Dépenses R&D\")\n",
    "df['depcoll_benef'] = calculer_benef_optimise(df, col_dep_coll, \"Dépenses Collection\")\n",
    "df['depinno_benef'] = calculer_benef_optimise(df, col_dep_inno, \"Dépenses Innovation\")\n",
    "\n",
    "# Calculer le montant total des dépenses bénéficiaires\n",
    "df['deptot_benef'] = df['deprd_benef'] + df['depcoll_benef'] + df['depinno_benef']\n",
    "print(f\"Montant total des dépenses bénéficiaires: {df['deptot_benef'].sum():,.2f} €\")\n",
    "\n",
    "\n",
    "print(\"\\n=== CRÉATION DES INDICATRICES ===\")\n",
    "\n",
    "# i_dep_rd : \"Oui\" si dépenses R&D > 0\n",
    "if colonne_depenses_rd and colonne_depenses_rd in df.columns:\n",
    "    df['i_dep_rd'] = np.where(df[colonne_depenses_rd] > 0, \"Oui\", \"Non\")\n",
    "else:\n",
    "    df['i_dep_rd'] = \"Non\"\n",
    "\n",
    "# i_dep_inno : \"Oui\" si dépenses inno > 0\n",
    "if col_dep_inno and col_dep_inno in df.columns:\n",
    "    df['i_dep_inno'] = np.where(df[col_dep_inno] > 0, \"Oui\", \"Non\")\n",
    "else:\n",
    "    df['i_dep_inno'] = \"Non\"\n",
    "\n",
    "# i_dep_coll : \"Oui\" si dépenses collection > 0\n",
    "if col_dep_coll and col_dep_coll in df.columns:\n",
    "    df['i_dep_coll'] = np.where(df[col_dep_coll] > 0, \"Oui\", \"Non\")\n",
    "else:\n",
    "    df['i_dep_coll'] = \"Non\"\n",
    "\n",
    "# i_bef : \"Oui\" si bénéficiaire du CIR total\n",
    "df['i_bef'] = np.where(df['cirtot_benef'] > 0, \"Oui\", \"Non\")\n",
    "\n",
    "# i_bef_rech : \"Oui\" si bénéficiaire du CIR recherche\n",
    "df['i_bef_rech'] = np.where(df['cirrech_benef'] > 0, \"Oui\", \"Non\")\n",
    "\n",
    "# i_bef_inno : \"Oui\" si bénéficiaire du CII\n",
    "df['i_bef_inno'] = np.where(df['cii_benef'] > 0, \"Oui\", \"Non\")\n",
    "\n",
    "# i_bef_crc : \"Oui\" si bénéficiaire du CRC\n",
    "df['i_bef_crc'] = np.where(df['crecrc_benef'] > 0, \"Oui\", \"Non\")\n",
    "\n",
    "# i_bef_coll : \"Oui\" si bénéficiaire du CI collection\n",
    "df['i_bef_coll'] = np.where(df['cic_benef'] > 0, \"Oui\", \"Non\")\n",
    "\n",
    "print(\"Indicatrices créées avec succès\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RAPPORT DÉTAILLÉ DE VÉRIFICATION DES DONNÉES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Vérifier les totaux des montants nets de dépenses\n",
    "print(\"\\n1. MONTANTS NETS DES DÉPENSES BÉNÉFICIAIRES:\")\n",
    "print(f\"   • Dépenses R&D bénéficiaires: {df['deprd_benef'].sum():,.2f} €\")\n",
    "print(f\"   • Dépenses Collection bénéficiaires: {df['depcoll_benef'].sum():,.2f} €\")\n",
    "print(f\"   • Dépenses Innovation bénéficiaires: {df['depinno_benef'].sum():,.2f} €\")\n",
    "print(f\"   • TOTAL dépenses bénéficiaires: {df['deptot_benef'].sum():,.2f} €\")\n",
    "\n",
    "# Vérifier les totaux des crédits DOM-TOM\n",
    "print(\"\\n2. CRÉDITS D'IMPÔT DOM-TOM:\")\n",
    "print(f\"   • CIR Recherche DOM: {df['crerd_genom'].sum():,.2f} €\")\n",
    "print(f\"   • CIR Collection DOM: {df['crecoll_genom'].sum():,.2f} €\")\n",
    "print(f\"   • CIR Innovation DOM: {df['creinno_genom'].sum():,.2f} €\")\n",
    "print(f\"   • TOTAL CIR DOM: {df['cretot_genom'].sum():,.2f} €\")\n",
    "\n",
    "# Vérifier les comptes des indicatrices\n",
    "print(\"\\n3. RÉPARTITION DES INDICATRICES:\")\n",
    "indicatrices = ['i_dep_rd', 'i_dep_inno', 'i_dep_coll', 'i_bef', 'i_bef_rech', 'i_bef_inno', 'i_bef_crc', 'i_bef_coll']\n",
    "\n",
    "for indicatrice in indicatrices:\n",
    "    if indicatrice in df.columns:\n",
    "        count_oui = (df[indicatrice] == \"Oui\").sum()\n",
    "        count_non = (df[indicatrice] == \"Non\").sum()\n",
    "        pct_oui = count_oui/len(df)*100\n",
    "        pct_non = count_non/len(df)*100\n",
    "        print(f\"   • {indicatrice:<12}: {count_oui:>6,} Oui ({pct_oui:>5.1f}%) | {count_non:>6,} Non ({pct_non:>5.1f}%)\")\n",
    "\n",
    "# Vérification de cohérence des bénéficiaires\n",
    "print(\"\\n4. VÉRIFICATIONS DE COHÉRENCE:\")\n",
    "\n",
    "# Cohérence entre i_bef et les autres indicatrices bénéficiaires\n",
    "nb_benef_total = (df['i_bef'] == \"Oui\").sum()\n",
    "nb_benef_rech = (df['i_bef_rech'] == \"Oui\").sum()\n",
    "nb_benef_coll = (df['i_bef_coll'] == \"Oui\").sum()\n",
    "nb_benef_inno = (df['i_bef_inno'] == \"Oui\").sum()\n",
    "nb_benef_crc = (df['i_bef_crc'] == \"Oui\").sum()\n",
    "\n",
    "print(f\"   • Bénéficiaires totaux: {nb_benef_total:,}\")\n",
    "print(f\"   • Détail: Recherche {nb_benef_rech:,} | Collection {nb_benef_coll:,} | Innovation {nb_benef_inno:,} | CRC {nb_benef_crc:,}\")\n",
    "\n",
    "# Vérifier la cohérence entre dépenses et bénéfices\n",
    "coherence_rd = ((df['i_dep_rd'] == \"Oui\") & (df['i_bef_rech'] == \"Non\")).sum()\n",
    "coherence_coll = ((df['i_dep_coll'] == \"Oui\") & (df['i_bef_coll'] == \"Non\")).sum()\n",
    "coherence_inno = ((df['i_dep_inno'] == \"Oui\") & (df['i_bef_inno'] == \"Non\")).sum()\n",
    "\n",
    "print(f\"   • Entreprises avec dépenses R&D mais sans bénéfice recherche: {coherence_rd:,}\")\n",
    "print(f\"   • Entreprises avec dépenses Collection mais sans bénéfice collection: {coherence_coll:,}\")\n",
    "print(f\"   • Entreprises avec dépenses Innovation mais sans bénéfice innovation: {coherence_inno:,}\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 5. FINALISATION ET SAUVEGARDE\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# Supprimer les colonnes temporaires\n",
    "colonnes_temp = ['SIREN_DEPOSANT_STD', 'SIREN_DECLARANT_STD', 'IS_MATCH']\n",
    "for col in colonnes_temp:\n",
    "    if col in df.columns:\n",
    "        df = df.drop(col, axis=1)\n",
    "\n",
    "# Ajouter une colonne de contrôle avec la date de traitement\n",
    "from datetime import datetime\n",
    "df['date_traitement'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Sauvegarder le fichier avec les nouvelles colonnes\n",
    "output_file = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_format_2021_complet.csv\"\n",
    "df.to_csv(output_file, sep=';', encoding='utf-8-sig', index=False)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"TRAITEMENT TERMINÉ AVEC SUCCÈS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Fichier sauvegardé: {output_file}\")\n",
    "print(f\"Nombre total de lignes: {len(df):,}\")\n",
    "print(f\"Nombre total de colonnes: {len(df.columns):,}\")\n",
    "print(f\"Taille du fichier final: {len(df) * len(df.columns):,} cellules\")\n",
    "\n",
    "# Résumé des nouvelles colonnes créées\n",
    "nouvelles_colonnes = [\n",
    "    'crerd_genom', 'crecoll_genom', 'creinno_genom', 'cretot_genom',\n",
    "    'deprd_benef', 'depcoll_benef', 'depinno_benef', 'deptot_benef',\n",
    "    'i_dep_rd', 'i_dep_inno', 'i_dep_coll', 'i_bef', 'i_bef_rech', \n",
    "    'i_bef_inno', 'i_bef_crc', 'i_bef_coll', 'date_traitement'\n",
    "]\n",
    "\n",
    "print(f\"\\nNOUVELLES COLONNES CRÉÉES ({len(nouvelles_colonnes)}):\")\n",
    "for i, col in enumerate(nouvelles_colonnes, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\nFichier prêt \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f5e09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement et préparation de 'C://Users//msamb//Documents//StockUniteLegale_utf8.csv'...\n",
      "Colonnes de stock_ul_extract après préparation : ['SIREN_DECLARANT', 'dateCreationUniteLegale', 'trancheEffectifsUniteLegale', 'categorieEntreprise', 'denominationUniteLegale', 'denominationUsuelle1UniteLegale', 'denominationUsuelle2UniteLegale', 'denominationUsuelle3UniteLegale', 'activitePrincipaleUniteLegale', 'nicSiegeUniteLegale', 'nic', 'siret']\n",
      "Chargement de la base à siréniser depuis 'M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_format_2021_complet.csv'...\n",
      "Colonnes de base_a_sireniser : ['SIREN_DECLARANT', 'SIREN_DEPOSANT', 'DESIGNATION', 'L1_DOTATION_AMORT_IMMO', 'L2_DOTATION_AMORT_SINISTR', 'L3_DEPENSES_PERSONNEL_CHERCHEURS', 'L4_REMUNERATION_INVENTEURS', 'L5_DEPENSES_JEUNES_DOCTEURS', 'L6_AUTRES_DEP_FONCT_DECLARE', 'L6_AUTRES_DEP_FONCT_CALCULE', 'L6_ECART', 'L7_TOTAL_DEP_FONCT_DECLARE', 'L7_TOTAL_DEP_FONCT_CALCULE', 'L7_ECART', 'L8_FRAIS_BREVETS_COV', 'L9_DEPENSES_DEFENSE_BREVETS', 'L10_DOTATION_AMORT_BREVETS', 'L11_DEPENSES_NORMALISATION_BRUT', 'L11_DEPENSES_NORMALISATION_DECLARE', 'L12_PRIMES_COTISATIONS_BRUT', 'L12_PRIMES_COTISATIONS_PLAFONNEES', 'L13_VEILLE_TECHNO_BRUT', 'L13_VEILLE_TECHNO_PLAFONNEE', 'L14_TOTAL_DEPENSES_INTERNES_DECLARE', 'L14_TOTAL_DEPENSES_INTERNES_CALCULE', 'L14_ECART', 'L15A_DEPENSES_ORG_LIES_FR', 'L15B_DEPENSES_ORG_LIES_ETR', 'L16A_DEPENSES_ORG_NON_LIES_FR', 'L16B_DEPENSES_ORG_NON_LIES_ETR', 'L17_TOTAL_DEP_EXTERNALISEES_DECLARE', 'L17_TOTAL_DEP_EXTERNALISEES_CALCULE', 'L17_ECART', 'L18_PLAFOND_GLOBAL_DECLARE', 'L18_PLAFOND_GLOBAL_CALCULE', 'L18_ECART', 'L19_PLAFOND_ORG_LIES_DECLARE', 'L19_PLAFOND_ORG_LIES_CALCULE', 'L19_ECART', 'L20_PLAFOND_ORG_NON_LIES_DECLARE', 'L20_PLAFOND_ORG_NON_LIES_CALCULE', 'L20_ECART', 'L21_TOTAL_DEP_EXT_PLAFONNEES_DECLARE', 'L21_TOTAL_DEP_EXT_PLAFONNEES_CALCULE', 'L21_ECART', 'L22_TOTAL_DEPENSES_RECHERCHE_DECLARE', 'L22_TOTAL_DEPENSES_RECHERCHE_CALCULE', 'L22_ECART', 'L23A_SUBVENTIONS', 'L23B_SOMMES_ENCAISSEES_TIERS', 'L24_DEPENSES_CONSEIL_CIR', 'L25_REMBOURSEMENTS_SUBVENTIONS', 'L26A_MONTANT_NET_DEPENSES_DECLARE', 'L26A_MONTANT_NET_DEPENSES_CALCULE', 'L26A_ECART', 'L26B_MONTANT_NET_DEPENSES_DOM_DECLARE', 'L26B_MONTANT_NET_DEPENSES_DOM_CALCULE', 'L26B_ECART', 'L27_FRAIS_COLLECTION', 'L28_FRAIS_DEFENSE_DESSINS_BRUT', 'L28_FRAIS_DEFENSE_DESSINS_PLAFONNES', 'L29_TOTAL_DEPENSES_COLLECTION_DECLARE', 'L29_TOTAL_DEPENSES_COLLECTION_CALCULE', 'L29_ECART', 'L30_SUBVENTIONS_COLLECTION', 'L31_DEPENSES_CONSEIL_COLLECTION', 'L32_REMBOURSEMENTS_SUBVENTIONS_COLL', 'L33A_MONTANT_NET_COLLECTION_DECLARE', 'L33A_MONTANT_NET_COLLECTION_CALCULE', 'L33A_ECART', 'L33B_MONTANT_NET_COLLECTION_DOM_DECLARE', 'L33B_MONTANT_NET_COLLECTION_DOM_CALCULE', 'L33B_ECART', 'L34A_MONTANT_NET_TOTAL_RD_COLL', 'L34B_MONTANT_NET_TOTAL_RD_COLL_DOM', 'L36_CREDIT_IMPOT_RECHERCHE_MOINS_100M', 'L37_QUOTE_PART_RECHERCHE_SOC_PERSONNES', 'L38A_CREDIT_IMPOT_RECHERCHE_TOTAL', 'L38B_CREDIT_IMPOT_RECHERCHE_DOM', 'L40_CREDIT_IMPOT_COLLECTION_MOINS_100M', 'L41_QUOTE_PART_COLLECTION_SOC_PERSONNES', 'L42A_CREDIT_IMPOT_COLL_AVANT_PLAF', 'L42B_CREDIT_IMPOT_COLL_DOM_AVANT_PLAF', 'L43_AIDES_MINIMIS', 'L44_CUMUL_CREDIT_IMPOT_ET_AIDES', 'L45A_CREDIT_IMPOT_COLL_APRES_PLAF', 'L46A_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION', 'L46B_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION_DOM', 'L47A_DEPENSES_RECHERCHE_LIMITE_100M', 'L47B_DEPENSES_RECHERCHE_DOM_LIMITE', 'L48_CIR_RECHERCHE_PREMIERE_TRANCHE', 'L49_DEPENSES_RECHERCHE_SUP_100M', 'L50_CIR_RECHERCHE_DEUXIEME_TRANCHE', 'L51_CIR_RECHERCHE_PLUS_100M', 'L52_QUOTE_PART_RECHERCHE_SOC_PERSONNES_PLUS_100M', 'L53A_CREDIT_IMPOT_RECHERCHE_TOTAL_PLUS_100M', 'L53B_CREDIT_IMPOT_RECHERCHE_DOM_PLUS_100M', 'L54A_MONTANT_NET_COLLECTION_PLUS_100M', 'L54B_MONTANT_NET_COLLECTION_DOM_PLUS_100M', 'L55_PLAFOND_DISPO_COLLECTION', 'L56_CIR_COLLECTION_PREMIERE_TRANCHE', 'L57_CIR_COLLECTION_DEUXIEME_TRANCHE', 'L58_CIR_COLLECTION_PLUS_100M', 'L59_QUOTE_PART_COLLECTION_SOC_PERSONNES_PLUS_100M', 'L60_CREDIT_IMPOT_COLL_AVANT_PLAF_PLUS_100M', 'L61_AIDES_MINIMIS_PLUS_100M', 'L62_CUMUL_CREDIT_IMPOT_ET_AIDES_PLUS_100M', 'L63A_CREDIT_IMPOT_COLL_APRES_PLAF_PLUS_100M', 'L64A_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION_PLUS_100M', 'L64B_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION_DOM_PLUS_100M', 'L65_DOTATION_AMORT_IMMO_INNOVATION', 'L66_DEPENSES_PERSONNEL_INNOVATION', 'L67_FRAIS_BREVETS_INNOVATION', 'L68_FRAIS_DEFENSE_BREVETS_INNOVATION', 'L69_OPERATIONS_CONFIEES_INNOVATION', 'L70_TOTAL_DEPENSES_INNOVATION_DECLARE', 'L70_TOTAL_DEPENSES_INNOVATION_CALCULE', 'L70_ECART', 'L71_DEPENSES_INNOVATION_PLAFONNEES_DECLARE', 'L71_DEPENSES_INNOVATION_PLAFONNEES_CALCULE', 'L71_ECART', 'L72_SUBVENTIONS_INNOVATION', 'L73_PRESTATIONS_INNOVATION', 'L74_DEPENSES_CONSEIL_INNOVATION', 'L75_REMBOURSEMENTS_SUBVENTIONS_INNO', 'L76A_MONTANT_NET_INNOVATION_DECLARE', 'L76A_MONTANT_NET_INNOVATION_CALCULE', 'L76A_ECART', 'L76B_MONTANT_NET_INNOVATION_DOM', 'L76C_MONTANT_NET_INNOVATION_CORSE_MPE', 'L76D_MONTANT_NET_INNOVATION_CORSE_ME', 'L77_CREDIT_IMPOT_INNOVATION', 'L78_QUOTE_PART_INNOVATION_SOC_PERSONNES', 'L79A_TOTAL_CREDIT_IMPOT_INNOVATION', 'L79B_CREDIT_IMPOT_INNOVATION_DOM', 'L79C_CREDIT_IMPOT_INNOVATION_CORSE', 'L80A_TOTAL_CIR_RECH_COLL_INNO', 'L80B_TOTAL_CIR_RECH_COLL_INNO_DOM', 'L81_DEPENSES_RECHERCHE_COLLABORATIVE', 'L82A_DEPENSES_RC_FRANCE', 'L82B_DEPENSES_RC_ETRANGER', 'L82_TOTAL_DEPENSES_RC', 'L83_DEPENSES_RC_PLAFONNEES_DECLARE', 'L83_DEPENSES_RC_PLAFONNEES_CALCULE', 'L83_ECART', 'L84_AIDES_PUBLIQUES_RC', 'L85_REMBOURSEMENTS_AIDES_RC', 'L86_MONTANT_NET_RC_DECLARE', 'L86_MONTANT_NET_RC_CALCULE', 'L86_ECART', 'L87_MONTANT_NET_RC_PME', 'L88_CREDIT_IMPOT_RC', 'L89_QUOTE_PART_RC_SOC_PERSONNES', 'L90_MONTANT_TOTAL_CIR_RECHERCHE_COLLABORATIVE', 'crerd_gen_declare', 'crerd_gen', 'crerd_gen_ecart', 'crecoll_gen_declare', 'crecoll_gen', 'crecoll_gen_ecart', 'creinno_gen_declare', 'creinno_gen', 'creinno_gen_ecart', 'crecrc_declare', 'crecrc', 'crecrc_ecart', 'cretot_gen_declare', 'cretot_gen_calcule', 'cretot_gen_ecart', 'CORRESPONDANCE_CIR', 'ECART_RELATIF_POURCENT', 'TRAITEMENT_APPLIQUE', 'cretot_gen', 'type_final', 'mere_final', 'cir_benef_total', 'cirrech_benef', 'cic_benef', 'cii_benef', 'crecrc_benef', 'cirtot_benef', 'crerd_genom', 'crecoll_genom', 'creinno_genom', 'cretot_genom', 'deprd_benef', 'depcoll_benef', 'depinno_benef', 'deptot_benef', 'i_dep_rd', 'i_dep_inno', 'i_dep_coll', 'i_bef', 'i_bef_rech', 'i_bef_inno', 'i_bef_crc', 'i_bef_coll', 'date_traitement']\n",
      "\n",
      "Jonction de 'base_a_sireniser' avec 'stock_ul_extrait' sur la colonne 'SIREN_DECLARANT'...\n",
      "Nombre de lignes après la première jonction : 28309\n",
      "Chargement et préparation de la nomenclature 'C://Users//msamb//Documents//Nomenclature_secteur_sittar.xlsx'...\n",
      "Colonnes de nomenclature_sitar après préparation : ['activiteprincipaleunitelegale', 'secteur_dactivit', 'libell_code_ape_entreprise']\n",
      "\n",
      "Jonction avec 'nomenclature_sitar' sur la colonne APE (harmonisées)...\n",
      "Nombre de lignes après la seconde jonction : 28309\n",
      "Colonnes finales : ['SIREN_DECLARANT', 'SIREN_DEPOSANT', 'DESIGNATION', 'L1_DOTATION_AMORT_IMMO', 'L2_DOTATION_AMORT_SINISTR', 'L3_DEPENSES_PERSONNEL_CHERCHEURS', 'L4_REMUNERATION_INVENTEURS', 'L5_DEPENSES_JEUNES_DOCTEURS', 'L6_AUTRES_DEP_FONCT_DECLARE', 'L6_AUTRES_DEP_FONCT_CALCULE', 'L6_ECART', 'L7_TOTAL_DEP_FONCT_DECLARE', 'L7_TOTAL_DEP_FONCT_CALCULE', 'L7_ECART', 'L8_FRAIS_BREVETS_COV', 'L9_DEPENSES_DEFENSE_BREVETS', 'L10_DOTATION_AMORT_BREVETS', 'L11_DEPENSES_NORMALISATION_BRUT', 'L11_DEPENSES_NORMALISATION_DECLARE', 'L12_PRIMES_COTISATIONS_BRUT', 'L12_PRIMES_COTISATIONS_PLAFONNEES', 'L13_VEILLE_TECHNO_BRUT', 'L13_VEILLE_TECHNO_PLAFONNEE', 'L14_TOTAL_DEPENSES_INTERNES_DECLARE', 'L14_TOTAL_DEPENSES_INTERNES_CALCULE', 'L14_ECART', 'L15A_DEPENSES_ORG_LIES_FR', 'L15B_DEPENSES_ORG_LIES_ETR', 'L16A_DEPENSES_ORG_NON_LIES_FR', 'L16B_DEPENSES_ORG_NON_LIES_ETR', 'L17_TOTAL_DEP_EXTERNALISEES_DECLARE', 'L17_TOTAL_DEP_EXTERNALISEES_CALCULE', 'L17_ECART', 'L18_PLAFOND_GLOBAL_DECLARE', 'L18_PLAFOND_GLOBAL_CALCULE', 'L18_ECART', 'L19_PLAFOND_ORG_LIES_DECLARE', 'L19_PLAFOND_ORG_LIES_CALCULE', 'L19_ECART', 'L20_PLAFOND_ORG_NON_LIES_DECLARE', 'L20_PLAFOND_ORG_NON_LIES_CALCULE', 'L20_ECART', 'L21_TOTAL_DEP_EXT_PLAFONNEES_DECLARE', 'L21_TOTAL_DEP_EXT_PLAFONNEES_CALCULE', 'L21_ECART', 'L22_TOTAL_DEPENSES_RECHERCHE_DECLARE', 'L22_TOTAL_DEPENSES_RECHERCHE_CALCULE', 'L22_ECART', 'L23A_SUBVENTIONS', 'L23B_SOMMES_ENCAISSEES_TIERS', 'L24_DEPENSES_CONSEIL_CIR', 'L25_REMBOURSEMENTS_SUBVENTIONS', 'L26A_MONTANT_NET_DEPENSES_DECLARE', 'L26A_MONTANT_NET_DEPENSES_CALCULE', 'L26A_ECART', 'L26B_MONTANT_NET_DEPENSES_DOM_DECLARE', 'L26B_MONTANT_NET_DEPENSES_DOM_CALCULE', 'L26B_ECART', 'L27_FRAIS_COLLECTION', 'L28_FRAIS_DEFENSE_DESSINS_BRUT', 'L28_FRAIS_DEFENSE_DESSINS_PLAFONNES', 'L29_TOTAL_DEPENSES_COLLECTION_DECLARE', 'L29_TOTAL_DEPENSES_COLLECTION_CALCULE', 'L29_ECART', 'L30_SUBVENTIONS_COLLECTION', 'L31_DEPENSES_CONSEIL_COLLECTION', 'L32_REMBOURSEMENTS_SUBVENTIONS_COLL', 'L33A_MONTANT_NET_COLLECTION_DECLARE', 'L33A_MONTANT_NET_COLLECTION_CALCULE', 'L33A_ECART', 'L33B_MONTANT_NET_COLLECTION_DOM_DECLARE', 'L33B_MONTANT_NET_COLLECTION_DOM_CALCULE', 'L33B_ECART', 'L34A_MONTANT_NET_TOTAL_RD_COLL', 'L34B_MONTANT_NET_TOTAL_RD_COLL_DOM', 'L36_CREDIT_IMPOT_RECHERCHE_MOINS_100M', 'L37_QUOTE_PART_RECHERCHE_SOC_PERSONNES', 'L38A_CREDIT_IMPOT_RECHERCHE_TOTAL', 'L38B_CREDIT_IMPOT_RECHERCHE_DOM', 'L40_CREDIT_IMPOT_COLLECTION_MOINS_100M', 'L41_QUOTE_PART_COLLECTION_SOC_PERSONNES', 'L42A_CREDIT_IMPOT_COLL_AVANT_PLAF', 'L42B_CREDIT_IMPOT_COLL_DOM_AVANT_PLAF', 'L43_AIDES_MINIMIS', 'L44_CUMUL_CREDIT_IMPOT_ET_AIDES', 'L45A_CREDIT_IMPOT_COLL_APRES_PLAF', 'L46A_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION', 'L46B_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION_DOM', 'L47A_DEPENSES_RECHERCHE_LIMITE_100M', 'L47B_DEPENSES_RECHERCHE_DOM_LIMITE', 'L48_CIR_RECHERCHE_PREMIERE_TRANCHE', 'L49_DEPENSES_RECHERCHE_SUP_100M', 'L50_CIR_RECHERCHE_DEUXIEME_TRANCHE', 'L51_CIR_RECHERCHE_PLUS_100M', 'L52_QUOTE_PART_RECHERCHE_SOC_PERSONNES_PLUS_100M', 'L53A_CREDIT_IMPOT_RECHERCHE_TOTAL_PLUS_100M', 'L53B_CREDIT_IMPOT_RECHERCHE_DOM_PLUS_100M', 'L54A_MONTANT_NET_COLLECTION_PLUS_100M', 'L54B_MONTANT_NET_COLLECTION_DOM_PLUS_100M', 'L55_PLAFOND_DISPO_COLLECTION', 'L56_CIR_COLLECTION_PREMIERE_TRANCHE', 'L57_CIR_COLLECTION_DEUXIEME_TRANCHE', 'L58_CIR_COLLECTION_PLUS_100M', 'L59_QUOTE_PART_COLLECTION_SOC_PERSONNES_PLUS_100M', 'L60_CREDIT_IMPOT_COLL_AVANT_PLAF_PLUS_100M', 'L61_AIDES_MINIMIS_PLUS_100M', 'L62_CUMUL_CREDIT_IMPOT_ET_AIDES_PLUS_100M', 'L63A_CREDIT_IMPOT_COLL_APRES_PLAF_PLUS_100M', 'L64A_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION_PLUS_100M', 'L64B_MONTANT_TOTAL_CIR_RECHERCHE_COLLECTION_DOM_PLUS_100M', 'L65_DOTATION_AMORT_IMMO_INNOVATION', 'L66_DEPENSES_PERSONNEL_INNOVATION', 'L67_FRAIS_BREVETS_INNOVATION', 'L68_FRAIS_DEFENSE_BREVETS_INNOVATION', 'L69_OPERATIONS_CONFIEES_INNOVATION', 'L70_TOTAL_DEPENSES_INNOVATION_DECLARE', 'L70_TOTAL_DEPENSES_INNOVATION_CALCULE', 'L70_ECART', 'L71_DEPENSES_INNOVATION_PLAFONNEES_DECLARE', 'L71_DEPENSES_INNOVATION_PLAFONNEES_CALCULE', 'L71_ECART', 'L72_SUBVENTIONS_INNOVATION', 'L73_PRESTATIONS_INNOVATION', 'L74_DEPENSES_CONSEIL_INNOVATION', 'L75_REMBOURSEMENTS_SUBVENTIONS_INNO', 'L76A_MONTANT_NET_INNOVATION_DECLARE', 'L76A_MONTANT_NET_INNOVATION_CALCULE', 'L76A_ECART', 'L76B_MONTANT_NET_INNOVATION_DOM', 'L76C_MONTANT_NET_INNOVATION_CORSE_MPE', 'L76D_MONTANT_NET_INNOVATION_CORSE_ME', 'L77_CREDIT_IMPOT_INNOVATION', 'L78_QUOTE_PART_INNOVATION_SOC_PERSONNES', 'L79A_TOTAL_CREDIT_IMPOT_INNOVATION', 'L79B_CREDIT_IMPOT_INNOVATION_DOM', 'L79C_CREDIT_IMPOT_INNOVATION_CORSE', 'L80A_TOTAL_CIR_RECH_COLL_INNO', 'L80B_TOTAL_CIR_RECH_COLL_INNO_DOM', 'L81_DEPENSES_RECHERCHE_COLLABORATIVE', 'L82A_DEPENSES_RC_FRANCE', 'L82B_DEPENSES_RC_ETRANGER', 'L82_TOTAL_DEPENSES_RC', 'L83_DEPENSES_RC_PLAFONNEES_DECLARE', 'L83_DEPENSES_RC_PLAFONNEES_CALCULE', 'L83_ECART', 'L84_AIDES_PUBLIQUES_RC', 'L85_REMBOURSEMENTS_AIDES_RC', 'L86_MONTANT_NET_RC_DECLARE', 'L86_MONTANT_NET_RC_CALCULE', 'L86_ECART', 'L87_MONTANT_NET_RC_PME', 'L88_CREDIT_IMPOT_RC', 'L89_QUOTE_PART_RC_SOC_PERSONNES', 'L90_MONTANT_TOTAL_CIR_RECHERCHE_COLLABORATIVE', 'crerd_gen_declare', 'crerd_gen', 'crerd_gen_ecart', 'crecoll_gen_declare', 'crecoll_gen', 'crecoll_gen_ecart', 'creinno_gen_declare', 'creinno_gen', 'creinno_gen_ecart', 'crecrc_declare', 'crecrc', 'crecrc_ecart', 'cretot_gen_declare', 'cretot_gen_calcule', 'cretot_gen_ecart', 'CORRESPONDANCE_CIR', 'ECART_RELATIF_POURCENT', 'TRAITEMENT_APPLIQUE', 'cretot_gen', 'type_final', 'mere_final', 'cir_benef_total', 'cirrech_benef', 'cic_benef', 'cii_benef', 'crecrc_benef', 'cirtot_benef', 'crerd_genom', 'crecoll_genom', 'creinno_genom', 'cretot_genom', 'deprd_benef', 'depcoll_benef', 'depinno_benef', 'deptot_benef', 'i_dep_rd', 'i_dep_inno', 'i_dep_coll', 'i_bef', 'i_bef_rech', 'i_bef_inno', 'i_bef_crc', 'i_bef_coll', 'date_traitement', 'dateCreationUniteLegale', 'trancheEffectifsUniteLegale', 'categorieEntreprise', 'denominationUniteLegale', 'denominationUsuelle1UniteLegale', 'denominationUsuelle2UniteLegale', 'denominationUsuelle3UniteLegale', 'activitePrincipaleUniteLegale', 'nicSiegeUniteLegale', 'nic', 'siret', 'activiteprincipaleunitelegale', 'secteur_dactivit', 'libell_code_ape_entreprise']\n",
      "\n",
      "✓ Processus de sirénisation terminé.\n",
      "\n",
      "Aperçu du DataFrame final (base_finale_df) :\n",
      "  SIREN_DECLARANT  SIREN_DEPOSANT                       DESIGNATION  \\\n",
      "0       005520325         5520325     ETABLISSEMENTS ADRIEN RIQUIER   \n",
      "1       005580436         5580436                        BAUDINVEST   \n",
      "2       005680145         5680145  ROTOVIA  MONTOIR DE BRETAGNE SAS   \n",
      "3       006380042         6380042           Laboratoire NUTERGIA NS   \n",
      "4       006580195         6580195                         SAS SIDES   \n",
      "\n",
      "   L1_DOTATION_AMORT_IMMO  L2_DOTATION_AMORT_SINISTR  \\\n",
      "0                     0.0                        0.0   \n",
      "1                     0.0                        0.0   \n",
      "2                 11503.0                        0.0   \n",
      "3                 28326.0                        0.0   \n",
      "4                  3665.0                        0.0   \n",
      "\n",
      "   L3_DEPENSES_PERSONNEL_CHERCHEURS  L4_REMUNERATION_INVENTEURS  \\\n",
      "0                               0.0                         0.0   \n",
      "1                               0.0                         0.0   \n",
      "2                           10414.0                         0.0   \n",
      "3                          251477.0                         0.0   \n",
      "4                          398511.0                         0.0   \n",
      "\n",
      "   L5_DEPENSES_JEUNES_DOCTEURS  L6_AUTRES_DEP_FONCT_DECLARE  \\\n",
      "0                          0.0                          0.0   \n",
      "1                          0.0                          0.0   \n",
      "2                          0.0                      13105.0   \n",
      "3                          0.0                     129380.0   \n",
      "4                          0.0                     174109.0   \n",
      "\n",
      "   L6_AUTRES_DEP_FONCT_CALCULE  ...  denominationUsuelle1UniteLegale  \\\n",
      "0                         0.00  ...                              NaN   \n",
      "1                         0.00  ...                              NaN   \n",
      "2                     13105.27  ...                              NaN   \n",
      "3                    129379.61  ...                              NaN   \n",
      "4                    174108.48  ...                              NaN   \n",
      "\n",
      "   denominationUsuelle2UniteLegale  denominationUsuelle3UniteLegale  \\\n",
      "0                              NaN                              NaN   \n",
      "1                              NaN                              NaN   \n",
      "2                              NaN                              NaN   \n",
      "3                              NaN                              NaN   \n",
      "4                              NaN                              NaN   \n",
      "\n",
      "   activitePrincipaleUniteLegale  nicSiegeUniteLegale    nic           siret  \\\n",
      "0                         46.74B                00027  00027  00552032500027   \n",
      "1                         70.22Z                00060  00060  00558043600060   \n",
      "2                         22.22Z                00017  00017  00568014500017   \n",
      "3                         10.86Z                00033  00033  00638004200033   \n",
      "4                         29.10Z                00078  00078  00658019500078   \n",
      "\n",
      "   activiteprincipaleunitelegale                       secteur_dactivit  \\\n",
      "0                         46.74B                              COMMERCES   \n",
      "1                         70.22Z  CONSEIL ET ASSISTANCE AUX ENTREPRISES   \n",
      "2                         22.22Z         CHIMIE, CAOUTCHOUC, PLASTIQUES   \n",
      "3                         10.86Z   INDUSTRIES AGRICOLES ET ALIMENTAIRES   \n",
      "4                         29.10Z                   INDUSTRIE AUTOMOBILE   \n",
      "\n",
      "                          libell_code_ape_entreprise  \n",
      "0  Commerce de gros (commerce interentreprises) d...  \n",
      "1  Conseil pour les affaires et autres conseils d...  \n",
      "2    Fabrication d'emballages en matières plastiques  \n",
      "3  Fabrication d'aliments homogénéisés et diététi...  \n",
      "4              Construction de véhicules automobiles  \n",
      "\n",
      "[5 rows x 212 columns]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Ce script :\n",
    "1. Charge et prépare un fichier de référence des unités légales (StockUniteLegale).\n",
    "2. Charge une base de données principale à enrichir (\"base_a_sireniser\").\n",
    "3. Joint ces deux bases sur le numéro SIREN.\n",
    "4. Charge une nomenclature d'activités (Nomenclature Sittar).\n",
    "5. Joint le résultat précédent avec cette nomenclature sur le code APE.\n",
    "\n",
    "librairie pandas installée requis: pip install pandas openpyxl\n",
    "(openpyxl est nécessaire pour lire les fichiers Excel .xlsx)\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd # Librairie pour la manipulation de données\n",
    "import re           # Librairie pour les expressions régulières (nettoyage des noms de colonnes)\n",
    "# La librairie 'os' n'est plus nécessaire car on ne crée plus de dossier/fichiers de test.\n",
    "\n",
    "# --- Fonction Auxiliaire pour Nettoyer les Noms de Colonnes ---\n",
    "def nettoyer_noms_colonnes(df_a_nettoyer):\n",
    "    \"\"\"\n",
    "    Nettoie les noms de colonnes d'un DataFrame :\n",
    "    1. Convertit en minuscules.\n",
    "    2. Remplace les espaces et caractères spéciaux par des tirets bas ('_').\n",
    "    3. Supprime les tirets bas en début ou fin de nom.\n",
    "    Retourne un nouveau DataFrame avec les noms de colonnes nettoyés.\n",
    "    \"\"\"\n",
    "    df = df_a_nettoyer.copy() # Travailler sur une copie\n",
    "    nouveaux_noms = {}\n",
    "    for col in df.columns:\n",
    "        nouveau_nom = str(col).lower()\n",
    "        nouveau_nom = re.sub(r'\\s+', '_', nouveau_nom)\n",
    "        nouveau_nom = re.sub(r'[^a-z0-9_]', '', nouveau_nom)\n",
    "        nouveau_nom = re.sub(r'_+', '_', nouveau_nom)\n",
    "        nouveau_nom = nouveau_nom.strip('_')\n",
    "        nouveaux_noms[col] = nouveau_nom\n",
    "    df.rename(columns=nouveaux_noms, inplace=True)\n",
    "    return df\n",
    "\n",
    "# --- 1. Chargement et Préparation des Données 'StockUniteLegale' ---\n",
    "def charger_et_preparer_stock_ul(chemin_fichier_stock_ul):\n",
    "    \"\"\"\n",
    "    Charge et prépare les données du fichier 'StockUniteLegale'.\n",
    "    \"\"\"\n",
    "    print(f\"Chargement et préparation de '{chemin_fichier_stock_ul}'...\")\n",
    "    colonnes_a_garder = [\n",
    "        'siren', 'nicSiegeUniteLegale', 'denominationUniteLegale',\n",
    "        'denominationUsuelle1UniteLegale', 'denominationUsuelle2UniteLegale',\n",
    "        'denominationUsuelle3UniteLegale', 'dateCreationUniteLegale',\n",
    "        'activitePrincipaleUniteLegale', 'categorieEntreprise',\n",
    "        'trancheEffectifsUniteLegale'\n",
    "    ]\n",
    "    try:\n",
    "        stock_ul_df = pd.read_csv(chemin_fichier_stock_ul, \n",
    "                                  usecols=colonnes_a_garder, \n",
    "                                  dtype=str, \n",
    "                                  encoding='utf-8')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERREUR : Le fichier '{chemin_fichier_stock_ul}' est introuvable.\")\n",
    "        raise\n",
    "    except ValueError as e:\n",
    "        print(f\"ERREUR : Vérifiez que les colonnes {colonnes_a_garder} existent bien dans '{chemin_fichier_stock_ul}'. Détail : {e}\")\n",
    "        raise\n",
    "\n",
    "    stock_ul_df['nic'] = stock_ul_df['nicSiegeUniteLegale'].str.zfill(5)\n",
    "    stock_ul_df['siren'] = stock_ul_df['siren'].str.zfill(9)\n",
    "    stock_ul_df['siret'] = stock_ul_df['siren'] + stock_ul_df['nic']\n",
    "    stock_ul_df.rename(columns={'siren': 'SIREN_DECLARANT'}, inplace=True)\n",
    "    print(f\"Colonnes de stock_ul_extract après préparation : {stock_ul_df.columns.tolist()}\")\n",
    "    return stock_ul_df\n",
    "\n",
    "# --- Fonction pour Charger la 'base_a_sireniser' ---\n",
    "def charger_base_a_sireniser(chemin_fichier_base, nom_colonne_siren='SIREN_DECLARANT'):\n",
    "    \"\"\"\n",
    "    Charge les données de la 'base_a_sireniser'.\n",
    "    'nom_colonne_siren' doit être le nom de la colonne SIREN dans ce fichier.\n",
    "    \"\"\"\n",
    "    print(f\"Chargement de la base à siréniser depuis '{chemin_fichier_base}'...\")\n",
    "    try:\n",
    "        base_df = pd.read_csv(chemin_fichier_base,\n",
    "                      dtype={nom_colonne_siren: str}, \n",
    "                      encoding='utf-8',\n",
    "                      sep=';') # Ajoutez sep=';' ou le séparateur correct\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERREUR : Le fichier '{chemin_fichier_base}' est introuvable.\")\n",
    "        raise\n",
    "    except KeyError:\n",
    "        print(f\"ERREUR : La colonne '{nom_colonne_siren}' (spécifiée pour le SIREN) est introuvable dans '{chemin_fichier_base}'.\")\n",
    "        raise\n",
    "        \n",
    "    if nom_colonne_siren in base_df.columns:\n",
    "        base_df[nom_colonne_siren] = base_df[nom_colonne_siren].str.zfill(9)\n",
    "    print(f\"Colonnes de base_a_sireniser : {base_df.columns.tolist()}\")\n",
    "    return base_df\n",
    "\n",
    "# --- 3. Chargement et Préparation des Données de la 'Nomenclature Sittar' ---\n",
    "def charger_et_preparer_nomenclature(chemin_fichier_nomenclature, nom_original_col_ape='code_ape_entreprise'):\n",
    "    \"\"\"\n",
    "    Charge et prépare les données du fichier 'Nomenclature_secteur_sittar.xlsx'.\n",
    "    'nom_original_col_ape' est le nom original de la colonne du code APE dans le fichier Excel.\n",
    "    \"\"\"\n",
    "    print(f\"Chargement et préparation de la nomenclature '{chemin_fichier_nomenclature}'...\")\n",
    "    try:\n",
    "        nomenclature_df = pd.read_excel(chemin_fichier_nomenclature)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERREUR : Le fichier '{chemin_fichier_nomenclature}' est introuvable.\")\n",
    "        raise\n",
    "\n",
    "    nomenclature_df = nettoyer_noms_colonnes(nomenclature_df)\n",
    "    col_ape_nettoyee_candidate = nettoyer_noms_colonnes(pd.DataFrame(columns=[nom_original_col_ape])).columns[0]\n",
    "    nom_cible_col_ape_pour_jointure = 'activiteprincipaleunitelegale'\n",
    "\n",
    "    if col_ape_nettoyee_candidate in nomenclature_df.columns:\n",
    "        nomenclature_df.rename(columns={col_ape_nettoyee_candidate: nom_cible_col_ape_pour_jointure}, inplace=True)\n",
    "    elif nom_original_col_ape.lower() in nomenclature_df.columns and nom_original_col_ape.lower() != nom_cible_col_ape_pour_jointure :\n",
    "         nomenclature_df.rename(columns={nom_original_col_ape.lower(): nom_cible_col_ape_pour_jointure}, inplace=True)\n",
    "    elif nom_cible_col_ape_pour_jointure not in nomenclature_df.columns:\n",
    "        print(f\"Attention : Colonne APE ('{col_ape_nettoyee_candidate}' ou '{nom_original_col_ape.lower()}') non trouvée \"\n",
    "              f\"pour renommage en '{nom_cible_col_ape_pour_jointure}'. Colonnes dispo : {nomenclature_df.columns.tolist()}\")\n",
    "\n",
    "    if nom_cible_col_ape_pour_jointure in nomenclature_df.columns:\n",
    "        cols = [nom_cible_col_ape_pour_jointure] + [col for col in nomenclature_df.columns if col != nom_cible_col_ape_pour_jointure]\n",
    "        nomenclature_df = nomenclature_df[cols]\n",
    "    print(f\"Colonnes de nomenclature_sitar après préparation : {nomenclature_df.columns.tolist()}\")\n",
    "    return nomenclature_df\n",
    "\n",
    "# --- Processus Principal de Sirénisation ---\n",
    "def processus_principal_sirenisation():\n",
    "    \"\"\"\n",
    "    Fonction principale orchestrant le processus de sirénisation.\n",
    "    \"\"\"\n",
    "    # --- Configuration : Définissez vos chemins de fichiers ici ---\n",
    "    chemin_stock_ul = \"C://Users//msamb//Documents//StockUniteLegale_utf8.csv\"\n",
    "    chemin_base_a_sireniser = \"M://str-dgri-gecir-donnees-fiscales//x-pour MF-SAMB//scripts//Calcul_Creance_CIR_format_2021_complet.csv\"\n",
    "    nom_col_siren_dans_base = \"SIREN_DECLARANT\" \n",
    "    chemin_nomenclature_sittar = \"C://Users//msamb//Documents//Nomenclature_secteur_sittar.xlsx\"\n",
    "    nom_original_col_ape_nomenclature = \"Code APE Entreprise\"\n",
    "    # --- Fin de la Configuration ---\n",
    "\n",
    "    try:\n",
    "        # 1. Charger et préparer 'stock_ul_extract'\n",
    "        stock_ul_extrait_df = charger_et_preparer_stock_ul(chemin_stock_ul)\n",
    "\n",
    "        # 2. Charger 'base_a_sireniser'\n",
    "        base_a_sireniser_df = charger_base_a_sireniser(chemin_base_a_sireniser, nom_colonne_siren=nom_col_siren_dans_base)\n",
    "\n",
    "        # 3. Première jointure (sirénisation)\n",
    "        print(f\"\\nJonction de 'base_a_sireniser' avec 'stock_ul_extrait' sur la colonne '{nom_col_siren_dans_base}'...\")\n",
    "        base_finale_def_sirenise = pd.merge(\n",
    "            left=base_a_sireniser_df,\n",
    "            right=stock_ul_extrait_df,\n",
    "            left_on=nom_col_siren_dans_base,\n",
    "            right_on='SIREN_DECLARANT',\n",
    "            how='left'\n",
    "        )\n",
    "        print(f\"Nombre de lignes après la première jonction : {len(base_finale_def_sirenise)}\")\n",
    "\n",
    "        # 4. Charger et préparer 'nomenclature_sitar'\n",
    "        nomenclature_sitar_df = charger_et_preparer_nomenclature(\n",
    "            chemin_nomenclature_sittar, \n",
    "            nom_original_col_ape=nom_original_col_ape_nomenclature\n",
    "        )\n",
    "\n",
    "        # 5. Seconde jointure avec la nomenclature\n",
    "        cle_jointure_ape_base = 'activitePrincipaleUniteLegale'\n",
    "        cle_jointure_ape_nomenclature = 'activiteprincipaleunitelegale'\n",
    "\n",
    "        if cle_jointure_ape_base not in base_finale_def_sirenise.columns:\n",
    "            print(f\"ERREUR : Colonne '{cle_jointure_ape_base}' absente de la base après première jointure.\")\n",
    "            return\n",
    "        if cle_jointure_ape_nomenclature not in nomenclature_sitar_df.columns:\n",
    "            print(f\"ERREUR : Colonne '{cle_jointure_ape_nomenclature}' absente de la nomenclature préparée.\")\n",
    "            return\n",
    "\n",
    "        # Harmonisation des clés de jointure APE pour robustesse\n",
    "        base_finale_def_sirenise[cle_jointure_ape_base + '_pour_jointure'] = base_finale_def_sirenise[cle_jointure_ape_base].astype(str).str.strip().str.lower()\n",
    "        nomenclature_sitar_df[cle_jointure_ape_nomenclature + '_pour_jointure'] = nomenclature_sitar_df[cle_jointure_ape_nomenclature].astype(str).str.strip().str.lower()\n",
    "        \n",
    "        print(f\"\\nJonction avec 'nomenclature_sitar' sur la colonne APE (harmonisées)...\")\n",
    "        base_finale_df = pd.merge(\n",
    "            base_finale_def_sirenise,\n",
    "            nomenclature_sitar_df,\n",
    "            left_on=cle_jointure_ape_base + '_pour_jointure',\n",
    "            right_on=cle_jointure_ape_nomenclature + '_pour_jointure',\n",
    "            how='left',\n",
    "            suffixes=('_base', '_nomenclature')\n",
    "        )\n",
    "        \n",
    "        # Optionnel: supprimer les colonnes temporaires de jointure APE\n",
    "        base_finale_df.drop(columns=[cle_jointure_ape_base + '_pour_jointure', cle_jointure_ape_nomenclature + '_pour_jointure'], inplace=True, errors='ignore')\n",
    "        \n",
    "        print(f\"Nombre de lignes après la seconde jonction : {len(base_finale_df)}\")\n",
    "        print(f\"Colonnes finales : {base_finale_df.columns.tolist()}\")\n",
    "\n",
    "        print(\"\\n✓ Processus de sirénisation terminé.\")\n",
    "        print(\"\\nAperçu du DataFrame final (base_finale_df) :\")\n",
    "        print(base_finale_df.head())\n",
    "        base_finale_df.to_csv(\"C://Users//msamb//Documents//base_finale_sirenise.csv\", sep=';', encoding='utf-8-sig', index=False)\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"ERREUR CRITIQUE : Un ou plusieurs fichiers d'entrée sont introuvables. Vérifiez les chemins dans la 'Configuration'.\")\n",
    "    except KeyError as e:\n",
    "        print(f\"ERREUR DE COLONNE (KeyError) : {e}. Vérifiez les noms de colonnes dans vos fichiers et la configuration.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Une erreur inattendue est survenue : {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# --- Point d'Entrée du Script ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Ce code est exécuté lorsque vous lancez le script directement.\n",
    "    \n",
    "    # Exécuter le processus principal de sirénisation.\n",
    "    # Assurez-vous d'avoir bien configuré les chemins et noms de colonnes\n",
    "    # dans la section 'Configuration' de la fonction 'processus_principal_sirenisation'.\n",
    "    processus_principal_sirenisation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ced8d2d6",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de SIREN déclarants en doublon : 79\n",
      "Exemples de doublons :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SIREN_DECLARANT</th>\n",
       "      <th>SIREN_DEPOSANT</th>\n",
       "      <th>DESIGNATION</th>\n",
       "      <th>L1_DOTATION_AMORT_IMMO</th>\n",
       "      <th>L2_DOTATION_AMORT_SINISTR</th>\n",
       "      <th>L3_DEPENSES_PERSONNEL_CHERCHEURS</th>\n",
       "      <th>L4_REMUNERATION_INVENTEURS</th>\n",
       "      <th>L5_DEPENSES_JEUNES_DOCTEURS</th>\n",
       "      <th>L6_AUTRES_DEP_FONCT_DECLARE</th>\n",
       "      <th>L6_AUTRES_DEP_FONCT_CALCULE</th>\n",
       "      <th>...</th>\n",
       "      <th>denominationUsuelle1UniteLegale</th>\n",
       "      <th>denominationUsuelle2UniteLegale</th>\n",
       "      <th>denominationUsuelle3UniteLegale</th>\n",
       "      <th>activitePrincipaleUniteLegale</th>\n",
       "      <th>nicSiegeUniteLegale</th>\n",
       "      <th>nic</th>\n",
       "      <th>siret</th>\n",
       "      <th>activiteprincipaleunitelegale</th>\n",
       "      <th>secteur_dactivit</th>\n",
       "      <th>libell_code_ape_entreprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>324284611</td>\n",
       "      <td>324284611</td>\n",
       "      <td>SAS</td>\n",
       "      <td>1147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>88491</td>\n",
       "      <td>0</td>\n",
       "      <td>38911</td>\n",
       "      <td>38911.38</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.01Z</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3.242846e+13</td>\n",
       "      <td>62.01Z</td>\n",
       "      <td>CONSEIL ET ASSISTANCE EN INFORMATIQUE</td>\n",
       "      <td>Programmation informatique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25116</th>\n",
       "      <td>324284611</td>\n",
       "      <td>892447798</td>\n",
       "      <td>VIDEOR</td>\n",
       "      <td>1147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>88491</td>\n",
       "      <td>0</td>\n",
       "      <td>38911</td>\n",
       "      <td>38911.38</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.01Z</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3.242846e+13</td>\n",
       "      <td>62.01Z</td>\n",
       "      <td>CONSEIL ET ASSISTANCE EN INFORMATIQUE</td>\n",
       "      <td>Programmation informatique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>334380409</td>\n",
       "      <td>334380409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.29C</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.343804e+13</td>\n",
       "      <td>58.29C</td>\n",
       "      <td>CONSEIL ET ASSISTANCE EN INFORMATIQUE</td>\n",
       "      <td>Edition de logiciels applicatifs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>334380409</td>\n",
       "      <td>334380409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.29C</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.343804e+13</td>\n",
       "      <td>58.29C</td>\n",
       "      <td>CONSEIL ET ASSISTANCE EN INFORMATIQUE</td>\n",
       "      <td>Edition de logiciels applicatifs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>334380409</td>\n",
       "      <td>334380409</td>\n",
       "      <td>SASU</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.29C</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.343804e+13</td>\n",
       "      <td>58.29C</td>\n",
       "      <td>CONSEIL ET ASSISTANCE EN INFORMATIQUE</td>\n",
       "      <td>Edition de logiciels applicatifs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>342174018</td>\n",
       "      <td>334381746</td>\n",
       "      <td>GEOFIT</td>\n",
       "      <td>42781</td>\n",
       "      <td>0</td>\n",
       "      <td>197507</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117013</td>\n",
       "      <td>117013.76</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.12A</td>\n",
       "      <td>354.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>3.421740e+13</td>\n",
       "      <td>71.12A</td>\n",
       "      <td>SERVICES D'ARCHITECTURE ET D'INGIENERIE</td>\n",
       "      <td>Activité des géomètres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>342174018</td>\n",
       "      <td>380853507</td>\n",
       "      <td>GEOFIT GROUP</td>\n",
       "      <td>38988</td>\n",
       "      <td>0</td>\n",
       "      <td>779507</td>\n",
       "      <td>0</td>\n",
       "      <td>26707</td>\n",
       "      <td>391136</td>\n",
       "      <td>391136.01</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.12A</td>\n",
       "      <td>354.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>3.421740e+13</td>\n",
       "      <td>71.12A</td>\n",
       "      <td>SERVICES D'ARCHITECTURE ET D'INGIENERIE</td>\n",
       "      <td>Activité des géomètres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3595</th>\n",
       "      <td>387558315</td>\n",
       "      <td>300349636</td>\n",
       "      <td>KRAMPOUZ</td>\n",
       "      <td>19878</td>\n",
       "      <td>0</td>\n",
       "      <td>135791</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73299</td>\n",
       "      <td>73298.63</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.51Z</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3.875583e+13</td>\n",
       "      <td>27.51Z</td>\n",
       "      <td>INDUSTRIE DES EQUIPEMENTS DU FOYER</td>\n",
       "      <td>Fabrication d'appareils électroménagers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3596</th>\n",
       "      <td>387558315</td>\n",
       "      <td>387558315</td>\n",
       "      <td>SAS</td>\n",
       "      <td>6912</td>\n",
       "      <td>0</td>\n",
       "      <td>76005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37866</td>\n",
       "      <td>37866.15</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.51Z</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3.875583e+13</td>\n",
       "      <td>27.51Z</td>\n",
       "      <td>INDUSTRIE DES EQUIPEMENTS DU FOYER</td>\n",
       "      <td>Fabrication d'appareils électroménagers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4115</th>\n",
       "      <td>393819636</td>\n",
       "      <td>899429377</td>\n",
       "      <td>NOMOTECH NS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43524</td>\n",
       "      <td>43524.17</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.90Z</td>\n",
       "      <td>217.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>3.938196e+13</td>\n",
       "      <td>61.90Z</td>\n",
       "      <td>SERVICES DE TELECOMMUNICATIONS</td>\n",
       "      <td>Autres activités de télécommunication</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 212 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SIREN_DECLARANT  SIREN_DEPOSANT   DESIGNATION  L1_DOTATION_AMORT_IMMO  \\\n",
       "1084         324284611       324284611           SAS                    1147   \n",
       "25116        324284611       892447798        VIDEOR                    1147   \n",
       "1699         334380409       334380409           NaN                       0   \n",
       "1700         334380409       334380409           NaN                       0   \n",
       "1698         334380409       334380409          SASU                       0   \n",
       "2098         342174018       334381746        GEOFIT                   42781   \n",
       "2099         342174018       380853507  GEOFIT GROUP                   38988   \n",
       "3595         387558315       300349636      KRAMPOUZ                   19878   \n",
       "3596         387558315       387558315           SAS                    6912   \n",
       "4115         393819636       899429377   NOMOTECH NS                       0   \n",
       "\n",
       "       L2_DOTATION_AMORT_SINISTR  L3_DEPENSES_PERSONNEL_CHERCHEURS  \\\n",
       "1084                           0                                 0   \n",
       "25116                          0                                 0   \n",
       "1699                           0                                 0   \n",
       "1700                           0                                 0   \n",
       "1698                           0                                 0   \n",
       "2098                           0                            197507   \n",
       "2099                           0                            779507   \n",
       "3595                           0                            135791   \n",
       "3596                           0                             76005   \n",
       "4115                           0                            101219   \n",
       "\n",
       "       L4_REMUNERATION_INVENTEURS  L5_DEPENSES_JEUNES_DOCTEURS  \\\n",
       "1084                        88491                            0   \n",
       "25116                       88491                            0   \n",
       "1699                            0                            0   \n",
       "1700                            0                            0   \n",
       "1698                            0                            0   \n",
       "2098                            0                            0   \n",
       "2099                            0                        26707   \n",
       "3595                            0                            0   \n",
       "3596                            0                            0   \n",
       "4115                            0                            0   \n",
       "\n",
       "       L6_AUTRES_DEP_FONCT_DECLARE  L6_AUTRES_DEP_FONCT_CALCULE  ...  \\\n",
       "1084                         38911                     38911.38  ...   \n",
       "25116                        38911                     38911.38  ...   \n",
       "1699                             0                         0.00  ...   \n",
       "1700                             0                         0.00  ...   \n",
       "1698                             0                         0.00  ...   \n",
       "2098                        117013                    117013.76  ...   \n",
       "2099                        391136                    391136.01  ...   \n",
       "3595                         73299                     73298.63  ...   \n",
       "3596                         37866                     37866.15  ...   \n",
       "4115                         43524                     43524.17  ...   \n",
       "\n",
       "       denominationUsuelle1UniteLegale  denominationUsuelle2UniteLegale  \\\n",
       "1084                               NaN                              NaN   \n",
       "25116                              NaN                              NaN   \n",
       "1699                               NaN                              NaN   \n",
       "1700                               NaN                              NaN   \n",
       "1698                               NaN                              NaN   \n",
       "2098                               NaN                              NaN   \n",
       "2099                               NaN                              NaN   \n",
       "3595                               NaN                              NaN   \n",
       "3596                               NaN                              NaN   \n",
       "4115                               NaN                              NaN   \n",
       "\n",
       "       denominationUsuelle3UniteLegale  activitePrincipaleUniteLegale  \\\n",
       "1084                               NaN                         62.01Z   \n",
       "25116                              NaN                         62.01Z   \n",
       "1699                               NaN                         58.29C   \n",
       "1700                               NaN                         58.29C   \n",
       "1698                               NaN                         58.29C   \n",
       "2098                               NaN                         71.12A   \n",
       "2099                               NaN                         71.12A   \n",
       "3595                               NaN                         27.51Z   \n",
       "3596                               NaN                         27.51Z   \n",
       "4115                               NaN                         61.90Z   \n",
       "\n",
       "       nicSiegeUniteLegale    nic         siret  \\\n",
       "1084                  70.0   70.0  3.242846e+13   \n",
       "25116                 70.0   70.0  3.242846e+13   \n",
       "1699                  30.0   30.0  3.343804e+13   \n",
       "1700                  30.0   30.0  3.343804e+13   \n",
       "1698                  30.0   30.0  3.343804e+13   \n",
       "2098                 354.0  354.0  3.421740e+13   \n",
       "2099                 354.0  354.0  3.421740e+13   \n",
       "3595                  33.0   33.0  3.875583e+13   \n",
       "3596                  33.0   33.0  3.875583e+13   \n",
       "4115                 217.0  217.0  3.938196e+13   \n",
       "\n",
       "       activiteprincipaleunitelegale                         secteur_dactivit  \\\n",
       "1084                          62.01Z    CONSEIL ET ASSISTANCE EN INFORMATIQUE   \n",
       "25116                         62.01Z    CONSEIL ET ASSISTANCE EN INFORMATIQUE   \n",
       "1699                          58.29C    CONSEIL ET ASSISTANCE EN INFORMATIQUE   \n",
       "1700                          58.29C    CONSEIL ET ASSISTANCE EN INFORMATIQUE   \n",
       "1698                          58.29C    CONSEIL ET ASSISTANCE EN INFORMATIQUE   \n",
       "2098                          71.12A  SERVICES D'ARCHITECTURE ET D'INGIENERIE   \n",
       "2099                          71.12A  SERVICES D'ARCHITECTURE ET D'INGIENERIE   \n",
       "3595                          27.51Z       INDUSTRIE DES EQUIPEMENTS DU FOYER   \n",
       "3596                          27.51Z       INDUSTRIE DES EQUIPEMENTS DU FOYER   \n",
       "4115                          61.90Z           SERVICES DE TELECOMMUNICATIONS   \n",
       "\n",
       "                    libell_code_ape_entreprise  \n",
       "1084                Programmation informatique  \n",
       "25116               Programmation informatique  \n",
       "1699          Edition de logiciels applicatifs  \n",
       "1700          Edition de logiciels applicatifs  \n",
       "1698          Edition de logiciels applicatifs  \n",
       "2098                    Activité des géomètres  \n",
       "2099                    Activité des géomètres  \n",
       "3595   Fabrication d'appareils électroménagers  \n",
       "3596   Fabrication d'appareils électroménagers  \n",
       "4115     Autres activités de télécommunication  \n",
       "\n",
       "[10 rows x 212 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger la base finale sirénisée\n",
    "base_finale = pd.read_excel('C://Users//msamb//Documents//base_finale_sirenise.xlsx')\n",
    "\n",
    "# Chercher les SIREN déclarants en doublon\n",
    "doublons_declarant = base_finale[base_finale.duplicated(subset=['SIREN_DECLARANT'], keep=False)]\n",
    "\n",
    "print(f\"Nombre de SIREN déclarants en doublon : {doublons_declarant['SIREN_DECLARANT'].nunique()}\")\n",
    "print(\"Exemples de doublons :\")\n",
    "display(doublons_declarant.sort_values('SIREN_DECLARANT').head(10))\n",
    "doublons_declarant.to_csv(\"C://Users//msamb//Documents//doublons_siren_declarant.csv\", sep=';', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7530d2f",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes original : 28309\n",
      "Nombre de lignes après suppression des doublons : 28299\n",
      "Nombre de doublons supprimés : 10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lire le fichier Excel\n",
    "df = pd.read_csv(\"C://Users//msamb//Documents//base_finale_sirenise.csv\", sep=';', encoding='utf-8-sig', low_memory=False)\n",
    "\n",
    "# Définir les colonnes clés pour identifier les doublons\n",
    "colonnes_clés = ['SIREN_DECLARANT', 'cretot_gen','mere_final']\n",
    "\n",
    "# Supprimer les doublons en gardant la première occurrence\n",
    "df_sans_doublons = df.drop_duplicates(subset=colonnes_clés, keep='first')\n",
    "\n",
    "# Ou si vous voulez garder la dernière occurrence :\n",
    "# df_sans_doublons = df.drop_duplicates(subset=colonnes_clés, keep='last')\n",
    "\n",
    "# Sauvegarder le résultat dans un nouveau fichier\n",
    "df_sans_doublons.to_excel('C://Users//msamb//Documents//base_finale_sirenise.xlsx', index=False)\n",
    "\n",
    "# Afficher quelques statistiques\n",
    "print(f\"Nombre de lignes original : {len(df)}\")\n",
    "print(f\"Nombre de lignes après suppression des doublons : {len(df_sans_doublons)}\")\n",
    "print(f\"Nombre de doublons supprimés : {len(df) - len(df_sans_doublons)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "58565219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msamb\\AppData\\Local\\Temp\\ipykernel_14148\\3955505606.py:9: DtypeWarning: Columns (204) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_path, sep=\";\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statique : ['SIREN_DECLARANT', 'SIREN_DEPOSANT', 'DESIGNATION']\n",
      "Génériques : ['crerd_gen', 'crerd_genom', 'crecoll_gen', 'crecoll_genom', 'creinno_gen', 'creinno_genom', 'cretot_gen', 'cretot_genom', 'cirrech_benef', 'cic_benef', 'cii_benef', 'cirtot_benef']\n",
      "Calculées : ['L6_AUTRES_DEP_FONCT_CALCULE', 'L7_TOTAL_DEP_FONCT_CALCULE', 'L14_TOTAL_DEPENSES_INTERNES_CALCULE', 'L17_TOTAL_DEP_EXTERNALISEES_CALCULE', 'L18_PLAFOND_GLOBAL_CALCULE', 'L19_PLAFOND_ORG_LIES_CALCULE', 'L20_PLAFOND_ORG_NON_LIES_CALCULE', 'L21_TOTAL_DEP_EXT_PLAFONNEES_CALCULE', 'L22_TOTAL_DEPENSES_RECHERCHE_CALCULE', 'L26A_MONTANT_NET_DEPENSES_CALCULE', 'L26B_MONTANT_NET_DEPENSES_DOM_CALCULE', 'L29_TOTAL_DEPENSES_COLLECTION_CALCULE', 'L33A_MONTANT_NET_COLLECTION_CALCULE', 'L33B_MONTANT_NET_COLLECTION_DOM_CALCULE', 'L70_TOTAL_DEPENSES_INNOVATION_CALCULE', 'L71_DEPENSES_INNOVATION_PLAFONNEES_CALCULE', 'L76A_MONTANT_NET_INNOVATION_CALCULE', 'L83_DEPENSES_RC_PLAFONNEES_CALCULE', 'L86_MONTANT_NET_RC_CALCULE', 'cretot_gen_calcule']\n",
      "Transformé écrit dans : C://Users//msamb//Documents//base_finale_sirenise_transforme.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 1) Chemins\n",
    "input_path  = \"C://Users//msamb//Documents//base_finale_sirenise.csv\"\n",
    "output_path = \"C://Users//msamb//Documents//base_finale_sirenise_transforme.csv\"\n",
    "\n",
    "# 2) Chargement du CSV\n",
    "df = pd.read_csv(input_path, sep=\";\")\n",
    "\n",
    "# 3) Mapping des colonnes “statiques” à conserver et renommer\n",
    "static_map = {\n",
    "    \"SIREN_DECLARANT\": \"siren\",\n",
    "    \"SIREN_DEPOSANT\":  \"siren_g\",\n",
    "    \"DESIGNATION\":     \"nom\",\n",
    "}\n",
    "\n",
    "# 4) Ordre voulu des colonnes “génériques” (déjà recalculées)\n",
    "generic_order = [\n",
    "    \"crerd_gen\",\"crerd_genom\",\n",
    "    \"crecoll_gen\",\"crecoll_genom\",\n",
    "    \"creinno_gen\",\"creinno_genom\",\n",
    "    \"cretot_gen\",\"cretot_genom\",\n",
    "    \"cirrech_benef\",\"cic_benef\",\n",
    "    \"cii_benef\",\"cirtot_benef\",\n",
    "]\n",
    "\n",
    "# 5) Détection des colonnes à garder\n",
    "# — statiques réellement présentes\n",
    "statics = [c for c in static_map if c in df.columns]\n",
    "\n",
    "# — génériques dans l’ordre souhaité, mais uniquement celles qui existent\n",
    "generics = [c for c in generic_order if c in df.columns]\n",
    "\n",
    "# — toutes les colonnes recalculées (suffixe _CALCULE)\n",
    "calcules = [c for c in df.columns if c.upper().endswith(\"_CALCULE\")]\n",
    "\n",
    "# (Optionnel) affichage pour debug\n",
    "print(\"Statique :\", statics)\n",
    "print(\"Génériques :\", generics)\n",
    "print(\"Calculées :\", calcules)\n",
    "\n",
    "# 6) Sélection de la sous-partie du DataFrame\n",
    "df2 = df[statics + generics + calcules].copy()\n",
    "\n",
    "# 7) Construction du mapping de renommage complet\n",
    "rename_map = {}\n",
    "\n",
    "# — statiques\n",
    "for c in statics:\n",
    "    rename_map[c] = static_map[c]\n",
    "\n",
    "# — génériques → minuscules\n",
    "for c in generics:\n",
    "    rename_map[c] = c.lower()\n",
    "\n",
    "# — dynamiques L*…_CALCULE → _<num><a/b?>\n",
    "# — autres *_CALCULE hors L* → nom minuscules sans \"_calcule\"\n",
    "for c in calcules:\n",
    "    m = re.match(r\"^L(\\d+)([AB])?_.*_CALCULE$\", c, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        num    = m.group(1)\n",
    "        letter = m.group(2).lower() if m.group(2) else \"\"\n",
    "        rename_map[c] = f\"_{num}{letter}\"\n",
    "    else:\n",
    "        rename_map[c] = c.lower().replace(\"_calcule\", \"\")\n",
    "\n",
    "df2 = df2.rename(columns=rename_map)\n",
    "\n",
    "# 8) Réordonnancement final des colonnes\n",
    "# — statiques renommées\n",
    "final_statics = [static_map[c] for c in statics]\n",
    "\n",
    "# — génériques renommés\n",
    "final_generics = [c.lower() for c in generics]\n",
    "\n",
    "# — dynamiques L* triées par numéro et lettre\n",
    "dyn_tuples = []\n",
    "for c in calcules:\n",
    "    if re.match(r\"^L\\d+([AB])?_.*_CALCULE$\", c, flags=re.IGNORECASE):\n",
    "        m = re.match(r\"^L(\\d+)([AB])?_.*_CALCULE$\", c, flags=re.IGNORECASE)\n",
    "        num    = int(m.group(1))\n",
    "        letter = m.group(2).lower() if m.group(2) else \"\"\n",
    "        dyn_tuples.append((num, letter, rename_map[c]))\n",
    "\n",
    "final_dyn = [name for _, _, name in sorted(dyn_tuples, key=lambda x: (x[0], x[1]))]\n",
    "\n",
    "# — autres *_CALCULE hors L* placées après\n",
    "other_calcules = [\n",
    "    rename_map[c] for c in calcules\n",
    "    if not re.match(r\"^L\\d+([AB])?_.*_CALCULE$\", c, flags=re.IGNORECASE)\n",
    "]\n",
    "\n",
    "# — ordre complet\n",
    "final_columns = final_statics + final_generics + final_dyn + other_calcules\n",
    "df2 = df2[final_columns]\n",
    "\n",
    "# 9) Export vers CSV\n",
    "df2.to_csv(output_path, index=False, sep=\";\")\n",
    "print(f\"Transformé écrit dans : {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
